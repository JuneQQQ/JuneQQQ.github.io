[{"id":"0078db1e0e91966be57f6a3288ece9dc","title":"浅析HTTP发展历程","content":"浅析HTTP发展历程HTTP0.9 - 诞生最初版本的 HTTP 协议并没有版本号，后来它的版本号被定位在 0.9 以区分后来的版本。 HTTP&#x2F;0.9 极其简单：请求由单行指令构成，以唯一可用方法GET开头，其后跟目标资源的路径（一旦连接到服务器，协议、服务器、端口号这些都不是必须的）。\nGET /mypage.html\n\n响应也极其简单的：只包含响应文档本身。\n&lt;HTML&gt;\n这是一个非常简单的 HTML 页面\n&lt;&#x2F;HTML&gt;\n\n跟后来的版本不同，HTTP&#x2F;0.9 的响应内容并不包含 HTTP 头，这意味着只有 HTML 文件可以传送，无法传输其他类型的文件；也没有状态码或错误代码：一旦出现问题，一个特殊的包含问题描述信息的 HTML 文件将被发回，供人们查看。\nHTTP1.0 - 构建可扩展性一个典型的请求看起来就像这样：\nGET /mypage.html HTTP/1.0\nUser-Agent: NCSA_Mosaic/2.0 (Windows 3.1)\n\n200 OK\nDate: Tue, 15 Nov 1994 08:12:31 GMT\nServer: CERN/3.0 libwww/2.17\nContent-Type: text/html\n&lt;HTML>\n一个包含图片的页面\n  &lt;IMG SRC=\"/myimage.gif\">\n&lt;/HTML>\n\n接下来是第二个连接，请求获取图片：\nGET /myimage.gif HTTP/1.0\nUser-Agent: NCSA_Mosaic/2.0 (Windows 3.1)\n\n200 OK\nDate: Tue, 15 Nov 1994 08:12:32 GMT\nServer: CERN/3.0 libwww/2.17\nContent-Type: text/gif\n(这里是图片内容)\n\nHTTP1.1 - 标准化的协议\n持久连接：HTTP&#x2F;1.1 最大的变化就是引入了持久连接（persistent connection），在HTTP&#x2F;1.1中默认开启 Connection: keep-alive，即TCP连接默认不关闭，可以被多个请求复用，但是这里存在队头阻塞问题\n缓存处理：HTTP&#x2F;1.0 使用 Pragma:no-cache + Last-Modified&#x2F;If-Modified-Since来作为缓存判断的标准；HTTP&#x2F;1.1 引入了更多的缓存控制策略：Cache-Control、Etag&#x2F;If-None-Match等\n范围请求：HTTP&#x2F;1.1在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接，支持断点续传\n错误状态管理：HTTP&#x2F;1.1新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。\n\n\n\n\n\n\n\n\n\n\nHTTP&#x2F;1.1 的持久连接和管道机制允许复用TCP连接，在一个TCP连接中，也可以同时发送多个请求，但是所有的数据通信都是按次序完成的，服务器只有处理完一个回应，才会处理下一个回应。比如客户端需要A、B两个资源，管道机制允许浏览器同时发出A请求和B请求，但服务器还是按照顺序，先回应A请求，完成后再回应B请求，这样如果前面的回应特别慢，后面就会有很多请求排队等着，这称为”队头阻塞(Head-of-line blocking)”。这个问题到HTTP3才被完全解决。\nHTTP2.0 - 为了更优异的表现这些年来，网页愈渐变得的复杂，甚至演变成了独有的应用，可见媒体的播放量，增进交互的脚本大小也增加了许多：更多的数据通过 HTTP 请求被传输。HTTP&#x2F;1.1 链接需要请求以正确的顺序发送，理论上可以用一些并行的链接（尤其是 5 到 8 个），带来的成本和复杂性堪忧。比如，HTTP 管线化（pipelining）就成为了 Web 开发的负担。\n在 2010 年到 2015 年，谷歌通过实践了一个实验性的 SPDY 协议，证明了一个在客户端和服务器端交换数据的另类方式。其收集了浏览器和服务器端的开发者的焦点问题。明确了响应数量的增加和解决复杂的数据传输，SPDY 成为了 HTTP&#x2F;2 协议的基础。HTTP2的主要特点如下：\n\n二进制分帧：HTTP&#x2F;1.1的头信息是文本（ASCII编码），数据体可以是文本，也可以是二进制；HTTP&#x2F;2 头信息和数据体都是二进制，统称为“帧”：头信息帧和数据帧；\n\n\n\n\n多路复用：在http1.1中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源 CDN 域名的原因之一。\n而http2.0中的多路复用优化了这一性能。多路复用允许同时通过单一的http&#x2F;2 连接发起多重的请求-响应消息。有了新的分帧机制后，http&#x2F;2 不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级，最后再在另一端把它们重新组合起来。\nhttp 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接（每个域名一个连接）即可。http2连接可以承载数十或数百个流的复用，多路复用意味着来自很多流的数据包能够混合在一起通过同样连接传输。当到达终点时，再根据不同帧首部的流标识符重新连接将不同的数据流进行组装。\n\n\n头部压缩：HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。HTTP&#x2F;2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息压缩后再发送（SPDY 使用的是通用的DEFLATE 算法，而 HTTP&#x2F;2 则使用了专门为首部压缩而设计的 HPACK 算法）。；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n\n\n​\t例如：下图中的两个请求， 请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销。\n\n\n服务端推送：HTTP&#x2F;2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。\n\n穿插一下HTTPSHTTPS可以说是安全版的HTTP，HTTPS基于安全SSL&#x2F;TLS（安全套接层Secure Sockets Layer&#x2F;安全传输层Transport Layer Security）层，即在传统的HTTP和TCP之间加了一层用于加密解密的SSL&#x2F;TLS层。HTTP默认使用80端口，HTTPS默认使用443端口。\n\n不使用SSL&#x2F;TLS的HTTP通信，所有信息明文传播，会带来三大风险；\n\n窃听风险：第三方可以获取通信内容；篡改风险：第三方可以修改通信内容；冒充风险：第三方可以冒充他人进行通信。SSL&#x2F;TLS协议是为了解决这三大风险而设计的，以期达到；\n\n信息加密传输：第三方无法窃听；校验机制：一旦被篡改，通信双方会立刻发现；身份证书：防止身份被冒充。\n\n\nHTTPS通信过程\n\nTCP的3次握手\nTLS连接\nHTTP请求和响应\n\n共计3RTT，速度略慢，所以HTTP3将对此进行优化\n以下三幅图不同程度描述了HTTPS通信过程：\n\n\n这里是TLS1.2，请注意\n\n\n\n\n\n\nHTTP3.0 - 为什么更快的速度Quick是什么？\n\n\n\n\n\n\n\n\n​\tQUIC（Quick UDP Internet Connection）是谷歌制定的一种基于UDP的低时延的互联网传输层协议。我们知道，TCP&#x2F;IP协议族是互联网的基础。其中传输层协议包括TCP和UDP协议。与TCP协议相比，UDP更为轻量，但是错误校验也要少得多。这意味着UDP往往效率更高（不经常跟服务器端通信查看数据包是否送达或者按序），但是可靠性比不上TCP。通常游戏、流媒体以及VoIP等应用均采用UDP，而网页、邮件、远程登录等大部分的应用均采用TCP。\n​\t\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t————————摘自百度百科\n\n\n从协议栈可以看出：QUIC &#x3D; HTTP&#x2F;2 + TLS + UDP\n数据包格式\n\n\n\n由 header 和 data 两部分组成。\nheader 是明文的，包含 4 个字段：Flags、Connection ID、QUIC Version、Packet Number；\ndata 是加密的，可以包含 1 个或多个 frame，每个 frame 又分为 type 和 payload，其中 payload 就是应用数据；\n数据帧有很多类型：Stream、ACK、Padding、Window_Update、Blocked 等，这里重点介绍下用于传输应用数据的 Stream 帧。\n\nFrame Type： 帧类型，占用 1 个字节\n\n（1）Bit7：必须设置为 1，表示 Stream 帧\n（2）Bit6：如果设置为 1，表示发送端在这个 stream 上已经结束发送数据，流将处于半关闭状态\n（3）Bit5：如果设置为 1，表示 Stream 头中包含 Data length 字段\n（4）Bit432：表示 offset 的长度。000 表示 0 字节，001 表示 2 字节，010 表示 3 字节，以此类推\n（5）Bit10：表示 Stream ID 的长度。00 表示 1 字节，01 表示 2 字节，10 表示 3 字节，11 表示 4 字节\nStream ID： 流 ID，用于标识数据包所属的流。后面的流量控制和多路复用会涉及到\nOffset：偏移量，表示该数据包在整个数据中的偏移量，用于数据排序。\nData Length： 数据长度，占用 2 个字节，表示实际应用数据的长度\nData： 实际的应用数据\n建立连接先分析下 HTTPS 的握手过程，包含 TCP 握手和 TLS 握手，TCP 握手：\n\n\n从图中可以看出，TCP 握手需要 2 个 RTT。\nTLS 握手：密钥协商（1.3 版本）\n\n\n\n\n从图中可以看出，TLS 握手需要 1 个 RTT，也就是 1 次 RTT 就把通信密钥协商好了，这是怎么做到的？\n（1）客户端：生成随机数 a，选择公开的大数 G 和 P，计算 A&#x3D;a*G%P，将 A 和 G 发送给服务器，也就是 Client Hello 消息\n（2）服务器：生成随机数 b，计算 B&#x3D;b*G%P，将 B 发送给客户端，也就是 Server Hello 消息\n（3）客户端：使用 ECDH 算法生成通信密钥 KEY &#x3D; aB &#x3D; ab*G%P\n（4）服务器：使用 ECDH 算法生成通信密钥 KEY &#x3D; bA &#x3D; ba*G%P\n所以，这里的关键就是 ECDH 算法，a 和 b 是客户端和服务器的私钥，是不公开的，而其他参数是公开的。ECDH 算法有个非常重要的特征：即使知道 A、G、P，通过 A &#x3D; a*G%P 公式也是无法推到出 a 的，保证了私钥的安全性。\n综上所述，HTTPS 建立连接需要 3 个 RTT，由于 QUIC 的握手是基于 TLS1.3 实现的，所以首次建立连接时也是需要 1 次 RTT，那 QUIC 是如何做到 0-RTT 握手的呢？\n如何做到0RTT握手？其实原理很简单：客户端缓存了 ServerConfig（B&#x3D;b*G%P），下次建连直接使用缓存数据计算通信密钥：\n\n\n（1）客户端：生成随机数 c，选择公开的大数 G 和 P，计算 A&#x3D;c*G%P，将 A 和 G 发送给服务器，也就是 Client Hello 消息\n（2）客户端：客户端直接使用缓存的 ServerConfig 计算通信密钥 KEY &#x3D; cB &#x3D; cb*G%P，加密发送应用数据\n（3）服务器：根据 Client Hello 消息计算通信密钥 KEY &#x3D; bA &#x3D; bc*G%P\n也就是说，客户端不需要经过握手就可以发送应用数据，这就是 0-RTT 握手。再来思考一个问题：假设攻击者记录下所有的通信数据和公开参数（A1&#x3D;aG%P，A2&#x3D;cG%P，……），一旦服务器的随机数 b（私钥）泄漏了，那之前通信的所有数据就都可以破解了。\n为了解决这个问题，需要为每次会话都创建一个新的通信密钥，来保证前向安全性\n可靠传输QUIC 是基于 UDP 协议的，而 UDP 是不可靠传输协议，那 QUIC 是如何实现可靠传输的呢？\n可靠传输有 2 个重要特点：\n（1）完整性：发送端发出的数据包，接收端都能收到\n（2）有序性：接收端能按序组装数据包，解码得到有效的数据\n问题 1：发送端怎么知道发出的包是否被接收端收到了？\n解决方案：通过包号（PKN）和确认应答（SACK）\n\n\n（1）客户端：发送 3 个数据包给服务器（PKN &#x3D; 1，2，3）\n（2）服务器：通过 SACK 告知客户端已经收到了 1 和 3，没有收到 2\n（3）客户端：重传第 2 个数据包（PKN&#x3D;4）\n由此可以看出，QUIC 的数据包号是单调递增的。也就是说，之前发送的数据包（PKN&#x3D;2）和重传的数据包（PKN&#x3D;4），虽然数据一样，但包号不同。\n问题 2：既然包号是单调递增的，那接收端怎么保证数据的有序性呢？\n解决方案：通过数据偏移量 offset\n每个数据包都有一个 offset 字段，表示在整个数据中的偏移量。\n\n\n接收端根据 offset 字段就可以对异步到达的数据包进行排序了。为什么 QUIC 要将 PKN 设计为单调递增？解决 TCP 的重传歧义问题：\n由于原始包和重传包的序列号是一样的，客户端不知道服务器返回的 ACK 包到底是原始包的，还是重传包的。但 QUIC 的原始包和重传包的序列号是不同的，也就可以判断 ACK 包的归属。\n流量控制和 TCP 一样，QUIC 也是利用滑动窗口机制实现流量控制：\n\n\n发送端的窗口大小由接收端告知，包括发送窗口和可用窗口，如果发送端收到了接收端的 ACK 确认应答（比如 ACK 36），那整个窗口就会向右滑动，发送新的数据包。\n\n\n和 TCP 不同的是，QUIC 的滑动窗口分为 Connection 和 Stream 两种级别。Connection 流量控制：规定了所有数据流的总窗口大小；Stream 流量控制：规定了每个流的窗口大小。\n假设现在有 3 个 Stream，滑动窗口分别如下：\n\n\n则整个 Connection 的可用窗口大小为：20+30+10 &#x3D; 60\n拥塞控制拥塞控制是通过拥塞窗口限制发送方的数据量，避免整个网络发生拥塞。那拥塞窗口（cwnd）和滑动窗口（发送窗口：swnd，接收窗口：rwnd）有什么关系呢？\nswnd &#x3D; min（cwnd，rwnd）\n也就是说，发送窗口的大小是由接收窗口和拥塞窗口共同决定的。那拥塞窗口的大小是如何计算的？通过 4 个拥塞控制算法：慢启动、拥塞避免、拥塞发生、快速恢复\n1.慢启动初始拥塞窗口大小 cwnd&#x3D;1，也就是可以传输 1 个 MDS（Max Datagram Size）大小的数据包，一般网卡允许传输的最大数据单元 MTU 的大小是 1500 字节。对于 UDP 数据报而言：MDS &#x3D; 1500（MTU）- 20（IP 首部）- 8（UDP 首部） &#x3D; 1472 字节\n慢启动算法： 当发送方每收到一个 ACK，拥塞窗口就加 1（cwnd++）\n\n\n由此可以看出，慢启动阶段，拥塞窗口呈指数增长，那增长到多少是个头？\n有一个上限值：ssthresh（slow start threshold），从源码看，这个值是 2000 * MDS\nconst QuicPacketCount kDefaultMaxCongestionWindowPackets &#x3D; 2000;\n\n\n当 cwnd &lt; ssthresh 时，使用慢启动算法\n当 cwnd &gt;&#x3D; ssthresh 时，使用拥塞避免算法\n\n2.拥塞避免当拥塞窗口大小超过慢启动上限后，就会进入拥塞避免阶段。\n拥塞避免算法： 当发送方每收到一个 ACK，拥塞窗口就加 1&#x2F;cwnd\n\n\n假设现在的 cwnd&#x3D;8，可以发送 8 个数据包，当收到这 8 个包的 ACK 时，拥塞窗口才会加 1，由此可知，在拥塞避免阶段，拥塞窗口是线性增长的。\n那啥时候是个头呢？不管，让它继续增长，直到网络发生拥塞，出现丢包，这时就会触发重传机制，进入拥塞发生阶段\n3.拥塞发生重传有 2 种：超时重传和快速重传\n如果发生超时重传，使用的拥塞发生算法为：\n\nssthresh &#x3D; cwnd &#x2F; 2\ncwnd &#x3D; 1\n\n\n\n重新使用慢启动和拥塞避免算法增加拥塞窗口的大小。\n如果发生快速重传（发送方收到 3 个相同的 ACK），使用的拥塞发生算法为：\n\ncwnd &#x3D; cwnd &#x2F; 2\nssthresh &#x3D; cwnd\n\n接下来就会进入快速恢复阶段。\n4.快速恢复快速恢复算法：cwnd &#x3D; ssthresh + 3（因为收到 3 个 ACK），然后进入拥塞避免阶段。\n\n\n5.拥塞控制常见算法\nNew Reno：基于丢包检测\nCUBIC：基于丢包检测\nBBR：基于网络带宽\n\n和 TCP 不同的是，QUIC 是在用户空间实现的拥塞控制，可以非常灵活的设置，甚至可以为每一个请求都设置一种拥塞控制算法。\n解决队头阻塞多路复用是 HTTP&#x2F;2 的主要特性之一，但 HTTP&#x2F;3 的多路复用不完全和2相同。\n概念：单条 TCP 连接上可以同时发送多个 HTTP 请求，解决了 HTTP1.1 中单个连接 1 次只能发送 1 个请求的性能瓶颈。HTTP&#x2F;2 能实现多路复用的根本原因是采用了二进制帧格式的数据结构。\n\n\nLength：表示 Payload 的长度\nType：表示帧类型\nFlags：帧标识\nStream ID：数据帧所属的流\nPayload：应用数据，长度由 Length 字段指定\n\n一个请求就对应一条流，通过 Stream ID 就可以判断该数据帧属于哪个请求，假设有 A 和 B 两个请求，对应的 Stream ID 分别为 1 和 2，那这个 TCP 连接上传输的数据大概如下：\n\n虽然在 HTTP 应用层，可以同时发送多个请求，但是在 TCP 传输层，仍然只有 1 个滑动窗口来发送这些数据包，考虑下面的情形：\n\n\n客户端发送的 5 个数据包（56789）服务器都收到了，并且回应了 5 个 ACK，但是第 5 个数据包的 ACK 丢失了，导致客户端的发送窗口无法向前移动，也就无法发送新的数据，这就是 TCP 层的队头阻塞问题。\nHTTP&#x2F;2 虽然通过多路复用解决了 HTTP 层的队头阻塞，但仍然存在 TCP 层的队头阻塞。那 QUIC 是如何解决 TCP 层的队头阻塞问题的呢？其实很简单，HTTP&#x2F;2 之所以存在 TCP 层的队头阻塞，是因为所有请求流都共享一个滑动窗口，那如果给每个请求流都分配一个独立的滑动窗口，是不是就可以解决这个问题了？\nQUIC 就是这么做的：\n\nA 请求流上的丢包不会影响 B 请求流上的数据发送。但是，对于每个请求流而言，也是存在队头阻塞问题的，也就是说，虽然 QUIC 解决了 TCP 层的队头阻塞，但仍然存在单条流上的队头阻塞。这就是 QUIC 声明的无队头阻塞的多路复用。\n连接迁移连接迁移：当客户端切换网络时，和服务器的连接并不会断开，仍然可以正常通信，对于 TCP 协议而言，这是不可能做到的。因为 TCP 的连接基于 4 元组：源 IP、源端口、目的 IP、目的端口，只要其中 1 个发生变化，就需要重新建立连接。但 QUIC 的连接是基于 64 位的 Connection ID，网络切换并不会影响 Connection ID 的变化，连接在逻辑上仍然是通的。\n\n假设客户端先使用 IP1 发送了 1 和 2 数据包，之后切换网络，IP 变更为 IP2，发送了 3 和 4 数据包，服务器根据数据包头部的 Connection ID 字段可以判断这 4 个包是来自于同一个客户端。QUIC 能实现连接迁移的根本原因是底层使用 UDP 协议就是面向无连接的。\n\n\n\n\n\n\n\n\n\n参考链接\n为什么需要QUIC | HTTP&#x2F;3详解 (hungryturbo.com)\nQUIC 协议详解 - 知乎 (zhihu.com)\nhttp2是如何解决tcp的队首阻塞的？ - 知乎 (zhihu.com)\n一文读懂 HTTP&#x2F;2 特性 - 知乎 (zhihu.com)\n深入解读HTTP3的原理及应用 - 知乎 (zhihu.com)\n详解HTTP&#x2F;1.0、HTTP&#x2F;1.1、HTTP&#x2F;2、HTTPS - 腾讯云开发者社区-腾讯云 (tencent.com)\n深入理解http2.0协议，看这篇就够了！ - 知乎 (zhihu.com)\n\n","slug":"浅析HTTP发展历程1-3","date":"2022-09-27T10:10:10.000Z","categories_index":"","tags_index":"计算机网络","author_index":"JuneQQQ"},{"id":"34c2acd56bc16b503002a852a65f4137","title":"Java 集合","content":"Java 集合Collection 接口 （父接口）\n\n\n\nIterator 迭代器所有实现了Iteratable接口的类都可以通过iterator()方法获取迭代器\n注意：重新获取iterator即可重置迭代器；\n增强 for 循环\n可以对 数组 和 集合 使用；\n底层使用的仍然是 iterator；\n大写 I 可以快速生成代码（Idea）。\n\nList 接口  可重复-有顺序ArrayList\n线程不安全\n\nArrayList 维护了一个 Object 类型的数组 elementData – transient Object[] elementData &#x2F;&#x2F; transient 表示该属性不会被序列化\n\n两种构造方式（构造时数组已经初始化）：\n\n无参构造： ArrayList，则初始化 elementData 容量为0，第一次添加时，则扩容至默认容量10，如需再次扩容，则扩容为当前的1.5倍（1+1&#x2F;2）;Vector（无参情况下） 扩容倍数是2，线程安全是因为每个方法头上添加了 synchronized\n指定initialCapacity大小的构造器：初始 elementData 容量为指定大小，如需扩容，则直接扩容 elementData 为当前的1.5倍\n\n\n每次添加元素时，都会触发一次扩容检查，容量不满足 size+1 就扩容\n\n源码解读如下\n\n\n\n\nVector\n线程安全\n如果无参，默认10，满后，2倍扩容；如果指定大小，满后则每次直接2倍扩容（优先使用自定义增量capacityIncrement）\n有参构造可以指定扩容大小 Vector(int initialCapacity, int capacityIncrement)\n源码解读如下\n\n====================================================\npublic synchronized boolean add(E e) &#123;\n    modCount++;\n    ensureCapacityHelper(elementCount + 1);   // 扩容检查\n    elementData[elementCount++] = e;\n    return true;\n&#125;\n====================================================\nprivate void ensureCapacityHelper(int minCapacity) &#123;\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        grow(minCapacity);    // 真正扩容方法\n&#125;\n====================================================\nprivate void grow(int minCapacity) &#123;\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    //扩容的关键算法\n    int newCapacity = oldCapacity + ((capacityIncrement > 0) ?\n                                     capacityIncrement : oldCapacity);\n    if (newCapacity - minCapacity &lt; 0)    // 扩容后仍不满足最小capacity要求\n        newCapacity = minCapacity;\n    if (newCapacity - MAX_ARRAY_SIZE > 0)    // 超过最大容量\n        newCapacity = hugeCapacity(minCapacity);\n    elementData = Arrays.copyOf(elementData, newCapacity);\n&#125;\n====================================================\n\n\n\nLinkedList\n\n底层维护了一个双向链表\n可以添加任意元素\n其中有两个属性first和last分别指向首节点和尾结点\n每个节点（Node对象），里面又维护了prev，next，item三个属性，其中通过prev指向前一个，通过next指向后一个节点，最终实现双向链表\nLinkedList 增删快，查找慢\n源码解读如下（尾插头删）\n\n-----------------------------\npublic boolean add(E e) &#123;\n        linkLast(e);\n        return true;\n    &#125;\n-----------------------------\nvoid linkLast(E e) &#123;\n        final Node&lt;E> l = last;  // 旧尾结点\n        final Node&lt;E> newNode = new Node&lt;>(l, e, null);  // 创建新节点\n        last = newNode;     // 新节点上位尾结点\n        if (l == null)\n            first = newNode; // 第一个节点 first->a  last->a\n        else\n            l.next = newNode;  // 新节点是从尾部连接的！新节点赋值->旧尾结点.next \n        size++;\n        modCount++;\n    &#125;\n-----------------------------\npublic E remove() &#123;\n        return removeFirst();  //注意是第一个\n    &#125;\npublic E removeFirst() &#123;\n        final Node&lt;E> f = first;\n        if (f == null)\n            throw new NoSuchElementException();\n        return unlinkFirst(f);\n    &#125;\n-----------------------------\nprivate E unlinkFirst(Node&lt;E> f) &#123;\n        // assert f == first &amp;&amp; f != null;\n        final E element = f.item;\n        final Node&lt;E> next = f.next;\n        f.item = null;\n        f.next = null; // help GC\n        first = next;\n        if (next == null)\n            last = null;   // 只有一个节点\n        else\n            next.prev = null;  \n        size--;\n        modCount++;\n        return element;   // 返回删除的元素\n    &#125;\n-----------------------------\n\n\n\n集合选择\nArrayList 查询快，增删慢\nLinkedList查询慢，增删快\n一般来说，程序中 80~90的业务都是查询，因此大部分情况下选择ArrayList\n也可以根据业务需要灵活选择\n\nSet 接口\nTreeSet有序，HashSet无序\n不允许重复，最多包含一个null\n\nHashSet\n\n\n\n\n\n\n\n\n如何决定元素是相同的？\n\nhashCode() 决定节点添加到数组下标的位置；\n真正地逻辑是：**(table.length -1) &amp; hash(hashCode())**\n\n\n当 hashCode() 方法算出的元素落到了某个链表上，从头到尾依次比较，有相同元素，添加失败，无相同元素，添加到链表尾部；\n可以存放null，但只能有一个（null的哈希值为0）\n\n\n\n\n\n\n\n\n\n\n\n\n源码分析\n\n底层实际上是HashMap\n底层调用的是Hashmap的API，value是占位符PRESENT – new Object()\n元素顺序取决于hash函数的结果，是一个固定的顺序\n无参构造器：default-capacity(16)  loadFactor(0.75) \n单链表长度达到9个（在添加第9个元素后立刻检查，这是由于binCount是之前的容量！）时才进入 treeifbin()方法\ntab == null || (n = tab.length) &lt; 64\n64指的是HashSet中所有的元素（包括链表上的）\n\n\nresize 扩容发生在以下三个时机：\n初始化一个HashSet，第一次添加元素时，table为null，此时扩容为长度为16的数组(无参构造，有参则初始化为指定的大小向上取2^n值)\n当前HashMap.size&gt;threshold时，成功添加第(threshold+1)个元素时，触发扩容方法\n链表的节点数大于8，若table.length&lt;64，触发扩容方法；若table.length&gt;&#x3D;64，触发树化\n\n\n不错的帖子\n从泊松分布谈起HashMap为什么默认扩容因子是0.75 - 知乎 (zhihu.com)\n2022面试题：HashMap相关问题硬核梳理_小牛呼噜噜的博客-CSDN博客\n\n\n\n// 调用链 add->put->putVal(hash->hashCode)\n---------------------------------\npublic boolean add(E e) &#123;\n    \t//PRESENT相当于一个占位符，Object[]\n        return map.put(e, PRESENT)==null;\n    &#125;\n---------------------------------\npublic V put(K key, V value) &#123;\n        return putVal(hash(key), key, value, false, true);\n    &#125;\n---------------------------------\nstatic final int hash(Object key) &#123;\n        int h;\n    \t// 由此可见，真正的哈希值是hashCode方法进一步包装的值\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n    &#125;\n---------------------------------\n/**------------------------核心算法------------------------**/\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) &#123;\n        Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i;\n    \t  // 初始化 table 数组\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n    \t  // tab[i]初始化\n        if ((p = tab[i = (n - 1) &amp; hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n        else &#123;\n          \t// tab[i]已经有节点了\n            Node&lt;K,V> e; K k;\n            // p 是 table[i] 的第一个元素（可能是Node或TreeNode，TreeNode是HashMap的静态内部类，已树化的节点）\n            // 以下代码判断是否是同一个对象\n            // CASE1:Node 第一个节点的hash、equals||地址 与加入节点相同\n            if (p.hash == hash &amp;&amp;\n                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))\n                e = p;\n            else if (p instanceof TreeNode)\n                // CASE2:p 是一颗红黑树\n                e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else &#123;\n                // CASE3:Node 有多个节点，第一个节点不能匹配，遍历链表\n                for (int binCount = 0; ; ++binCount) &#123;\n                    // 注意此处 p.next 赋给 e\n                    if ((e = p.next) == null) &#123;\n                        p.next = newNode(hash, key, value, null);\n                        // 本次添加过后链表元素达到了9个才进行扩容，因为binCount是之前的容量\n                        if (binCount >= TREEIFY_THRESHOLD - 1) \n                            //是否要进行红黑树化判断，以下是条件，不满足执行 resize() 方法\n                            // treeifyBin方法中还有判断：tab == null || (n = tab.length) &lt; 64  \n                            // 满足才能真正树化\n                            treeifyBin(tab, hash);\n                        break;\n                    &#125;\n                    // e = p.next\n                    if (e.hash == hash &amp;&amp;\n                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                        break;\n                    // p 向下指一个节点\n                    p = e;\n                &#125;\n            &#125;\n            \n            // value 替换细节\n            if (e != null) &#123;\n                //此处把k-v的v替换，value是传参进来的v\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            &#125;\n        &#125;\n        ++modCount;\n        // 添加后检查，第十三个元素添加后进入if执行扩容\n        if (++size > threshold)\n            resize();\n    \t  // 为 HashMap 子类准备的方法（如LinkedList），在本类中为空实现\n        afterNodeInsertion(evict);\n        return null;\n    &#125;\n\n/**-------------------数组扩容---------------------**/\nfinal Node&lt;K,V>[] resize() &#123;\n    Node&lt;K,V>[] oldTab = table;\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) &#123;\n        // 超过最大值就不再扩充了，就只好随你碰撞去吧\n        if (oldCap >= MAXIMUM_CAPACITY) &#123;\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        &#125;\n        // 没超过最大值，就扩充为原来的2倍\n        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;\n                 oldCap >= DEFAULT_INITIAL_CAPACITY)\n            newThr = oldThr &lt;&lt; 1; // double threshold\n    &#125;\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        newCap = oldThr;\n    else &#123;               // zero initial threshold signifies using defaults\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    &#125;\n    // 计算新的resize上限\n    if (newThr == 0) &#123;\n\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?\n                  (int)ft : Integer.MAX_VALUE);\n    &#125;\n    threshold = newThr;\n    @SuppressWarnings(&#123;\"rawtypes\"，\"unchecked\"&#125;)\n        Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap];\n    table = newTab;\n    if (oldTab != null) &#123;\n        // 把每个bucket都移动到新的buckets中\n        for (int j = 0; j &lt; oldCap; ++j) &#123;\n            Node&lt;K,V> e;\n            if ((e = oldTab[j]) != null) &#123;\n                oldTab[j] = null;\n                if (e.next == null)\n                    newTab[e.hash &amp; (newCap - 1)] = e;\n                else if (e instanceof TreeNode)\n                    ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap);\n                else &#123; // 链表优化重hash的代码块\n                    Node&lt;K,V> loHead = null, loTail = null; // 原索引存放的引用\n                    Node&lt;K,V> hiHead = null, hiTail = null; // 原索引+oldCap存放的引用\n                    Node&lt;K,V> next;\n                    do &#123;\n                        next = e.next;\n                       /*\n                       \t取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作\n                     \t （也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。\n                      */\n                        // 原索引\n                        if ((e.hash &amp; oldCap) == 0) &#123;\n                            if (loTail == null)\n                                loHead = e;\n                            else\n                                loTail.next = e; // 尾插\n                            loTail = e; // 尾插\n                        &#125; else &#123; // 原索引+oldCap\n                            if (hiTail == null)\n                                hiHead = e;\n                            else\n                                hiTail.next = e;\n                            hiTail = e;\n                        &#125;\n                    &#125; while ((e = next) != null);\n                    // 原索引放到bucket里\n                    if (loTail != null) &#123;\n                        loTail.next = null;\n                        newTab[j] = loHead;\n                    &#125;\n                    // 原索引+oldCap放到bucket里\n                    if (hiTail != null) &#123;\n                        hiTail.next = null;\n                        newTab[j + oldCap] = hiHead;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    return newTab;\n&#125;\n\n\n\n\n\nLinkedHashSet\n\n\n\n\n\n\n\n\n继承HashSet，实现Set\n\nHashMap维护对象是 Node ，LinkedHashSet维护对象是 Entry extends HashMap.Node\n底层维护了一个哈希表和双向链表\n每一个节点有pre和next属性，这样可以形成双向链表\n在添加一个元素时，先求hash值，再求索引，确定该元素在hashtable中的位置，然后将添加的元素加入到双向链表中（如果已经存在，则不添加，原则上通hashset一致）\n这样LinkedHashSet能确保插入顺序和遍历顺序一致\n源码解读\n\n/*LinkedHashSet内部类 Entry ，将来会取代Node成为LinkedHashSet的table的节点元素*/\nstatic class Entry&lt;K,V> extends HashMap.Node&lt;K,V> &#123;\n        Entry&lt;K,V> before, after;\n        Entry(int hash, K key, V value, Node&lt;K,V> next) &#123;\n            super(hash, key, value, next);\n        &#125;\n    &#125;\n\n\n\n\n\n\n\nTreeSet\n使用无参构造器时，元素仍是无序的\nTreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树\n源码解析如下\n\npublic V put(K key, V value) &#123;\n        Entry&lt;K,V> t = root;\n    \t// 第一次添加元素，注意节点对象是 Entry\n        if (t == null) &#123;\n            compare(key, key); // 此处的compare是为了检查 key 是否为空值\n            \n            root = new Entry&lt;>(key, value, null);\n            size = 1;\n            modCount++;\n            return null;\n        &#125;\n        int cmp;\n        Entry&lt;K,V> parent;\n        // split comparator and comparable paths\n        Comparator&lt;? super K> cpr = comparator;\n        if (cpr != null) &#123;\n            do &#123;\n                // 遍历所有的 key，给key找适当的位置\n                parent = t;\n                cmp = cpr.compare(key, t.key);  //绑定到定义的 compare 方法\n                if (cmp &lt; 0)\n                    t = t.left;\n                else if (cmp > 0)\n                    t = t.right;\n                else // 发现相等的 key ，用 value 的值覆盖这个 key 的 value，且方法退出\n                    return t.setValue(value);\n            &#125; while (t != null);\n        &#125;\n        else &#123;\n            if (key == null)\n                throw new NullPointerException();\n            @SuppressWarnings(\"unchecked\")\n                Comparable&lt;? super K> k = (Comparable&lt;? super K>) key;\n            do &#123;\n                parent = t;\n                cmp = k.compareTo(t.key);\n                if (cmp &lt; 0)\n                    t = t.left;\n                else if (cmp > 0)\n                    t = t.right;\n                else\n                    return t.setValue(value);\n            &#125; while (t != null);\n        &#125;\n        Entry&lt;K,V> e = new Entry&lt;>(key, value, parent);\n        if (cmp &lt; 0)\n            parent.left = e;\n        else\n            parent.right = e;\n        fixAfterInsertion(e);\n        size++;\n        modCount++;\n        return null;\n    &#125;\n\n\n\n\n\nMap 接口\nTreeMap有序，HashMap无序\nkey 不允许重复(null也不能重复），value可以重复\nk-v 最后是 HashMap$Node node &#x3D; newNode(hash , key , value , null)\nk-v 是为了方便程序员进行遍历设计的，会创建 EntrySet 集合，该集合存放的元素类型 Entry ，而一个 Entry 对象就有 k-v EntrySet&lt;Entry&lt;K,V&gt;&gt; 即： transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;\nentrySet 中，定义的类型是 Map.Entry , 但实际上存放的是 HashMap$Node , 这是因为 HashMap$Node implements Map.Entry static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;\n当把 HashMap$Node 对象存放到 entrySet 就方便我们的遍历，因为 Map.Entry 提供了重要方法 K getKey() – V getValue()\n\nMap 遍历\n增强 FOR\n迭代器 Iterator\nvalues() 方法 ，此方法返回集合 Collection ，可以使用以上两种遍历方式\nentrySet() 方法 ， 此方法返回 Set –&gt; EntrySet&lt;Map.Entry&lt;K,V&gt;&gt;  ， 可以使用 1 ，2 两种方式遍历\n\nHashMap\n\n\n\n\n当添加 key-val 时，通过 key 的哈希值得到在table的索引，然后判断该索引处是否有元素，如果没有元素则直接添加，如果有元素则继续判断该元素的 key 和准备加入的 key 是否相等，如果相等，则直接替换 val；如果不相等则需要判断是树结构还是链表结构，做出相应处理，如果添加时发现容量不够，则需要扩容。\n执行构造 new HashMap() ，初始化加载因子 loadfactor &#x3D; 0.75 &amp; hashMap$Node[] table &#x3D; null\n执行 put 调用 putVal() ，详细细节见 HashSet\n\n\n\n\n\nHashtable\n实现了 Map 集合，即存放 k-v 键值对，key不能重复\nHashtable 的键和值都不能为 null ，否则抛出 NullPointerException\nHashtable 使用方法基本上和 HashMap 一致\nHashtable 线程安全\n默认值 initialCapacity-11 loadFactor-0.75，扩容方式 2*old+1\n源码解析如下\n\n--------------------------------------------\n// 无参构造 默认大小是 11 ，loadFactor仍然是 0.75，所以threshold是 11*0.75=8\npublic Hashtable() &#123;\n        this(11, 0.75f);\n    &#125;\n--------------------------------------------\npublic synchronized V put(K key, V value) &#123;\n        // Make sure the value is not null\n        if (value == null) &#123;\n            throw new NullPointerException();\n        &#125;\n\n        // Makes sure the key is not already in the hashtable.\n        Entry&lt;?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V> entry = (Entry&lt;K,V>)tab[index];\n        for(; entry != null ; entry = entry.next) &#123;\n            if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123;\n                V old = entry.value;\n                entry.value = value;\n                return old;\n            &#125;\n        &#125;\n\n        addEntry(hash, key, value, index);\n        return null;\n    &#125;\n-------------------------------------------------------------\nprivate void addEntry(int hash, K key, V value, int index) &#123;\n        modCount++;\n\n        Entry&lt;?,?> tab[] = table;\n        if (count >= threshold) &#123;\n            // Rehash the table if the threshold is exceeded\n            rehash();\n\n            tab = table;\n            hash = key.hashCode();\n            index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        &#125;\n\n        // Creates the new entry.\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V> e = (Entry&lt;K,V>) tab[index];\n        tab[index] = new Entry&lt;>(hash, key, value, e);\n        count++;\n    &#125;\n-------------------------------------------------------------\nprotected void rehash() &#123;\n        int oldCapacity = table.length;\n        Entry&lt;?,?>[] oldMap = table;\n\n        //扩容机制如下 2*oldCapacity+1\n        int newCapacity = (oldCapacity &lt;&lt; 1) + 1;\n        if (newCapacity - MAX_ARRAY_SIZE > 0) &#123;\n            if (oldCapacity == MAX_ARRAY_SIZE)\n                // Keep running with MAX_ARRAY_SIZE buckets\n                return;\n            newCapacity = MAX_ARRAY_SIZE;\n        &#125;\n    \t//数组扩容\n        Entry&lt;?,?>[] newMap = new Entry&lt;?,?>[newCapacity];\n\n        modCount++;\n        threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1);\n        table = newMap;\n\n        for (int i = oldCapacity ; i-- > 0 ;) &#123;\n            for (Entry&lt;K,V> old = (Entry&lt;K,V>)oldMap[i] ; old != null ; ) &#123;\n                Entry&lt;K,V> e = old;\n                old = old.next;\n\n                int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity;\n                e.next = (Entry&lt;K,V>)newMap[index];\n                newMap[index] = e;\n            &#125;\n        &#125;\n    &#125;\n\n\n\nProperties\n继承自 Hashtable，仍然以 k-v 键值对保存数据\n使用方式与 Hashtable 类似\nProperties可以从 xxx.properties文件中，加载数据到其创建的对象中，并对其修改\n\nTreeMap这个类不依赖hashCode和equals\n\n使用比较器构造器\n\n&#96;&#96;&#96;javapublic TreeSet(Comparator&lt;? super E&gt; comparator) {    this(new TreeMap&lt;&gt;(comparator));}\n2. 第一次添加，把k-v封装到 Entry 对象，放入 root\n\n   - &#96;&#96;&#96;java\n     Entry&lt;K,V&gt; t &#x3D; root;\n     if (t &#x3D;&#x3D; null) &#123;\n         compare(key, key); &#x2F;&#x2F; type (and possibly null) check\n     \n         root &#x3D; new Entry&lt;&gt;(key, value, null);\n         size &#x3D; 1;\n         modCount++;\n         return null;\n     &#125;\n\n\n以后添加\n\n&#96;&#96;&#96;javaint cmp;Entry&lt;K,V&gt; parent;&#x2F;&#x2F; split comparator and comparable pathsComparator&lt;? super K&gt; cpr &#x3D; comparator;if (cpr !&#x3D; null) {do {  &#x2F;&#x2F; 遍历所有key，给key找适当的位置    parent &#x3D; t;    cmp &#x3D; cpr.compare(key, t.key); &#x2F;&#x2F;调用的是传入的比较器    if (cmp &lt; 0)        t &#x3D; t.left;    else if (cmp &gt; 0)        t &#x3D; t.right;    else          &#x2F;&#x2F; 发现已经有重复的key，覆盖value并返回        return t.setValue(value);} while (t !&#x3D; null);}\n\n\n## 集合选择\n\n1. 先判断存储的类型（一组对象或一组键值对）\n2. 一组对象：Collection接口实现类\n   1. 允许重复：List\n      - 增删多：LinkedList（底层维护了一个双向链表）\n      - 改查多：ArrayList（底层维护Object类型可变数组）\n   2. 不允许重复：Set\n      - 无序：HashSet（底层是HashMap，维护了一个哈希表，即数组+链表+红黑树）\n      - 排序：TreeSet\n      - 插入和取出顺序一致：LinkedHashSet（底层维护了数组+双向链表）\n3. 一组键值对：Map\n   - 键无序：HashMap（底层是哈希表）\n   - 键排序：TreeMap\n   - 键插入和取出顺序一致：LinkedHashMap\n   - 文件操作：Properties\n\n\n\n## Collections 工具类\n\n1. 排序相关\n   - reverse()   &#x2F;&#x2F; 反转\n   - shuffle()     &#x2F;&#x2F; 乱序\n   - sort()        &#x2F;&#x2F; 排序 ，可以定义比较器\n   - swap()     &#x2F;&#x2F; 交换\n2. 查找、替换\n   - max()   &#x2F;&#x2F; 可以定义比较器\n   - **frequency()**   &#x2F;&#x2F; 某元素出现频率\n   - copy()     &#x2F;&#x2F; 注意数组越界问题！\n   - replaceAll()  &#x2F;&#x2F; 集合中某元素替换\n\n\n\n&#96;&#96;&#96;java\n\n\n\n\n","slug":"Java集合详解","date":"2022-09-22T01:13:17.000Z","categories_index":"","tags_index":"Java,Python","author_index":"JuneQQQ"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new \"My New Post\"\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-09-20T06:36:56.163Z","categories_index":"","tags_index":"","author_index":"JuneQQQ"}]