[{"id":"e770f8dee4e3c6fbfdcee5dd8a2fe82a","title":"Kubernetes入门","content":"1. Kubernetes介绍1.1 kubernetes组件一个kubernetes集群主要是由**控制节点(master)、工作节点(node)**构成，每个节点上都会安装不同的组件。\nmaster：集群的控制平面，负责集群的决策 ( 管理 )\n\n\n\n\n\n\n\n\n\nApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制\nScheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上\nControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等\nEtcd ：负责存储集群中各种资源对象的信息\nnode：集群的数据平面，负责为容器提供运行环境 ( 干活 )\n\n\n\n\n\n\n\n\n\nKubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器\nKubeProxy : 负责提供集群内部的服务发现和负载均衡\nDocker : 负责节点上容器的各种操作\n\n1.2 kubernetes概念Pod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器\nController：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等\nService：pod对外服务的统一入口，下面可以维护者同一类的多个pod\nLabel：标签，用于对pod进行分类，同一类pod会拥有相同的标签\nNameSpace：命名空间，用来隔离pod的运行环境\n2. 部署见 Linux环境部署.md\n3. 资源管理3.1 资源管理介绍在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。\n\n\n\n\n\n\n\n\n\nkubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。\nkubernetes的最小管理单元是pod而不是容器，所以只能将容器放在Pod中，而kubernetes一般也不会直接管理Pod，而是通过Pod控制器来管理Pod的。\nPod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了Service资源实现这个功能。\n当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种存储系统。\n\n\n\n\n\n\n\n\n\n\n学习kubernetes的核心，就是学习如何对集群上的Pod、Pod控制器、Service、存储等各种资源进行操作\n3.2 YAML语言介绍# 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期\n# 1 布尔类型\nc1: true (或者True)\n# 2 整型\nc2: 234\n# 3 浮点型\nc3: 3.14\n# 4 null类型 \nc4: ~  \n# 5 日期类型\nc5: 2018-02-17    # 日期必须使用ISO 8601格式，即yyyy-MM-dd\n# 6 时间类型\nc6: 2018-02-17T15:02:31+08:00  # 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区\n# 7 字符串类型\nc7: heima     # 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 \nc8: line1\n    line2     # 字符串过多的情况可以拆成多行，每一行会被转化成一个空格\n\n# 对象\n# 形式一(推荐):\nheima:\n  age: 15\n  address: Beijing\n# 形式二(了解):\nheima: &#123;age: 15,address: Beijing&#125;\n\n# 数组\n# 形式一(推荐):\naddress:\n  - 顺义\n  - 昌平  \n# 形式二(了解):\naddress: [顺义,昌平]\n\n\n\n\n\n\n\n\n\n\nyaml ↔ json网站\n3.3 资源管理方式\n命令式对象管理：直接使用命令去操作kubernetes资源\nkubectl run nginx-pod --image=nginx:1.17.1 --port=80\n\n命令式对象配置：通过命令配置和配置文件去操作kubernetes资源\nkubectl create/patch -f nginx-pod.yaml\n\n声明式对象配置：通过apply命令和配置文件去操作kubernetes资源\nkubectl apply -f nginx-pod.yaml\n\n\n\n\n\n类型\n操作对象\n适用环境\n优点\n缺点\n\n\n\n命令式对象管理\n对象\n测试\n简单\n只能操作活动对象，无法审计、跟踪\n\n\n命令式对象配置\n文件\n开发\n可以审计、跟踪\n项目大时，配置文件多，操作麻烦\n\n\n声明式对象配置\n目录\n开发\n支持目录操作\n意外情况下难以调试\n\n\n3.3.1 命令式对象管理kubectl命令\nkubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。kubectl命令的语法如下：\nkubectl [command] [type] [name] [flags]\n\ncomand：指定要对资源执行的操作，例如create、get、delete\ntype：指定资源类型，比如deployment、pod、service\nname：指定资源的名称，名称大小写敏感\nflags：指定额外的可选参数\n# 查看所有pod\nkubectl get pod \n# 查看某个pod\nkubectl get pod pod_name\n# 查看某个pod,以yaml格式展示结果\nkubectl get pod pod_name -o yaml\n\n资源类型\nkubernetes中所有的内容都抽象为资源，可以通过下面的命令进行查看:\nkubectl api-resources\n\n经常使用的资源有下面这些：\n\n\n\n资源分类\n资源名称\n缩写\n资源作用\n\n\n\n集群级别资源\nnodes\nno\n集群组成部分\n\n\nnamespaces\nns\n隔离Pod\n\n\n\npod资源\npods\npo\n装载容器\n\n\npod资源控制器\nreplicationcontrollers\nrc\n控制pod资源\n\n\n\nreplicasets\nrs\n控制pod资源\n\n\n\ndeployments\ndeploy\n控制pod资源\n\n\n\ndaemonsets\nds\n控制pod资源\n\n\n\njobs\n\n控制pod资源\n\n\n\ncronjobs\ncj\n控制pod资源\n\n\n\nhorizontalpodautoscalers\nhpa\n控制pod资源\n\n\n\nstatefulsets\nsts\n控制pod资源\n\n\n服务发现资源\nservices\nsvc\n统一pod对外接口\n\n\n\ningress\ning\n统一pod对外接口\n\n\n存储资源\nvolumeattachments\n\n存储\n\n\n\npersistentvolumes\npv\n存储\n\n\n\npersistentvolumeclaims\npvc\n存储\n\n\n配置资源\nconfigmaps\ncm\n配置\n\n\n\nsecrets\n\n配置\n\n\n操作\nkubernetes允许对资源进行多种操作，可以通过–help查看详细的操作命令\nkubectl --help\n\n经常使用的操作有下面这些：\n\n\n\n命令分类\n命令\n翻译\n命令作用\n\n\n\n基本命令\ncreate\n创建\n创建一个资源\n\n\n\nedit\n编辑\n编辑一个资源\n\n\n\nget\n获取\n获取一个资源\n\n\n\npatch\n更新\n更新一个资源\n\n\n\ndelete\n删除\n删除一个资源\n\n\n\nexplain\n解释\n展示资源文档\n\n\n运行和调试\nrun\n运行\n在集群中运行一个指定的镜像\n\n\n\nexpose\n暴露\n暴露资源为Service\n\n\n\ndescribe\n描述\n显示资源内部信息\n\n\n\nlogs\n日志输出容器在 pod 中的日志\n输出容器在 pod 中的日志\n\n\n\nattach\n缠绕进入运行中的容器\n进入运行中的容器\n\n\n\nexec\n执行容器中的一个命令\n执行容器中的一个命令\n\n\n\ncp\n复制\n在Pod内外复制文件\n\n\n\nrollout\n首次展示\n管理资源的发布\n\n\n\nscale\n规模\n扩(缩)容Pod的数量\n\n\n\nautoscale\n自动调整\n自动调整Pod的数量\n\n\n高级命令\napply\nrc\n通过文件对资源进行配置\n\n\n\nlabel\n标签\n更新资源上的标签\n\n\n其他命令\ncluster-info\n集群信息\n显示集群信息\n\n\n\nversion\n版本\n显示当前Server和Client的版本\n\n\n# 下面以一个namespace / pod的创建和删除简单演示下命令的使用：\n# 创建一个namespace\n[root@master ~]# kubectl create namespace dev\nnamespace/dev created\n\n# 获取namespace\n[root@master ~]# kubectl get ns\nNAME              STATUS   AGE\ndefault           Active   21h\ndev               Active   21s\nkube-node-lease   Active   21h\nkube-public       Active   21h\nkube-system       Active   21h\n\n# 在此namespace下创建并运行一个nginx的Pod\n[root@master ~]# kubectl run pod --image=nginx:latest -n dev\nkubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\ndeployment.apps/pod created\n\n# 查看新创建的pod\n[root@master ~]# kubectl get pod -n dev\nNAME  READY   STATUS    RESTARTS   AGE\npod   1/1     Running   0          21s\n\n# 删除指定的pod\n[root@master ~]# kubectl delete pod pod-864f9875b9-pcw7x\npod \"pod\" deleted\n\n# 删除指定的namespace\n[root@master ~]# kubectl delete ns dev\nnamespace \"dev\" deleted\n\n3.3.3 声明式对象配置\n如果资源不存在，就创建，相当于 kubectl create\n如果资源已存在，就更新，相当于 kubectl patch\n\n\n\n\n\n\n\n\n\n\n扩展：kubectl可以在node节点上运行吗 ?\nkubectl的运行是需要进行配置的，它的配置文件是$HOME&#x2F;.kube，如果想要在node节点运行此命令，需要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作：\n# 主节点执行\nscp  -r  ~/.kube   k8s.node2:~/\n\n4. 实战入门4.1 NamespaceNamespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离。\n\n# 默认创建的namespace\nNAME              STATUS   AGE\ndefault           Active   45h     #  所有未指定Namespace的对象都会被分配在default命名空间\nkube-node-lease   Active   45h     #  集群节点之间的心跳维护，v1.13开始引入\nkube-public       Active   45h     #  此命名空间下的资源可以被所有人访问（包括未认证用户）\nkube-system       Active   45h     #  所有由Kubernetes系统创建的资源都处于这个命名空间\n\n查看\n# 1 查看所有的ns  命令：kubectl get ns\nkubectl get ns\n# 2 查看指定的ns   命令：kubectl get ns ns名称\nkubectl get ns default\n# 3 指定输出格式  命令：kubectl get ns ns名称  -o 格式参数\n# kubernetes支持的格式有很多，比较常见的是wide、json、yaml\nkubectl get ns default -o yaml  \n# 4 查看ns详情  命令：kubectl describe ns ns名称\nsudo kubectl describe ns default\n# 5 创建&amp;删除\nkubectl create ns dev\nkubectl delete ns dev\n\nYAML语法\n# ns-dev.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n\n4.2 PodPod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。\nPod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。\n\nPod相关命令\nkubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的\n# 查看指定名称空间\nkubectl get pod -n kube-system\n# 创建并运行【这种方式创建了控制器，想要删除还需要删除deployment】\nkubectl run nginx --image=nginx:latest --port=80 --namespace dev \n# 查看Pod基本信息\nkubectl get pods -n dev\n# 查看Pod的详细信息 describe  最后的events较为重要，用于拍错\nkubectl describe pod nginx -n dev\n# 获取podIP\nkubectl get pods -n dev -o wide\n#访问POD\ncurl http://10.244.37.201\n# 删除指定Pod\nkubectl delete pod nginx -n dev\n# 查询一下当前namespace下的Pod控制器\nkubectl get deploy -n  dev\n\nYAML配置\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: dev\nspec:\n  containers:\n  - image: nginx:latest\n    name: pod\n    ports:\n    - name: nginx-port\n      containerPort: 80\n      protocol: TCP\n\n4.3 Label\n\n\n\n\n\n\n\n\n一些常用的Label 示例如下：\n\n版本标签：”version”:”release”, “version”:”stable”……\n环境标签：”environment”:”dev”，”environment”:”test”，”environment”:”pro”\n架构标签：”tier”:”frontend”，”tier”:”backend”\n\n当前有两种Label Selector：\n\n基于等式的Label Selector\nname = slave 选择所有包含Label中key&#x3D;”name”且value&#x3D;”slave”的对象\nenv != production选择所有包括Label中的key&#x3D;”env”且value不等于”production”的对象\n\n基于集合的Label Selector\nname in (master, slave) 选择所有包含Label中的key&#x3D;”name”且value&#x3D;”master”或”slave”的对象\nname not in (frontend) 选择所有包含Label中的key&#x3D;”name”且value不等于”frontend”的对象\n\n\n标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号”,”进行分隔即可。例如：\nname=slave,env!=production\nname not in (frontend),env!=production\nLabel相关命令\n# 为pod资源打标签\nkubectl label pod nginx-pod version=1.0 -n dev\n# 为pod资源更新标签\nkubectl label pod nginx-pod version=2.0 -n dev --overwrite\n# 查看标签\nkubectl get pod nginx-pod  -n dev --show-labels\n# 筛选标签\nkubectl get pod -n dev -l version=2.0  --show-labels\nkubectl get pod -n dev -l version!=2.0 --show-labels\n#删除标签\nkubectl label pod nginx-pod version- -n dev\n\nYAML配置\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: dev\n  labels:\n    version: \"3.0\" \n    env: \"test\"\nspec:\n  containers:\n  - image: nginx:latest\n    name: pod\n    ports:\n    - name: nginx-port\n      containerPort: 80\n      protocol: TCP\n\n4.4 Deployment在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。\nPod控制器其中的一种是 Deployment\n\n命令操作\n# 命令格式: kubectl create deployment 名称  [参数] \n# --image  指定pod的镜像\n# --port   指定端口\n# --replicas  指定创建pod数量\n# --namespace  指定namespace\nkubectl create deploy nginx --image=nginx:latest --port=80 --replicas=3 -n dev\n# 查看创建的Pod\nkubectl get pods -n dev\n# 查看deployment的信息\n# UP-TO-DATE：成功升级的副本数量\n# AVAILABLE：可用副本的数量\nkubectl get deploy -n dev -o wide\n# 查看deployment的详细信息\nkubectl describe deploy nginx -n dev\n# 删除 \nkubectl delete deploy nginx -n dev\n\n配置操作\n# deploy-nginx.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: dev\n  \nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      run: nginx\n      \n  template:\n    metadata:\n      labels:\n        run: nginx\n    spec:\n      containers:\n      - image: nginx:latest\n        name: nginx\n        ports:\n        - containerPort: 80\n          protocol: TCP\n\n\n\n4.5 ServiceService可以看作是一组同类Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。\n\n操作一：创建集群内部可访问的Service\n# 暴露Service\nkubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev\n# 查看service\nkubectl get svc  -n dev -o wide\n# 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的\n# 可以通过这个IP访问当前service对应的POD\ncurl 10.109.179.231:80\n\n操作二：创建集群外部也可访问的Service\n# 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问\n# 如果需要创建外部也可以访问的Service，需要修改type为NodePort\nkubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev\n# 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928/TC）\nkubectl get svc  svc-nginx2  -n dev -o wide\n# 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了\n# 例如在的电脑主机上通过浏览器访问下面的地址\nhttp://192.168.5.4:31928/\n#删除Service\nkubectl delete svc svc-nginx1 -n dev\n\n配置方式\n创建一个svc-nginx.yaml，内容如下：\napiVersion: v1\nkind: Service\nmetadata:\n  name: svc-nginx\n  namespace: dev\nspec:\n  clusterIP: 10.109.179.231 #固定svc的内网ip\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    run: nginx\n  type: ClusterIP\n\n5. Pod详解5.1 Pod介绍5.1.1 Pod结构\n每个Pod中都可以包含一个或者多个容器，这些容器可以分为两类：\n\n用户程序所在的容器，数量可多可少\n\nPause容器，这是每个Pod都会有的一个根容器，它的作用有两个：\n\n可以以它为依据，评估整个Pod的健康状态\n\n可以在根容器上设置Ip地址，其它容器都此Ip（Pod IP），以实现Pod内部的网路通信\n\n\n\n\n5.1.2 Pod定义apiVersion: v1     #必选，版本号，例如v1\nkind: Pod       　 #必选，资源类型，例如 Pod\nmetadata:       　 #必选，元数据\n  name: string     #必选，Pod名称\n  namespace: string  #Pod所属的命名空间,默认为\"default\"\n  labels:       　　  #自定义标签列表\n    - name: string      　          \nspec:  #必选，Pod中容器的详细定义\n  containers:  #必选，Pod中容器列表\n  - name: string   #必选，容器名称\n    image: string  #必选，容器的镜像名称\n    imagePullPolicy: [ Always|Never|IfNotPresent ]  #获取镜像的策略 \n    command: [string]   #容器的启动命令列表，如不指定，使用打包时使用的启动命令\n    args: [string]      #容器的启动命令参数列表\n    workingDir: string  #容器的工作目录\n    volumeMounts:       #挂载到容器内部的存储卷配置\n    - name: string      #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名\n      mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符\n      readOnly: boolean #是否为只读模式\n    ports: #需要暴露的端口库号列表\n    - name: string        #端口的名称\n      containerPort: int  #容器需要监听的端口号\n      hostPort: int       #容器所在主机需要监听的端口号，默认与Container相同\n      protocol: string    #端口协议，支持TCP和UDP，默认TCP\n    env:   #容器运行前需设置的环境变量列表\n    - name: string  #环境变量名称\n      value: string #环境变量的值\n    resources: #资源限制和请求的设置\n      limits:  #资源限制的设置\n        cpu: string     #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数\n        memory: string  #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数\n      requests: #资源请求的设置\n        cpu: string    #Cpu请求，容器启动的初始可用数量\n        memory: string #内存请求,容器启动的初始可用数量\n    lifecycle: #生命周期钩子\n        postStart: #容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启\n        preStop: #容器终止前执行此钩子,无论结果如何,容器都会终止\n    livenessProbe:  #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器\n      exec:       　 #对Pod容器内检查方式设置为exec方式\n        command: [string]  #exec方式需要制定的命令或脚本\n      httpGet:       #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port\n        path: string\n        port: number\n        host: string\n        scheme: string\n        HttpHeaders:\n        - name: string\n          value: string\n      tcpSocket:     #对Pod内个容器健康检查方式设置为tcpSocket方式\n         port: number\n       initialDelaySeconds: 0       #容器启动完成后首次探测的时间，单位为秒\n       timeoutSeconds: 0    　　    #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒\n       periodSeconds: 0     　　    #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次\n       successThreshold: 0\n       failureThreshold: 0\n       securityContext:\n         privileged: false\n  restartPolicy: [Always | Never | OnFailure]  #Pod的重启策略\n  nodeName: &lt;string> #设置NodeName表示将该Pod调度到指定到名称的node节点上\n  nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上\n  imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定\n  - name: string\n  hostNetwork: false   #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络\n  volumes:   #在该pod上定义共享存储卷列表\n  - name: string    #共享存储卷名称 （volumes类型有很多种）\n    emptyDir: &#123;&#125;       #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值\n    hostPath: string   #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录\n      path: string      　　        #Pod所在宿主机的目录，将被用于同期中mount的目录\n    secret:       　　　#类型为secret的存储卷，挂载集群与定义的secret对象到容器内部\n      scretname: string  \n      items:     \n      - key: string\n        path: string\n    configMap:         #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部\n      name: string\n      items:\n      - key: string\n        path: string\n\n#小提示：\n#   在这里，可通过一个命令来查看每种资源的可配置项\n#   kubectl explain 资源类型         查看某种资源可以配置的一级属性\n#   kubectl explain 资源类型.属性     查看属性的子属性\nkubectl explain pod\n#   apiVersion   &lt;string>\n#   kind &lt;string>\n#   metadata     &lt;Object>\n#   spec &lt;Object>\n#   status       &lt;Object>\nkubectl explain pod.metadata\n\n在kubernetes中基本所有资源的一级属性都是一样的，主要包含5部分：\n\napiVersion  版本，由kubernetes内部定义，版本号可以用 kubectl api-versions 查询到\nkind  类型，由kubernetes内部定义，版本号可以用 kubectl api-resources 查询到\nmetadata  元数据，主要是资源标识和说明，常用的有name、namespace、labels等\nstatus  状态信息，里面的内容不需要定义，由kubernetes自动生成\nspec  描述，这是配置中最重要的一部分，里面是对各种资源配置的详细描述\n\n在上面的属性中，spec是接下来研究的重点，常见子属性：\n\ncontainers &lt;[]Object&gt; 容器列表，用于定义容器的详细信息\nnodeName  根据nodeName的值将pod调度到指定的Node节点上\nnodeSelector &lt;map[]&gt; 根据NodeSelector中定义的信息选择将该Pod调度到包含这些label的Node 上\nhostNetwork  是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络\nvolumes &lt;[]Object&gt; 存储卷，用于定义Pod上面挂在的存储信息\nrestartPolicy  重启策略，表示Pod在遇到故障的时候的处理策略\n\n5.2 Pod配置主要来研究pod.spec.containers属性\nkubectl explain pod.spec.containers\n# KIND:     Pod\n# VERSION:  v1\n# RESOURCE: containers &lt;[]Object>   # 数组，代表可以有多个容器\n# FIELDS:\n#    name  &lt;string>     # 容器名称\n#    image &lt;string>     # 容器需要的镜像地址\n#    imagePullPolicy  &lt;string> # 镜像拉取策略 \n#    command  &lt;[]string> # 容器的启动命令列表，如不指定，使用打包时使用的启动命令\n#    args     &lt;[]string> # 容器的启动命令需要的参数列表\n#    env      &lt;[]Object> # 容器环境变量的配置\n#    ports    &lt;[]Object>     # 容器需要暴露的端口号列表\n#    resources &lt;Object>      # 资源限制和资源请求的设置\n\n5.2.1 基本配置# pod-base.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-base\n  namespace: dev\n  labels:\n    user: heima\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1 # 用1.17.1版本的nginx镜像创建，（nginx是一个轻量级web容器）\n  - name: busybox\n    image: busybox:1.30 # 用1.30版本的busybox镜像创建，（busybox是一个小巧的linux命令集合）\n\n# 创建Pod\nkubectl apply -f pod-base.yaml\nkubectl get pod -n dev\n# 可以通过describe查看内部的详情\n# 此时已经运行起来了一个基本的Pod，虽然它暂时有问题\nkubectl describe pod pod-base -n dev\n\n5.2.2 镜像拉取# pod-imagepullpolicy.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-imagepullpolicy\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    imagePullPolicy: Never # 用于设置镜像拉取策略\n  - name: busybox\n    image: busybox:1.30\n\nimagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：\n\nAlways：只使用远程\nIfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像【默认】\nNever：只使用本地\n\n# 创建Pod\nkubectl create -f pod-imagepullpolicy.yaml\n# 查看Pod详情\n# 此时明显可以看到nginx镜像有一步Pulling image \"nginx:1.17.1\"的过程\nkubectl describe pod pod-imagepullpolicy -n dev\n\n5.2.3 启动命令在前面的案例中：busybox并不是一个程序，而是类似于一个工具类的集合，kubernetes集群启动管理后，它会自动关闭。解决方法就是让其一直在运行，这就用到了command配置。command，用于在pod中的容器初始化完毕之后运行一个命令。\n# pod-command.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-command\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) >> /tmp/hello.txt; sleep 3; done;\"]\n\n\n\n\n\n\n\n\n\n\n每隔3秒向文件中写入当前时间\n“&#x2F;bin&#x2F;sh”,”-c”, 使用sh执行命令\ntouch &#x2F;tmp&#x2F;hello.txt; 创建一个&#x2F;tmp&#x2F;hello.txt 文件\nwhile true;do &#x2F;bin&#x2F;echo $(date +%T) &gt;&gt; &#x2F;tmp&#x2F;hello.txt; sleep 3; done; \n# 重试\nkubectl create  -f pod-command.yaml\nkubectl get pods pod-command -n dev\n\n# 进入pod中的busybox容器，查看文件内容\n# 补充一个命令: kubectl exec  pod名称 -n 命名空间 -it -c 容器名称 /bin/sh  在容器内部执行命令\n# 使用这个命令就可以进入某个容器的内部，然后进行相关操作了\n# 比如，可以查看txt文件的内容\nkubectl exec pod-command -n dev -it -c busybox /bin/sh\n/ # tail -f /tmp/hello.txt\n14:44:19\n14:44:22\n14:44:25\n\n特别说明：\n    通过上面发现command已经可以完成启动命令和传递参数的功能，为什么这里还要提供一个args选项，用于传递参数呢?这其实跟docker有点关系，kubernetes中的command、args两项其实是实现覆盖Dockerfile中ENTRYPOINT的功能。\n 1 如果command和args均没有写，那么用Dockerfile的配置。\n 2 如果command写了，但args没有写，那么Dockerfile默认的配置会被忽略，执行输入的command\n 3 如果command没写，但args写了，那么Dockerfile中配置的ENTRYPOINT的命令会被执行，使用当前args的参数\n 4 如果command和args都写了，那么Dockerfile的配置被忽略，执行command并追加上args参数\n\n5.2.4 环境变量# pod-env.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-env\n  namespace: dev\nspec:\n  containers:\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"while true;do /bin/echo $(date +%T);sleep 60; done;\"]\n    env: # 设置环境变量列表\n    - name: \"username\"\n      value: \"admin\"\n    - name: \"password\"\n      value: \"123456\"\n\nenv，环境变量，用于在pod中的容器设置环境变量。\n# 创建Pod\nkubectl create -f pod-env.yaml\n# 进入容器，输出环境变量\nkubectl exec pod-env -n dev -c busybox -it /bin/sh\n/ # echo $username\nadmin\n/ # echo $password\n123456\n\n这种方式不是很推荐，推荐将这些配置单独存储在配置文件中\n5.2.5 端口设置kubectl explain pod.spec.containers.ports\n#KIND:     Pod\n#VERSION:  v1\n#RESOURCE: ports &lt;[]Object>\n#FIELDS:\n#   name         &lt;string>  # 端口名称，如果指定，必须保证name在pod中是唯一的\t\t\n#   containerPort&lt;integer> # 容器要监听的端口(0&lt;x&lt;65536)\n#   hostPort     &lt;integer> # 容器要在主机上公开的端口，如果设置，主机上只能运行容器的一个副本(一般省略) \n#   hostIP       &lt;string>  # 要将外部端口绑定到的主机IP(一般省略)\n#   protocol     &lt;string>  # 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。\n\n# pod-ports.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-ports\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports: # 设置容器暴露的端口列表\n    - name: nginx-port\n      containerPort: 80\n      protocol: TCP\n\n# 创建Pod\nkubectl create -f pod-ports.yaml\n# 查看pod\nkubectl get pod pod-ports -n dev -o yaml\n\n5.2.6 资源配额\nlimits：用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启\nrequests ：用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动\n\n# pod-resources.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-resources\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    resources: # 资源配额\n      limits:  # 限制资源（上限）\n        cpu: \"2\" # CPU限制，单位是core数【整数||小数】\n        memory: \"10Gi\" # 内存限制【Gi、Mi、G、M】\n      requests: # 请求资源（下限）\n        cpu: \"1\"  # CPU限制，单位是core数【整数||小数】\n        memory: \"10Mi\"  # 内存限制【Gi、Mi、G、M】\n\n5.3 Pod生命周期我们一般将pod对象从创建至终的这段时间范围称为pod的生命周期，它主要包含下面的过程：\n\npod创建过程\n运行初始化容器（init container）过程\n运行主容器（main container）\n容器启动后钩子（post start）、容器终止前钩子（pre stop）\n容器的存活性探测（liveness probe）、就绪性探测（readiness probe）\n\n\npod终止过程\n\n\n在整个生命周期中，Pod会出现5种状态（相位），分别如下：\n\n挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中\n运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成\n成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启\n失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态\n未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致\n\n5.3.1 创建和终止pod的创建过程\n\n用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer\n\napiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端\n\napiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动\n\nscheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer\n\nnode节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer\n\napiServer将接收到的pod状态信息存入etcd中\n\n\n\npod的终止过程\n\n用户向apiServer发送删除pod对象的命令\napiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead\n将pod标记为terminating状态\nkubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程\n端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除\n如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行\npod对象中的容器进程收到停止信号\n宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号\nkubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见\n\n5.3.2 初始化容器初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征：\n\n初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成\n初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行\n\n初始化容器有很多的应用场景，下面列出的是最常见的几个：\n\n提供主容器镜像中不具备的工具程序或自定义代码\n初始化容器要先于应用容器串行启动并运行完成，因此可用于延后应用容器的启动直至其依赖的条件得到满足\n\n接下来做一个案例，模拟下面这个需求：\n假设要以主容器来运行nginx，但是要求在运行nginx之前先要能够连接上mysql和redis所在服务器\n为了简化测试，事先规定好mysql(192.168.5.4)和redis(192.168.5.5)服务器的地址\n# pod-initcontainer.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-initcontainer\n  namespace: dev\nspec:\n  containers:\n  - name: main-container\n    image: nginx:1.17.1\n    ports: \n    - name: nginx-port\n      containerPort: 80\n  initContainers:\n  - name: test-mysql\n    image: busybox:1.30\n    command: ['sh', '-c', 'until ping 192.168.5.14 -c 1 ; do echo waiting for mysql...; sleep 2; done;']\n  - name: test-redis\n    image: busybox:1.30\n    command: ['sh', '-c', 'until ping 192.168.5.15 -c 1 ; do echo waiting for reids...; sleep 2; done;']\n\n# 创建pod\nkubectl create -f pod-initcontainer.yaml\n# 查看pod状态\n# 发现pod卡在启动第一个初始化容器过程中，后面的容器不会运行\nkubectl describe pod  pod-initcontainer -n dev\n# 动态查看pod\nkubectl get pods pod-initcontainer -n dev -w\n# 接下来新开一个shell，为当前服务器新增两个ip，观察pod的变化\nifconfig ens33:1 192.168.5.14 netmask 255.255.255.0 up\nifconfig ens33:2 192.168.5.15 netmask 255.255.255.0 up\n\n5.3.3 钩子函数\npost start：容器创建之后执行，如果失败了会重启容器\npre stop ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作\n\n钩子处理器支持使用下面三种方式定义动作：\n\nExec命令：在容器内执行一次命令\n……\n  lifecycle:\n    postStart: \n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n……\n\nTCPSocket：在当前容器尝试访问指定的socket\n……      \n  lifecycle:\n    postStart:\n      tcpSocket:\n        port: 8080\n……\n\nHTTPGet：在当前容器中向某url发起http请求\n……\n  lifecycle:\n    postStart:\n      httpGet:\n        path: / #URI地址\n        port: 80 #端口号\n        host: 192.168.5.3 #主机地址\n        scheme: HTTP #支持的协议，http或者https\n……\n\n# pod-hook-exec.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-hook-exec\n  namespace: dev\nspec:\n  containers:\n  - name: main-container\n    image: nginx:1.17.1\n    ports:\n    - name: nginx-port\n      containerPort: 80\n    lifecycle:\n      postStart: \n        exec: # 在容器启动的时候执行一个命令，修改掉nginx的默认首页内容\n          command: [\"/bin/sh\", \"-c\", \"echo postStart... > /usr/share/nginx/html/index.html\"]\n      preStop:\n        exec: # 在容器停止之前停止nginx服务\n          command: [\"/usr/sbin/nginx\",\"-s\",\"quit\"]\n\n# 创建pod\nkubectl create -f pod-hook-exec.yaml\n# 查看pod\nkubectl get pods  pod-hook-exec -n dev -o wide\n# 访问pod\ncurl 10.244.2.48\n\n5.3.4 容器探测容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例” 摘除 “，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是：\n\nliveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器\nreadiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量\n\n\n\n\n\n\n\n\n\n\nlivenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。\n上面两种探针目前均支持三种探测方式：\n\nExec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常\n……\n  livenessProbe:\n    exec:\n      command:\n      - cat\n      - /tmp/healthy\n……\n\nTCPSocket：将会尝试访问一个用户容器的端口，如果能够建立这条连接，则认为程序正常，否则不正常\n……      \n  livenessProbe:\n    tcpSocket:\n      port: 8080\n……\n\nHTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间，则认为程序正常，否则不正常\n……\n  livenessProbe:\n    httpGet:\n      path: / #URI地址\n      port: 80 #端口号\n      host: 127.0.0.1 #主机地址\n      scheme: HTTP #支持的协议，http或者https\n……\n\n方式一：Exec\n# pod-liveness-exec.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-liveness-exec\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports: \n    - name: nginx-port\n      containerPort: 80\n    livenessProbe:\n      exec:\n        command: [\"/bin/cat\",\"/tmp/hello.txt\"] # 执行一个查看文件的命令\n\n# 创建Pod\nkubectl create -f pod-liveness-exec.yaml\n# 查看Pod详情\nkubectl describe pods pod-liveness-exec -n dev\n# 观察上面的信息就会发现nginx容器启动之后就进行了健康检查\n# 检查失败之后，容器被kill掉，然后尝试进行重启（这是重启策略的作用，后面讲解）\n# 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长\nkubectl get pods pod-liveness-exec -n dev\n# 当然接下来，可以修改成一个存在的文件，比如/tmp/hello.txt，再试，结果就正常了......\n\n方式二：TCPSocket\n# pod-liveness-tcpsocket.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-liveness-tcpsocket\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports: \n    - name: nginx-port\n      containerPort: 80\n    livenessProbe:\n      tcpSocket:\n        port: 8080 # 尝试访问8080端口\n\n# 创建Pod\nkubectl create -f pod-liveness-tcpsocket.yaml\n# 查看Pod详情\nkubectl describe pods pod-liveness-tcpsocket -n dev\n# 观察上面的信息，发现尝试访问8080端口,但是失败了\n# 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长\nkubectl get pods pod-liveness-tcpsocket  -n dev\n# 当然接下来，可以修改成一个可以访问的端口，比如80，再试，结果就正常了......\n\n方式三：HTTPGet\n# pod-liveness-httpget.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-liveness-httpget\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports:\n    - name: nginx-port\n      containerPort: 80\n    livenessProbe:\n      httpGet:  # 其实就是访问http://127.0.0.1:80/hello  \n        scheme: HTTP #支持的协议，http或者https\n        port: 80 #端口号\n        path: /hello #URI地址\n\n# 创建Pod\nkubectl create -f pod-liveness-httpget.yaml\n# 查看Pod详情\nkubectl describe pod pod-liveness-httpget -n dev\n# 观察上面信息，尝试访问路径，但是未找到,出现404错误\n# 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长\nkubectl get pod pod-liveness-httpget -n dev\n# 当然接下来，可以修改成一个可以访问的路径path，比如/，再试，结果就正常了......\n\n# livenessProbe子属性\nkubectl explain pod.spec.containers.livenessProbe\nFIELDS:\n   exec &lt;Object>  \n   tcpSocket    &lt;Object>\n   httpGet      &lt;Object>\n   initialDelaySeconds  &lt;integer>  # 容器启动后等待多少秒执行第一次探测\n   timeoutSeconds       &lt;integer>  # 探测超时时间。默认1秒，最小1秒\n   periodSeconds        &lt;integer>  # 执行探测的频率。默认是10秒，最小1秒\n   failureThreshold     &lt;integer>  # 连续探测失败多少次才被认定为失败。默认是3。最小值是1\n   successThreshold     &lt;integer>  # 连续探测成功多少次才被认定为成功。默认是1\n\n5.3.5 重启策略\nAlways ：容器失效时，自动重启该容器，这也是默认值。\nOnFailure ： 容器终止运行且退出码不为0时重启\nNever ： 不论状态为何，都不重启该容器\n\n重启策略适用于pod对象中的所有容器，首次需要重启的容器，将在其需要时立即进行重启，随后再次需要重启的操作将由kubelet延迟一段时间后进行，且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。\n# pod-restartpolicy.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-restartpolicy\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports:\n    - name: nginx-port\n      containerPort: 80\n    livenessProbe:\n      httpGet:\n        scheme: HTTP\n        port: 80\n        path: /hello\n  restartPolicy: Never # 设置重启策略为Never\n\n# 创建Pod\nkubectl create -f pod-restartpolicy.yaml\n# 查看Pod详情，发现nginx容器失败\nkubectl  describe pods pod-restartpolicy  -n dev\n# 多等一会，再观察pod的重启次数，发现一直是0，并未重启   \nkubectl  get pods pod-restartpolicy -n dev\n\n5.4 Pod调度在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：\n\n自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出\n定向调度：NodeName、NodeSelector\n亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity\n污点（容忍）调度：Taints、Toleration\n\n5.4.1 定向调度【强制策略】NodeName这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。\n# pod-nodename.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-nodename\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  nodeName: node1 # 指定调度到node1节点上\n\nNodeSelectorNodeSelector用于将pod调度到添加了指定标签的node节点上。\nkubectl label nodes node1 nodeenv=pro\nubectl label nodes node2 nodeenv=test\n\n# pod-nodeselector.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-nodeselector\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  nodeSelector: \n    nodeenv: pro # 指定调度到具有nodeenv=pro标签的节点上\n\n\n\n5.4.2 亲和性调度上一节，介绍了两种定向调度的方式，使用起来非常方便，但是也有一定的问题，那就是如果没有满足条件的Node，那么Pod将不会被运行，即使在集群中还有可用Node列表也不行，这就限制了它的使用场景。\n基于上面的问题，kubernetes还提供了一种亲和性调度（Affinity）。它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。\nAffinity主要分为三类：\n\nnodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题\npodAffinity(pod亲和性) : 以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题\npodAntiAffinity(pod反亲和性) : 以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题\n\n\n\n\n\n\n\n\n\n\n关于亲和性(反亲和性)使用场景的说明：\n亲和性：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。\n反亲和性：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。\nNodeAffinity# 首先来看一下`NodeAffinity`的可配置项：\npod.spec.affinity.nodeAffinity\n  requiredDuringSchedulingIgnoredDuringExecution  #Node节点必须满足指定的所有规则才可以，相当于硬限制\n    nodeSelectorTerms  #节点选择列表\n      matchFields   #按节点字段列出的节点选择器要求列表\n      matchExpressions   #按节点标签列出的节点选择器要求列表(推荐)\n        key    #键\n        values #值\n        operator #关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt\n  preferredDuringSchedulingIgnoredDuringExecution #优先调度到满足指定的规则的Node，相当于软限制 (倾向)\n    preference   #一个节点选择器项，与相应的权重相关联\n      matchFields   #按节点字段列出的节点选择器要求列表\n      matchExpressions   #按节点标签列出的节点选择器要求列表(推荐)\n        key    #键\n        values #值\n        operator #关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt\n\tweight #倾向权重，在范围1-100。\n\n#关系符的使用说明:\n- matchExpressions:\n  - key: nodeenv              # 匹配存在标签的key为nodeenv的节点\n    operator: Exists\n  - key: nodeenv              # 匹配标签的key为nodeenv,且value是\"xxx\"或\"yyy\"的节点\n    operator: In\n    values: [\"xxx\",\"yyy\"]\n  - key: nodeenv              # 匹配标签的key为nodeenv,且value大于\"xxx\"的节点\n    operator: Gt\n    values: \"xxx\"\n\n# requiredDuringSchedulingIgnoredDuringExecution\n# pod-nodeaffinity-required.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-nodeaffinity-required\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  affinity:  #亲和性设置\n    nodeAffinity: #设置node亲和性\n      requiredDuringSchedulingIgnoredDuringExecution: # 硬限制，需要满足以下的至少一个\n        nodeSelectorTerms:\n        - matchExpressions: # 匹配env的值在[\"xxx\",\"yyy\"]中的标签\n          - key: nodeenv\n            operator: In\n            values: [\"xxx\",\"yyy\"]\n\n# requiredDuringSchedulingIgnoredDuringExecution\n# pod-nodeaffinity-preferred.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-nodeaffinity-preferred\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  affinity:  #亲和性设置\n    nodeAffinity: #设置node亲和性\n      preferredDuringSchedulingIgnoredDuringExecution: # 软限制\n      - weight: 1\n        preference:\n          matchExpressions: # 匹配env的值在[\"xxx\",\"yyy\"]中的标签(当前环境没有)\n          - key: nodeenv\n            operator: In\n            values: [\"xxx\",\"yyy\"]\n\nNodeAffinity规则设置的注意事项：\n\n如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能运行在指定的Node上\n如果nodeAffinity指定了多个nodeSelectorTerms，那么只需要其中一个能够匹配成功即可\n如果一个nodeSelectorTerms中有多个matchExpressions ，则一个节点必须满足所有的才能匹配成功\n如果一个pod所在的Node在Pod运行期间其标签发生了改变，不再符合该Pod的节点亲和性需求，则系统将忽略此变化\n\nPodAffinity# 首先来看一下`PodAffinity`的可配置项：\npod.spec.affinity.podAffinity\n  requiredDuringSchedulingIgnoredDuringExecution  硬限制\n    namespaces       # 指定参照pod的namespace\n    topologyKey      # 指定调度作用域\n    labelSelector    # 标签选择器\n      matchExpressions  # 按节点标签列出的节点选择器要求列表(推荐)\n        key    # 键\n        values # 值\n        operator # 关系符 支持In, NotIn, Exists, DoesNotExist.\n      matchLabels    # 指多个matchExpressions映射的内容\n  preferredDuringSchedulingIgnoredDuringExecution # 软限制\n    podAffinityTerm  # 选项\n      namespaces      \n      topologyKey\n      labelSelector\n        matchExpressions  \n          key    # 键\n          values # 值\n          operator\n        matchLabels \n    weight # 倾向权重，在范围1-100\n\ntopologyKey 用于指定调度时作用域,例如:\n    如果指定为kubernetes.io&#x2F;hostname，那就是以Node节点为区分范围\n\t  如果指定为beta.kubernetes.io&#x2F;os,则以Node节点的操作系统类型来区分\n\n# pod-podaffinity-required.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-podaffinity-required\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  affinity:  #亲和性设置\n    podAffinity: #设置pod亲和性\n      requiredDuringSchedulingIgnoredDuringExecution: # 硬限制\n      - labelSelector:\n          matchExpressions: # 匹配env的值在[\"xxx\",\"yyy\"]中的标签\n          - key: podenv\n            operator: In\n            values: [\"xxx\",\"yyy\"]\n        topologyKey: kubernetes.io/hostname\n\nPodAntiAffinityPodAntiAffinity主要实现以运行的Pod为参照，新创建的Pod跟参照pod不在一个区域中的功能。与上面的PodAffinity是一种相反策略\n5.4.3 污点和容忍污点（Taints）\n前面的调度方式都是站在Pod的角度上，通过在Pod上添加属性，来确定Pod是否要调度到指定的Node上，其实我们也可以站在Node的角度上，通过在Node上添加污点属性，来决定是否允许Pod调度过来。\nNode被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。\n污点的格式为：key=value:effect, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：\n\nPreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度\nNoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod\nNoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离\n\n\n污点API# 设置污点\nkubectl taint nodes k8s.node1 key=value:policy\n# 去除污点\nkubectl taint nodes k8s.node2 key:policy-\n# 去除所有污点\nkubectl taint nodes k8s.node2 key-\n# 查看污点\nkubectl describe node k8s.node1 | grep Taints\n\n注意：使用kubeadm搭建的集群，默认就会给master节点添加一个污点标记,所以pod就不会调度到master节点上.\n\n容忍（Toleration）\n\n\n\n\n\n\n\n\n\n\n污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝\n# pod-toleration.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-toleration\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n  tolerations:      # 添加容忍\n  - key: \"tag\"        # 要容忍的污点的key  \n    operator: \"Equal\" # 操作符  EqualExists（默认）\n    value: \"heima\"    # 容忍的污点的value\n    effect: \"NoExecute\"   # 添加容忍的规则，这里必须和标记的污点规则相同\n\nkubectl explain pod.spec.tolerations\n......\nFIELDS:\n   key       # 对应着要容忍的污点的键，空意味着匹配所有的键\n   value     # 对应着要容忍的污点的值\n   operator  # key-value的运算符，支持Equal和Exists（默认）\n   effect    # 对应污点的effect，空意味着匹配所有影响\n   tolerationSeconds   # 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间\n\n6. Pod控制器详解6.1 Pod控制器介绍Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：\n\n自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建\n控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建\n\n\n\n\n\n\n\n\n\n\n什么是Pod控制器\nPod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。\n在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些：\n\nReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代\nReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级\nDeployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本\nHorizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷\nDaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务\nJob：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务\nCronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行\nStatefulSet：管理有状态应用\n\n6.2 ReplicaSet(RS)ReplicaSet的主要作用是保证一定数量的pod正常运行，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。\n\nReplicaSet的资源清单文件：\napiVersion: apps/v1 # 版本号\nkind: ReplicaSet # 类型       \nmetadata: # 元数据\n  name: # rs名称 \n  namespace: # 所属命名空间 \n  labels: #标签\n    controller: rs\nspec: # 详情描述\n  replicas: 3 # 副本数量\n  selector: # 选择器，通过它指定该控制器管理哪些pod\n    matchLabels:      # Labels匹配规则\n      app: nginx-pod\n    matchExpressions: # Expressions匹配规则\n      - &#123;key: app, operator: In, values: [nginx-pod]&#125;\n  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        ports:\n        - containerPort: 80\n\n在这里面，需要新了解的配置项就是spec下面几个选项：\n\nreplicas：指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1\n\nselector：选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制\n在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了\n\ntemplate：模板，就是当前控制器创建pod所使用的模板板，里面其实就是前一章学过的pod的定义\n\n\nReplicaSet Demo# pc-replicaset.yaml\napiVersion: apps/v1\nkind: ReplicaSet   \nmetadata:\n  name: pc-replicaset\n  namespace: dev\nspec:\n  replicas: 3\n  selector: \n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n\n# 创建rs\nkubectl create -f pc-replicaset.yaml\n# 查看rs\n# DESIRED:期望副本数量  \n# CURRENT:当前副本数量  \n# READY:已经准备好提供服务的副本数量\nkubectl get rs pc-replicaset -n dev -o wide\n# 查看当前控制器创建出来的pod\n# 这里发现控制器创建出来的pod的名称是在控制器名称后面拼接了-xxxxx随机码\nkubectl get pod -n dev\n\n扩缩容# 编辑rs的副本数量，修改spec:replicas: 6即可\nkubectl edit rs pc-replicaset -n dev\n# 查看pod\nkubectl get pods -n dev\n# 当然也可以直接使用命令实现\n# 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可\nkubectl scale rs pc-replicaset --replicas=2 -n dev\n# 命令运行完毕，立即查看，发现已经有4个开始准备退出了\nkubectl get pods -n dev\n#稍等片刻，就只剩下2个了\nkubectl get pods -n dev\n\n镜像升级# 编辑rs的容器镜像 - image: nginx:1.17.2\nkubectl edit rs pc-replicaset -n dev\n# 再次查看，发现镜像版本已经变更了\nkubectl get rs -n dev -o wide\n# 同样的道理，也可以使用命令完成这个工作\n# kubectl set image rs rs名称 容器=镜像版本 -n namespace\nkubectl set image rs pc-replicaset nginx=nginx:1.17.1  -n dev\n# 再次查看，发现镜像版本已经变更了\nkubectl get rs -n dev -o wide\n\n删除ReplicaSet# 使用kubectl delete命令会删除此RS以及它管理的Pod\n# 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除\nkubectl delete rs pc-replicaset -n dev\nkubectl get pod -n dev -o wide\n# 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。\nkubectl delete rs pc-replicaset -n dev --cascade=false\nkubectl get pods -n dev\n# 也可以使用yaml直接删除(推荐)\nkubectl delete -f pc-replicaset.yaml\n\n6.3 Deployment(Deploy)为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。\n\nDeployment主要功能有下面几个：\n\n支持ReplicaSet的所有功能\n支持发布的停止、继续\n支持滚动升级和回滚版本\n\nDeployment的资源清单文件：\napiVersion: apps/v1 # 版本号\nkind: Deployment # 类型       \nmetadata: # 元数据\n  name: # rs名称 \n  namespace: # 所属命名空间 \n  labels: #标签\n    controller: deploy\nspec: # 详情描述\n  replicas: 3 # 副本数量\n  revisionHistoryLimit: 3 # 保留历史版本，版本回退时用的\n  paused: false # 暂停部署，默认是false  deployment -> pod 部署 是否立即执行\n  progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600\n  strategy: # 策略\n    type: RollingUpdate # 滚动更新策略\n    rollingUpdate: # 滚动更新\n      maxSurge: 30% # 最大额外可以存在的副本数，可以为百分比，也可以为整数\n      maxUnavailable: 30% # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数\n  selector: # 选择器，通过它指定该控制器管理哪些pod\n    matchLabels:      # Labels匹配规则\n      app: nginx-pod\n    matchExpressions: # Expressions匹配规则\n      - &#123;key: app, operator: In, values: [nginx-pod]&#125;\n  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        ports:\n        - containerPort: 80\n\nDeployment Demo\n# pc-deployment.yaml\napiVersion: apps/v1\nkind: Deployment      \nmetadata:\n  name: pc-deployment\n  namespace: dev\nspec: \n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n\n# 创建deployment\n[root@k8s-master01 ~]# kubectl create -f pc-deployment.yaml --record=true\ndeployment.apps/pc-deployment created\n\n# 查看deployment\n# UP-TO-DATE 最新版本的pod的数量\n# AVAILABLE  当前可用的pod的数量\n[root@k8s-master01 ~]# kubectl get deploy pc-deployment -n dev\nNAME            READY   UP-TO-DATE   AVAILABLE   AGE\npc-deployment   3/3     3            3           15s\n\n# 查看rs\n# 发现rs的名称是在原来deployment的名字后面添加了一个10位数的随机串\n[root@k8s-master01 ~]# kubectl get rs -n dev\nNAME                       DESIRED   CURRENT   READY   AGE\npc-deployment-6696798b78   3         3         3       23s\n\n# 查看pod\n[root@k8s-master01 ~]# kubectl get pods -n dev\nNAME                             READY   STATUS    RESTARTS   AGE\npc-deployment-6696798b78-d2c8n   1/1     Running   0          107s\npc-deployment-6696798b78-smpvp   1/1     Running   0          107s\npc-deployment-6696798b78-wvjd8   1/1     Running   0          107s\n\n扩缩容# 变更副本数量为5个\nkubectl scale deploy pc-deployment --replicas=5  -n dev\n# 查看deployment\nkubectl get deploy pc-deployment -n dev\n# 查看pod\nkubectl get pods -n dev\n# 编辑deployment的副本数量，修改spec:replicas: 4即可\nkubectl edit deploy pc-deployment -n dev\n# 查看pod\nkubectl get pods -n dev\n\n镜像更新deployment支持两种更新策略:重建更新和滚动更新,可以通过strategy指定策略类型,支持两个属性:\nstrategy：指定新的Pod替换旧的Pod的策略， 支持两个属性：\n  type：指定策略类型，支持两种策略\n    Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod\n    RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod\n  rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性：\n    maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。\n    maxSurge： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。\n\n重建更新\n编辑pc-deployment.yaml,在spec节点下添加更新策略\n\nspec:\n  strategy: # 策略\n    type: Recreate # 重建更新\n\n\n创建deploy进行验证\n\n# 变更镜像\nkubectl set image deployment pc-deployment nginx=nginx:1.17.2 -n dev\n# 观察升级过程\n[root@k8s-master01 ~]#  kubectl get pods -n dev -w\nNAME                             READY   STATUS    RESTARTS   AGE\npc-deployment-5d89bdfbf9-65qcw   1/1     Running   0          31s\npc-deployment-5d89bdfbf9-w5nzv   1/1     Running   0          31s\npc-deployment-5d89bdfbf9-xpt7w   1/1     Running   0          31s\n\npc-deployment-5d89bdfbf9-xpt7w   1/1     Terminating   0          41s\npc-deployment-5d89bdfbf9-65qcw   1/1     Terminating   0          41s\npc-deployment-5d89bdfbf9-w5nzv   1/1     Terminating   0          41s\n\npc-deployment-675d469f8b-grn8z   0/1     Pending       0          0s\npc-deployment-675d469f8b-hbl4v   0/1     Pending       0          0s\npc-deployment-675d469f8b-67nz2   0/1     Pending       0          0s\n\npc-deployment-675d469f8b-grn8z   0/1     ContainerCreating   0          0s\npc-deployment-675d469f8b-hbl4v   0/1     ContainerCreating   0          0s\npc-deployment-675d469f8b-67nz2   0/1     ContainerCreating   0          0s\n\npc-deployment-675d469f8b-grn8z   1/1     Running             0          1s\npc-deployment-675d469f8b-67nz2   1/1     Running             0          1s\npc-deployment-675d469f8b-hbl4v   1/1     Running             0          2s\n\n滚动更新\n编辑pc-deployment.yaml,在spec节点下添加更新策略\n\n# pc-deployment.yaml\napiVersion: apps/v1\nkind: Deployment      \nmetadata:\n  name: pc-deployment\n  namespace: dev\nspec: \n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  strategy: # 策略\n    type: RollingUpdate # 滚动更新策略\n    rollingUpdate:\n      maxSurge: 25% \n      maxUnavailable: 25%\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n\n\n创建deploy进行验证\n\n# 变更镜像\nkubectl set image deployment pc-deployment nginx=nginx:1.17.3 -n dev \n# 观察升级过程\n[root@k8s-master01 ~]# kubectl get pods -n dev -w\nNAME                           READY   STATUS    RESTARTS   AGE\npc-deployment-c848d767-8rbzt   1/1     Running   0          31m\npc-deployment-c848d767-h4p68   1/1     Running   0          31m\npc-deployment-c848d767-hlmz4   1/1     Running   0          31m\npc-deployment-c848d767-rrqcn   1/1     Running   0          31m\n\npc-deployment-966bf7f44-226rx   0/1     Pending             0          0s\npc-deployment-966bf7f44-226rx   0/1     ContainerCreating   0          0s\npc-deployment-966bf7f44-226rx   1/1     Running             0          1s\npc-deployment-c848d767-h4p68    0/1     Terminating         0          34m\n\npc-deployment-966bf7f44-cnd44   0/1     Pending             0          0s\npc-deployment-966bf7f44-cnd44   0/1     ContainerCreating   0          0s\npc-deployment-966bf7f44-cnd44   1/1     Running             0          2s\npc-deployment-c848d767-hlmz4    0/1     Terminating         0          34m\n\npc-deployment-966bf7f44-px48p   0/1     Pending             0          0s\npc-deployment-966bf7f44-px48p   0/1     ContainerCreating   0          0s\npc-deployment-966bf7f44-px48p   1/1     Running             0          0s\npc-deployment-c848d767-8rbzt    0/1     Terminating         0          34m\n\npc-deployment-966bf7f44-dkmqp   0/1     Pending             0          0s\npc-deployment-966bf7f44-dkmqp   0/1     ContainerCreating   0          0s\npc-deployment-966bf7f44-dkmqp   1/1     Running             0          2s\npc-deployment-c848d767-rrqcn    0/1     Terminating         0          34m\n\n# 至此，新版本的pod创建完毕，就版本的pod销毁完毕\n# 中间过程是滚动进行的，也就是边销毁边创建\n\n滚动更新的过程：\n\n镜像更新中rs的变化\n# 查看rs,发现原来的rs的依旧存在，只是pod数量变为了0，而后又新产生了一个rs，pod数量为4\n# 其实这就是deployment能够进行版本回退的奥妙所在，后面会详细解释\n[root@k8s-master01 ~]# kubectl get rs -n dev\nNAME                       DESIRED   CURRENT   READY   AGE\npc-deployment-6696798b78   0         0         0       7m37s\npc-deployment-6696798b11   0         0         0       5m37s\npc-deployment-c848d76789   4         4         4       72s\n\n版本回退deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能。\nkubectl rollout： 版本升级相关功能，支持下面的选项：\n\nstatus 显示当前升级状态\nhistory 显示 升级历史记录\npause 暂停版本升级过程\nresume 继续已经暂停的版本升级过程\nrestart 重启版本升级过程\nundo 回滚到上一级版本（可以使用--to-revision回滚到指定版本）\n\n# 查看当前升级版本的状态\n[root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev\ndeployment \"pc-deployment\" successfully rolled out\n# 查看升级历史记录\n[root@k8s-master01 ~]# kubectl rollout history deploy pc-deployment -n dev\ndeployment.apps/pc-deployment\nREVISION  CHANGE-CAUSE\n1         kubectl create --filename=pc-deployment.yaml --record=true\n2         kubectl create --filename=pc-deployment.yaml --record=true\n3         kubectl create --filename=pc-deployment.yaml --record=true\n# 可以发现有三次版本记录，说明完成过两次升级\n\n# 版本回滚\n# 这里直接使用--to-revision=1回滚到了1版本， 如果省略这个选项，就是回退到上个版本，就是2版本\n[root@k8s-master01 ~]# kubectl rollout undo deployment pc-deployment --to-revision=1 -n dev\ndeployment.apps/pc-deployment rolled back\n\n# 查看发现，通过nginx镜像版本可以发现到了第一版\n[root@k8s-master01 ~]# kubectl get deploy -n dev -o wide\nNAME            READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         \npc-deployment   4/4     4            4           74m   nginx        nginx:1.17.1   \n\n# 查看rs，发现第一个rs中有4个pod运行，后面两个版本的rs中pod为运行\n# 其实deployment之所以可是实现版本的回滚，就是通过记录下历史rs来实现的，\n# 一旦想回滚到哪个版本，只需要将当前版本pod数量降为0，然后将回滚版本的pod提升为目标数量就可以了\n[root@k8s-master01 ~]# kubectl get rs -n dev\nNAME                       DESIRED   CURRENT   READY   AGE\npc-deployment-6696798b78   4         4         4       78m\npc-deployment-966bf7f44    0         0         0       37m\npc-deployment-c848d767     0         0         0       71m\n\n金丝雀发布\nDeployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。\n比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。\n# 更新deployment的版本，并配置暂停deployment\n[root@k8s-master01 ~]#  sudo kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev &amp;&amp;  sudo kubectl rollout pause deployment pc-deployment  -n dev\ndeployment.apps/pc-deployment image updated\ndeployment.apps/pc-deployment paused\n\n#观察更新状态\n[root@k8s-master01 ~]# sudo kubectl rollout status deploy pc-deployment -n dev\nWaiting for deployment \"pc-deployment\" rollout to finish: 2 out of 4 new replicas have been updated...\n\n# 监控更新的过程，可以看到已经新增了一个资源，但是并未按照预期的状态去删除一个旧的资源，就是因为使用了pause暂停命令\n\n[root@k8s-master01 ~]# kubectl get rs -n dev -o wide\nNAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         \npc-deployment-5d89bdfbf9   3         3         3       19m     nginx        nginx:1.17.1   \npc-deployment-675d469f8b   0         0         0       14m     nginx        nginx:1.17.2   \npc-deployment-6c9f56fcfb   2         2         2       3m16s   nginx        nginx:1.17.4   \n[root@k8s-master01 ~]# kubectl get pods -n dev\nNAME                             READY   STATUS    RESTARTS   AGE\npc-deployment-5d89bdfbf9-rj8sq   1/1     Running   0          7m33s\npc-deployment-5d89bdfbf9-ttwgg   1/1     Running   0          7m35s\npc-deployment-5d89bdfbf9-v4wvc   1/1     Running   0          7m34s\npc-deployment-6c9f56fcfb-996rt   1/1     Running   0          3m31s\npc-deployment-6c9f56fcfb-j2gtj   1/1     Running   0          3m31s\n\n# 确保更新的pod没问题了，继续更新\n[root@k8s-master01 ~]# kubectl rollout resume deploy pc-deployment -n dev\ndeployment.apps/pc-deployment resumed\n\n# 查看最后的更新情况\n[root@k8s-master01 ~]# kubectl get rs -n dev -o wide\nNAME                       DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES         \npc-deployment-5d89bdfbf9   0         0         0       21m     nginx        nginx:1.17.1   \npc-deployment-675d469f8b   0         0         0       16m     nginx        nginx:1.17.2   \npc-deployment-6c9f56fcfb   4         4         4       5m11s   nginx        nginx:1.17.4   \n\n[root@k8s-master01 ~]# kubectl get pods -n dev\nNAME                             READY   STATUS    RESTARTS   AGE\npc-deployment-6c9f56fcfb-7bfwh   1/1     Running   0          37s\npc-deployment-6c9f56fcfb-996rt   1/1     Running   0          5m27s\npc-deployment-6c9f56fcfb-j2gtj   1/1     Running   0          5m27s\npc-deployment-6c9f56fcfb-rf84v   1/1     Running   0          37s\n\n删除Deployment\n# 删除deployment，其下的rs和pod也将被删除\nkubectl delete -f pc-deployment.yaml\n\n\n\n6.4 Horizontal Pod Autoscaler(HPA)在前面的课程中，我们已经可以实现通过手工执行kubectl scale命令实现Pod扩容或缩容，但是这显然不符合Kubernetes的定位目标–自动化、智能化。 Kubernetes期望可以实现通过监测Pod的使用情况，实现pod数量的自动调整，于是就产生了Horizontal Pod Autoscaler（HPA）这种控制器。\nHPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。其实HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数，这是HPA的实现原理。\n\n接下来，我们来做一个实验\n1 安装metrics-server\nmetrics-server可以用来收集集群中的资源使用情况\n# 安装git\n[root@k8s-master01 ~]# yum install git -y\n# 获取metrics-server, 注意使用的版本\n[root@k8s-master01 ~]# git clone -b v0.3.6 https://github.com/kubernetes-incubator/metrics-server\n# 修改deployment, 注意修改的是镜像和初始化参数\n[root@k8s-master01 ~]# cd /root/metrics-server/deploy/1.8+/\n[root@k8s-master01 1.8+]# vim metrics-server-deployment.yaml\n按图中添加下面选项\nhostNetwork: true\nimage: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6\nargs:\n- --kubelet-insecure-tls\n- --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP\n\n\n# 安装metrics-server\n[root@k8s-master01 1.8+]# kubectl apply -f ./\n\n# 查看pod运行情况\n[root@k8s-master01 1.8+]# kubectl get pod -n kube-system\nmetrics-server-6b976979db-2xwbj   1/1     Running   0          90s\n\n# 使用kubectl top node 查看资源使用情况\n[root@k8s-master01 1.8+]# kubectl top node\nNAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\nk8s-master01   289m         14%    1582Mi          54%       \nk8s-node01     81m          4%     1195Mi          40%       \nk8s-node02     72m          3%     1211Mi          41%  \n[root@k8s-master01 1.8+]# kubectl top pod -n kube-system\nNAME                              CPU(cores)   MEMORY(bytes)\ncoredns-6955765f44-7ptsb          3m           9Mi\ncoredns-6955765f44-vcwr5          3m           8Mi\netcd-master                       14m          145Mi\n...\n# 至此,metrics-server安装完成\n\n2 准备deployment和servie\n创建pc-hpa-pod.yaml文件，内容如下：\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: dev\nspec:\n  strategy: # 策略\n    type: RollingUpdate # 滚动更新策略\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        resources: # 资源配额\n          limits:  # 限制资源（上限）\n            cpu: \"1\" # CPU限制，单位是core数\n          requests: # 请求资源（下限）\n            cpu: \"100m\"  # CPU限制，单位是core数\n\n# 创建service\n[root@k8s-master01 1.8+]# kubectl expose deployment nginx --type=NodePort --port=80 -n dev\n\n# 查看\n[root@k8s-master01 1.8+]# kubectl get deployment,pod,svc -n dev\nNAME                    READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/nginx   1/1     1            1           47s\n\nNAME                         READY   STATUS    RESTARTS   AGE\npod/nginx-7df9756ccc-bh8dr   1/1     Running   0          47s\n\nNAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/nginx   NodePort   10.101.18.29   &lt;none>        80:31830/TCP   35s\n\n3 部署HPA\n创建pc-hpa.yaml文件，内容如下：\napiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: pc-hpa\n  namespace: dev\nspec:\n  minReplicas: 1  #最小pod数量\n  maxReplicas: 10 #最大pod数量\n  targetCPUUtilizationPercentage: 3 # CPU使用率指标\n  scaleTargetRef:   # 指定要控制的nginx信息\n    apiVersion: apps/v1\n    kind: Deployment\n    name: nginx\n\n# 创建hpa\n[root@k8s-master01 1.8+]# kubectl create -f pc-hpa.yaml\nhorizontalpodautoscaler.autoscaling/pc-hpa created\n\n# 查看hpa\n[root@k8s-master01 1.8+]# kubectl get hpa -n dev\nNAME     REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\npc-hpa   Deployment/nginx   0%/3%     1         10        1          62s\n\n4 测试\n使用压测工具对service地址192.168.5.4:31830进行压测，然后通过控制台查看hpa和pod的变化\nhpa变化\n[root@k8s-master01 ~]# kubectl get hpa -n dev -w\nNAME   REFERENCE      TARGETS  MINPODS  MAXPODS  REPLICAS  AGE\npc-hpa  Deployment/nginx  0%/3%   1     10     1      4m11s\npc-hpa  Deployment/nginx  0%/3%   1     10     1      5m19s\npc-hpa  Deployment/nginx  22%/3%   1     10     1      6m50s\npc-hpa  Deployment/nginx  22%/3%   1     10     4      7m5s\npc-hpa  Deployment/nginx  22%/3%   1     10     8      7m21s\npc-hpa  Deployment/nginx  6%/3%   1     10     8      7m51s\npc-hpa  Deployment/nginx  0%/3%   1     10     8      9m6s\npc-hpa  Deployment/nginx  0%/3%   1     10     8      13m\npc-hpa  Deployment/nginx  0%/3%   1     10     1      14m\n\ndeployment变化\n[root@k8s-master01 ~]# kubectl get deployment -n dev -w\nNAME    READY   UP-TO-DATE   AVAILABLE   AGE\nnginx   1/1     1            1           11m\nnginx   1/4     1            1           13m\nnginx   1/4     1            1           13m\nnginx   1/4     1            1           13m\nnginx   1/4     4            1           13m\nnginx   1/8     4            1           14m\nnginx   1/8     4            1           14m\nnginx   1/8     4            1           14m\nnginx   1/8     8            1           14m\nnginx   2/8     8            2           14m\nnginx   3/8     8            3           14m\nnginx   4/8     8            4           14m\nnginx   5/8     8            5           14m\nnginx   6/8     8            6           14m\nnginx   7/8     8            7           14m\nnginx   8/8     8            8           15m\nnginx   8/1     8            8           20m\nnginx   8/1     8            8           20m\nnginx   1/1     1            1           20m\n\npod变化\n[root@k8s-master01 ~]# kubectl get pods -n dev -w\nNAME                     READY   STATUS    RESTARTS   AGE\nnginx-7df9756ccc-bh8dr   1&#x2F;1     Running   0          11m\nnginx-7df9756ccc-cpgrv   0&#x2F;1     Pending   0          0s\nnginx-7df9756ccc-8zhwk   0&#x2F;1     Pending   0          0s\nnginx-7df9756ccc-rr9bn   0&#x2F;1     Pending   0          0s\nnginx-7df9756ccc-cpgrv   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-8zhwk   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-rr9bn   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-m9gsj   0&#x2F;1     Pending             0          0s\nnginx-7df9756ccc-g56qb   0&#x2F;1     Pending             0          0s\nnginx-7df9756ccc-sl9c6   0&#x2F;1     Pending             0          0s\nnginx-7df9756ccc-fgst7   0&#x2F;1     Pending             0          0s\nnginx-7df9756ccc-g56qb   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-m9gsj   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-sl9c6   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-fgst7   0&#x2F;1     ContainerCreating   0          0s\nnginx-7df9756ccc-8zhwk   1&#x2F;1     Running             0          19s\nnginx-7df9756ccc-rr9bn   1&#x2F;1     Running             0          30s\nnginx-7df9756ccc-m9gsj   1&#x2F;1     Running             0          21s\nnginx-7df9756ccc-cpgrv   1&#x2F;1     Running             0          47s\nnginx-7df9756ccc-sl9c6   1&#x2F;1     Running             0          33s\nnginx-7df9756ccc-g56qb   1&#x2F;1     Running             0          48s\nnginx-7df9756ccc-fgst7   1&#x2F;1     Running             0          66s\nnginx-7df9756ccc-fgst7   1&#x2F;1     Terminating         0          6m50s\nnginx-7df9756ccc-8zhwk   1&#x2F;1     Terminating         0          7m5s\nnginx-7df9756ccc-cpgrv   1&#x2F;1     Terminating         0          7m5s\nnginx-7df9756ccc-g56qb   1&#x2F;1     Terminating         0          6m50s\nnginx-7df9756ccc-rr9bn   1&#x2F;1     Terminating         0          7m5s\nnginx-7df9756ccc-m9gsj   1&#x2F;1     Terminating         0          6m50s\nnginx-7df9756ccc-sl9c6   1&#x2F;1     Terminating         0          6m50s\n\n\n\n6.5 DaemonSet(DS)DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。\n\nDaemonSet控制器的特点：\n\n每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上\n当节点从集群中移除时，Pod 也就被垃圾回收了\n\n下面先来看下DaemonSet的资源清单文件\napiVersion: apps/v1 # 版本号\nkind: DaemonSet # 类型       \nmetadata: # 元数据\n  name: # rs名称 \n  namespace: # 所属命名空间 \n  labels: #标签\n    controller: daemonset\nspec: # 详情描述\n  revisionHistoryLimit: 3 # 保留历史版本\n  updateStrategy: # 更新策略\n    type: RollingUpdate # 滚动更新策略\n    rollingUpdate: # 滚动更新\n      maxUnavailable: 1 # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数\n  selector: # 选择器，通过它指定该控制器管理哪些pod\n    matchLabels:      # Labels匹配规则\n      app: nginx-pod\n    matchExpressions: # Expressions匹配规则\n      - &#123;key: app, operator: In, values: [nginx-pod]&#125;\n  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        ports:\n        - containerPort: 80\n\n创建pc-daemonset.yaml，内容如下：\napiVersion: apps/v1\nkind: DaemonSet      \nmetadata:\n  name: pc-daemonset\n  namespace: dev\nspec: \n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n\n# 创建daemonset\n[root@k8s-master01 ~]# kubectl create -f  pc-daemonset.yaml\ndaemonset.apps/pc-daemonset created\n\n# 查看daemonset\n[root@k8s-master01 ~]#  kubectl get ds -n dev -o wide\nNAME        DESIRED  CURRENT  READY  UP-TO-DATE  AVAILABLE   AGE   CONTAINERS   IMAGES         \npc-daemonset   2        2        2      2           2        24s   nginx        nginx:1.17.1   \n\n# 查看pod,发现在每个Node上都运行一个pod\n[root@k8s-master01 ~]#  kubectl get pods -n dev -o wide\nNAME                 READY   STATUS    RESTARTS   AGE   IP            NODE    \npc-daemonset-9bck8   1/1     Running   0          37s   10.244.1.43   node1     \npc-daemonset-k224w   1/1     Running   0          37s   10.244.2.74   node2      \n\n# 删除daemonset\n[root@k8s-master01 ~]# kubectl delete -f pc-daemonset.yaml\ndaemonset.apps \"pc-daemonset\" deleted\n\n6.6 JobJob，主要用于负责**批量处理(一次要处理指定数量任务)短暂的一次性(每个任务仅运行一次就结束)**任务。Job特点如下：\n\n当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量\n当成功结束的pod达到指定的数量时，Job将完成执行\n\n\nJob的资源清单文件：\n# pc-job.yaml\napiVersion: batch/v1 # 版本号\nkind: Job # 类型       \nmetadata: # 元数据\n  name: # rs名称 \n  namespace: # 所属命名空间 \n  labels: #标签\n    controller: job\nspec: # 详情描述\n  completions: 1 # 指定job需要成功运行Pods的次数。默认值: 1\n  parallelism: 1 # 指定job在任一时刻应该并发运行Pods的数量。默认值: 1\n  activeDeadlineSeconds: 30 # 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。\n  backoffLimit: 6 # 指定job失败后进行重试的次数。默认是6\n  manualSelector: true # 是否可以使用selector选择器选择pod，默认是false\n  selector: # 选择器，通过它指定该控制器管理哪些pod\n    matchLabels:      # Labels匹配规则\n      app: counter-pod\n    matchExpressions: # Expressions匹配规则\n      - &#123;key: app, operator: In, values: [counter-pod]&#125;\n  template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本\n    metadata:\n      labels:\n        app: counter-pod\n    spec:\n      restartPolicy: Never # 重启策略只能设置为Never或者OnFailure\n      containers:\n      - name: counter\n        image: busybox:1.30\n        command: [\"bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 2;done\"]\n\n关于重启策略设置的说明：\n    如果指定为OnFailure，则job会在pod出现故障时重启容器，而不是创建pod，failed次数不变\n    如果指定为Never，则job会在pod出现故障时创建新的pod，并且故障pod不会消失，也不会重启，failed次数加1\n    如果指定为Always的话，就意味着一直重启，意味着job任务会重复去执行了，当然不对，所以不能设置为Always\n\n创建pc-job.yaml，内容如下：\napiVersion: batch/v1\nkind: Job      \nmetadata:\n  name: pc-job\n  namespace: dev\nspec:\n  manualSelector: true\n  selector:\n    matchLabels:\n      app: counter-pod\n  template:\n    metadata:\n      labels:\n        app: counter-pod\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: counter\n        image: busybox:1.30\n        command: [\"bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done\"]\n\n# 创建job\n[root@k8s-master01 ~]# kubectl create -f pc-job.yaml\njob.batch/pc-job created\n\n# 查看job\n[root@k8s-master01 ~]# kubectl get job -n dev -o wide  -w\nNAME     COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES         SELECTOR\npc-job   0/1           21s        21s   counter      busybox:1.30   app=counter-pod\npc-job   1/1           31s        79s   counter      busybox:1.30   app=counter-pod\n\n# 通过观察pod状态可以看到，pod在运行完毕任务后，就会变成Completed状态\n[root@k8s-master01 ~]# kubectl get pods -n dev -w\nNAME           READY   STATUS     RESTARTS      AGE\npc-job-rxg96   1/1     Running     0            29s\npc-job-rxg96   0/1     Completed   0            33s\n\n# 接下来，调整下pod运行的总数量和并行数量 即：在spec下设置下面两个选项\n#  completions: 6 # 指定job需要成功运行Pods的次数为6\n#  parallelism: 3 # 指定job并发运行Pods的数量为3\n#  然后重新运行job，观察效果，此时会发现，job会每次运行3个pod，总共执行了6个pod\n[root@k8s-master01 ~]# kubectl get pods -n dev -w\nNAME           READY   STATUS    RESTARTS   AGE\npc-job-684ft   1/1     Running   0          5s\npc-job-jhj49   1/1     Running   0          5s\npc-job-pfcvh   1/1     Running   0          5s\npc-job-684ft   0/1     Completed   0          11s\npc-job-v7rhr   0/1     Pending     0          0s\npc-job-v7rhr   0/1     Pending     0          0s\npc-job-v7rhr   0/1     ContainerCreating   0          0s\npc-job-jhj49   0/1     Completed           0          11s\npc-job-fhwf7   0/1     Pending             0          0s\npc-job-fhwf7   0/1     Pending             0          0s\npc-job-pfcvh   0/1     Completed           0          11s\npc-job-5vg2j   0/1     Pending             0          0s\npc-job-fhwf7   0/1     ContainerCreating   0          0s\npc-job-5vg2j   0/1     Pending             0          0s\npc-job-5vg2j   0/1     ContainerCreating   0          0s\npc-job-fhwf7   1/1     Running             0          2s\npc-job-v7rhr   1/1     Running             0          2s\npc-job-5vg2j   1/1     Running             0          3s\npc-job-fhwf7   0/1     Completed           0          12s\npc-job-v7rhr   0/1     Completed           0          12s\npc-job-5vg2j   0/1     Completed           0          12s\n\n# 删除job\n[root@k8s-master01 ~]# kubectl delete -f pc-job.yaml\njob.batch \"pc-job\" deleted\n\n6.7 CronJob(CJ)CronJob控制器以Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行时间点及重复运行的方式。也就是说，CronJob可以在特定的时间点(反复的)去运行job任务。\n\nCronJob的资源清单文件：\napiVersion: batch/v1beta1 # 版本号\nkind: CronJob # 类型       \nmetadata: # 元数据\n  name: # rs名称 \n  namespace: # 所属命名空间 \n  labels: #标签\n    controller: cronjob\nspec: # 详情描述\n  schedule: # cron格式的作业调度运行时间点,用于控制任务在什么时间执行\n  concurrencyPolicy: # 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业\n  failedJobHistoryLimit: # 为失败的任务执行保留的历史记录数，默认为1\n  successfulJobHistoryLimit: # 为成功的任务执行保留的历史记录数，默认为3\n  startingDeadlineSeconds: # 启动作业错误的超时时长\n  jobTemplate: # job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义\n    metadata:\n    spec:\n      completions: 1\n      parallelism: 1\n      activeDeadlineSeconds: 30\n      backoffLimit: 6\n      manualSelector: true\n      selector:\n        matchLabels:\n          app: counter-pod\n        matchExpressions: 规则\n          - &#123;key: app, operator: In, values: [counter-pod]&#125;\n      template:\n        metadata:\n          labels:\n            app: counter-pod\n        spec:\n          restartPolicy: Never \n          containers:\n          - name: counter\n            image: busybox:1.30\n            command: [\"bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 20;done\"]\n\nCron表达式的详细用法 - 简书 (jianshu.com)\n需要重点解释的几个选项：\nschedule: cron表达式，用于指定任务的执行时间\n    */1    *      *    *     *\n    &lt;分钟> &lt;小时> &lt;日> &lt;月份> &lt;星期>\n\n    分钟 值从 0 到 59.\n    小时 值从 0 到 23.\n    日 值从 1 到 31.\n    月 值从 1 到 12.\n    星期 值从 0 到 6, 0 代表星期日\n    多个时间可以用逗号隔开； 范围可以用连字符给出；*可以作为通配符； /表示每...\nconcurrencyPolicy:\n    Allow:   允许Jobs并发运行(默认)\n    Forbid:  禁止并发运行，如果上一次运行尚未完成，则跳过下一次运行\n    Replace: 替换，取消当前正在运行的作业并用新作业替换它\n\n# pc-cronjob.yaml\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: pc-cronjob\n  namespace: dev\n  labels:\n    controller: cronjob\nspec:\n  schedule: \"*/1 * * * *\"\n  jobTemplate:\n    metadata:\n    spec:\n      template:\n        spec:\n          restartPolicy: Never\n          containers:\n          - name: counter\n            image: busybox:1.30\n            command: [\"bin/sh\",\"-c\",\"for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done\"]\n\n# 创建cronjob\nkubectl create -f pc-cronjob.yaml\n# 查看cronjob\nkubectl get cronjobs -n dev\n# 查看job\nkubectl get jobs -n dev\n# 查看pod\nkubectl get pods -n dev\n# 删除cronjob\nkubectl  delete -f pc-cronjob.yaml\n\n7. Service详解7.1 Service介绍在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。\n\nService在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后它会将最新的Service信息转换成对应的访问规则。\n\n# 10.97.97.97:80 是service提供的访问入口\n# 当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用，\n# kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去\n# 这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点上访问都可以。\n[root@node1 ~]# ipvsadm -Ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.97.97.97:80 rr\n  -> 10.244.1.39:80               Masq    1      0          0\n  -> 10.244.1.40:80               Masq    1      0          0\n  -> 10.244.2.33:80               Masq    1      0          0\n\nkube-proxy目前支持三种工作模式:\nuserspace 模式userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。  该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。\n\niptables 模式iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。  该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。\n\nipvs 模式ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。\n\n# 此模式必须安装ipvs内核模块，否则会降级为iptables\n# 开启ipvs\n[root@k8s-master01 ~]# kubectl edit cm kube-proxy -n kube-system\n# 修改mode: \"ipvs\"\n[root@k8s-master01 ~]# kubectl delete pod -l k8s-app=kube-proxy -n kube-system\n[root@node1 ~]# ipvsadm -Ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.97.97.97:80 rr\n  -> 10.244.1.39:80               Masq    1      0          0\n  -> 10.244.1.40:80               Masq    1      0          0\n  -> 10.244.2.33:80               Masq    1      0          0\n\n7.2 Service类型Service的资源清单文件：\nkind: Service  # 资源类型\napiVersion: v1  # 资源版本\nmetadata: # 元数据\n  name: service # 资源名称\n  namespace: dev # 命名空间\nspec: # 描述\n  selector: # 标签选择器，用于确定当前service代理哪些pod\n    app: nginx\n  type: # Service类型，指定service的访问方式\n  clusterIP:  # 虚拟服务的ip地址\n  sessionAffinity: # session亲和性，支持ClientIP、None两个选项\n  ports: # 端口信息\n    - protocol: TCP \n      port: 3017  # service端口\n      targetPort: 5003 # pod端口\n      nodePort: 31122 # 主机端口\n\n\nClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问\nNodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务\nLoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持\nExternalName： 把集群外部的服务引入集群内部，直接使用\n\n7.3 Service使用7.3.1 实验环境准备在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置app=nginx-pod的标签\n# pc-deployment.yaml\napiVersion: apps/v1\nkind: Deployment      \nmetadata:\n  name: pc-deployment\n  namespace: dev\nspec: \n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        ports:\n        - containerPort: 80\n\n[root@k8s-master01 ~]# kubectl create -f pc-deployment.yaml\ndeployment.apps/pc-deployment created\n\n# 查看pod详情\n[root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels\nNAME                             READY   STATUS     IP            NODE     LABELS\npc-deployment-66cb59b984-8p84h   1/1     Running    10.244.1.39   node1    app=nginx-pod\npc-deployment-66cb59b984-vx8vx   1/1     Running    10.244.2.33   node2    app=nginx-pod\npc-deployment-66cb59b984-wnncx   1/1     Running    10.244.1.40   node1    app=nginx-pod\n\n# 为了方便后面的测试，修改下三台nginx的index.html页面（三台修改的IP地址不一致）\nsudo kubectl exec -it pc-deployment-5ffc5bf56c-sg76p -n dev /bin/sh\n echo \"1\" > /usr/share/nginx/html/index.html\n exit\nsudo kubectl exec -it pc-deployment-5ffc5bf56c-hzp79 -n dev /bin/sh\n echo \"2\" > /usr/share/nginx/html/index.html\n  exit\nsudo kubectl exec -it pc-deployment-5ffc5bf56c-46rht -n dev /bin/sh\n echo \"3\" > /usr/share/nginx/html/index.html\n  exit\n#修改完毕之后，访问测试\n[root@k8s-master01 ~]# curl 10.244.1.39\n10.244.1.39\n[root@k8s-master01 ~]# curl 10.244.2.33\n10.244.2.33\n[root@k8s-master01 ~]# curl 10.244.1.40\n10.244.1.40\n\n7.3.2 ClusterIP类型的Service# pc-service-clusterip.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-clusterip\n  namespace: dev\nspec:\n  selector:\n    app: nginx-pod\n  clusterIP: 10.96.97.97 # service的ip地址，如果不写，默认会生成一个\n  type: ClusterIP\n  ports:\n  - port: 80  # Service端口       \n    targetPort: 80 # pod端口\n\n# 创建service\n[root@k8s-master01 ~]# kubectl create -f pc-service-clusterip.yaml\nservice/service-clusterip created\n\n# 查看service\n[root@k8s-master01 ~]# kubectl get svc -n dev -o wide\nNAME                TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice-clusterip   ClusterIP   10.96.97.97   &lt;none>        80/TCP    13s   app=nginx-pod\n\n# 查看service的详细信息\n# 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口\n[root@k8s-master01 ~]# kubectl describe svc service-clusterip -n dev\nName:              service-clusterip\nNamespace:         dev\nLabels:            &lt;none>\nAnnotations:       &lt;none>\nSelector:          app=nginx-pod\nType:              ClusterIP\nIP:                10.97.97.97\nPort:              &lt;unset>  80/TCP\nTargetPort:        80/TCP\nEndpoints:         10.244.1.39:80,10.244.1.40:80,10.244.2.33:80\nSession Affinity:  None\nEvents:            &lt;none>\n\n# 查看ipvs的映射规则\n[root@k8s-master01 ~]# ipvsadm -Ln\nTCP  10.97.97.97:80 rr\n  -> 10.244.1.39:80               Masq    1      0          0\n  -> 10.244.1.40:80               Masq    1      0          0\n  -> 10.244.2.33:80               Masq    1      0          0\n\n# 访问10.97.97.97:80观察效果\n[root@k8s-master01 ~]# curl 10.97.97.97:80\n10.244.2.33\n\nEndpoint\nEndpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。\n一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，Endpoints是实现实际服务的端点集合。换句话说，service和pod之间的联系是通过endpoints实现的。\n\n负载分发策略\n对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：\n\n如果不定义，默认使用kube-proxy的策略，比如随机、轮询\n\n基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上\n此模式可以使在spec中添加sessionAffinity:ClientIP选项\n\n\nsudo kubectl get endpoints -n dev -o wide\n\n# 查看ipvs的映射规则【rr 轮询】\n[root@k8s-master01 ~]# ipvsadm -Ln\nTCP  10.97.97.97:80 rr\n  -> 10.244.1.39:80               Masq    1      0          0\n  -> 10.244.1.40:80               Masq    1      0          0\n  -> 10.244.2.33:80               Masq    1      0          0\n\n# 循环访问测试\n[root@k8s-master01 ~]# while true;do curl 10.96.97.97:80; sleep 1; done;\n10.244.1.40\n10.244.1.39\n10.244.2.33\n10.244.1.40\n10.244.1.39\n10.244.2.33\n\n# 修改分发策略----sessionAffinity:ClientIP\n# 查看ipvs规则【persistent 代表持久】\n[root@k8s-master01 ~]# ipvsadm -Ln\nTCP  10.97.97.97:80 rr persistent 10800\n  -> 10.244.1.39:80               Masq    1      0          0\n  -> 10.244.1.40:80               Masq    1      0          0\n  -> 10.244.2.33:80               Masq    1      0          0\n\n# 循环访问测试\n[root@k8s-master01 ~]# while true;do curl 192.168.150.136:30002; sleep 1; done;\n10.244.2.33\n10.244.2.33\n10.244.2.33\n  \n# 删除service\n[root@k8s-master01 ~]# kubectl delete -f service-clusterip.yaml\nservice \"service-clusterip\" deleted\n\n7.3.3 HeadLiness类型的Service在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。\n# service-headliness.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-headliness\n  namespace: dev\nspec:\n  selector:\n    app: nginx-pod\n  clusterIP: None # 将clusterIP设置为None，即可创建headliness Service\n  type: ClusterIP\n  ports:\n  - port: 80    \n    targetPort: 80\n\n# 创建service\n[root@k8s-master01 ~]# kubectl create -f service-headliness.yaml\nservice/service-headliness created\n\n# 获取service， 发现CLUSTER-IP未分配\n[root@k8s-master01 ~]# kubectl get svc service-headliness -n dev -o wide\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice-headliness   ClusterIP   None         &lt;none>        80/TCP    11s   app=nginx-pod\n\n# 查看service详情\n[root@k8s-master01 ~]# kubectl describe svc service-headliness  -n dev\nName:              service-headliness\nNamespace:         dev\nLabels:            &lt;none>\nAnnotations:       &lt;none>\nSelector:          app=nginx-pod\nType:              ClusterIP\nIP:                None\nPort:              &lt;unset>  80/TCP\nTargetPort:        80/TCP\nEndpoints:         10.244.1.39:80,10.244.1.40:80,10.244.2.33:80\nSession Affinity:  None\nEvents:            &lt;none>\n\n# 查看域名的解析情况\n[root@k8s-master01 ~]# kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh\n/ # cat /etc/resolv.conf\nnameserver 10.96.0.10\nsearch dev.svc.cluster.local svc.cluster.local cluster.local\n\n[root@k8s-master01 ~]# dig @10.96.0.10 service-headliness.dev.svc.cluster.local\nservice-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.40\nservice-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.39\nservice-headliness.dev.svc.cluster.local. 30 IN A 10.244.2.33\n\n7.3.4 NodePort类型的Service在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是将service的端口映射到Node的一个端口上，然后就可以通过NodeIp:NodePort来访问service了。\n\n# pc-service-nodeport.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-nodeport\n  namespace: dev\nspec:\n  selector:\n    app: nginx-pod\n  type: NodePort # service类型\n  ports:\n  - port: 80\n    nodePort: 30002 # 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配\n    targetPort: 80\n\n# 创建service\n[root@k8s-master01 ~]# kubectl create -f pc-service-nodeport.yaml\nservice/service-nodeport created\n\n# 查看service\n[root@k8s-master01 ~]# kubectl get svc -n dev -o wide\nNAME               TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)       SELECTOR\nservice-nodeport   NodePort   10.105.64.191   &lt;none>        80:30002/TCP  app=nginx-pod\n\n# 接下来可以通过电脑主机的浏览器去访问集群中任意一个nodeip的30002端口，即可访问到pod\n\n7.3.5 LoadBalancer类型的ServiceLoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。\n\n7.3.6 ExternalName类型的ServiceExternalName类型的Service用于引入集群外部的服务，它通过externalName属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: service-externalname\n  namespace: dev\nspec:\n  type: ExternalName # service类型\n  externalName: www.baidu.com  #改成ip地址也可以\n\n# 创建service\n[root@k8s-master01 ~]# kubectl  create -f service-externalname.yaml\nservice/service-externalname created\n\n# 域名解析\n[root@k8s-master01 ~]# dig @10.96.0.10 service-externalname.dev.svc.cluster.local\nservice-externalname.dev.svc.cluster.local. 30 IN CNAME www.baidu.com.\nwww.baidu.com.          30      IN      CNAME   www.a.shifen.com.\nwww.a.shifen.com.       30      IN      A       39.156.66.18\nwww.a.shifen.com.       30      IN      A       39.156.66.14\n\n\n\n\n\n7.4 Ingress介绍在前面课程中已经提到，Service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点：\n\nNodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显\nLB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持\n\n基于这种现状，kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示：\n\n实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务。在这里有两个核心概念：\n\ningress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则\ningress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等\n\nIngress（以Nginx为例）的工作原理如下：\n\n用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service\nIngress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置\nIngress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新\n到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则\n\n\n7.5 Ingress使用7.5.1 环境准备搭建ingress环境kubectl apply -f ingress-control.yaml\nkubectl get pod -n ingress-nginx\n# 查看service\nkubectl get svc -n ingress-nginx\n\n准备service和pod为了后面的实验比较方便，创建如下图所示的模型\n\n# tomcat-nginx.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: dev\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.17.1\n        ports:\n        - containerPort: 80\n\n---\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tomcat-deployment\n  namespace: dev\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: tomcat-pod\n  template:\n    metadata:\n      labels:\n        app: tomcat-pod\n    spec:\n      containers:\n      - name: tomcat\n        image: tomcat:8.5-jre10-slim\n        ports:\n        - containerPort: 8080\n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\n  namespace: dev\nspec:\n  selector:\n    app: nginx-pod\n  clusterIP: None\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: 80\n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: tomcat-service\n  namespace: dev\nspec:\n  selector:\n    app: tomcat-pod\n  clusterIP: None\n  type: ClusterIP\n  ports:\n  - port: 8080\n    targetPort: 8080\n\n7.5.2 Http代理# pc-ingress-http.yaml\n# kubectl explain Ingress.spec.rules.http.paths.backend.service\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-http\n  namespace: dev\nspec:\n  rules:\n  - host: nginx.itheima.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx-service\n            port: \n              number: 80\n  - host: tomcat.itheima.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: tomcat-service\n            port: \n              number: 8080\n\n# 创建\nkubectl apply -f pc-ingress-http.yaml\n# 查看\nsudo kubectl get ing ingress-http -n dev\n# 查看详情\nsudo kubectl describe ing ingress-http  -n dev\n# 注意看上面的Address栏\n\n7.5.3 Https代理创建证书# 生成证书\nopenssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/C=CN/ST=BJ/L=BJ/O=nginx/CN=itheima.com\"\n\n# 创建密钥\nkubectl create secret tls tls-secret --key tls.key --cert tls.crt\n\n# ingress-https.yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-https\n  namespace: dev\nspec:\n  tls:\n    - hosts:\n      - nginx.itheima.com\n      - tomcat.itheima.com\n      secretName: tls-secret # 指定秘钥\n  rules:\n  - host: nginx.itheima.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: nginx-service\n          servicePort: 80\n  - host: tomcat.itheima.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: tomcat-service\n          servicePort: 8080\n\n# 创建\nkubectl create -f ingress-https.yaml\n# 查看\nkubectl get ing ingress-https -n dev\n# 查看详情\nkubectl describe ing ingress-https -n dev\n\n8. 数据存储为了持久化保存容器的数据，kubernetes引入了Volume的概念。\nVolume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。\nkubernetes的Volume支持多种类型，比较常见的有下面几个：\n\n简单存储：EmptyDir、HostPath、NFS\n高级存储：PV、PVC\n配置存储：ConfigMap、Secret\n\n8.1 基本存储8.1.1 EmptyDirEmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。\nEmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：\n\n临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留\n一个容器需要从另一个容器中获取数据的目录（多容器共享目录）\n\n接下来，通过一个容器之间文件共享的案例来使用一下EmptyDir。\n在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。\n\n# volume-emptydir.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: volume-emptydir\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports:\n    - containerPort: 80\n    volumeMounts:  # 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx\n    - name: logs-volume\n      mountPath: /var/log/nginx\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] # 初始命令，动态读取指定文件中内容\n    volumeMounts:  # 将logs-volume 挂在到busybox容器中，对应的目录为 /logs\n    - name: logs-volume\n      mountPath: /logs\n  volumes: # 声明volume， name为logs-volume，类型为emptyDir\n  - name: logs-volume\n    emptyDir: &#123;&#125;\n\n# 创建Pod\nkubectl create -f volume-emptydir.yaml\n# 查看pod\nkubectl get pods volume-emptydir -n dev -o wide\n# 通过podIp访问nginx\ncurl 10.42.2.9\n# 通过kubectl logs命令查看指定容器的标准输出\nkubectl logs -f volume-emptydir -n dev -c busybox\n\n\n\n8.1.2 HostPathHostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。\n\n# volume-hostpath.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: volume-hostpath\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports:\n    - containerPort: 80\n    volumeMounts:\n    - name: logs-volume\n      mountPath: /var/log/nginx\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"]\n    volumeMounts:\n    - name: logs-volume\n      mountPath: /logs\n  volumes:\n  - name: volume\n    persistentVolumeClaim:\n      claimName: pvc1\n      readOnly: false\n  - name: logs-volume\n    hostPath: \n      path: /root/logs\n      type: DirectoryOrCreate  # 目录存在就使用，不存在就先创建后使用\n\n# sudo kubectl apply -f volume-hostpath.yaml\n关于type的值的一点说明：\n    DirectoryOrCreate 目录存在就使用，不存在就先创建后使用\n    Directory   目录必须存在\n    FileOrCreate  文件存在就使用，不存在就先创建后使用\n    File 文件必须存在 \n    Socket  unix套接字必须存在\n    CharDevice  字符设备必须存在\n    BlockDevice 块设备必须存在\n\n\n\n8.1.3 NFSHostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。\nNFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。\n\nnfs安装见 Linux环境配置\n\n# volume-nfs.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: volume-nfs\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    ports:\n    - containerPort: 80\n    volumeMounts:\n    - name: logs-volume\n      mountPath: /var/log/nginx\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] \n    volumeMounts:\n    - name: logs-volume\n      mountPath: /logs\n  volumes:\n  - name: logs-volume\n    nfs:\n      server: 192.168.5.6  #nfs服务器地址\n      path: /root/data/nfs #共享文件路径\n\n# 查看主节点挂载目录\nshowmount -e\n# 创建pod\nkubectl create -f volume-nfs.yaml\n# 查看pod\nkubectl get pods volume-nfs -n dev\n# 查看nfs服务器上的共享目录，发现已经有文件了\nls /root/data/\n\n8.2 高级存储PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。\nPVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。\n\n使用了PV和PVC之后，工作可以得到进一步的细分：\n\n存储：存储工程师维护\nPV： kubernetes管理员维护\nPVC：kubernetes用户维护\n\n8.2.1 PVPV是存储资源的抽象，下面是资源清单文件:\napiVersion: v1  \nkind: PersistentVolume\nmetadata:\n  name: pv2\nspec:\n  nfs: # 存储类型，与底层真正存储对应\n  capacity:  # 存储能力，目前只支持存储空间的设置\n    storage: 2Gi\n  accessModes:  # 访问模式\n  storageClassName: # 存储类别\n  persistentVolumeReclaimPolicy: # 回收策略\n\nPV 的关键配置参数说明：\n\n存储类型\n底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异\n\n存储能力（capacity）\n\n\n目前只支持存储空间的设置( storage&#x3D;1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置\n\n访问模式（accessModes）\n用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：\n\nReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载\nReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载\nReadWriteMany（RWX）：读写权限，可以被多个节点挂载\n\n需要注意的是，底层不同的存储类型可能支持的访问模式不同\n\n回收策略（persistentVolumeReclaimPolicy）\n当PV不再被使用了之后，对其的处理方式。目前支持三种策略：\n\nRetain （保留） 保留数据，需要管理员手工清理数据\nRecycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf &#x2F;thevolume&#x2F;*\nDelete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务\n\n需要注意的是，底层不同的存储类型可能支持的回收策略不同\n\n存储类别\nPV可以通过storageClassName参数指定一个存储类别\n\n具有特定类别的PV只能与请求了该类别的PVC进行绑定\n未设定类别的PV则只能与不请求任何类别的PVC进行绑定\n\n\n状态（status）\n一个 PV 的生命周期中，可能会处于4中不同的阶段：\n\nAvailable（可用）： 表示可用状态，还未被任何 PVC 绑定\nBound（已绑定）： 表示 PV 已经被 PVC 绑定\nReleased（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明\nFailed（失败）： 表示该 PV 的自动回收失败\n\n\n\n实验\n使用NFS作为存储，来演示PV的使用，创建3个PV，对应NFS中的3个暴露的路径。\n\n准备NFS环境\n\n# 创建目录\nmkdir /nfs/test/&#123;pv1,pv2,pv3&#125; -pv\n\n# 暴露服务\ncat >  /etc/exports &lt;&lt;EOF  # 覆盖写！\n/nfs/test/pv1     192.168.150.0/24(rw,no_root_squash)\n/nfs/test/pv2     192.168.150.0/24(rw,no_root_squash)\n/nfs/test/pv3     192.168.150.0/24(rw,no_root_squash)\n/nfs/data  *(rw,async,no_root_squash)\nEOF\nsystemctl restart nfs\nservice nfs status\necho \"/nfs/data/ 192.168.150.0/24(insecure,rw,sync,no_root_squash)\"  >> /etc/exports  #追加写\n\nsystemctl status rpcbind\nsystemctl status nfs\n\numount /nfs/data\nmount -t nfs 192.168.150.135:/nfs/data /nfs/data\n\n\n创建\n\n# pv-test001.yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name:  pv1\n  labels:\n    number: pv1\nspec:\n  capacity: \n    storage: 1Gi\n  accessModes:\n  - ReadWriteMany\n  nfs:\n    path: /nfs/test/pv1\n    server: 192.168.150.135\n\n---\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name:  pv2\n  labels:\n    number: pv2\nspec:\n  capacity: \n    storage: 2Gi\n  accessModes:\n  - ReadWriteMany\n  nfs:\n    path: /nfs/test/pv2\n    server: 192.168.150.135\n    \n---\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name:  pv3\n  labels:\n    number: pv3\nspec:\n  capacity: \n    storage: 3Gi\n  accessModes:\n  - ReadWriteMany\n  nfs:\n    path: /nfs/test/pv3\n    server: 192.168.150.135\n\n# 创建 pv\nsudo kubectl apply -f pv-test001.yaml\n# 查看pv\nkubectl get pv -o wide\n\n8.2.2 PVCPVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc\n  namespace: dev\nspec:\n  accessModes: # 访问模式\n  selector: # 采用标签对PV选择\n  storageClassName: # 存储类别\n  resources: # 请求空间\n    requests:\n      storage: 5Gi\n\nPVC 的关键配置参数说明：\n\n访问模式（accessModes）\n\n用于描述用户应用对存储资源的访问权限\n\n选择条件（selector）\n通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选\n\n存储类别（storageClassName）\nPVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出\n\n资源请求（Resources ）\n描述对存储资源的请求\n\n\n实验\n# pvc-test001.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc1\n  namespace: dev\nspec:\n  accessModes: \n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi \n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc2\n  namespace: dev\nspec:\n  accessModes: \n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc3\n  namespace: dev\nspec:\n  accessModes: \n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi\n\n# 创建pvc\nsudo kubectl apply -f pvc-test001.yaml\n# 查看pvc\nsudo kubectl get pvc  -n dev -o wide\n# 查看pv\nsudo kubectl get pv -o wide\n\n# pods-test001.yaml  使用pvc\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod1\n  namespace: dev\nspec:\n  containers:\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"while true;do echo pod1 >> /root/out.txt; sleep 1; done;\"]\n    volumeMounts:\n    - name: volume\n      mountPath: /root\n  volumes:\n    - name: volume\n      persistentVolumeClaim:\n        claimName: pvc1\n        readOnly: false\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod2\n  namespace: dev\nspec:\n  containers:\n  - name: busybox\n    image: busybox:1.30\n    command: [\"/bin/sh\",\"-c\",\"while true;do echo pod2 >> /root/out.txt; sleep 1; done;\"]\n    volumeMounts:\n    - name: volume\n      mountPath: /root\n  volumes:\n    - name: volume\n      persistentVolumeClaim:\n        claimName: pvc2\n        readOnly: false\n\nkubectl exec -it pod1 -n dev -- /bin/bash \n\n# 创建pod\nsudo kubectl apply -f pods-test001.yaml\n# 查看pod\nkubectl get pods -n dev -o wide\n# 查看pvc\nkubectl get pvc -n dev -o yaml\n# 查看pv挂载路径\nsudo kubectl get pv pvc-9c9e200c-259a-4652-8a35-ab19927447b4  -o yaml | grep path\n# 查看所有 path\nsudo kubectl get pv -o yaml | grep path | grep &lt;pvc-name>\n\n\n\n8.2.3 生命周期\n8.3 配置存储8.3.1 ConfigMapConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。\n# pc-configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: configmap\n  namespace: dev\ndata:\n  info: |\n    username:admin\n    password:123456\n\n# 创建configmap\nsudo kubectl create -f pc-configmap.yaml\n# 查看configmap详情\nsudo kubectl describe cm configmap -n dev\n\n# pod-configmap.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-configmap\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    volumeMounts: # 将configmap挂载到目录\n    - name: config\n      mountPath: /configmap/config\n  volumes: # 引用configmap\n  - name: config\n    configMap:\n      name: configmap\n\n# 创建pod\nsudo kubectl create -f pod-configmap.yaml\n# 查看pod\nkubectl get pod pod-configmap -n dev\n#进入容器\nsudo kubectl exec -it pod-configmap -n dev /bin/sh\ncd /configmap/config/\nls\ncat info\n# info\nusername:admin\npassword:123456\n# 可以看到映射已经成功，每个configmap都映射成了一个目录\n# key--->文件     value---->文件中的内容\n# 此时如果更新configmap的内容, 容器中的值也会动态更新\n\n8.3.2 Secret在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。\n\n首先使用base64对数据进行编码\n\necho -n 'admin' | base64 #准备username\n# YWRtaW4=\necho -n '123456' | base64 #准备password\n# MTIzNDU2\n\n\n接下来编写secret.yaml，并创建Secret\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: secret\n  namespace: dev\ntype: Opaque\ndata:\n  username: YWRtaW4=\n  password: MTIzNDU2\n\n# 创建secret\nkubectl create -f secret.yaml\n# 查看secret详情\nkubectl describe secret secret -n dev\n\n\n创建pod-secret.yaml，将上面创建的secret挂载进去：\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-secret\n  namespace: dev\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.17.1\n    volumeMounts: # 将secret挂载到目录\n    - name: config\n      mountPath: /secret/config\n  volumes:\n  - name: config\n    secret:\n      secretName: secret\n\n# 创建pod\nkubectl create -f pod-secret.yaml\n# 查看pod\nkubectl get pod pod-secret -n dev\n# 进入容器，查看secret信息，发现已经自动解码了\nkubectl exec -it pod-secret /bin/sh -n dev\nls /secret/config/\n# password  username\nmore /secret/config/username\n# admin\nmore /secret/config/password\n# 123456\n\n至此，已经实现了利用secret实现了信息的编码。\n9. 安全认证9.1 访问控制概述Kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对Kubernetes的各种客户端进行认证和鉴权操作。\n客户端\n在Kubernetes集群中，客户端通常有两类：\n\nUser Account：一般是独立于kubernetes之外的其他服务管理的用户账号。\nService Account：kubernetes管理的账号，用于为Pod中的服务进程在访问Kubernetes时提供身份标识。\n\n\n认证、授权与准入控制\nApiServer是访问及管理资源对象的唯一入口。任何一个请求访问ApiServer，都要经过下面三个流程：\n\nAuthentication（认证）：身份鉴别，只有正确的账号才能够通过认证\nAuthorization（授权）： 判断用户是否有权限对访问的资源执行特定的动作\nAdmission Control（准入控制）：用于补充授权机制以实现更加精细的访问控制功能。\n\n\n9.2 认证管理Kubernetes集群安全的最关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式：\n\nHTTP Base认证：通过用户名+密码的方式认证\n这种认证方式是把“用户名:密码”用BASE64算法进行编码后的字符串放在HTTP请求中的Header Authorization域里发送给服务端。服务端收到后进行解码，获取用户名及密码，然后进行用户身份认证的过程。\n\nHTTP Token认证：通过一个Token来识别合法用户\n这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求时，需要在HTTP Header里放入Token，API Server接到Token后会跟服务器中保存的token进行比对，然后进行用户身份认证的过程。\n\nHTTPS证书认证：基于CA根证书签名的双向数字证书认证方式\n这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式。\n\n\nHTTPS认证大体分为3个过程：\n\n证书申请和下发\nHTTPS通信双方的服务器向CA机构申请证书，CA机构下发根证书、服务端证书及私钥给申请者\n\n客户端和服务端的双向认证\n1&gt; 客户端向服务器端发起请求，服务端下发自己的证书给客户端，\n   客户端接收到证书后，通过私钥解密证书，在证书中获得服务端的公钥，\n   客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器\n2&gt; 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书，\n   在证书中获得客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法\n\n服务器端和客户端进行通信\n服务器端和客户端协商好加密方案后，客户端会产生一个随机的秘钥并加密，然后发送到服务器端。\n服务器端接收这个秘钥后，双方接下来通信的所有内容都通过该随机秘钥加密\n\n\n\n\n\n\n\n\n\n\n注意: Kubernetes允许同时配置多种认证方式，只要其中任意一个方式认证通过即可\n9.3 授权管理授权发生在认证成功之后，通过认证就可以知道请求用户是谁， 然后Kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权。\n每个发送到ApiServer的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。\nAPI Server目前支持以下几种授权策略：\n\nAlwaysDeny：表示拒绝所有请求，一般用于测试\nAlwaysAllow：允许接收所有请求，相当于集群不需要授权流程（Kubernetes默认的策略）\nABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制\nWebhook：通过调用外部REST服务对用户进行授权\nNode：是一种专用模式，用于对kubelet发出的请求进行访问控制\nRBAC：基于角色的访问控制（kubeadm安装方式下的默认选项）\n\nRBAC(Role-Based Access Control) 基于角色的访问控制，主要是在描述一件事情：给哪些对象授予了哪些权限\n其中涉及到了下面几个概念：\n\n对象：User、Groups、ServiceAccount\n角色：代表着一组定义在资源上的可操作动作(权限)的集合\n绑定：将定义好的角色跟用户绑定在一起\n\n\nRBAC引入了4个顶级资源对象：\n\nRole、ClusterRole：角色，用于指定一组权限\nRoleBinding、ClusterRoleBinding：角色绑定，用于将角色（权限）赋予给对象\n\nRole、ClusterRole\n一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单）。\n# Role只能对命名空间内的资源进行授权，需要指定nameapce\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  namespace: dev\n  name: authorization-role\nrules:\n- apiGroups: [\"\"]  # 支持的API组列表,\"\" 空字符串，表示核心API群\n  resources: [\"pods\"] # 支持的资源对象列表\n  verbs: [\"get\", \"watch\", \"list\"] # 允许的对资源对象的操作方法列表\n\n# ClusterRole可以对集群范围内资源、跨namespaces的范围资源、非资源类型进行授权\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: authorization-clusterrole\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n\n需要详细说明的是，rules中的参数：\n\napiGroups: 支持的API组列表\n&quot;&quot;,&quot;apps&quot;, &quot;autoscaling&quot;, &quot;batch&quot;\n\nresources：支持的资源对象列表\n&quot;services&quot;, &quot;endpoints&quot;, &quot;pods&quot;,&quot;secrets&quot;,&quot;configmaps&quot;,&quot;crontabs&quot;,&quot;deployments&quot;,&quot;jobs&quot;,\n&quot;nodes&quot;,&quot;rolebindings&quot;,&quot;clusterroles&quot;,&quot;daemonsets&quot;,&quot;replicasets&quot;,&quot;statefulsets&quot;,\n&quot;horizontalpodautoscalers&quot;,&quot;replicationcontrollers&quot;,&quot;cronjobs&quot;\n\nverbs：对资源对象的操作方法列表\n&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;, &quot;exec&quot;\n\nRoleBinding、ClusterRoleBinding\n角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount。\n# RoleBinding可以将同一namespace中的subject绑定到某个Role下，则此subject即具有该Role定义的权限\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: authorization-role-binding\n  namespace: dev\nsubjects:\n- kind: User\n  name: heima\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: authorization-role\n  apiGroup: rbac.authorization.k8s.io\n\n# ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: authorization-clusterrole-binding\nsubjects:\n- kind: User\n  name: heima\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: authorization-clusterrole\n  apiGroup: rbac.authorization.k8s.io\n\nRoleBinding引用ClusterRole进行授权\nRoleBinding可以引用ClusterRole，对属于同一命名空间内ClusterRole定义的资源主体进行授权。\n一种很常用的做法就是，集群管理员为集群范围预定义好一组角色（ClusterRole），然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅提高授权管理工作效率，也使得各个命名空间下的基础性授权规则与使用体验保持一致。\n\n# 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding\n# 所以heima只能读取dev命名空间中的资源\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: authorization-role-binding-ns\n  namespace: dev\nsubjects:\n- kind: User\n  name: heima\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: authorization-clusterrole\n  apiGroup: rbac.authorization.k8s.io\n\n实战：创建一个只能管理dev空间下Pods资源的账号\n\n创建账号\n\n# 1) 创建证书\n[root@k8s-master01 pki]# cd /etc/kubernetes/pki/\n[root@k8s-master01 pki]# (umask 077;openssl genrsa -out devman.key 2048)\n\n# 2) 用apiserver的证书去签署\n# 2-1) 签名申请，申请的用户是devman,组是devgroup\n[root@k8s-master01 pki]# openssl req -new -key devman.key -out devman.csr -subj \"/CN=devman/O=devgroup\"     \n# 2-2) 签署证书\n[root@k8s-master01 pki]# openssl x509 -req -in devman.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out devman.crt -days 3650\n\n# 3) 设置集群、用户、上下文信息\n[root@k8s-master01 pki]# kubectl config set-cluster kubernetes --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server=https://192.168.109.100:6443\n\n[root@k8s-master01 pki]# kubectl config set-credentials devman --embed-certs=true --client-certificate=/etc/kubernetes/pki/devman.crt --client-key=/etc/kubernetes/pki/devman.key\n\n[root@k8s-master01 pki]# kubectl config set-context devman@kubernetes --cluster=kubernetes --user=devman\n\n# 切换账户到devman\n[root@k8s-master01 pki]# kubectl config use-context devman@kubernetes\nSwitched to context \"devman@kubernetes\".\n\n# 查看dev下pod，发现没有权限\n[root@k8s-master01 pki]# kubectl get pods -n dev\nError from server (Forbidden): pods is forbidden: User \"devman\" cannot list resource \"pods\" in API group \"\" in the namespace \"dev\"\n\n# 切换到admin账户\n[root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes\nSwitched to context \"kubernetes-admin@kubernetes\".\n\n2） 创建Role和RoleBinding，为devman用户授权\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  namespace: dev\n  name: dev-role\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n  \n---\n\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: authorization-role-binding\n  namespace: dev\nsubjects:\n- kind: User\n  name: devman\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: dev-role\n  apiGroup: rbac.authorization.k8s.io\n\n[root@k8s-master01 pki]# kubectl create -f dev-role.yaml\nrole.rbac.authorization.k8s.io/dev-role created\nrolebinding.rbac.authorization.k8s.io/authorization-role-binding created\n\n\n切换账户，再次验证\n\n# 切换账户到devman\n[root@k8s-master01 pki]# kubectl config use-context devman@kubernetes\nSwitched to context \"devman@kubernetes\".\n\n# 再次查看\n[root@k8s-master01 pki]# kubectl get pods -n dev\nNAME                                 READY   STATUS             RESTARTS   AGE\nnginx-deployment-66cb59b984-8wp2k    1/1     Running            0          4d1h\nnginx-deployment-66cb59b984-dc46j    1/1     Running            0          4d1h\nnginx-deployment-66cb59b984-thfck    1/1     Running            0          4d1h\n\n# 为了不影响后面的学习,切回admin账户\n[root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes\nSwitched to context \"kubernetes-admin@kubernetes\".\n\n9.4 准入控制通过了前面的认证和授权之后，还需要经过准入控制处理通过之后，apiserver才会处理这个请求。\n准入控制是一个可配置的控制器列表，可以通过在Api-Server上通过命令行设置选择执行哪些准入控制器：\n--admission-control&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,\n                      DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds\n\n只有当所有的准入控制器都检查通过之后，apiserver才执行该请求，否则返回拒绝。\n当前可配置的Admission Control准入控制如下：\n\nAlwaysAdmit：允许所有请求\nAlwaysDeny：禁止所有请求，一般用于测试\nAlwaysPullImages：在启动容器之前总去下载镜像\nDenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求\nImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能。\nService Account：实现ServiceAccount实现了自动化\nSecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效\nResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标\nLimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制\nInitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置\nNamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒绝。当删除一个namespace时，系统将会删除该namespace中所有对象。\nDefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认的StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节\nDefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min\nPodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制\n\n10. DashBoard之前在kubernetes中完成的所有操作都是通过命令行工具kubectl完成的。其实，为了提供更丰富的用户体验，kubernetes还开发了一个基于web的用户界面（Dashboard）。用户可以使用Dashboard部署容器化的应用，还可以监控应用的状态，执行故障排查以及管理kubernetes中各种资源。\n10.1 部署Dashboard\n下载yaml，并运行Dashboard\n\n# 下载yaml\n[root@k8s-master01 ~]# wget  https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml\n\n# 修改kubernetes-dashboard的Service类型\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  type: NodePort  # 新增\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30009  # 新增\n  selector:\n    k8s-app: kubernetes-dashboard\n\n# 部署\n[root@k8s-master01 ~]# kubectl create -f recommended.yaml\n\n# 查看namespace下的kubernetes-dashboard下的资源\n[root@k8s-master01 ~]# kubectl get pod,svc -n kubernetes-dashboard\nNAME                                            READY   STATUS    RESTARTS   AGE\npod/dashboard-metrics-scraper-c79c65bb7-zwfvw   1/1     Running   0          111s\npod/kubernetes-dashboard-56484d4c5-z95z5        1/1     Running   0          111s\n\nNAME                               TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)         AGE\nservice/dashboard-metrics-scraper  ClusterIP  10.96.89.218    &lt;none>       8000/TCP        111s\nservice/kubernetes-dashboard       NodePort   10.104.178.171  &lt;none>       443:30009/TCP   111s\n\n2）创建访问账户，获取token\n# 创建账号\n[root@k8s-master01-1 ~]# kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard\n\n# 授权\n[root@k8s-master01-1 ~]# kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin\n\n# 获取账号token\n[root@k8s-master01 ~]#  kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin\ndashboard-admin-token-xbqhh        kubernetes.io/service-account-token   3      2m35s\n\n[root@k8s-master01 ~]# kubectl describe secrets dashboard-admin-token-xbqhh -n kubernetes-dashboard\nName:         dashboard-admin-token-xbqhh\nNamespace:    kubernetes-dashboard\nLabels:       &lt;none>\nAnnotations:  kubernetes.io/service-account.name: dashboard-admin\n              kubernetes.io/service-account.uid: 95d84d80-be7a-4d10-a2e0-68f90222d039\n\nType:  kubernetes.io/service-account-token\n\nData\n====\nnamespace:  20 bytes\ntoken:      eyJhbGciOiJSUzI1NiIsImtpZCI6ImJrYkF4bW5XcDhWcmNGUGJtek5NODFuSXl1aWptMmU2M3o4LTY5a2FKS2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4teGJxaGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOTVkODRkODAtYmU3YS00ZDEwLWEyZTAtNjhmOTAyMjJkMDM5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.NAl7e8ZfWWdDoPxkqzJzTB46sK9E8iuJYnUI9vnBaY3Jts7T1g1msjsBnbxzQSYgAG--cV0WYxjndzJY_UWCwaGPrQrt_GunxmOK9AUnzURqm55GR2RXIZtjsWVP2EBatsDgHRmuUbQvTFOvdJB4x3nXcYLN2opAaMqg3rnU2rr-A8zCrIuX_eca12wIp_QiuP3SF-tzpdLpsyRfegTJZl6YnSGyaVkC9id-cxZRb307qdCfXPfCHR_2rt5FVfxARgg_C0e3eFHaaYQO7CitxsnIoIXpOFNAR8aUrmopJyODQIPqBWUehb7FhlU1DCduHnIIXVC_UICZ-MKYewBDLw\nca.crt:     1025 bytes\n\n3）通过浏览器访问Dashboard的UI\n在登录页面上输入上面的token\n\n出现下面的页面代表成功\n\n10.2 使用DashBoard本章节以Deployment为例演示DashBoard的使用\n查看\n选择指定的命名空间dev，然后点击Deployments，查看dev空间下的所有deployment\n\n扩缩容\n在Deployment上点击规模，然后指定目标副本数量，点击确定\n\n编辑\n在Deployment上点击编辑，然后修改yaml文件，点击确定\n\n查看Pod\n点击Pods, 查看pods列表\n\n操作Pod\n选中某个Pod，可以对其执行日志（logs）、进入执行（exec）、编辑、删除操作\n\n\n\n\n\n\n\n\n\n\nDashboard提供了kubectl的绝大部分功能，这里不再一一演示\n","slug":"Kubernetes入门","date":"2022-09-30T09:46:09.000Z","categories_index":"","tags_index":"k8s,devops","author_index":"JuneQQQ"},{"id":"cfe9c60f951ff43b26c629865afffd67","title":"JVM内存与垃圾回收","content":"内存与垃圾回收篇\n\n\n类加载子系统\n\n类加载器子系统负责从文件系统或者网络中加载Class文件，class文件在文件开头有特定的文件表示。\nClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定\n加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射）\n\n类加载器ClassLoader角色\n\nclass file 存在于本地硬盘上，可以理解为设计师画在纸上的模块，而最终这个模板在执行时是要加载到JVM当中来根据这个文件实例化出n个一模一样的实例。\nclass file 加载到JVM中，被称为DNA元数据模板，放在方法区\n在 .class 文件 -&gt; JVM -&gt; 最终成为元数据模板，此过程就要一个运输工具（类装载器 ClassLoader），扮演一个快递员的角色\n\n类加载过程\n加载\n通过一个类的全限定类名定义此类的二进制字节流\n将这个字节流所代表的的静态存储结构转化为方法区的运行时数据结构\n在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n\n补充：加载 .class 文件的方式\n\n从本地系统中直接加载\n通过网络获取，典型场景：Web Applet\n从zip压缩包中读取，成为日后jar、war格式的基础\n运行时计算生成，使用最多的是：动态代理技术\n由其他文件生产，典型场景：JSP应用\n从专有数据库中提取 .class 文件，比较少见\n从加密文件中获取，典型的防class文件被反编译的保护措施\n\n链接\n初始化\n初始化阶段就是执行类构造器方法( )的过程。\n此方法不需要定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来\n构造器方法中的指令语句在原文件中出现的顺序执行\n( )不同于类的构造器。（关联：构造器是虚拟机视角下的( ) ）\n若该类具有父类，JVM会保证子类的( ) 执行前，父类的( )已经执行完毕。\n虚拟机必须保证一个类的( ) 方法在多线程下被同步加锁\n\npublic class Test1 &#123;\n  \tprivate int num0 = 0; // 实例变量\n    private static int num1 = 1; // 静态变量\n    static &#123;\n        num1 = 2;\n        num2 = 10;\n        System.out.println(num1);\n//        System.out.println(num2); 非法的前项引用\n    &#125;\n    private static int num2 = 20;\n// num2 -> (链接-prepare)0 -> (初始化) 10(从上到下执行) -> 20(从上到下执行)\n\n    public static void main(String[] args) &#123;\n        System.out.println(Test1.num1);\n        System.out.println(Test1.num2);\n    &#125;\n&#125;\n\n\n\n类加载器分类\n\nJVM支持两种类型的类加载器，分别为引导类加载器（Bootstrap ClassLoader）和自定义类加载器（User-Defined ClassLoader）\n从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类加载器，但是Java虚拟机规范却没有这么定义，而是将所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器。\n无论类加载器的类型如何划分，在程序中我们最常见的类加载器始终只有3个，如下图所示：\n\n虚拟机自带的加载器\n启动类加载器（引导类加载器，Bootstrap ClassLoader）\n\n这个类加载器使用C&#x2F;C++语言实现，嵌套在JVM内部\n它用来加载Java的核心库（JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar、resources.jar 或 sun.boot.class.path路径下的内容），用于提供JVM自身需要的类\n并不需要继承自java.lang.ClassLoader，没有父加载器\n加载扩展类和应用程序类加载器，并指定为他们的父类加载器。\n出去安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun开头的类\n\n\n扩展类加载器（Extension ClassLoader）\n\nJava语言编写，由sun.misc.Launcher$ExtClassLoader实现\n派生于ClassLoader类\n父类加载器为引导类加载器\n从java.ext.dirs系统属性指定的目录中加载类库，或从JDK的安装目录jre&#x2F;lib&#x2F;ext子目录（扩展目录）下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。\n\n\n应用程序类加载器（系统类加载器 ，AppClassLoader）\n\nJava语言编写，由sun.misc.Launcher$AppClassLoader实现\n派生于ClassLoader类\n父类加载器为扩展类加载器\n该类加载器是程序中默认的了加载器，一般来说，Java应用的类都是由它来完成加载\n通过ClassLoader#getSystemClassLoader( )方法可以获取到该类加载器\n\n\n\n用户自定义加载器\n在Java的日常应用程序开发中，类的加载几乎是有上述3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来制定类的加载方式\n为什么要自定义类加载器？\n隔离加载类\n修改类加载方式\n扩展加载源\n防止源码泄露\n\n\n如何自定义加载器？\n继承 java.lang.ClassLoader 类\n在JDK1.2之前，在自定义类加载器时，总会去继承ClassLoader类并重写loadCloass( )方法，从而实现自定义的类加载，但JDK1.2之后已不建议重写该方法，而是建议把自定义的类加载逻辑写在findClass( )方法中\n在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写 findClass( )方法及其获取字节码流的方式，使自定义类加载器编写更加简洁\n\n\n\n关于ClassLoaderClassLoader是一个抽象类，其后所有的类加载器都继承自ClassLoader（不包括启动类加载器）\n\n\n\n方法名称\n描述\n\n\n\ngetParent( )\n返回该类加载器的超类加载器\n\n\nloadClass(String name)\n加载名为 name 的类，返回结果为 java.lang.Class 类的实例\n\n\nfindClass(String name)\n查找名为 name 的类，返回结果为 java.lang.Class 类的实例\n\n\nfindLoadedClass(String name)\n查找名为 name 的已经被加载过的类，返回结果为 java.lang.Class 类的实例\n\n\ndefineCLass(String name, byte[] b, int off, int len)\n把字节数组b中的内容转换为一个Java类，返回结果为 java.lang.Class类的实例\n\n\nresolveClass(Class&lt;?&gt; c)\n连接指定的一个Java类\n\n\n\n\n\n\n\n\n\n\n\n获取ClassLoader的三种方式\n\nclass.getClassLoader( )  - 获取当前类的\nThread.currentThread( ).getContextClassLoader( ) - 获取当前线程上下文的\nClassLoader.getSystemClassLoader( )  - 获取当前系统的\nDriverManager.getCallerClassLoader( ) - 获取调用者的\n\n双亲委派机制http://www.javashuo.com/article/p-cfrecdij-dx.html\nJava虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类时才会将它的class文件加载到内存生成class对象。而且加载某个类的class文件时，Java虚拟机采用的是双亲委派机制，即把请求交由父类处理，它是一种任务委派模式。\n\n\npublic Class&lt;?> loadClass(String name) throws ClassNotFoundException &#123;\n    return loadClass(name, false);\n&#125;\n//              -----??-----\nprotected Class&lt;?> loadClass(String name, boolean resolve)\n    throws ClassNotFoundException\n&#123;\n        // 首先，检查是否已经被类加载器加载过\n        Class&lt;?> c = findLoadedClass(name);\n        if (c == null) &#123;\n            try &#123;\n                // 存在父加载器，递归的交由父加载器\n                if (parent != null) &#123;\n                    c = parent.loadClass(name, false);\n                &#125; else &#123;\n                    // 直到最上面的Bootstrap类加载器\n                    c = findBootstrapClassOrNull(name);\n                &#125;\n            &#125; catch (ClassNotFoundException e) &#123;\n                // ClassNotFoundException thrown if class not found\n                // from the non-null parent class loader\n            &#125;\n \n            if (c == null) &#123;\n                // If still not found, then invoke findClass in order\n                // to find the class.\n                c = findClass(name);\n            &#125;\n        &#125;\n        return c;\n&#125;\n\n\n优势\n避免类的重复加载\n保护程序安全，防止核心API被随意篡改\n\n沙箱安全机制Java安全模型的核心就是Java沙箱。沙箱机制就是将Java代码限定在虚拟机特定的运行范围中，并且严格限制代码对本地资源的访问，通过这样的措施来保证对代码的有效隔离，防止对本地系统造成破坏\n自定义String类，但是在加载自定义String类的时候会率先使用引导类加载器加载，而引导类加载器在加载过程中会先加载JDK自带的文件（rt.jar包中的java.lang.String ），报错信息说没有main方法，就是因为加载的是rt.jar包中的String类。这样可以保证对Java核心源代码的保护，这就是沙箱安全机制\n其他\n在JVM中表示两个class对象是否为同一个类存在两个必要条件：\n类的完整类名必须一致，包括包名\n加载这个类的ClassLoader必须相同\n\n\n换句话话说，在JVM中，即使这两个类对象（class对象）来源同一个Class文件，被同一个虚拟机所加载，但只要加载它们的ClassLoader实例对象不同，那么这两个类对象也是不相等的\n\n对类加载器的引用JVM必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的。如果一个类型是由后者加载的，那么JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中。当解析一个类型到另一个类型的引用的时候，JVM需要保证这两个类型的类加载器是相同的。\n类的主动使用和被动使用Java程序对类的使用方式分为：主动使用和被动使用\n\n主动使用，又分为七种情况：\n创建类的实例\n访问某个类或接口的静态变量，或者对该静态变量赋值\n调用类的静态方法\n反射（比如：Class.forName(“com.example.Test”) ）\n初始化一个类的子类\nJava虚拟机启动时被标明为启动类的类\nJDK 7 开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化\n\n\n除了以上七种情况，其他使用Java类的方式都被看做类的被动使用，都不会导致类的初始化\n\n运行时数据区\n\n\n\n\n\n\n\n\n\n\n线程介绍\n\n线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行\n在Hotspot JVM里，每个线程都与操作系统的本地线程直接映射。\n当一个Java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java线程执行终止后，本地线程也会回收。\n\n\n操作系统负责所有线程的安排调度到任何一个可用的CPU上。一旦本地线程初始化成功，他就会调用Java线程中的 run( ) 方法\n\n\n\n\n\n\n\n\n\n\nJVM系统线程\n\n如果使用jconsole或者任何一个调试工具，都能看到后台有许多线程在运行。这些后台线程不包括调用public static void main(String[ ] ) 的main线程以及所有这个main线程自己创建的线程\n这些主要的后台系统线程在HotSpot JVM里主要是以以下几个：\n虚拟机线程：该线程的操作是需要JVM达到安全点才会出现。这些操作必须在不同的线程中发生的原因是他们都需要JVM达到安全点，这样堆才不会变化。这种线程的执行类型包括“stop-the-world”的垃圾收集，线程栈收集，线程挂起以及偏向锁撤销\n周期任务线程：这种线程是时间周期事件的体现（比如中断），他们一般用于周期性操作的调度执行。\nGC线程：这种线程对在JVM里不同种类的垃圾收集行为提供了支持。\n编译线程：这种线程在运行时会将字节码编译到本地\n信号调度线程：这种线程接收信号并发送给JVM，在它内部通过适当的方法进行处理\n\n\n\n程序计数器JVM中的程序计数寄存器（Program Counter Register）中，Register的命名源于CPU的寄存器，寄存器存储指令相关的现场信息。CPU只有把数据装载到寄存器才能够运行。\n这里，并非是广义上所指的物理寄存器，或许将其翻译为PC计数器（或指令计数器）会更加贴切（也称为程序钩子），并且不容易引起一些不必要的误会。JVM中的PC寄存器是对物理PC寄存器的一种抽象模拟。\n作用PC寄存器用来存储指向下一条指令的地址，也即将要执行的指令代码。由执行引擎读取下一条指令。\n\n\n它是一块很小的内存空间，几乎可以忽略不计，也是运行速度最快的存储区域。\n在JVM规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。\n任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址；或者，如果是在执行native方法，则是未指定值（undefined）。\n它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。\n字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。\n它是唯一一个存在Java虚拟机规范中没有规定任何OutOfMemoryErroy情况的区域\n\n举例说明\n两个常见问题① 使用PC寄存器存储字节码指令地址有什么用？为什么使用PC寄存器记录当前线程的执行地址？\n因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。\n② PC寄存器为什么会被设为线程私有？\n我们都知道所谓的多线程在一个特定的时间段内只会执行其中的某一个线程的方法，CPU会不停地做任务切换，这样必然导致经常中断或回复，如何保证分毫无差呢？为了能够准确记录各个线程正在执行的当前字节码指令地址（最好的办法就是每人一份），最好的办法自然是为每一个线程都分配一个PC寄存器，这样一来各个线程之间便可以进行独立运算，从而不会出现相互干扰的情况。\n由于CPU时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或多核处理器中的一个内核，只会执行某个线程中的一条指令。这样必然导致经常中断或恢复，所以每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器在各个线程之间互不影响。\n虚拟机栈概述由于跨平台的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。优点是跨平台、指令集小、编译器容易实现；缺点是性能下降，实现同样的功能需要更多的指令。\n栈是运行时单位，而堆是存储的单位。\nJava虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。每个线程创建时都会创建一个虚拟机栈，其内部保存一个个栈帧（Stack Frame），对应一次次的Java方法调用。Java虚拟机栈是线程私有的，生命周期和线程一致。其主要作用是主管Java程序的运行，它保存方法的局部变量（8种数据基本类型和对象的引用地址）、部分结果，参与方法的调用和返回。\n栈的优点\n栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。\nJVM直接对Java栈的操作只有两个：\n每个方法执行，伴随着进栈（入栈、压栈）\n执行结束后的出栈工作\n\n\n对于栈来说不存在垃圾回收问题\n\n面试题：开发中遇到的异常有哪些？\nJava 虚拟机规范允许Java栈的大小是动态的或者是固定不变的。\n如果采用固定大小的，那么每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许得到最大容量，那么虚拟机将抛出一个 StackOveflowError 异常\n如果采用动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将抛出一个 OutOfMemoryError 异常\n-Xss256M 可以设置每个虚拟机栈大小\n默认虚拟机栈大小\n\n\n\n\n\n\n栈中存储什么？\n每个线程都有自己的栈，栈中的数据都是以栈帧（Stack Frame）的格式存在\n在这个线程上正在执行的每个方法都各自对应一个栈帧\n栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息\n\n栈运行原理\nJVM直接对Java栈的操作只有两个，就是对栈帧的压栈和出栈\n在一条活动线程上，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为当前栈帧（Current Frame），与当前栈帧相对应的方法就是当前方法（Current Method），定义这个方法的类就是当前类（Current Class）\n执行引擎运行的所有字节码指令只针对当前栈帧进行操作。\n如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前帧。\n不同线程中所包含的栈帧是不允许相互引用的，即不可能存在一个栈帧之中引用另外一个线程的栈帧\n如果当前方法调用了其他方法，方法返回时，当前栈帧会传回次防范的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为栈顶栈帧\nJava方法有两种返回函数的方式，一种是正常的返回，使用return；另一个是抛出异常。不管是用哪种，都会导致栈帧被弹出。\n\n栈帧的内部结构每个栈帧中存储着：\n\n局部变量表（Local Variables）\n操作数栈（Operand Stack）或称为表达式栈\n动态链接（Dynamic Linking）或指向运行时常量池的方法引用\n方法返回地址（Return Address）或方法正常退出或者异常退出的定义\n一些附加信息\n\n\n局部变量表\n局部变量表也被称为局部变量数组或本地变量表\n定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，这些数据类型包括各类基本数据类型、对象引用（reference），以及returnAddress类型。\n由于局部变量是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题\n局部变量表所需的容量大小是在编译期确定下来的，并保存在方法的Code属性的maximum locall variables数据项中。在方法运行期间是不会改变局部变量表的\n\n关于Slot（槽）的理解\n参数值的存放总是在局部变量数组的index0开始，到数组长度-1的索引结束\n局部变量表，最基本的存储单元是Slot（变量槽）\n局部变量表中存放编译期可知的各种基本数据类型（8种），引用类型（reference），returnAddress类型的变量\n在局部变量表里，32位以内的类型只占用一个slot（包括returnAddress类型），64位的类型（long和double）占用两个slot。\nbyte、short、char 在存储前被转换为int，boolean 也被转换为int，0表示false，非0表示true\nlong 和 double 则占两个slot\n\n\n\n\nSlot的重复利用\n举例：静态变量与局部变量的对比\n\n\n\n\n\n\n\n\n静态变量有两次赋初值机会，局部变量没有\n\n\n成员变量：在使用前（实例后），都经过默认初始化赋值\n类变量（static）：linking(prepare)-&gt;initialization\n实例变量（no static）：随着对象的创建，会在堆空间中分配实例变量空间，并进行默认赋值\n\n\n局部变量 ：在使用前，必须显式赋值\n\n补充说明\n在栈帧中，与性能调优关系最为密切的部分就是前面提到的局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递。\n局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会回收\n\n操作数栈\n每一个独立的栈帧中除了包含局部变量表以外，还包含一个后进先出（Last-In-First-Out）的操作数栈，也可以称之为表达式栈（Expression Stack）\n操作数栈，在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈（push）&#x2F; 出栈（pop）\n某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。\n比如：执行复制、交换、求和等操作\n\n\n\n\n\n\n代码演示\n\n\n\n\n栈顶缓存技术\n动态链接（指向运行时常量池的方法引用）\n每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。包含这个引用的目的是为了支持当前方法的代码能够实现动态链接。比如 invokedynamic 指令\n在Java源文件被编译到字节码文件时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在class文件的常量池里。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中的指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用。\n为什么要用常量池？\n为了提供一些符号和常量，便于指令的识别\n\n\n\n方法调用在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关\n\n静态链接\n\n当一个字节码文件被装载进JVM内部时，如果被调用的目标方法在编译期可知，且运行期保持不变。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接。\n\n动态链接\n\n如果被调用的方法在编译期无法被确定下来，也就是说，只能够在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此称之为动态链接。\n\n对应的方法绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。\n\n早期绑定\n\n早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用\n\n晚期绑定\n\n如果被调用的方法在编译期无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，称之为晚期绑定。 \n方法的调用：虚方法与非虚方法\n如果方法在编译期就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为 非虚方法\n静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法。\n其他方法称为虚方法。 \n虚拟机中提供了以下几条方法调用指令：\n普通调用指令：\ninvokestatic：调用静态方法，解析阶段唯一确定\ninvokespecial：调用方法、私有及父类方法，解析阶段唯一确定\ninvokevirtual：调用所有虚方法，不一定真的是是虚方法\ninvokeinterface：调用接口方法，虚方法\n\n\n动态调用指令：\ninvokeddynamic：动态解析出需要调用的方法，然后执行\n\n\n\n\n\n前四条指令固化在虚拟机内部，方法的调用执行不可人为干预，而invokedynamic指令则支持由用户确定方法版本。其中 invokestatic 和          invokespecial 指令调用的方法称为非虚方法，其余的称为虚方法（final修饰除外）。\n方法调用：关于invokedynamic指令\nJVM字节码指令集一直比较稳定，知道Java7中才增加了一个invokedynamic指令，这是为了Java实现【动态类型语言】支持而做的一种改进。\n但是在Java7中并没有提供直接生成invokedynamic指令的方法，需要借助ASM这种字节码工具来产生invokedynamic指令。知道Java8中的Lambda表达式的出现，invokedynamic指令的生成，在Java中才有了直接的生成方式。\nJava7中增加的动态语言类型支持的本质是对Java虚拟机规范的修改，而不是对Java语言规则的修改，这一块相对来说比较复杂，增加了虚拟机中的方法调用，最直接的受益者就是运行在Java平台的动态语言编译器。\n\n方法调用：方法重写的本质Java 语言中方法重写的本质：\n\n找到操作数栈顶的第一个元素所执行的对象的实际类型，记作C。\n如果在类型 C 中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过返回这个方法的直接引用，查找过程结束；如果不通过，则返回java.lang.IllegalAccessError异常。\n否则，按照继承关系从下往上依次对 C 的各个父类进行第二步的搜索和验证过程。\n如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。\n\nIllegalAccessError介绍\n程序视图访问或修改一个属性或调用一个方法，这个属性或方法，你没有权限访问。一般的，这个会引起编译器异常。如果这个错误发生在运行时，就说明一个类发生了不兼容的改变。\n方法调用：虚方法表\n在面向对象编程中，会很频繁的使用到动态分配，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，JVM采用在类的方法区建立一个虚方法表（virtual method table）（非虚方法不会出现在表中）来实现。使用索引表来代替查找。\n每个类中都有一个虚方法表，表中存放着各个方法的实际入口。\n那么虚方法表什么时候创建？\n虚方法表会在类加载的链接-解析阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM会把该类的方法表也初始化完毕。\n\n\n\n方法返回地址\n存放调用该方法的PC寄存器的值。\n一个方法的结束，有两种方式：\n正常结束\n异常退出\n\n\n无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的PC计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。\n正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。\n在字节码指令中，返回指令包括 ireturn（当前返回值是boolean、byte、char、short和int类型时使用）、lreturn、freturn、dreturn 以及 areturn，另外还有一个 return 指令供声明为 void 的方法、实例初始化方法、类和接口的初始化方法使用\n\n一些附加信息栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息。\n虚拟机栈的相关面试题\n举例栈溢出的情况（StackOverflowError）\nhttps://blog.csdn.net/weixin_40667145/article/details/78556182\n通过-Xss设置每个线程的栈的总大小；OOM（内存溢出）不同于栈溢出\n\n\n调整栈大小，就能保证不出现溢出吗？\n不能\n\n\n分配的栈内存越大越好吗？\n栈容量变大，总内存一定，栈的数目就会减少，或者说能开辟的线程变少，所以并不是越大越好\n\n\n垃圾回收是否会涉及到虚拟机栈？\n\n\n\n方法定义的局部变量是否线程安全？\n何为线程安全？\n如果只有一个线程可以操作此数据，则必是线程安全的。\n如果有多个线程操作此数据，则此数据是共享数据，如果不考虑同步机制的话，会存在线程安全问题。\n\n\n内部定义内部消亡–安全的；\n以参数传入–不安全的；\n以返回值返回–不安全的；\n\n\n命令确定异常线程？\njstack pid\ntop -H -p &lt;pid&gt;\njprofiler\n\n\n\n本地方法栈\n\nJava虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。\n本地方法栈，也是线程私有的。\n允许被实现成固定或者是可动态扩展的内存大小。（在内存溢出方面是相同的）\n如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会抛出一个 StackOverflowError 异常。\n如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么虚拟机将会抛出一个 OutOfMemoryError 异常。\n\n\n本地方法是使用C语言实现的。\n它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库。\n当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机用拥有同样的权限。\n本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区\n它甚至可以直接使用本地处理器中的寄存器。\n直接从本地内存的堆中分配任意数量的内存。\n\n\n并不是所有的JVM都支持本地方法。因为Java虚拟机规范并没有明确要求本地方法栈使用的语言、具体实现方式、数据结构等。如果JVM产品不打算支持 native 方法，也可以无需事先本地方法栈。\n在 HotSpot JVM中，直接将本地方法栈和虚拟机栈合二为一。\n\n堆堆的核心概述\n一个JVM实例只存在一个堆内存，堆也是Java内存管理的核心区域。\n\nJava 堆区在JVM启动的时候即被创建，其空间大小也就确定了。是JVM管理的最大的一块内存空间。\n\n堆内存的大小是可以调节的\n\n&#96;&#96;&#96;inijava -Xmx3550m -Xms3550m -Xmn2g -Xss128k-Xmx3550m：设置JVM最大可用内存为3550M。-Xms3550m：设置JVM初始内存为3550m-Xmn2g：设置年轻代大小为2G。-Xss128k：设置每个线程的栈大小。\n\n- 《Java虚拟机规范》规定：堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。\n\n- 所有的线程共享Java堆，在这里还可以划分**线程私有的缓冲区**（Thread Local Allocation Buffer，TLAB）。\n\n- 《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应该在运行时分配在堆上。\n\n  - “几乎”所有的对象实例都是在这里分配内存。--从实际使用角度来看\n\n- 数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。\n\n- 在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾回收的时候才会被移除。\n\n- 堆，是GC（Garbage Collection）执行垃圾回收的重点区域。\n\n\n\n#### 堆的核心概述：内存细分\n\n![584866-20170426175411428-34722603](https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;5848662017042617541142834722603.png)\n\n\n\n#### 堆空间大小的设置\n\n- Java堆区用于存储Java对象实例，那么堆的大小在JVM启动时就已经设定好了，可以通过选项 &#96;-Xmx&#96;和&#96;-Xms&#96;来进行设置\n  - &#96;-Xms&#96;表示堆区的起始内存，等价于&#96;-XX:InitialHeapSize&#96;\n    - 堆空间（年轻代 + 老年代）\n    - -X是JVM的运行参数\n    - ms 是 Memory start\n  - &#96;-Xmx&#96;表示堆区的最大内存，等价于&#96;-XX:MaxHeapSize&#96;\n    - 查看参数的设置：\n      - 方式一：&#96;jinfo -flags &lt;pid&gt;&#96;\n      - 方式二：  &#96;-XX:+PrintFlagsFinal&#96;\n- 一旦堆区中的内存大小超过&#96;-Xmx&#96;所指定的最大内存时，将会抛出OutOfMemoryError异常。\n- 通常会将&#96;-Xms&#96;和&#96;-Xmx&#96;两个参数配置相同的值，**其目的是为了能够在Java垃圾回收机制清理完堆区后不需要重新分配计算堆区的大小，从而提高性能。**\n- 初始内存大小：物理电脑内存大小 &#x2F; 64 （默认情况下）\n  最大内存大小：物理电脑内存大小 &#x2F; 4\n\n\n\n#### OutOfMemory 举例\n\n![截屏2021-09-20上午11.15.02](https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;jie-ping20210920-shang-wu111502.png)\n\n \n\n#### 新生代与老年代\n\n- 存储在JVM中的Java对象可以被划分为两类：\n  - 一类是生命周期较短的瞬间对象，这类对象的创建和消亡都非常迅速。\n  - 另外一类对象生命周期较长，在某些极端情况下还能够与JVM的生命周期保持一致。\n- Java堆区进一步细分的话，可以划分为年轻代（YoungGen）和老年代（OldGen）\n- 其中年轻代又可以划分为Eden空间、Survivor0空间和Survivor1空间（有时也叫做 from区 、to区）\n\n&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;jie-ping20210920-shang-wu112531.png&quot; alt&#x3D;&quot;截屏2021-09-20上午11.25.31&quot; style&#x3D;&quot;zoom:67%;&quot; &#x2F;&gt;\n\n&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;jie-ping20210920-shang-wu112919.png&quot; alt&#x3D;&quot;截屏2021-09-20上午11.29.19&quot; style&#x3D;&quot;zoom:67%;&quot; &#x2F;&gt;\n\n- 查看以上设置： jinfo -flag NewRatio 进程id（jps  得到）\n\n---\n\n- 在HotSpot中，Eden空间和另外两个Survivor空间缺省所占的比例是**8:1:1**\n  - &#96;-XX:-UseAdaptiveSizePolicy&#96;：关闭自适应的内存分配策略（实测没用）\n  - 分配空间过小仍然不会达到设定的比例（200M）\n  - 还是需要下面的命令设置 ↓ 注意上面这条 ↑\n- 当然开发人员可以通过选项 &#96;-XX:SurvivorRatio&#96; 调整这个空间比例。\n  - &#96;-XX:NewRatio&#96;：设置老年代与新生代的比例！\n  - &#96;-XX:SurvivorRatio&#96;：设置新生代中Eden区与Survivor区的比例\n  - &#96;-XX:-UseAdaptiveSizePolicy&#96;：关闭自适应分配策略\n  - &#96;-Xmn&#96;：设置新生代空间的大小（该命令优先级比第一条优先）\n  - &#96;-XX:+PrintGCDetails&#96;：打印GC详细信息\n- **几乎所有**的Java对象都是在Eden区被new出来的。\n- 绝大部分的Java对象的销毁都是在新生代中进行的。\n  - IBM公司专门研究表明：新生代中80%的对象都是“朝生夕死”的\n- 可以使用选项&#96;-Xmn&#96;设置新生代最大内存大小\n  - 这个参数一般使用默认值即可\n\n![d](https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;center.png)\n\n\n\n\n\n#### 对象的一般分配过程\n\n##### 对象分配过程：概述\n\n为新对象分配内存是一件非常严谨和复杂的任务，JVM的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑GC执行完内存回收后是否会在内存空间中产生内存碎片。\n\n1. new的对象先放Eden区。此区大小有限制。\n2. 当Eden区空间填满时，程序又需要创建新的对象，JVM的垃圾回收器将对Eden区进行垃圾回收（Minor GC &#x2F; YGC），将此区域中的不再被其他对象所引用的对象进行销毁，再加载新的对象到此区域。\n3. 然后将Eden区中的剩余对象移动到Survivor0区\n4. 如果再次触发垃圾回收，此时上次幸存下来的放到Survivor0区的，如果没有回收，就会放到Survivor1区。\n5. 如果再次经历垃圾回收，此时会重新放回Survivor0区，接着再去Survivor1区。\n6. 什么时候能去老年代？可以设置次数，默认是15次。\n\n   - **&#96;-XX:MaxTenuringThreshold&#x3D;&lt;N&gt;&#96; 进行设置**\n7. 在养老区，相对悠闲。当养老区内存不足时，再次触发GC：Major GC，进行养老区的内存清理。\n8. 若养老区执行了Major GC之后发现仍无法进行对象的保存，就会产生OOM错误。\n&gt; 总结\n\n- **针对幸存者s0,s1区：复制后有交换，谁空谁是to。**\n- **关于垃圾回收：频繁在新生区收集，很少在老年区收集，几乎不在永久区 &#x2F; 元空间收集。**\n\n\n\n##### 对象分配过程：特殊情况\n\n![截屏2021-09-20下午12.49.58](https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;jie-ping20210920-xia-wu124958.png)\n\n#####   对象分配过程：图解\n\n![截屏2021-09-20下午7.16.35](https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;jie-ping20210920-xia-wu71635.png)\n\n\n\n#### 常用调优工具\n\n- Eclipse：Memory Analyzer Tool\n- Jconsole\n- VisualVM\n- Jprofiler\n- Java Flight Recoder\n- GCViewer\n- GC Easy\n\n\n\n#### 初步认识几种GC\n\n&gt; Minor GC、Major GC、Full GC\n\nJVM在进行GC时，并非每次都对上面三个内存区域（新生代、老年代；方法区）一起回收，大部分时候回收的都是指新生代。\n\n针对HotSp VM的实现，它里面的GC按照回收区域又分为两大类型：一种是部分收集（Partial GC），一种是整堆收集（Full GC）\n\n- 部分收集：不是完整收集整个Java堆的垃圾收集。其中又分为：\n  - 新生代收集（Minjor GC &#x2F; Young GC）：只是新生代的垃圾收集。\n  - 老年代收集（Major GC &#x2F; Old GC）：只是老年代的垃圾收集。\n    - 目前，只有CMS GC会有单独收集老年代的行为\n    - **注意，很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。**\n  - 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。\n    - 目前，只有G1 GC会有这种行为。\n- 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾。\n\n\n\n##### 最简单的分代式GC策略的触发条件\n\n- **年轻代（Minor GC）触发机制：**\n\n  - 当年轻代空间不足时，就会触发Minor GC，这里的**年轻代满指的是Eden代满，Survivor满不会引发GC。**（每次Minor GC会清理**年轻代的内存**）\n  -  因为Java对象大多具备较短的生命周期，所以Minor GC非常频繁，一般回收速度也比较快，这一定义既清晰又易于理解。\n  - Minor GC会引发STW，暂停其他用户的线程，等垃圾回收结束，用户线程才恢复运行。\n\n- **老年代（Major GC&#x2F;Full GC）触发机制：**\n\n  - 指发生在老年代的GC，对象从老年代消失时，我们说“Major GC”或“Full GC”发生了\n  - 出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对，在Parallel Scavenge 收集器的收集策略里就有直接进行Major GC的策略选择过程）。\n    - 也就是在老年代空间不足时，会先尝试触发Minor GC。如果之后空间还不足，则触发Major GC。\n  - Major GC的速度一般会比Minor GC慢十倍以上，STW时间更长。\n  - 如果Major GC之后，内存仍然不足-&gt;OOM \n\n- **Full GC触发机制（后面细讲）触发机制：**\n\n  - 调用System.gc( )时，系统建议执行Full GC，但是不必然执行\n  - 老年代空间不足\n  - 方法区（区分于 堆）空间不足\n  - 通过Minor GC后进入老年代的平均大小大于老年代的可用内存\n  - 由Eden区、s0（from区）向s1（to区）复制时，对象大小大于to区可用内存，则把对象转存到老年代，这时老年代的可用内存小于对象大小。\n\n  说明：Full GC是开发或调优中要尽量避免的，这样暂停时间更短。\n\n\n\n#### 堆空间分代思想\n\n&gt; 为什么要把Java堆分代？\n\n- 经研究，70%-90%的对象是临时变量。\n  - 新生代：有Eden、两块大小相同的Survivor（又称from&#x2F;to，s0&#x2F;s1）构成，to总为空。\n  - 老年代：存放新生代中经历多次GC仍然存活的对象。\n- 其实不分代完全可以，分代的唯一理由就是**优化GC性能**。如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。\n\n####    内存分配策略（对象提升[Promotion]规则）\n\n如果对象在Eden出生并经过第一次MinorGC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并将对象年龄设置为1。对象在Survivor区中没经过一次MinorGC（未被清理），年龄就加一，当它的年龄增加到一定程度（默认15，每个JVM、GC都有所不同）时，就会被晋升到老年代中，设置阈值 &#96;-XX:MaxTenuringThreshold&#96;。\n\n针对不同年龄段的对象分配原则如下所示：\n\n- 优先分配到Eden\n- 大对象直接分配到老年代\n  - 尽量避免程序中出现过多大对象\n- 长期存活的对象分配到老年代\n- 动态对象年龄判断\n  - 如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无需等到MaxTenuringThreshold要求的年龄。\n\n#### 为对象分配分配内存：TLAB   \n\n&gt; 什么是TLAB？\n\n[TLAB-简书](https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;8be816cbb5ed)\n\n- 从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为**每个线程都分配了一个私有缓冲区域**，它包含在Eden空间内。\n- 据我所知所有OpenJDK衍生出来的JVM都提供了TLAB的设计。\n\n&gt; 为什么要有TLAB（Thread Local Allocation Buffer）？\n\n- 堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据\n- 由于对象实例的创建在JVM中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的。\n- 为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度。\n- 多线程同时分配内存时，使用TLAB可以避免这一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为 **快速分配策略**。\n\n&gt; TLAB详细说明\n\n- 尽管不是所有的对象实例都能够在TLAB中成功分配内存，**但JVM确实是将TLAB作为内存分配的首选。**\n- 可以通过 &#96;-XX:UseTLAB&#96;设置是否开启TLAB空间。\n- 默认情况下，TLAB空间的内存非常小，仅占有整个Eden空间的1%，可以设置&#96;-XX:TLABWasteTargetPercent&#96;设置TLAB空间所占用的Eden空间百分比大小。\n- 一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用**加锁机制**确保数据操作的原子性，从而直接在Eden空间中分配内存。\n\n![截屏2021-09-20下午9.46.38](https:&#x2F;&#x2F;markdown-pic-june.oss-cn-beijing.aliyuncs.com&#x2F;2022&#x2F;09&#x2F;30&#x2F;jie-ping20210920-xia-wu94638.png)\n\n \n\n#### 小结堆空间常用参数\n\n&#96;&#96;&#96;shell\n-XX:+PrintFlagsInitial  #查看所有的参数的默认初始值\n-XX:+PrintFlagsFinal    #查看所有的参数的最终值\n\t具体查看某个参数的指令： jps  -查看当前运行中的进程\n\t\t\t\t\t\t\t\tjinfo  -flag SruvivorRatio 进程id\n-Xms\t\t\t\t\t\t#初始堆空间内存（默认 1&#x2F;64物理内存）\n-Xmx\t\t\t\t\t\t#最大堆空间内存（默认 1&#x2F;4物理内存）\n-Xmn \t\t\t\t\t\t#设置新生代大小（初始值及最大值）\n-XX:NewRatio\t\t#配置老年代与新生代在堆结构的占比\n-XX:SurvivorRatio \t#设置新生代中Eden和S0&#x2F;S1的比例。过大会导致Minor GC失去意义，Major GC频繁；过小会导致YGC频繁，STW时间边长。\n-XX:MaxTenuringThreshold:  #设置新生代垃圾的最大年龄\n-XX:+PrintGCDetails\t\t\t\t#输出详细的GC日志\n打印简要信息： -XX:+PrintGC   -verbose:gc\n-XX:HandlePromotionFailure  #是否设置空间分配担保\n\n\n\n\n堆是对象存储的唯一选择吗？在《深入理解Java虚拟机》中关于Java堆内存有这样一段描述：随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分析、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么绝对了。\n在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的的尝试。但是，有一种特殊情况，那就是如果经过逃逸分析后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需堆分配内存，也无需垃圾回收了，这也是最常见的对外存储技术。\n此外，前面提到的基于OpenJDK深度定制的TaoBaoJVM，其中创新的GCIH（GC Invisible Heap）技术实现Off-Heap，将生命周期较长的对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。\n逃逸分析概述\n如何将堆上的对象分配到栈，需要使用逃逸分析手段。\n这是一种可以有效减少Java程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。\n通过逃逸分析，Java HotSpot编译器能够分析出一个新的对象的引用适用范围从而决定是否要将这个对象分配到堆上。\n逃逸分析的基本行为就是分析对象动态作用域：\n当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。\n当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他方法中。\n\n\n\n \n参数设置\n在JDK 6u23之后，HotSpot中默认开启了逃逸分析。\n命令开启：-XX:+DoEscapeAnalysis\n查看逃逸分析的筛选结果：-XX:+PrintEscapeAnalysis\n\n结论开发中能使用局部变量的，就不要使用在方法外定义。\n逃逸分析-代码优化使用逃逸分析，编译器可以对代码做如下优化：\n\n栈上分配：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配。\n同步省略：如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。\n分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。\n\n代码优化之栈上分配\nJIT编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无需进行垃圾回收；\n常见的栈上分配的场景\n给成员变量赋值、方法返回值、实例引用传递。\n\n\n\n逃逸分析之同步省略\n线程同步的代价是相当高的，同步的后果是降低并发性和性能。\n在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断代码块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。如果没有，那么JIT编译器在编译这个同步代码块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫做同步省略，也叫锁消除。\n\n\n逃逸分析之标量替换标量（Scalar）是指一个无法再分解成更小的数据的数据。Java中的原始数据类型就是标量。\n相对的，那些还可以分解的数据叫做聚合量（Aggregate），Java中的对象就是聚合量，因为他可以分解成其他聚合量和标量。\n在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个包含若干个成员变量来替代，这个过程就是标量替换。\n参数设置：-XX:+EliminateAllocations 开启标量替换（默认开启），允许将对象打散分配在栈上。  \n\n本章小结\n方法区概述\n\n方法区和堆一样，是各个线程共享的区域。\n方法区在JVM启动时被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。\n方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。\n方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutOfMemoryError:PermGen space或者java.lang.OutOfMemoryError:Metaspace\n关闭JVM就会释放这个区域的内存。\n\n\n栈、堆、方法区的交互关系\nHotSpot中方法区的演进\n在JDK 7 及以前，习惯上把方法区，称为永久代。JDK 8 开始，使用元空间取代了永久代。\n本质上，方法区和永久代并不等价，仅是对HotSpot而言。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEA JRocikt、IBM J9中不存在永久代的概念。\n现在来看，当年使用永久代，不是好的idea，导致Java程序更容易OOM（超过-XX:MaxPermSize设定值）\n\n\n而到了JDK 8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替。\n元空间的本质和永久代类似，都是对JVM规范中方法区的实现，不过元空间与永久代最大的区别在于：元空间不设置在虚拟机设置的内存中，而是使用本地内存。\n永久代、元空间二者并不只是名字变了，内部结构也变了。\n根据《Java虚拟机规范》规定：如果方法区无法满足新的内存分配需求时，将抛出OOM异常。\n\n常量池-解释\n常量池，即一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等信息。\n运行时常量池，在 class 文件中，当该类被加载，它的常量池信息就会放入运行时常量池，并把里面的符号地址变为真实地址，这是内存中的常量池形式\n\n设置方法区大小与OOM\n方法区的大小不必是固定的，JVM可以根据应用的需要动态调整。\nJDK 7及以前：\n通过-XX:PermSize设置永久代初始分配空间。默认是20.75M\n-XX:MaxPermSize设置永久代最大可用分配空间，32位机器默认64M，64位默认82M。\n当JVM加载的类信息容量超过了这个值，会报异常OutOfMemoryError:PermGen space\n\n\nJDK 8及以后：\n元数据区大小可以使用参数-XX:MetaspaceSize和-XX:MaxMetaspaceSize指定，替代上述原有的两个参数。\n默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize 的值是-1，即没有限制。\n与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError:Metaspace\n-XX:MetaspaceSize：设置初始元空间大小。对于一个64位的服务器端JVM来说，其默认的-XX:MetaspaceSize值为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值，如果释放空间过多，则适当降低该值。\n如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将 -XX:MetaspaceSize设置为一个相对较高的值。\n\n\n\n如何解决这些OOM？\n方法区的内部结构\n\n\n\n\n\n\n\n\n\n\n方法区存储什么？\n\n《深入理解Java虚拟机》书中对方法区存储内容描述如下：它用于存储已被虚拟机加载的类型信息（全类名、父类名、接口列表、修饰符）、常量、静态变量（JDK6及以前）、即时编译器编译后的代码缓存等。\n类型信息对每个加载的类型（类class、接口interface、枚举enum、注解annotation），JVM必须在方法区中存储以下类型信息：\n\n这个类型的完整有效名称（全名&#x3D;包名.类名）\n这个类型直接父类的完整有效名（对于interface或是Object，都没有父类）\n这个类型的修饰符（public，abstract，final的某个子集）\n这个类型直接接口的一个有序列表\n\n域（Field）信息\nJVM必须在方法区中保存类型的所有域相关信息以及域的声明顺序。\n域的相关信息包括：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient的某个子集）\n\n方法（Method）信息JVM保存所有方法的以下信息，同域信息包括声明顺序：\n\n方法名称\n方法返回类型（包括void）\n方法参数的数量和类型（按顺序）\n方法的修饰符（public、private、protected、static、final、synchronized、native、abstract的一个子集）\n方法的字节码（bytecodes）、操作数栈、局部变量表及大小（abstract和native方法除外）\n异常表（abstract和natvie方法除外）\n每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引\n\n\n\n\n\n\n\n\n\n\n\n\n non-final的类变量\n\n静态变量和类关联在一起，随着类的加载而加载，它们成为类数据在逻辑上的一部分。\n类变量被类的所有实例共享，即使没有类实例也可以访问它。\n\n\n\n\n\n\n\n\n\n\n 补充说明：全局常量：static fiinal\n被声明为final的类变量的处理方法则不同，每个全局常量在编译的时候就会被分配了。\n运行时常量池 &amp; 常量池\n方法区，内部包含了运行时常量池。\n字节码文件，内部包含了常量池。\n\n\n\n\n\n\n\n\n\n\n为什么需要常量池？\n一个java源文件中的类、接口、编译后产生一个字节码文件。而Java中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另外一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候会用到运行时常量池，之前有介绍。\n比如：如下的代码\npublic class SimpleClass&#123;\n  public void sayHello()&#123;\n    System.out.println(\"hello\");\n  &#125;\n&#125;\n\n虽然只有194字节，但是里面却使用了String、System、PrintStream及Object等结构。这里代码量其实已经很小了，如果代码多，引用到的结构会更多！这里就需要使用常量池。\n\n\n\n\n\n\n\n\n\n常量池中有什么?\n\n小结：\n常量池，可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。\n\n\n\n\n\n\n\n\n\n运行时常量池\n\n方法区使用举例\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法区的演进细节\n\n\n\n\n\n\n\n\n\n\n\n\n永久代为什么要被元空间替换？\n\n随着Java 8 的到来，HotSpot VM中再也见不到永久代了。但是这并不意味着类的元数据信息也消失了。这些数据被移到了一个与堆不相连的本地内存区域，这个区域叫做元空间（Metaspace）。\n这项改动的原因如下：\n为永久代设置空间大小是很难确定的。在某些场景下，如果动态加载类过多，容易产生Perm区的OOM。比如某个实际Web工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误。而元空间和永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。\n对永久代进行调优是很困难的。\n\n\n\n\n\n\n\n\n\n\n\n\nStringTable（字符串常量池）为什么要调整？\nJDK 7 中将StringTable放到了堆空间中。因为永久代的回收效率很低，在full gc的时候才会触发。而full gc是老年代的空间不足、永久代不足时才会触发。这就导致StringTable回收效率不高。而我们开发中会有大量得字符串被创建，回收效率低，导致永久代内存不足。放到堆里，能及时回收内存。 \n\n\n\n\n\n\n\n\n\n静态变量放在哪？\n public static byte[] arr = new byte[1024 * 1024 * 100]\n// -XX:+PrintGCDetails\n// 实验发现：JDK 6，7，8 new出来的对象始终放在堆中\n  \n// 而通过下面的实验，得出的结论是：\n// 位置发生变化的是 类本身存储位置\n// 6：静态变量存放在方法区（永久代）\n// 7&amp;8:\n// 局部变量（基本数据类型） 本身存放在栈帧中的局部变量表中\n// 成员变量（非static修饰的） 本身随着对象实例放在 堆 中\n\n\n\n方法区的垃圾回收方法区的垃圾收集有些人认为方法区（如HotSpot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集，事实上也确实有未实现或未能完整实现方法区类型卸载的收集齐存在（如JDK 11时期的ZGC收集器就不支持类卸载）。\n一般来说这个区域的回收效果比较难以令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前Sun公司的Bug列表中，曾出现过若干个严重的就是由于低版本的HopSpot虚拟机对此区域未完全回收而导致内存泄漏。\n方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。\n\n判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”条件就比较苛刻了，有以下三个条件：\n该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。\n加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则是很难达成的。\n该类对应的java.lang.Class。对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n\nJava虚拟机被允许满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有了引用就必然会被回收。关于是否要对类型进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose:class以及-XX:+TraceClass-Loading、-XX:+TraceClassUnLoading查看类加载信息和卸载信息\n在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及OSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。\n\n总结\n\n\n执行引擎执行引擎概述\n\n执行引擎是Java虚拟机核心的组成部分之一。\n“虚拟机”是一个相对于“物理机”的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的，而虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地指定指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。\nJVM的主要任务是负责装载字节码到其内部，但字节码并不能够直接运行在操作系统上，因为字节码指令并非等价于本地机器指令，它内部包含的仅仅是一些能被JVM所识别的字节码指令、符号表，以及其他辅助信息。\n如果想要一个Java程序跑起来，执行引擎（Execution Engine）的任务就是将字节码指令解释&#x2F;编译为对应平台上的本地机器指令才可以。简而言之，JVM中的执行引擎充当了将高级语言翻译为机器语言的功能。\n\nJava代码编译和执行过程\n大部分的程序代码转换为物理机的目标代码或虚拟机能执行的指令集之前，都需要经过上图的各个步骤。\n\n\n\n\n\n\n\n\n\n为什么说Java是半编译半解释型语言？\nJDK1.0时代，将Java语言定位为“解释执行“还是比较准确的。再后来，Java也发展出可以直接生成本地代码的编译器。现在JVM在执行Java代码的时候，通常都会将解释执行与编译执行二者结合起来进行。\n机器码、指令、汇编语言机器码\n采用二进制编码方式表示的指令，叫做机器指令码。开始，人们就用它编写程序，这就是机器语言。\n机器语言虽然能够被计算机理解和接受，但和人们的语言差别太大，不易被人们理解和记忆，并且用它编程容易出差错。\n用它编写的程序一经输入计算机，CPU直接读取运行，因此和其他语言编写的程序相比，执行速度最快。\n机器指令与CPU紧密相关，所以不同种类的CPU所对应的机器指令也就不同。\n\n指令\n由于机器码是有0和1组成的二进制序列，可读性实在太差，于是人们发明了指令。\n指令就是把机器码中特定的0和1序列，简化成对应的指令（一般为英文缩写，如mov，inc等），可读性稍好。\n由于不同的硬件平台，执行同一个操作，对应的机器码可能不同，所以不同的硬件平台的同一种指令（比如mov），对应的机器码也可能不同。\n\n指令集\n不同的硬件平台，各自支持的指令，是有差别的。因此每个平台所支持的指令，称之为对应平台的指令集。\n如常见的\nx86指令集，对应的是x86架构的平台\nARM指令集，对应的是ARM架构平台\n\n\n\n汇编语言\n由于指令的可读性还是太差，于是人们又发明了汇编语言。\n在汇编语言中，使用助记符（Mnemoics）代替机器指令的操作码，用地址符号（Symbol）或标号（Label）代替指令或操作数的地址。\n在不同的硬件平台，汇编语言对应着不同的机器语言指令集，通过汇编过程转换成机器指令。\n由于计算机只认识指令码，所以用汇编语言编写的程序还必须翻译成机器码指令，计算机才能识别和执行。\n\n\n\n高级语言\n为了使计算机用户编程序更容易些，后来就出现了各种高级计算机语言，高级语言比计算机语言、汇编语言更接近人类的语言\n当计算机执行高级语言编写的程序时，仍然需要把程序解释和编译成机器的指令码。完成这个过程的程序就叫做解释程序或编译程序。\n\n字节码\n字节码是一种中间状态（中间码）的二进制代码（文件），它比机器码更具体，需要直译器转译后才能成为机器码\n字节码主要为了实现特定软件运行和软件环境、与硬件环境无关。\n字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令。\n字节码典型应用为Java bytecode\n\n\n\n解释器Java设计者们的初衷仅仅是单纯地为了满足Java程序实现跨平台特性，因此避免采用静态编译的方式直接生成本地机器指令，从而诞生了实现解释器在运行时采用逐行解释字节码执行程序的想法。\n在Java的发展历史里，一共有两套解释执行器，即古老的字节码解释器、现在普遍使用的模板解释器。\n\n字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率非常低下。\n模板解释器将每一条字节码和一个函数模板相关联，模板函数中直接产生这条字节码执行时的机器码，从而很 大程度上提高了解释器的性能。\n在HotSpot VM中，解释器主要由Interpreter模块和Code模块构成。\nInterpreter模块：实现了解释器的核心功能\nCode模块：用于管理HotSpot VM在运行时产生的本地机器指令\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n现状\n\nJIT编译器\n\nHotSpot VM是市面上高性能虚拟机的代表之作。它采用解释器与即时编译器并存的架构。在Java虚拟机运行时，解释器和即时编译器能够相互协作，各自取长补短，尽力去选择合适的方式来权衡编译本地代码的时间和直接解释执行代码的时间。\n如今，Java程序的运行性能早已脱胎换骨，已经达到了可以和C&#x2F;C++程序一较高下的地步。\n\n问题来了\n编译 - 概念解释\nJava语言的“编译期”其实是一段“不确定的”操作过程，因为它可能是指一个前端编译器（其实叫“编译期的前端”更贴切）把 .java 文件转变成 .class 文件的过程；\n也可能是指虚拟机的后端运行期编译器（JIT编译器，Just In Time Compiler）把字节码转变成机器码的过程；\n还可能是指静态提前编译器（AOT编译器，Ahead Of Time Compiler）直接把 .java文件编译成本地机器代码的过程。\n\n\n\n热点代码及探测方式\n一个被多次调用的方法，或者是一个方法体内部循环次数较多的循环体都可以被称之为“热点代码”，因此都可以通过JIT编译器编译为本地机器指令。由于这种编译方式发生在方法的执行过程中，因此也被称之为栈上替换，或简称OSR（On Stack Replacement）编译。\n\n一个方法究竟要被调用多少次，或者一个循环体究竟要执行多少次循环才可以达到这个标准？必然需要一个明确的阈值，JIT编译期才会将这些“热点代码”编译为本地机器指令执行，这里主要靠热点探测功能.\n\n目前HotSpot VM 所采用的热点探测方式是基于计数器的热点探测。\n\n采用基于计数器的热点探测，HotSpot VM将会为每一个方法都建立两个不同类型的计数器，分别为方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。\n\n方法调用计数器用于统计方法的调用次数\n回边计数器则用于统计循环体执行的循环次数\n\n\n\n方法调用计数器\n这个计数器就用于方法被调用的次数，它的默认阈值在Client模式下是1500次，在Server模式下是10000次。超过这个阈值，就会触发JIT编译。\n这个阈值可以通过虚拟机参数-XX:CompileThreshold来人为设定。\n当一个方法被调用时，会先检查该方法是否存在被JIT编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在已经被编译过的版本，则将此方法的调用计数器值 +1，然后判断方法调用计数器与回边计数器值的和是否超过方法调用计数器的阈值，如果超过，那么将会向即时编译器提交一个该方法的代码编译请求。\n\n\n\n\n\n\n\n\n\n\n\n热度衰减\n\n如果不作任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间之内方法被调用的次数。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那么这个方法的调用计数器就会被减少一半，这个过程称为方法调用计数器热度的衰减（Counter Decay），而这段时间就称为此方法统计的半衰周期（Counter Half Life Time）。\n进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数-XX:-UseCounterDecay来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。\n另外可以使用-XX:CounterHalfLifeTime参数设置半衰周期的时间，单位是秒。\n\nHotSpot VM可以设置程序执行方式-Xint      # 采用完全解释器模式\n-Xcomp     # 采用完全JIT编译器模式，如果编译出现问题，解释器介入\n-Xmixed    # 混合模式\n\n\n\nHotSpot VM中JIT分类在HotSpot VM中内嵌有两个JIT编译器，分别为Client Compiler和Server Compiler，但大多数情况下我们简称为C1编译器和C2编译器。开发人员可以通过如下命令指定编译器：\n\n-client：指定Java虚拟机运行在Client模式下，并使用C1编译器；\nC1编译器会对字节码进行简单和可靠的优化，耗时短，以达到更快的编译速度。\n\n\n-server：指定Java虚拟机运行在Server模式下，并使用C2编译器。\nC2进行耗时较长的优化，以及激进优化。但优化的代码执行效率更高。\n\n\n\nC1和C2编译器不同的优化策略\n在不同的编译器上有不同的优化策略，C1编译器上主要由方法内联，去虚拟化、冗余消除。\n方法内敛：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程。\n去虚拟化：对唯一的实现类进行内联\n冗余消除：在运行期间把一些不会执行的代码折叠掉\n\n\nC2的优化主要是在全局层面，逃逸分析是优化的基础。基于逃逸分析在C2上有如下几种优化：\n标量替换：用标量值代替聚合对象的属性值\n栈上分配：对于未逃逸的对象分配对象在栈上而不是堆\n同步消除：清除同步操作，通常指synchronized\n\n\n\n写在最后1：\n自JDK10起，HotSpot又加入了一个全新的即时编译器：Graal编译器。\n编译效果短短几年时间就追平了C2编译器，未来可期。\n目前，带着“试验状态”标签，需要使用开关参数-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler去激活才能使用\n\n写在最后2：关于AOT编译器\nJDK 9引入了AOT编译器（静态提前编译器，Ahead Of Time Compiler）\nJava 9 引入了实验性AOT编译工具jaotc。它借助了Graal编译器，将所输入的Java类文件转换为机器码，并存放至生成的动态共享库之中。\n所谓AOT编译，是与即时编译相对立的一个概念。我们知道，即时编译器指的是在程序运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而AOT编译器指的则是，在程序运行之前，便将字节码转换为机器码的过程。\n最大好处：Java虚拟机加载已经预编译成二进制库，可以直接执行。不必等待即时编译器的预热，减少Java应用给人带来的“第一次运行慢”的不良体验。\n缺点：\n破坏了java“一次编译，到处运行”，必须为每个不同硬件，OS编译对应的发行包。\n降低了Java链接过程的动态性，加载的代码在编译期就必须全部已知。\n还需要继续优化中，最初只支持Linux x64 java base\n\n\n\n面试提要：String 相关String 的基本特性\nString：字符串，使用一对””引起来表示。\nString s1 &#x3D; “ads”;   &#x2F;&#x2F;字面量定义方式\nString s2 &#x3D; new String(“hello”);\n\n\nString 声明为 final，不可被继承\nString 实现了 Serializable 接口：表示字符串是支持序列化的。实现了Comparable接口：表示 String 可以比较大小\nJDK 8 -&gt; JDK 9 : final char[ ] -&gt; final byte[ ]\n\n\n\n字符串常量池是不会存储相同内容的字符串的。\nString 的 String Pool 是一个固定大小的 Hashtable，默认值大小长度是1009，如果放进String Pool的String非常多，就会造成Hash冲突严重，导致链表会很长，而链表长了以后直接会造成的影响就是当调用String.intern时性能大幅度下降。\n使用-XX:StringTableSize可设置StringTable的长度\n在JDK6中StringTable是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快。StringTableSize设置没有要求\n在JDK7中，StringTable的长度默认值是60013，长度设置没有要求\n在JDK8开始，设置StringTable长度最小值是1009\n\nString 的内存分配\n在Java语言中有8种基本数据类型和一种比较特殊的类型String。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。\n常量池就类似一个Java系统级别提供的缓存。8种基本数据类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种。\n直接使用双引号声明出来的String对象会直接存储在常量池中。\n比如：String info &#x3D; “xxx”；\n\n\n如果不是使用双引号声明的String对象，可以使用String提供的intern( )方法。下面会讲到。\n\n\nJava8元空间，字符串常量在堆。\n\n字符串拼接操作\n常量与常量的拼接结果在常量池，原理是编译期优化\n常量池中不会存在相同内容的字符串\n只要其中有一个是变量，结果就在堆中，变量拼接的原理是 StringBuilder\n如果拼接的结果调用 intern( )方法，则主动将常量池中还没有的字符串对象放入池中，并返回此对象。 \n使用StringBuilder的append( )方式添加字符串效率要远高于String的+ 字符串拼接方式，前者只创建了一个对象，后者每拼接一次，就要创建一个StringBuilder对象。 \n如果基本确定要创建的字符串大小，建议使用构造器\nStringBuilder(int capacity)   &#x2F;&#x2F; char[ capacity ]\n\n\n\n\n \n \nintern( ) 使用JDK 6 与 7&amp;8对于字符串常量池中不存在的对象的处理不同：\n\nJDK6 在字符串常量池中创建新的对象返回这个对象的地址\nJDK7以后只是在字符串常量池中存储调用方法对象的指针，并返回，本质上没有创建新对象\n\n\n\n\n\n\n\n\n\n\n\nnew String(“ab”)会创建几个对象？和new String(“a”) + new String(“b”)、”ab” 有什么区别？\n两个，一个对象是：new关键字在堆空间创建的，另一个对象是：字符串常量池中的对象。字节码指令：ldc；\nString s &#x3D; “ab” 这样创建直接在串池中创建了一个对象 “ab” ，s指向这个对象\nnew String(“a”) + new String(“b”) 创建了6个对象（注意串池不创建对象”ab”）案例如下\n\n\n\n\n\n\n\n\n\nnew String(“a”) + new String(“b”) + new String(“c”) 创建几个对象？\n对象1：new StringBuilder( ) （字符串拼接会首先创建StringBuilder）对象2：new String(“a”)对象3：常量池中的”a”对象4：new String(“b”)对象5：常量池中的”b”对象6：new String(“c”)对象7：常量池中的”c”对象8：new String(“abc”)  （toString不创建”abc”串池对象，其构造方法用的char[]&#x2F;byte[]）\n\n\n\n\n\n\n\n\n\n\nJDK 6 : false &#x2F; falseJDK 7&amp;8：false &#x2F; true\n总结String的intern( ) 的使用\n在JDK1.6中，将这个字符串对象尝试放入字符串常量池\n如果其中存在，啥也不做，返回串池中的地址；\n如果不存在，仅在字符串常量池中创建一份，返回串池对象地址。\n\n\n自JDK1.7起，将这个字符串对象尝试放入字符串常量池\n如果其中存在，啥也不做，返串池的地址；\n如果不存在，则会把调用对象的引用地址复制一份，放入串池，并返回该地址，访问串池对象实际都是访问这个已经创建过的堆空间对象\n\n\n以上的其中都是指字符串常量池\n\n\n\nIntern( )效率测试：空间角度\n结论：对于程序中大量存在的重复字符串，使用intern( )可以节省内存空间\nStringTable 的垃圾回收\n参数\n-XX:+PrintStringTableStatistics\n-XX:+PrintGCDetails\n\n\n\nfor (int i = 0; i &lt; 100000; i++) &#123;\n  String.valueOf(i).intern();\n&#125;\n\n\n\nG1中的 String 去重操作\n背景：对许多Java应用（有大也有小的）做的测试得出以下结果：\n堆存活数据集合里面String对象占了25%\n堆存活数据集合里面重复的String对象有13.5%\nString对象的平均长度是45\n\n\n许多大规模的Java应用的瓶颈在于内存，测试表明，在这些类型的应用里面，Java堆中存活的数据集合差不多25%是String对象。更进一步，这里差不多一半String对象是重复的，重复的意思是：\nstring1.equals(string2) &#x3D; true 。堆上存在重复的String对象必然是一种内存的浪费。这个项目将在G1垃圾收集器中实现自动持续对重复的String对象进行去重，这样就能避免浪费内存。\n\n\n实现：\n当垃圾收集器工作时，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的String对象。\n如果是，把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去重它引用的String对象。\n使用一个hashtable来记录所有的被String对象使用的不重复的char数组。当去重的时候，会查这个hashtable，来看堆上是否已经存在一个一模一样的char数组。\n如果存在，String对象会被调整引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉。\n如果查找失败，char数组会被插入到hashtable，这样以后的时候就可以共享这个数组了。\n\n\n命令开启：\nUseStringDeduplication (bool)：开启去重，默认不开启\nPrintStringDeduplicationStatistics (bool)：打印详细去重统计信息\nStringDeduplicationAgeThreshold (uintx)：达到这个年龄的String对象被认为是去重的候选对象。\n\n\n\n面试提要：对象实例化\n\n\n\n\n\n\n\n\n 创建对象的方式\n\nnew\n最常见的方式\n变形1：Xxx的静态方法\n变形2：XxxBuilder&#x2F;XxxFactory的静态方法\n\n\nClass的newInstance( ) ：反射的方式，只能调用空参构造器，权限必须是public\nConstructor的newInstance( Xxx )：反射的方式，可以调用空参或带参的构造器，权限没有要求。\n使用clone( )：不需要任何构造器，需要当前类实现Cloneable接口，实现clone( )\n使用反序列化：从文件中、网络中获取对象的二进制流\n使用第三方库Objenesis\n\n\n\n\n\n\n\n\n\n\n创建对象的步骤\n\n判断对象对应的类是否加载、链接、初始化\n虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化。（存在则进入第二步）。如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader+包名+类名为key进行查找对应的.class文件。如果没有找到文件，则抛出ClassNotFoundException异常，如果找到，则进行类加载，并生成对应的Class对象。\n\n\n为对象分配内存：首先计算对象占用空间大小，接着在堆中划分一块内存给新对象。如果实例成员变量是引用变量，仅分配引用变量空间即可，即4个字节大小。\n如果内存规整–指针碰撞（Bump The Pointer）\n所有用过的内存在一边，空闲的内存在一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针向空闲那边挪动一小段与对象大小相等的距离。如果垃圾收集器选择的是Serial、ParNew这种基于压缩算法的，虚拟机将采用这种分配方式。一般使用带有compact（整理）过程的收集器时，使用指针碰撞。\n\n\n如果内存不规整–空闲列表分配\n虚拟机维护了一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容，这种分配方式称为“空闲列表（Free List）”\n\n\n\n\n处理并发安全问题 ×\n采用CAS失败重试、区域加锁保证更新的原子性\n每个线程预先分配一块TLAB——通过-XX:+/-UseTLAB参数来设置\n\n\n初始化分配到的空间\n成员属性设置默认值，保证对象实例字段在不赋值时可以直接使用\n\n\n设置对象的对象头\n将对象的所属类（类的元数据信息）、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。\n\n\n执行init方法进行初始化\n在Java程序的视角来看，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内存对象的首地址赋值给引用变量。\n因此一般来说（由字节码中是否跟随有invokespecial指令所决定），new指令之后会接着执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用 的对象才算创建出来\n\n\n\n内存布局对象头包含两部分；如果是数组，还需记录数组的长度。\n\n运行时元数据（Mark Word）\n哈希值（HashCode）\nGC分代年龄\n帧状态标志\n线程持有的锁\n偏向进程ID\n偏向时间戳\n\n\n类型指针 KClass\n指向类元数据InstanceKlass，确定该对象所属的类型\n\n\n\n实例数据\n\n\n\n\n\n\n\n\n说明：它是对象真正存储的有效信息，包括程序代码中定义的各种类型的字段（包括从父类继承下来的和本身拥有的字段）\n\n相同宽度的字段总是被分配在一起；\n父类中定义的变量会出现在子类之前；\n如果CompactFields参数为true（默认true）：子类的窄变量可能插入到父类变量的空隙\n\n对齐填充（Padding）不是必须的，也没有特殊含义，仅仅起到占位符的作用\n小结：图示\n面试提要：对象访问定位\n\n\n\n\n\n\n\n\nJVM是如何通过栈帧中的对象引用访问到其内部的对象实例的呢？\n\n 定位，通过栈上reference访问\n对象访问的两种方式句柄访问 \n优点：reference中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针即可，reference本身不需要移动。\n直接访问（HostSpot采用）\n优点：节省空间，速度快。\n简介：直接内存\n直接内存是在Java堆外的、直接向系统申请的内存空间。\n来源于NIO，通过存在堆中的DirectByteBuffer操作Native内存\n通常，访问直接内存的速度会优于Java堆，即可读性能高。\n因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。\nJava的NIO库允许Java程序使用直接内存，用于数据缓冲区。\n\n\n\n\n\n\n也可能导致OutOfMemoryError异常\n由于直接内存存在Java堆外，因此它的大小不会直接受限于-Xmx指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。\n缺点\n分配回收成本较高\n不受JVM内存回收管理\n\n\n直接内存大小可以通过MaxDirectMemorySize这只\n如果不指定，默认与堆的最大值-Xmx参数值一致\n\n本地方法接口什么是本地方法？简单的讲，一个 Native Method 就是一个Java调用非Java代码的接口。一个Native Method就是这样一个Java方法；该方法的实现由非Java语言实现，比如C。这个特征并非Java所特有，很多其他的编程语言都有这一机制，比如在C++中，可以使用extern “C” 告知编译器去调用一个C的函数\n“A native method is a Java Method whose implmentation is provided by non-java code”\n在定义一个native method时，并不提供实现体（有些像定义一个Javainterface），因为其实现体是由非Java语言在外面实现的。\n本地接口的作用是融合不同的编程语言为Java所用，它的初衷是为了结合 C&#x2F;C++ 程序\n为什么要使用 Native Method？Java使用非常方便，然而有些层次的任务用Java实现起来不容器，或者程序效率不够理想，那么问题就来了。\n\n与Java环境外交互\n\n有时Java应用需要与Java外面的环境交互，这就是本地方法存在的主要原因。你可以想象Java需要一些与底层系统，如操作系统或某些硬件交换信息时的情况，本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解Java应用之外的繁琐细节。\n\n与操作系统交互\n\nJVM支持着Java语言本身和运行时库，它是Java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟是一个完整的系统，它经常依赖于一些底层系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用Java实现了jre的底层系统的交互，甚至JVM的一些部分就是用C编写的。还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特征时，我们也需要使用本地方法。\n\nSun’s Java\n\nSun的解释器使用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分使用Java实现的，它也通过一些本地方法与外界交互。例如，类java.lang.Thread的 setPriority( ) 方法使用Java实现的，但是它实现调用的是该类里的本地方法 setPriority0( )。这个本地方法是由C实现的，并被置入JVM内部，在Windows 95的平台上，这个本地方法最终将调用Win 32 SetPriority( ) API。这是一个本地方法的具体实现，由JVM直接提供，更多的情况是本地方法由外部的动态链接库(external dynamic link library)提供，ranhoubeiJVM调用。\n现状目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，在企业及应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用Socket通信，也可以使用Web Service等等，不多做介绍。\n重点：垃圾回收器垃圾回收概述什么是垃圾\n垃圾是指在运行程序中没有任何指针指向的对象\n\n为什么需要GC\n对于高级语言来说，一个基本认知是如果不进行垃圾回收，内存迟早都会被消耗完，因为不断地分配内存空间而不进行回收，就好像不停地生产生活垃圾而从来不打扫一样。\n除了释放没用的对象，垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存移到堆的另一端，以便JVM将整理出的内存分配给新的对象。\n随着应用程序所应付的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序的正常进行。而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。\n\n早期垃圾回收\n在早起的C&#x2F;C++时代，垃圾回收基本上是手工进行的，开发人员可以使用 new 关键字进行内存申请，并使用 delete 关键字进行内存释放。比如以下代码：\n\n这种方式可以灵活控制内存释放的时间，但是会给开发人员带来频繁申请和释放内存的管理负担。倘若有一处内存区间由于程序员编码的问题忘记被回收，那么就会产生内存泄漏，垃圾对象永远无法被清除，随着系统运行时间的不断增长，垃圾对象所消耗内存可能持续上升，直到出现内存溢出并造成程序崩溃。\n\n\nJava垃圾回收机制\n自动内存管理，无需开发人员手动参与内存分配与回收，这样降低内存泄漏和内存溢出的风险\n自动内存管理，将程序员从繁重的内存管理中释放出来，可以更专心地专注于业务开发\n\n\n\n对于Java开发人员而言，自动内存管理就像是一个黑匣子，如果过度依赖于“自动”，那么这将会是一场灾难，最严重的就会弱化Java开发人员在程序出现内存溢出时定位问题和解决问题的能力。\n当需要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，我们就必须对这些“自动化”的技术\n\n\n\n垃圾回收器可以对年轻代回收，也可以对老年代回收，甚至是全堆和方法区的回收。\n其中，Java堆是垃圾收集器的工作重点。\n\n\n从次数上来讲：\n频繁收集Young区\n较少收集Old区\n基本不动Perm区（元空间）\n\n\n\n垃圾回收相关算法标记阶段：引用计数算法\n\n\n\n\n\n\n\n\n垃圾标记阶段：对象存活判断\n\n在堆里存放着几乎所有的Java对象实例，在GC执行垃圾回收之前，首先需要区分出内存中哪些是存活的对象，哪些是已经死亡的对象，只有被标记为已经死亡的对象，GC才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们称之为垃圾标记阶段。\n那么在JVM中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。\n判断对象存活一般有两种方式：引用计数算法 和 可达性分析算法。\n\n引用计数算法概述\n引用计数算法（Reference Counting）比较简单，对每个对象保存一个整型的引用计数器属性。用于记录对象被引用的情况。\n对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加一；当引用失效就减一。当为0时，即表示对象A不可能再被使用，可进行回收。\n优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。\n缺点：\n它需要单独的字段存储计数器，增加了存储空间的开销。\n每次赋值都需要更新计数器，伴随着加法和减法操作，增加了时间开销。\n引用计数器有一个严重的问题，即无法处理循环引用的情况，这是一条致命缺陷，导致在Java的垃圾回收器中没有使用这类算法。\n\n\n\n\n小结\n引用计数算法，是很多语言党的资源回收选择，例如Python，它更是同时支持引用计数和垃圾收集机制。\n具体哪种最优还是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。\nJava并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。\nPython 如何解决？\n手动解除：很好理解，就是在合适的时机，解除引用关系。\n使用弱引用 weakref，weakref是 Python 提供的标准库，旨在解决循环引用。\n\n\n\n标记阶段：可达性分析算法概述\n相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。\n相较于引用计数算法，这里的可达性分析就是 Java、C# 选择的。这种类型的垃圾收集通常也叫做追踪性垃圾收集（Tracing Garbage Collection）。\n所谓“GC Roots”根集合就是一组必须活跃的引用。\n基本思路：\n可达性分析算法是以跟对象集合（GC Roots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。\n使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）\n如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象已经死亡，可以标记为垃圾对象。\n在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。\n\n\n\nGC Roots在Java 语言中，GC Roots包括以下几类元素：\n\n虚拟机中栈中引用的对象\n比如：各个线程被调用的方法中使用到的参数、局部变量等。\n\n\n本地方法栈内JNI（通常说的本地方法）引用的对象\n堆中类静态属性引用的对象\n比如：Java 类的引用类型静态变量\n\n\n方法区中常量引用的对象\n比如：字符串常量池（String Table）里的引用\n\n\n所有被同步锁synchronized持有的对象\nJava虚拟机内部的引用。\n基本数据类型对应的Class对象，一些常驻的异常对象（如：NullPointerException、OutOfMemoryError），系统类加载器。\n\n\n反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。\n\n\n\n除了这些固定的GC Roots以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。比如：分代收集和局部回收（Partial GC）。\n如果只针对Java堆中的某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到内存区域是虚拟机自己的实现细节，更不是孤立封闭的，这个区域的对象完全有可能被去其他区域的对象所引用，这时候就需要一并将关联的区域对象也加入GC Roots集合中去考虑，才能保证可达性分析的准确性。\n\n\n小技巧：\n由于 Root 采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个Root。\n\n\n\n\n\n如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。\n这点也是导致GC进行时必须“Stop The World”的一个重要原因。即使是号称不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。\n\n对象的 finalization 机制\nJava语言提供了对象终止（finalization）机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。\n当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的 finalize( )方法。\nfinalize( ) 方法允许在子类中被重写，用于在对象被回收时进行资源释放。通常这个方法中进行一些资源释放和清理的工作，比如关闭文件套接字和数据库连接等等。\n永远不要主动调用 finalize( )方法，应该交给垃圾回收机制调用。理由包括以下三点：\nfinalize( ) 可能导致对象复活\nfinalize( ) 方法的执行时间是没有保证的，它完全由GC线程决定，极端情况下，若不发生GC，则 finalize( ) 方法没有执行机会。\n一个糟糕的 finalize( )会严重影响GC性能。\n\n\n从功能上来说， finalze( ) 方法与C++中的析构函数比较类似，但是Java所采用的是基于垃圾回收器的自动内存管理机制，所以 finalize( )方法在本质上不同于C++中的析构函数。\n由于finalize( )方法的存在，虚拟机中的对象一般处于三种可能的状态。\n\n\n\n如果从所有的根节点都无法访问某个对象，说明对象已经不再使用了。一般来说，此对象需要被回收。但事实上，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段。一个无法触及的对象有可能在某一个条件下“复活”自己，如果这样，那么对它的回收就是不合理的，为此，定义虚拟机中的对象可能的三种状态，如下：\n可触及的：从根节点开始，可以到达这个对象\n可复活的：对象的所有引用都被释放，但是对象有可能在 finalize( ) 中复活。\n不可触及的：对象的 finalize( )被调用，并且没有复活，那么就会进入不可触及状态，不可触及状态的对象不可能复活，因为 finalize( )方法只调用一次。\n\n\n以上三种状态中，由于 finalize( )方法的存在，进行的区分，只有在对象不可触及时才可以被回收。\n\n\n\n判定一个对象objA是否可回收，至少要经历两次标记过程：\n如果对象objA到GC Roots没有引用链，则进行第一次标记。\n进行筛选，判断此对象是否有必要执行 finalize( )方法\n如果对象objA没有重写 finalize( )方法，或者 finalize( )方法已经被虚拟机调用过，则虚拟机视为“没有必要执行”，objA被判定为不可触及的。\n如果对象objA重写了 finalize( )，且还未执行过，那么objA会被插入到 F-Queue 队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其 finalize( )方法执行。\nfinalize( )方法是对象逃脱死亡的最后且唯一一次机会，稍后GC会对 F-Queue 队列中的对象进行第二次标记。如果 objA在 finalize( )方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA会被移除“即将回收”集合。之后，对象会再次出现没有引用存在的情况。在这个情况下，finalize方法不会被在此调用，对象会直接变成不可触及的状态，也就是说，一个对象的 finalize 方法只会被调用一次。\n\n\n\n\n\n\n-XX:+HeapDumpOnOutOfMemoryError:堆空间内存溢出快照\n清除阶段：标记-清除算法常见的三种垃圾收集算法是：标记-清除算法（Mark-Sweep）、复制算法（Copying）、标记-压缩算法（Mark-Compact）。\n\n\n\n\n\n\n\n\n\n背景\n标记 - 清除算法是一种非常基础和常见的垃圾收集算法，该算法被J.McCarthy等人在1960年提出并应用于Lisp语言。\n\n\n\n\n\n\n\n\n\n执行过程\n当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（stop the world），然后进行两项工作：\n\n标记：Collector从引用根节点开始遍历，标记所有被引用的对象（非垃圾对象）。一般是在对象的Header中记录为可达对象。\n清除：Collector对堆内存从头到尾进行线性的遍历，如果发现某个对象在其Header中没有标记为可达对象，则将其回收。\n\n\n\n\n\n\n\n\n\n\n缺点\n\n效率不高\n在进行GC时，需要停止整个应用程序，导致用户体验差\n这种方式清理出来的空闲内存是不连续的，会产生内存碎片。需要维护一个空闲列表。\n\n\n\n\n\n\n\n\n\n\n注意：何为清除？\n\n这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放。\n\n清除阶段：复制算法\n\n\n\n\n\n\n\n\n背景\n\n\n\n\n\n\n\n\n\n\n核心思想\n将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。\n\n\n\n\n\n\n\n\n\n优点\n\n没有标记和清除过程，实现简单，运行高效\n复制过去以后保证空间的连续性，不会出现“碎片”问题。\n\n\n\n\n\n\n\n\n\n\n缺点\n\n此算法的缺点也是很明显的，就是需要两倍的内存空间。\n对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，不管是内存占用或者时间开销也不小。\n\n\n\n\n\n\n\n\n\n\n特别的\n\n如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大，或者说非常低。\n\n\n\n\n\n\n\n\n\n\n应用场景\n在新生代，对常规应用的垃圾回收，一词通常可以到达70%~99%的内存空间，回收性价比很高，所以现在的商业虚拟机都是用这种收集算法回收新生代。\n清除阶段：标记-压缩算法\n\n\n\n\n\n\n\n\n背景\n复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的，这种情况在新生代经常使用，但是在老年代，更常见的情况是大部分对象都是存活对象，如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。因此，基于老年代垃圾回收的特性，需要使用其他算法。\n标记 - 清除算法的确可以应用在老年代中，但是该算法不仅执行效率底下，而且在执行完内存回收后还会产生内存碎片，所以JVM的设计者需要在此基础上进行改进。标记 - 压缩 算法由此诞生。\n1970年前后，G.L.Steele、C.J.Chene和D.S.Wise等研究者发布 标记 - 压缩 算法。在许多现代的垃圾收集器中，很多都是用了 标记 - 压缩算法或其他改进版本。\n\n\n\n\n\n\n\n\n\n执行过程\n\n标记 - 压缩算法的最终效果等同于 标记 - 清除算法执行完后，再进行一次内存碎片整理，因此，也可以把它称为 标记 - 清除 - 压缩（Mark-Sweep-Compact）算法。\n二者的本质差异在于标记 - 清除算法是一种非移动式的回收算法，标记 - 压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。\n可以看到，标记的存活对象会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉，如此依赖，当我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了很多开销。 \n\n\n\n\n\n\n\n\n\n 优点\n\n消除了 标记 - 清除算法中，内存区域分散的缺点，我们需要给对象分配内存时，JVM只需要持有一个内存的起始地址即可。\n消除了复制算法中，内存减半的空间代价。\n\n\n\n\n\n\n\n\n\n\n缺点\n\n从效率上来说，标记 - 整理算法要低于复制算法。\n移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址。\n移动过程中，需要STW\n\n小结\nGC分代收集\n增量收集算法上述现有的算法，在垃圾回收过程中，应用软件将处于一种 Stop The World 的的状态，在Stop The World 状态下，应用程序所有的线程都会被挂起，暂停一切工作，等待垃圾回收工作的完成。如果该时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究诞生了 增量收集算法（Incremental Collecting）。\n\n\n\n\n\n\n\n\n\n 基本思想\n如果一次性将所有的垃圾进行处理，需要造成的系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替进行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。\n总的来说，增量收集算法的基础仍然是传统的标记 - 清除和复制算法。增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。\n缺点：\n\n使用这种方式，由于在垃圾回收过程中，间断性地还会执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。\n\n分区收集算法一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长，为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。\n分代算法将按照对象的生命周期长短划分为两个部分，分区算法将整个堆空间划分成连续的不同小区间 region。\n每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。\n\n\n\n\n垃圾回收相关概念System.gc( )的理解\n在默认情况下，通过System.gc( )或者Runtime.getRuntime( ).gc( )的调用，会显式触发Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。\n然而 System.gc( )调用附带一个免责声明，无法保证对垃圾收集器的调用。\nJVM实现者可以通过 System.gc( )调用来决定JVM的GC行为。而一般情况下，垃圾回收应该是自动进行的，无需手动触发，否则过于麻烦。在一些特殊情况下，比如我们正在编写一个性能基准，我们可以在运行之间调用 System.gc( )\n\n垃圾回收的并行与并发并发（Concurrent）\n在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理器上运行。\n并发并不是真正意义上的“同时进行”，只是CPU把一个时间段划分成几个时间段（时间区间），然后在这几个时间区间之间来回切换，由于CPU处理速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时进行。\n\n\n\n并行（Parallel）\n当系统有一个以上的CPU时，某一个 CPU执行一个进程时，另一个CPU可以执行另外一个进程，两个进程互不抢占CPU资源，可以同时进行，我们称之为并行（Parallel）。\n其实决定并行的因素并不是CPU的数量，而是CPU核心数量，比如一个CPU多个核也可以并行。\n适合科学计算，后台处理等弱交互场景\n\n\n\n\n\n二者对比并发，指的是多个事情，在同一时间段内同时发生了。并行，指的是多个事情，在同一时间点上同时发生了。\n并发的多个任务之间是相互抢占资源的。并行的多个任务之间是互不抢占资源的。\n只有多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。\n垃圾回收的并发与并行\n并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。\n如 ParNew、Parallel Scavenge、 Parallel Old；\n\n\n串行（Serial）\n相较于并行的概念，单线程执行。\n若果内存不够，则程序暂停，启动JVM垃圾回收器进行垃圾回收。回收完，再启动程序的线程。\n\n\n并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾回收线程在执行时不会停顿用户程序的运行。\n用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上；\n如：CMS、G1\n\n\n\n安全点与安全区域安全点程序执行时并非在所有地方都能停顿下来开始 GC，只有特定的位置才能停下来开始GC，这些位置称为“安全点（Safepoint）”。\nSafe Point 的选择很重要，如果太少可能会导致GC等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会根据“是否具有让程序长时间执行的特征”为标准。比如：选择一些执行时间较长的指令作为Safe Point，如方法调用、循环跳转和异常跳转等。\n\n\n\n\n\n\n\n\n\n如何在GC发生时，检查所有线程都跑到最近的安全点停顿下来呢？\n\n抢先式中断：（目前没有虚拟机采用了）\n\n首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。\n\n主动式中断：\n\n如果设置一个中断标志，各个线程运行到 Safe Point 的时候主动轮询这个标志，如果中断标志为真，则将自己进行中断挂起。 \n安全区域Safepoint 机制保证了程序执行时，在很短的时间内就会遇到可进入GC的 Safepoint。但是，程序“不执行”的时候呢？例如线程处于Sleep状态或Blocked状态，这时候线程无法响应JVM的中断请求，“走”到安全点去中断挂起，JVM也不太可能被等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。\n安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中任何位置开始GC都是安全的。我们也可以把 Safe Region看做是被扩展了的 Safepoint。\n实际执行时：\n\n当线程运行到 Safe Region 的代码时，首先标识已经进入了 Safe Region，如果这段时间内发生 GC，JVM会忽略标识为 Safe Region状态的线程；\n当线程即将离开 Safe Region时，会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等代直到收到可以安全离开 Safe Region 的信号为止。\n\n再谈引用我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是很紧张，则可以抛弃这些对象。\n【既偏门又非常高频的面试题】强引用、软引用、弱引用、虚引用有什么区别？具体使用场景是什么？\n在JDK 1.2 版本之后，Java对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）4种，这四种引用强度依次减弱。\n除强引用外，其他3种引用均可以在java.lang.ref包中找到，如下图，显示了这三种引用类型对应的类，开发人员可以在程序中直接使用。\n\n\n\n\nReference 子类中只有终结器引用是包内可见的，其他3种引用类型均为 public ，可以在应用程序中直接使用\n\n强引用（StrongReference）：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“Object obj &#x3D; new Object ( )”这种引用关系。无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。\n软引用（SoftReference）：在系统将要发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。\n弱引用（WeakReference）：被弱引用关联的对象只能生存到下一次垃圾收集之前。当垃圾收集器工作时，无论内存空间是否足够，都会回收掉被弱引用关联的对象。\n虚引用（PhantomReference）：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。\n\n强引用（Strong Reference） – 不回收在Java程序中，最常见的引用类型是强引用（普通系统99%以上都是强引用），也就是我们最常见的普通对象引用，也就是默认的引用类型。\n当在Java中使用 new 关键字创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。\n强引用的对象是可触及的，垃圾收集器就永远不会回收掉被引用的对象。\n对于一个普通的对象，如果没有其它应用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。\n相对的，软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成Java内存泄漏的主要原因之一。\n软引用（Soft Reference） – 内存不足即回收软引用是用来描述一些还有用，但非必要的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这回收仍然没有足够内存，则会抛出OOM异常。\n软引用通常用来实现内存敏感的缓存。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，以保证程序正常进行。\n垃圾回收器在某个时刻决定回收软件可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列（Reference Queue）。\n类似弱引用，只不过Java虚拟机会尽量让软引用的存活时间更长一些，迫不得已才清理。\n\n\n\n\n弱引用（Weak Referenc） – 发现即回收弱引用也是用来描述那些非必要对象，只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统GC时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。\n但是，由于垃圾回收器的线程优先级非常低，因此，并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。\n弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。\n软引用、弱引用都非常适合来保存那些可有可无的缓存数据，如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出，而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而加速程序运行。\n虚引用（Phantom Reference） – 对象回收跟踪也成为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个。\n一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可以被垃圾回收器回收。\n它不能单独使用，也无法通过虚引用来获取被引用的对象。当时图通过虚引用的 get( ) 方法获得对象时，总是 null。\n为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如：能在这个对象被回收时收到一个系统通知。\n\n虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。\n由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。\n在JDK 1.2之后提供了 PhantomReference 类来实现虚引用。\n\n\n\nNIO中缓冲区的 allocateDirect() 方法中就使用了虚引用，其中直接内存的分配是调用 Unsafe 对象的 allocateMemory 方法来分配直接内存，其中的 Cleaner 是该缓冲区的虚引用对象\n\n\n\n终结器引用（Final Reference）\n它用以实现对象的 finalize( ) 方法，也可以称为终结器引用\n无需手动编码，其内部配合引用队列使用\n在GC时，终结器引用入队，由Finalizer线程通过终结器引用找到被引用对象并调用它的finalize( )方法，第二次GC时才能回收被引用对象。\n\n垃圾回收器 - 实现\n\n\n\n\n\n\n\n\n概述\n\n垃圾收集器没有在规范中进行过多的规定，可以由不同的厂商、不同的版本的JVM来实现。\n由于JDK的版本处于高速迭代的过程中，因此Java发展至今已经衍生了众多的GC。\n从不同角度分析垃圾收集器，可以将其分为不同的类型。\n\n\n\n\n串行回收指的是在同一时间段内只允许有一个CPU用于执行垃圾回收操作，此时工作线程被暂停，直至垃圾收集工作结束。\n在诸如单CPU处理器或者较小的应用内存等硬件平台不是特别优越的场合，串行回收器的性能可以超过并行回收器和并发回收器。所以，串行回收默认被应用在客户端的Client模式下的JVM中\n在并发能力比较强的CPU上，并行回收器产生的停顿时间要短于串行回收器。\n\n\n并行收集可以运用多个CPU同时执行垃圾回收，因此1提升了应用的吞吐量，不过并行回收仍然与串行回收一样，采用独占式，存在STW。\n\n\n\n\n\n\n\nGC分类与性能指标\n吞吐量：运行用户代码的时间占总运行时间的比例\n总运行时间：程序运行的时间 + 内存回收时间\n\n\n垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例\n暂停时间：执行垃圾收集时，程序的工作线程被暂停的时间\n收集频率：相对于应用程序的执行，手机操作发生的频率\n内存占用：Java堆区所占的内存大小\n快速：一个对象从诞生到被回收所经历的时间\n\n\n\n这三者共同构成一个“不可能三角”。三者总体的表现会随着技术进步而越来越好。一款优秀的收集器通常最多同时满足其中的两项。\n这三项里，暂停时间的重要性日益凸显，因为随着硬件发展，内存占用多些越来越能容忍，硬件性能提升也有助于降低收集器运行时对应用程序的影响，即提高了吞吐量。而内存的扩大，对延迟反而带来负面效果。\n简单来说，主要抓两点：\n吞吐量、暂停时间\n\n\n\n评估GC的性能指标：吞吐量（throughput）\n吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 &#x3D; 运行用户代码时间 &#x2F; （运行用户代码时间 + 垃圾收集时间）。\n比如：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是 99%。\n\n\n这种情况下，应用程序能容忍较高的暂停时间，因此从，高吞吐量的的应用程序有更长的时间基准，快速响应是不必考虑的。\n吞吐量优先，意味着在单位时间内，STW时间最短： 0.2 + 0.2 &#x3D; 0.4\n\n\n\n评估GC的性能指标：暂停时间（pause time）\n“暂停时间”是指一个时间段内应用程序线程暂停，让GC线程执行的状态\n例如，GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的。\n\n\n暂停时间优先，意味着尽可能让单次STW时间最短：0.1 + 0.1 + 0.1 + 0.1 + 0.1 &#x3D; 0.5\n\n\n\n\n\n吞吐量 vs 暂停时间\n\n\n\n\n\n不同的垃圾回收器概述垃圾收集器发展史有了虚拟机，就一定需要收集垃圾的机制，这就是Garbage Collection，对应的产品我们称为 Garbage Collector。\n\n1999年随着JDK1.3.1 一起来的是串行方式的 Serial GC，它是第一款GC。ParNew 垃圾收集器是 Serial 收集器的多线程版本。\n2002年2月26日，Parallel GC和 Concurrent Mark Sweep GC跟随 JDK1.4.2一起发布\nParallel GC 在JDK1.6之后称为HopSpot默认GC\n2012年，在JDK1.7u4版本中，G1可用\n2017年，JDK9中G1编程默认的垃圾收集器，代替CMS\n2018年3月，JDK10中G1垃圾收集器的并行完整垃圾回收，实现并行性来改善最坏情况下的延迟。\n2018年9月，JDK11发布。引入Epsilon垃圾回收器，又被称为“No-Op（无操作）”回收器。同时，引入ZGC：可伸缩的低延迟垃圾回收器（Experimental）。\n2019年3月，JDK12发布。增强G1，自动返回未用堆内存给操作系统。同时，引入 Shenandoah GC；低停顿时间的GC（Experimental）\n2019年9月，JDK13发布。增强ZGC，自动返回未用堆内存给操作系统。\n2020年3月，JDK14发布。删除CMS垃圾回收器。扩展ZGC在 macOS和 Windows上的应用。\n\n\n\n\n\n\n\n\n\n\n\n\n如何查看默认垃圾收集器？\n-XX:+PrintCommandLineFlags：查看命令行相关参数，包括使用的垃圾收集器\njinfo -flag 相关垃圾回收器参数 进程id\nUseParallelGC  &amp;  UseParallelOldGC  &amp;  UseG1GC\n\n\n\nSerial 回收器：串行回收（标记清除）\nSerial 收集器是最基本、历史最久远的垃圾收集器了。JDK1.3之前回收新生代的唯一选择。\nSerial 收集器作为HotSpot中Client模式下的默认新生代垃圾收集器。\nSerial 收集器采用复制算法、串行回收和“Stop-The-World”机制的方式执行内存回收。\n除了年轻代之外，Serial收集器还提供用于执行老年代垃圾收集的Serial Old收集器。Serial Old收集器同样采用了串行回收和STW机制，只不过内存回收算法上使用的是标记 - 压缩算法。\nSerial Old是运行在Client模式下默认的老年代垃圾回收器。\nSerial Old在Server模式下主要由两个用途：①与新生代的Parallel Scavenge 配合使用 ②作为老年代CMS收集器的后背垃圾收集方案。\n\n\n\n\n\n\n优势：简单而高效（与其他收集器的单线程相比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。\n运行在Client模式下的虚拟机是个不错的选择。\n\n\n在用户的桌面应用场景中，可用内存一般不大（几十MB至一两百MB），可以在较短时间内完成垃圾收集，只要不频繁发生，使用串行回收器是可以接受的。\n在HotSpot虚拟机中，使用-XX:+UseSerialGC参数可以指定年轻代和老年代都使用串行收集器。\n等价于 新生代使用 Serial GC，老年代使用 Serial Old GC\n\n\n\n\n\n\n\n\n\n\n\n\n Serial 总结\n这种垃圾收集器了解即可，现在已经不使用了，而且限定在单核CPU才可以用，现在都是多核的。\n对于交互较强的应用而言，这种垃圾收集器是不能接受的。一般在Java web应用程序中是不会采用串行垃圾收集器的。\nParNew 回收器：并行回收（复制算法)\n由于ParNew 收集器是基于并行回收，那么是否可以判定ParNew收集器的回收效率在任何场景下都会比Serial收集器更高效？\nParNew收集器运行在多CPU的环境下，由于可以充分利用CPU、多核心等物理硬件优势，可以更快速地完成垃圾收集，提升程序吞吐量。\n但是在单个CPU的环境下，ParNew收集器不比Serial收集器效率高。虽然Serial收集器是基于串行回收，但是由于CPU不需要频繁地做任务切换，因此可以有效避免多线程交互过程中产生的一些额外开销。\n\n\n除Serial外，目前只有 ParNew GC能与CMS收集器配合工作。\n显式使用：-XX:+UseParNewGC\n限制线程数量：-XX:ParallelGCThreads，默认开启和CPU数据相同的线程数\n\nParallel回收器：吞吐量优先、并行回收（复制算法+标记压缩）\nHotSpot年轻代中除了拥有ParNew收集器是基于并行回收的以外，Parallel Scavenge 收集器同样也采用了复制算法、并行回收和“Stop - The - World”机制\n那么Parallel收集器的出现是否多此一举？\n与ParNew收集器不同，Parallel Scavenge收集器的目标是达到一个可控制的吞吐量（Throughput），它也被称为吞吐量优先的垃圾收集器。\n自适应调节策略也是Parallel Scavenge与ParNew的一个重要区别\n\n\n高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务，因此，常见在服务器环境中使用。例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。\nParallel 收集器在JDK1.6时提供了用于执行老年代垃圾收集的Parallel Old收集器，用来代替老年代的Serial Old收集器\nParallel Old收集器采用了 标记 - 压缩 算法，同样也是基于并行回收和STW机制。\n在程序吞吐量优先的应用场景中，Parallel 收集器和 Parallel Old收集器的组合，在Server模式下的内存回收性能很不错。\n在JDK 8中，作为默认收集器\n\n\n\n\n\n\n\n\n\n\n\n参数配置\n\n-XX:+UseParallelGC：手动指定使用此组收集器\n-XX:+UseParallelOldGC：手动指定使用此组收集器，效果同上\n-XX:ParallelGCThreads：设置年轻代并行收集器的线程数。一般地，最好与CPU数量相等，以避免过多的线程数量影响垃圾收集性能。\n默认情况下，当CPU数量小于8个，ParallelGCThreads的值等于CPU数量；大于8个时，其值等于 3 + [ 5*CPU_Count ] &#x2F; 8\n\n\n-XX:MaxGCPauseMillis：设置垃圾收集器的最大停顿时间（即STW的时间）。单位毫秒\n为了尽可能的把停顿时间控制在MaxGCPauseMills以内，收集器在工作时会调整Java堆大小或者其他一些参数。\n对于用户来讲，停顿时间越短体验越好。但是在服务器端，我们注重高并发，整体的吞吐量。所以服务器端适合Parallel，进行控制。\n该参数使用需谨慎\n\n\n-XX:GCTimeRatio：垃圾收集时间占总时间的比例（ &#x3D; 1 &#x2F; ( N + 1 )）。用于衡量吞吐量的大小\n取值范围 ( 0 , 100 )。默认99，也就是垃圾回收时间不超过 1%\n与前一个-XX:MaxGCPauseMillis参数有一定的矛盾性。暂停时间越长，Radio参数就越容易超过设定的比例。\n\n\n-XX:+UseAdaptiveSizePolicy：设置Parallel Scavenge收集器具有自适应调节策略\n在这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数会被自动调整，已达到在堆大小、吞吐量和停顿时间之间的平衡点。\n在手动调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMillis），让虚拟机自己完成调优工作。\n\n\n\nCMS 回收器：低延迟、并发（标记清除）\n在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可以认为有划时代意义的垃圾收集器：CMS（Concurrent-Mark-Sweep）收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的 并发 收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。\nCMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短（低延迟）就越适合做与用户交互的程序，良好的响应速度能提升用户体验。\n目前很大一部分的Java应用集中在互联网站或者B&#x2F;S系统的服务器端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。\n\n\nCMS的收集算法采用 标记 - 清除 算法，并且也会STW\n不幸的是，CMS作为老年代的收集器，无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK 1.5 中使用CMS来收集老年代色时候，新生代中只能选择ParNew或者Serial中的一个。\n\n\n\nCMS整个过程比之前的收集器要复杂，整个过程分为4个主要阶段，即 初始标记阶段、并发标记阶段、重新标记阶段 和 并发清除阶段\n\n初始标记阶段（Initial - Mark）：在这个阶段中，程序中所有的工作线程都将会因为STW机制而出现短暂的停顿，这个阶段的任务仅仅是标记出GC Roots能直接关联到的对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较小，所以这里的速度非常快。\n并发标记阶段（Concurrent - Mark）：从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但不需要暂停用户线程，可以与垃圾收集线程一起并发运行。\n重新标记（Remark）阶段：由于在并发标记阶段中，程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了修正并发标记期间，因用户程序继续运作而导致的标记变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段时间短。\n并发清除阶段（Concurrent - Sweep）：此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n 参数设置\n\n-XX:+UseCMSCompactAtFullCollection：用于指定在执行完Full GC后对内存空间进行压缩整理，以此避免内存碎片问题的产生。不过由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变长了。\n-XX:CMSFullGCsBeforeCompaction：设置在执行多少次Full GC后对内存空间进行压缩整理\n-XX:ParallelCMSThreads：设置CMS的线程数量\n默认：( n + 3 ) &#x2F; 4  ；ParallelGCThreads是年轻代并行收集器的线程数。当CPU资源比较紧张时，受到CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。\n\n\n-XX:+UseConcMarkSweepGC：手动指定使用CMS收集器\n开启该参数后将会自动将 -XX:+UseParNewGC（Young）打开\n\n\n-XX:CMSlnitiatingOccupanyFraction：设置堆内存使用率的阈值，一旦达到该阈值，便进行垃圾回收。\nJDK5及以前的默认值为 68；JDK 6 及以上的默认值为 92\n如果内存增长缓慢，则可以设置一个稍大的值，大的阈值可以有效地降低CMS的触发频率，减少老年代回收的次数可以较为明显的改善应用程序性能。反之，如果应用程序内存使用率增长很快，则应降低这个阈值，以避免频繁触发老年代串行收集器。因此通过该选项便可以有效降低Full GC的执行次数。\n\n\n\nCMS小结\n\n\n\n\n\nG1回收器：区域化分代式\n\n\n\n\n\n\n\n\nG1垃圾收集器是一种工作在堆内不同分区上的并发收集器。分区既可以归属于老年代，也可以归属新生代，同一个代的分区不需要保持连续。为老年代设计分区的初衷是我们发现并发后台线程在回收老年代中没有引用的对象时，有的分区垃圾对象的数量很多，另一些分区垃圾对象相对较少。\n虽然分区的垃圾收集工作实际还是要暂停应用线程，不过由于G1收集器专注于垃圾最多的分区，最终的效果是花费较少的时间就能回收这些分区的垃圾。这种只**专注于垃圾最多的分区**的方式就是G1垃圾收集器的名称由来，即首先收集垃圾最多的分区。\n这一算法并不适用新生代的分区，新生代进行垃圾回收时，整个新生代空间要么被回收，要么被晋升。那么新生代也采用分区的原因是因为：采用预定义的分区能够便于代的大小调整。\nG1收集器的收集活动包括4种操作：\n\n新生代垃圾收集；\n后台收集，并发周期；\n混合式垃圾收集；\n以及必要时的Full GC。\n\nG1 特点\n并行与并发\n并行性：G1在回收期间，可以有多个GC线程同时工作，有效利用多核计算能力。此时用户线程STW。\n并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况。\n\n\n分代收集\n从分代上看，G1依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区和Survivor区。但从堆1的结构上来看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。\n将堆空间分为若干个区域（Region），这些区域中包含了逻辑上的年轻代和老年代。\n和之前的各类回收器不同，它同时兼顾年轻代和老年代。对比其他回收器，或工作在年轻代，或工作在老年代。\n\n\n空间整合\nCMS：“标记 - 清除”算法、内存碎片、若干次GC后进行一次碎片整理\nG1将内存划分为一个个的region。内存的回收是以region作为基本单位的。Region之间是复制算法，但整体上实际可看做是 标记 - 压缩（Mark - Compact）算法。这两种算法都可以避免内存碎片，这种特性有利于程序长期运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其是当Java堆非常大的时候，G1的优势更加明显。\n\n\n可预测的停顿时间模型（软实时 soft real - time）\n这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间段内，消耗在垃圾收集上的时间不得超过 N 毫秒。\n由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对全局停顿情况的发生也能得到较好的控制。\nG1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的的空间大小以及回收所需要的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。\n相比于CMS GC，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多。\n\n\n\nG1 不足相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（Overload）都比CMS要高。\n从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在 6 - 8 GB之间。\n\n\n\n\n\n\n\n\n\nG1参数设置\n\n-XX:+UseG1GC：手动指定使用G1\n-XX:G1HeapRegionSize：设置每个Region的大小。值是2的幂，范围是1M~32M，目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的 1&#x2F;2000\n-XX:MaxGCPauseMillis：设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不保证达到）。默认值是200ms\n-XX:ParallelGCThread：设置STW工作线程数的值，最大为8\n-XX:ConcGCThreads：设置并发标记的线程数。将 n 设置为并行垃圾回收线程数（ParallelGCThreads）的 1&#x2F;4 左右。\n-XX:InitiatingHeapOccupancyPercent：设置触发并GC周期的Java堆占用率阈值，超过此值，就出发GC。默认45\n\n\n\n\n\n\n\n\n\n\nG1回收器常见操作步骤\n\n开启G1垃圾收集器\n设置堆的最大内存\n设置最大的停顿时间\n\nG1回收器的使用场景\n面向服务端应用，针对具有大内存、多处理器的机器。（在普通大小的堆里表现并太好）\n最主要的应用是需要低GC延迟，并具有大堆的应用程序提供解决方案；\n如：在堆大小约为6GB或更大时，可预测的暂停时间可以低于0.5秒；（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次GC停顿时间不会过长）\n\n\n用来替换掉JDK1.5中的CMS收集器；如下情况G1的性能可能更好：\n超过50%的Java堆被活动数据占用；\n对象分配频率或年代提升频率变化很大；\nGC停顿时间过长（&gt;0.5s）\n\n\nHotSpot垃圾收集器里，除了G1以外，其他的垃圾收集器使用内置的JVM线程执行GC的多线程操作，而G1 GC可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序线程帮助加速垃圾回收过程。\n\n分区Region：化整为零使用G1收集器时，它将整个Java堆划分成约2048个大小相同的独立Region块，每个Region块大小根据堆空间的实际大小而定，整体被控制在1~32MB之间，且为2的N次幂。可以通过 -XX:G1HeapRegionSize设定。所有的Region大小相同，且在JVM生命周期内不会改变。\n虽然还保留有新生代与老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。通过Region的动态分配方式实现逻辑上的连续。\n\n\n\n\n\n\nG1回收垃圾过程G1 GC垃圾回收过程主要包括如下三个环节：\n\n年轻代GC（Young GC）\n老年代并发标记过程（Concurrent Marking）\n混合回收（Mixed GC）\n如果需要，单线程、独占式、高强度的Full GC还是继续存在的。它针对GC的评估失败提供了一种失败保护机制，即强力回收。\n\n\n\n应用程序分配内存，当年轻代的Eden区用尽时开始年轻代回收过程；G1的年轻代收集阶段是一个并行的独占式收集器。在年轻代回收期，G1 GC暂停所有应用程序线程，启动多线程执行年轻代回收，然后从年轻代区间移动存活对象到Survivor区间或者老年区间，也有可能是两个区间都会涉及。\n当堆内存使用达到一定值（默认45%）时，开始老年代并发标记过程。\n标记完成马上开始混合回收过程。对于一个混合回收期，G1 GC从老年区间移动存活对象到空闲区间，这些空闲区间也就成为了老年代的一部分。和年轻代不同，老年代的G1回收器和其他GC不同，G1的老年代回收器不需要整个老年代被回收，一次只需要扫描 &#x2F; 回收一小部分老年代的Region就可以了。同时，这个老年代Region是和年轻代一起被回收的。\n举个例子：一个Web服务器，Java进程最大堆内存为4G，每分钟响应1500个请求，每45秒会新分配大约2G的内存，G1每45秒进行一次年轻代回收，每31小时整个堆的使用率会达到45%，会开始老年代并发标记过程，标记完成后开始四到五次的混合回收。\nG1回收器垃圾回收过程：Rememberd Set\n一个对象被不同区域引用的问题\n一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？\n在其他的分代收集器，也存在这样的问题（而G1更突出）\n回收新生代也不得不同时扫描老年代？\n这样的话会降低Minor GC的效率；\n\n\n\n解决方法：\n无论是G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描；\n每个Region都有一个对应的Remembered Set；\n每次Reference类型数据写操作时，都会产生一个Write Barrier暂是中断操作；\n然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）；\n如果不同，通过CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中；\n当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。\n\n\n\n\n\n\n\n\n\nJVM启动时，G1先准备好Eden区，程序在运行过程中不断创建对象到Eden区，当Eden空间耗尽时，G1会启动一次年轻代垃圾回收过程。\nYGC时，首先G1停止应用程序的执行（STW），G1创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG1回收器优化建议\n年轻代大小\n避免使用 -Xmn 或者 -XX:NewRatio等相关选项显式设置年轻代大小\n固定年轻代大小会覆盖暂停时间目标\n\n\n暂停时间目标不要过于严苛\nG1 GC的吞吐量目标是90%的应用程序时间和10%的垃圾收集时间\n评估G1 GC吞吐量时，暂停时间目标不要太严苛。目标太过严苛表示你愿意承受更多的垃圾回收开销，而这些会直接影响到吞吐量。\n\n\n\n垃圾回收器总结【Java】JVM - 各版本默认垃圾收集器 - 掘金 (juejin.cn)\n\n\n\n\n怎样选择垃圾回收器？\nJava垃圾收集器的配置对于JVM优化来说是一个很重要的选择，选择合适的垃圾收集器可以让JVM的性能有一个很大的提升。\n怎样选择？\n优先调整堆的大小让JVM自适应完成。\n如果内存小于100M，使用串行收集器\n如果是单核、单机程序并且没有停顿时间的要求，串行收集器\n如果是多CPU、高吞吐量要求、允许停顿时间超过1s，选择并行或者JVM自己选择\n如果是多CPU、追求低停顿时间、需快速响应，使用并发收集器；官方推荐G1，性能高。现在的互联网项目，基本都是G1\n\n\n\n面试题要\n垃圾收集的算法有哪些？如何判断一个对象是否可以回收？\n垃圾收集器工作的基本流程\n\nGC 日志分析常用GC日志参数\n-XX:+PrintGC：输出GC日志。类似 -verbose:gc\n-XX:+PrintGCDetails：输出GC的详细日志\n-XX:+PrintGCTimeStamps：输出GC的时间戳（以基准时间的形式）\n-XX:+PrintGCDateStamps：输出GC的时间戳（以日期的形式，如2020-05-20T21:33:33.234+0800）\n-XX:+PrintHeapAtGC：在进行GC的前后打印出堆的信息\n-Xloggc:../logs/gc.log：日志文件输出路径\n\n\n\n\n\n\n\n\n\n\n垃圾回收器的最新发展OpenJDK12 - Shenandoah GC\n令人震惊、革命性的 GC\n其他的垃圾回收器：AliGC\n\n\n","slug":"JVM内存与垃圾回收","date":"2022-09-30T09:38:16.000Z","categories_index":"","tags_index":"JVM,学习笔记","author_index":"JuneQQQ"},{"id":"0f9864dd4863efa9b41c7bba5ace71e0","title":"Redis原理","content":"Redis原理篇1、原理篇-Redis数据结构1.1 动态字符串我们都知道Redis中保存的Key是字符串，value往往是字符串或者字符串的集合。可见字符串是Redis中最常用的一种数据结构。\n不过Redis没有直接使用C语言中的字符串，因为C语言字符串存在很多问题：获取字符串长度的需要通过运算非二进制安全不可修改Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String），简称SDS。例如，我们执行命令：\n\n那么Redis将在底层创建两个SDS，其中一个是包含“name”的SDS，另一个是包含“虎哥”的SDS。\nRedis是C语言实现的，其中SDS是一个结构体，源码如下：\n\n例如，一个包含字符串“name”的sds结构如下：\n\nSDS之所以叫做动态字符串，是因为它具备动态扩容的能力，例如一个内容为“hi”的SDS：\n\n假如我们要给SDS追加一段字符串“,Amy”，这里首先会申请新内存空间：\n如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1；\n如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1。称为内存预分配。\n\n\n1.2 intsetIntSet是Redis中set集合的一种实现方式，基于整数数组来实现，并且具备长度可变、有序等特征。结构如下：\n\n其中的encoding包含三种模式，表示存储的整数大小不同：\n\n为了方便查找，Redis会将intset中所有的整数按照升序依次保存在contents数组中，结构如图：\n\n现在，数组中每个数字都在int16_t的范围内，因此采用的编码方式是INTSET_ENC_INT16，每部分占用的字节大小为：encoding：4字节length：4字节contents：2字节 * 3  &#x3D; 6字节\n\n我们向该其中添加一个数字：50000，这个数字超出了int16_t的范围，intset会自动升级编码方式到合适的大小。以当前案例来说流程如下：\n\n升级编码为INTSET_ENC_INT32, 每个整数占4字节，并按照新的编码方式及元素个数扩容数组\n倒序依次将数组中的元素拷贝到扩容后的正确位置\n将待添加的元素放入数组末尾\n最后，将inset的encoding属性改为INTSET_ENC_INT32，将length属性改为4\n\n\n源码如下：\n\n\n小总结：\nIntset可以看做是特殊的整数数组，具备一些特点：\n\nRedis会确保Intset中的元素唯一、有序\n具备类型升级机制，可以节省内存空间\n底层采用二分查找方式来查询\n\n1.3 Dict我们知道Redis是一个键值型（Key-Value Pair）的数据库，我们可以根据键实现快速的增删改查。而键与值的映射关系正是通过Dict来实现的。Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）\n\n当我们向Dict添加键值对时，Redis首先根据key计算出hash值（h），然后利用 h &amp; sizemask来计算元素应该存储到数组中的哪个索引位置。我们存储k1&#x3D;v1，假设k1的哈希值h &#x3D;1，则1&amp;3 &#x3D;1，因此k1&#x3D;v1要存储到数组角标1位置。\n\nDict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）\n\n\n\nDict的扩容\nDict中的HashTable就是数组结合单向链表的实现，当集合中元素较多时，必然导致哈希冲突增多，链表过长，则查询效率会大大降低。Dict在每次新增键值对时都会检查负载因子（LoadFactor &#x3D; used&#x2F;size） ，满足以下两种情况时会触发哈希表扩容：哈希表的 LoadFactor &gt;&#x3D; 1，并且服务器没有执行 BGSAVE 或者 BGREWRITEAOF 等后台进程；哈希表的 LoadFactor &gt; 5 ；\n\n\nDict的rehash\n不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的size和sizemask变化，而key的查询与sizemask有关。因此必须对哈希表中的每一个key重新计算索引，插入新的哈希表，这个过程称为rehash。过程是这样的：\n\n计算新hash表的realeSize，值取决于当前要做的是扩容还是收缩：\n\n如果是扩容，则新size为第一个大于等于dict.ht[0].used + 1的2^n\n如果是收缩，则新size为第一个大于等于dict.ht[0].used的2^n （不得小于4）\n\n\n按照新的realeSize申请内存空间，创建dictht，并赋值给dict.ht[1]\n\n设置dict.rehashidx &#x3D; 0，标示开始rehash\n\n将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1]\n\n将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表，释放原来的dict.ht[0]的内存\n\n将rehashidx赋值为-1，代表rehash结束\n\n在rehash过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保ht[0]的数据只减不增，随着rehash最终为空\n\n\n整个过程可以描述成：\n\n小总结：\nDict的结构：\n\n类似java的HashTable，底层是数组加链表来解决哈希冲突\nDict包含两个哈希表，ht[0]平常用，ht[1]用来rehash\n\nDict的伸缩：\n\n当LoadFactor大于5或者LoadFactor大于1并且没有子进程任务时，Dict扩容\n当LoadFactor小于0.1时，Dict收缩\n扩容大小为第一个大于等于used + 1的2^n\n收缩大小为第一个大于等于used 的2^n\nDict采用渐进式rehash，每次访问Dict时执行一次rehash\nrehash时ht[0]只减不增，新增操作只在ht[1]执行，其它操作在两个哈希表\n\n1.4 ZipListZipList 是一种特殊的“双端链表” ，由一系列特殊编码的连续内存块组成。可以在任意一端进行压入&#x2F;弹出操作, 并且该操作的时间复杂度为 O(1)。\n\n\n\n\n\n属性\n类型\n长度\n用途\n\n\n\nzlbytes\nuint32_t\n4 字节\n记录整个压缩列表占用的内存字节数\n\n\nzltail\nuint32_t\n4 字节\n记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过这个偏移量，可以确定表尾节点的地址。\n\n\nzllen\nuint16_t\n2 字节\n记录了压缩列表包含的节点数量。 最大值为UINT16_MAX （65534），如果超过这个值，此处会记录为65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。\n\n\nentry\n列表节点\n不定\n压缩列表包含的各个节点，节点的长度由节点保存的内容决定。\n\n\nzlend\nuint8_t\n1 字节\n特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。\n\n\nZipListEntry\nZipList 中的Entry并不像普通链表那样记录前后节点的指针，因为记录两个指针要占用16个字节，浪费内存。而是采用了下面的结构：\n\n\nprevious_entry_length：前一节点的长度，占1个或5个字节。\n\n如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值\n如果前一节点的长度大于等于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据\n\n\nencoding：编码属性，记录content的数据类型（字符串还是整数）以及长度，占用1个、2个或5个字节\n\ncontents：负责保存节点的数据，可以是字符串或整数\n\n\nZipList中所有存储长度的数值均采用小端字节序，即低位字节在前，高位字节在后。例如：数值0x1234，采用小端字节序后实际存储值为：0x3412\nEncoding编码\nZipListEntry中的encoding编码分为字符串和整数两种：字符串：如果encoding是以“00”、“01”或者“10”开头，则证明content是字符串\n\n\n\n编码\n编码长度\n字符串大小\n\n\n\n|00pppppp|\n1 bytes\n&lt;&#x3D; 63 bytes\n\n\n|01pppppp|qqqqqqqq|\n2 bytes\n&lt;&#x3D; 16383 bytes\n\n\n|10000000|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt|\n5 bytes\n&lt;&#x3D; 4294967295 bytes\n\n\n例如，我们要保存字符串：“ab”和 “bc”\n\n ZipListEntry中的encoding编码分为字符串和整数两种：\n\n整数：如果encoding是以“11”开始，则证明content是整数，且encoding固定只占用1个字节\n\n\n\n\n编码\n编码长度\n整数类型\n\n\n\n11000000\n1\nint16_t（2 bytes）\n\n\n11010000\n1\nint32_t（4 bytes）\n\n\n11100000\n1\nint64_t（8 bytes）\n\n\n11110000\n1\n24位有符整数(3 bytes)\n\n\n11111110\n1\n8位有符整数(1 bytes)\n\n\n1111xxxx\n1\n直接在xxxx位置保存数值，范围从0001~1101，减1后结果为实际值\n\n\n\n\n1.5 ZipList的连锁更新问题ZipList的每个Entry都包含previous_entry_length来记录上一个节点的大小，长度是1个或5个字节：如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值如果前一节点的长度大于等于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据现在，假设我们有N个连续的、长度为250~253字节之间的entry，因此entry的previous_entry_length属性用1个字节即可表示，如图所示：\n\nZipList这种特殊情况下产生的连续多次空间扩展操作称之为连锁更新（Cascade Update）。新增、删除都可能导致连锁更新的发生。\n小总结：\nZipList特性：\n\n压缩列表的可以看做一种连续内存空间的”双向链表”\n列表的节点之间不是通过指针连接，而是记录上一节点和本节点长度来寻址，内存占用较低\n如果列表数据过多，导致链表过长，可能影响查询性能\n增或删较大数据时有可能发生连续更新问题\n\n1.6 QuickList问题1：ZipList虽然节省内存，但申请内存必须是连续空间，如果内存占用较多，申请内存效率很低。怎么办？\n答：为了缓解这个问题，我们必须限制ZipList的长度和entry大小。\n\n问题2：但是我们要存储大量数据，超出了ZipList最佳的上限该怎么办？\n答：我们可以创建多个ZipList来分片存储数据。\n\n问题3：数据拆分后比较分散，不方便管理和查找，这多个ZipList如何建立联系？\n答：Redis在3.2版本引入了新的数据结构QuickList，它是一个双端链表，只不过链表中的每个节点都是一个ZipList。\n\n\n为了避免QuickList中的每个ZipList中entry过多，Redis提供了一个配置项：list-max-ziplist-size来限制。该参数对应下面的fill变量如果值为正，则代表ZipList的允许的entry个数的最大值如果值为负，则代表ZipList的最大内存大小，分5种情况：\n\n-1：每个ZipList的内存占用不能超过4kb\n-2：每个ZipList的内存占用不能超过8kb\n-3：每个ZipList的内存占用不能超过16kb\n-4：每个ZipList的内存占用不能超过32kb\n-5：每个ZipList的内存占用不能超过64kb\n\n其默认值为 -2：\n\n以下是QuickList的和QuickListNode的结构源码：\n\n我们接下来用一段流程图来描述当前的这个结构\n\n总结：\nQuickList的特点：\n\n是一个节点为ZipList的双端链表\n节点采用ZipList，解决了传统链表的内存占用问题\n控制了ZipList大小，解决连续内存空间申请效率问题\n中间节点可以压缩，进一步节省了内存，控制参数：list-compress-depth\n0 特殊值，不压缩\n1 首位各不压缩1个节点，中间节点全部压缩\n2 首位各不压缩2个节点，中间节点全部压缩\n\n\n\n1.7 SkipListSkipList（跳表）首先是链表，但与传统链表相比有几点差异：元素按照升序排列存储节点可能包含多个指针，指针跨度不同。\n\nSkipList（跳表）首先是链表，但与传统链表相比有几点差异：元素按照升序排列存储节点可能包含多个指针，指针跨度不同。\n\nSkipList（跳表）首先是链表，但与传统链表相比有几点差异：元素按照升序排列存储节点可能包含多个指针，指针跨度不同。\n\n小总结：\nSkipList的特点：\n\n跳跃表是一个双向链表，每个节点都包含score和ele值\n节点按照score值排序，score值一样则按照ele字典排序\n每个节点都可以包含多层指针，层数是1到32之间的随机数\n不同层指针到下一个节点的跨度不同，层级越高，跨度越大\n增删改查效率与红黑树基本一致，实现却更简单\n\n1.8 RedisObjectRedis中的任意数据类型的键和值都会被封装为一个RedisObject，也叫做Redis对象，共16个字节，源码如下：\n1、什么是redisObject：从Redis的使用者的角度来看，⼀个Redis节点包含多个database（非cluster模式下默认是16个，cluster模式下只能是1个），而一个database维护了从key space到object space的映射关系。这个映射关系的key是string类型，⽽value可以是多种数据类型，比如：string, list, hash、set、sorted set等。我们可以看到，key的类型固定是string，而value可能的类型是多个。⽽从Redis内部实现的⾓度来看，database内的这个映射关系是用⼀个dict来维护的。dict的key固定用⼀种数据结构来表达就够了，这就是动态字符串sds。而value则比较复杂，为了在同⼀个dict内能够存储不同类型的value，这就需要⼀个通⽤的数据结构，这个通用的数据结构就是robj，全名是redisObject。\n\nRedis的编码方式\nRedis中会根据存储的数据类型不同，选择不同的编码方式，共包含11种不同类型：\n\n\n\n编号\n编码方式\n说明\n\n\n\n0\nOBJ_ENCODING_RAW\nraw编码动态字符串\n\n\n1\nOBJ_ENCODING_INT\nlong类型的整数的字符串\n\n\n2\nOBJ_ENCODING_HT\nhash表（字典dict）\n\n\n3\nOBJ_ENCODING_ZIPMAP\n已废弃\n\n\n4\nOBJ_ENCODING_LINKEDLIST\n双端链表\n\n\n5\nOBJ_ENCODING_ZIPLIST\n压缩列表\n\n\n6\nOBJ_ENCODING_INTSET\n整数集合\n\n\n7\nOBJ_ENCODING_SKIPLIST\n跳表\n\n\n8\nOBJ_ENCODING_EMBSTR\nembstr的动态字符串\n\n\n9\nOBJ_ENCODING_QUICKLIST\n快速列表\n\n\n10\nOBJ_ENCODING_STREAM\nStream流\n\n\n五种数据结构\nRedis中会根据存储的数据类型不同，选择不同的编码方式。每种数据类型的使用的编码方式如下：\n\n\n\n数据类型\n编码方式\n\n\n\nOBJ_STRING\nint、embstr、raw\n\n\nOBJ_LIST\nLinkedList和ZipList(3.2以前)、QuickList（3.2以后）\n\n\nOBJ_SET\nintset、HT\n\n\nOBJ_ZSET\nZipList、HT、SkipList\n\n\nOBJ_HASH\nZipList、HT\n\n\n1.9 基本类型-StringString是Redis中最常见的数据存储类型：\n其基本编码方式是RAW，基于简单动态字符串（SDS）实现，存储上限为512mb。\n如果存储的SDS长度小于44字节，则会采用EMBSTR编码，此时object head与SDS是一段连续空间。申请内存时\n只需要调用一次内存分配函数，效率更高。\n（1）底层实现⽅式：动态字符串sds 或者 longString的内部存储结构⼀般是sds（Simple Dynamic String，可以动态扩展内存），但是如果⼀个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从⽽减少内存的使用。\n\n如果存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用INT编码：直接将数据保存在RedisObject的ptr指针位置（刚好8字节），不再需要SDS了。\n\n\n\n确切地说，String在Redis中是⽤⼀个robj来表示的。\n用来表示String的robj可能编码成3种内部表⽰：OBJ_ENCODING_RAW，OBJ_ENCODING_EMBSTR，OBJ_ENCODING_INT。其中前两种编码使⽤的是sds来存储，最后⼀种OBJ_ENCODING_INT编码直接把string存成了long型。在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。对⼀个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即⼗进制表示的字符串），而不是针对内部表⽰的long型进⾏操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。⽽如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执⾏setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。11\n2.0 基本类型-ListRedis的List类型可以从首、尾操作列表中的元素：\n\n哪一个数据结构能满足上述特征？\n\nLinkedList ：普通链表，可以从双端访问，内存占用较高，内存碎片较多\nZipList ：压缩列表，可以从双端访问，内存占用低，存储上限低\nQuickList：LinkedList + ZipList，可以从双端访问，内存占用较低，包含多个ZipList，存储上限高\n\nRedis的List结构类似一个双端链表，可以从首、尾操作列表中的元素：\n在3.2版本之前，Redis采用ZipList和LinkedList来实现List，当元素数量小于512并且元素大小小于64字节时采用ZipList编码，超过则采用LinkedList编码。\n在3.2版本之后，Redis统一采用QuickList来实现List：\n\n2.1 基本类型-SetSet是Redis中的单列集合，满足下列特点：\n\n不保证有序性\n保证元素唯一\n求交集、并集、差集\n\n\n可以看出，Set对查询元素的效率要求非常高，思考一下，什么样的数据结构可以满足？HashTable，也就是Redis中的Dict，不过Dict是双列集合（可以存键、值对）\nSet是Redis中的集合，不一定确保元素有序，可以满足元素唯一、查询效率要求极高。为了查询效率和唯一性，set采用HT编码（Dict）。Dict中的key用来存储元素，value统一为null。当存储的所有数据都是整数，并且元素数量不超过set-max-intset-entries时（默认512），Set会采用IntSet编码，以节省内存\n\n结构如下：\n![1653987454403](https://markdown-pic-june.oss-cn-beijing.aliyuncs.com/2022/09/30/1653987454403.png)\n\n2.2、基本类型-ZSETZSet也就是SortedSet，其中每一个元素都需要指定一个score值和member值：\n\n可以根据score值排序后\nmember必须唯一\n可以根据member查询分数\n\n\n因此，zset底层数据结构必须满足键值存储、键必须唯一、可排序这几个需求。之前学习的哪种编码结构可以满足？\n\nSkipList：可以排序，并且可以同时存储score和ele值（member）\nHT（Dict）：可以键值存储，并且可以根据key找value\n\n\n\n当元素数量不多时，HT和SkipList的优势不明显，而且更耗内存。因此zset还会采用ZipList结构来节省内存，不过需要同时满足两个条件：\n\n元素数量小于zset_max_ziplist_entries，默认值128\n每个元素都小于zset_max_ziplist_value字节，默认值64\n\nziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现：\n\nZipList是连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后\nscore越小越接近队首，score越大越接近队尾，按照score值升序排列\n\n\n\n2.3、基本类型-HashHash结构与Redis中的Zset非常类似：\n\n都是键值存储\n都需求根据键获取值\n键必须唯一\n\n区别如下：\n\nzset的键是member，值是score；hash的键和值都是任意值\nzset要根据score排序；hash则无需排序\n\n（1）底层实现方式：压缩列表ziplist 或者 字典dict当Hash中数据项比较少的情况下，Hash底层才⽤压缩列表ziplist进⾏存储数据，随着数据的增加，底层的ziplist就可能会转成dict，具体配置如下：\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n当满足上面两个条件其中之⼀的时候，Redis就使⽤dict字典来实现hash。Redis的hash之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点：\n\n每次插⼊或修改引发的realloc操作会有更⼤的概率造成内存拷贝，从而降低性能。\n⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。\n当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。\n\n总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存realloc，可能导致内存拷贝。\nhash结构如下：\n\nzset集合如下：\n\n因此，Hash底层采用的编码与Zset也基本一致，只需要把排序有关的SkipList去掉即可：\nHash结构默认采用ZipList编码，用以节省内存。 ZipList中相邻的两个entry 分别保存field和value\n当数据量较大时，Hash结构会转为HT编码，也就是Dict，触发条件有两个：\n\nZipList中的元素数量超过了hash-max-ziplist-entries（默认512）\nZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）\n\n\n2、原理篇-Redis网络模型2.1 用户空间和内核态空间服务器大多都采用Linux系统，这里我们以Linux为例来讲解:\nubuntu和Centos 都是Linux的发行版，发行版可以看成对linux包了一层壳，任何Linux发行版，其系统内核都是Linux。我们的应用都需要通过Linux内核与硬件交互\n\n用户的应用，比如redis，mysql等其实是没有办法去执行访问我们操作系统的硬件的，所以我们可以通过发行版的这个壳子去访问内核，再通过内核去访问计算机硬件\n\n\n计算机硬件包括，如cpu，内存，网卡等等，内核（通过寻址空间）可以操作硬件的，但是内核需要不同设备的驱动，有了这些驱动之后，内核就可以去对计算机硬件去进行 内存管理，文件系统的管理，进程的管理等等\n\n\n\n\n我们想要用户的应用来访问，计算机就必须要通过对外暴露的一些接口，才能访问到，从而简介的实现对内核的操控，但是内核本身上来说也是一个应用，所以他本身也需要一些内存，cpu等设备资源，用户应用本身也在消耗这些资源，如果不加任何限制，用户去操作随意的去操作我们的资源，就有可能导致一些冲突，甚至有可能导致我们的系统出现无法运行的问题，因此我们需要把用户和内核隔离开\n进程的寻址空间划分成两部分：内核空间、用户空间\n什么是寻址空间呢？我们的应用程序也好，还是内核空间也好，都是没有办法直接去物理内存的，而是通过分配一些虚拟内存映射到物理内存中，我们的内核和应用程序去访问虚拟内存的时候，就需要一个虚拟地址，这个地址是一个无符号的整数，比如一个32位的操作系统，他的带宽就是32，他的虚拟地址就是2的32次方，也就是说他寻址的范围就是0~2的32次方， 这片寻址空间对应的就是2的32个字节，就是4GB，这个4GB，会有3个GB分给用户空间，会有1GB给内核系统\n\n在linux中，他们权限分成两个等级，0和3，用户空间只能执行受限的命令（Ring3），而且不能直接调用系统资源，必须通过内核提供的接口来访问内核空间可以执行特权命令（Ring0），调用一切系统资源，所以一般情况下，用户的操作是运行在用户空间，而内核运行的数据是在内核空间的，而有的情况下，一个应用程序需要去调用一些特权资源，去调用一些内核空间的操作，所以此时他俩需要在用户态和内核态之间进行切换。\n比如：\nLinux系统为了提高IO效率，会在用户空间和内核空间都加入缓冲区：\n写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备\n读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区\n针对这个操作：我们的用户在写读数据时，会去向内核态申请，想要读取内核的数据，而内核数据要去等待驱动程序从硬件上读取数据，当从磁盘上加载到数据之后，内核会将数据写入到内核的缓冲区中，然后再将数据拷贝到用户态的buffer中，然后再返回给应用程序，整体而言，速度慢，就是这个原因，为了加速，我们希望read也好，还是wait for data也最好都不要等待，或者时间尽量的短。\n\n2.2.网络模型-阻塞IO在《UNIX网络编程》一书中，总结归纳了5种IO模型：\n\n阻塞IO（Blocking IO）\n非阻塞IO（Nonblocking IO）\nIO多路复用（IO Multiplexing）\n信号驱动IO（Signal Driven IO）\n异步IO（Asynchronous IO）\n\n应用程序想要去读取数据，他是无法直接去读取磁盘数据的，他需要先到内核里边去等待内核操作硬件拿到数据，这个过程就是1，是需要等待的，等到内核从磁盘上把数据加载出来之后，再把这个数据写给用户的缓存区，这个过程是2，如果是阻塞IO，那么整个过程中，用户从发起读请求开始，一直到读取到数据，都是一个阻塞状态。\n\n具体流程如下图：\n用户去读取数据时，会去先发起recvform一个命令，去尝试从内核上加载数据，如果内核没有数据，那么用户就会等待，此时内核会去从硬件上读取数据，内核读取数据之后，会把数据拷贝到用户态，并且返回ok，整个过程，都是阻塞等待的，这就是阻塞IO\n总结如下：\n顾名思义，阻塞IO就是两个阶段都必须阻塞等待：\n阶段一：\n\n用户进程尝试读取数据（比如网卡数据）\n此时数据尚未到达，内核需要等待数据\n此时用户进程也处于阻塞状态\n\n阶段二：\n\n数据到达并拷贝到内核缓冲区，代表已就绪\n将内核数据拷贝到用户缓冲区\n拷贝过程中，用户进程依然阻塞等待\n拷贝完成，用户进程解除阻塞，处理数据\n\n可以看到，阻塞IO模型中，用户进程在两个阶段都是阻塞状态。\n\n2.3 网络模型-非阻塞IO顾名思义，非阻塞IO的recvfrom操作会立即返回结果而不是阻塞用户进程。\n阶段一：\n\n用户进程尝试读取数据（比如网卡数据）\n此时数据尚未到达，内核需要等待数据\n返回异常给用户进程\n用户进程拿到error后，再次尝试读取\n循环往复，直到数据就绪\n\n阶段二：\n\n将内核数据拷贝到用户缓冲区\n拷贝过程中，用户进程依然阻塞等待\n拷贝完成，用户进程解除阻塞，处理数据\n可以看到，非阻塞IO模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。\n\n\n2.4 网络模型-IO多路复用无论是阻塞IO还是非阻塞IO，用户应用在一阶段都需要调用recvfrom来获取数据，差别在于无数据时的处理方案：\n如果调用recvfrom时，恰好没有数据，阻塞IO会使CPU阻塞，非阻塞IO使CPU空转，都不能充分发挥CPU的作用。如果调用recvfrom时，恰好有数据，则用户进程可以直接进入第二阶段，读取并处理数据\n所以怎么看起来以上两种方式性能都不好\n而在单线程情况下，只能依次处理IO事件，如果正在处理的IO事件恰好未就绪（数据不可读或不可写），线程就会被阻塞，所有IO事件都必须等待，性能自然会很差。\n文件描述符（File Descriptor）：简称FD，是一个从0 开始的无符号整数，用来关联Linux中的一个文件。在Linux中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）。\n通过FD，我们的网络模型可以利用一个线程监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。\n阶段一：\n\n用户进程调用select，指定要监听的FD集合\n核监听FD对应的多个socket\n任意一个或多个socket数据就绪则返回readable\n此过程中用户进程阻塞\n\n阶段二：\n\n用户进程找到就绪的socket\n依次调用recvfrom读取数据\n内核将数据拷贝到用户空间\n用户进程处理数据\n\n当用户去读取数据的时候，不再去直接调用recvfrom了，而是调用select的函数，select函数会将需要监听的数据交给内核，由内核去检查这些数据是否就绪了，如果说这个数据就绪了，就会通知应用程序数据就绪，然后来读取数据，再从内核中把数据拷贝给用户态，完成数据处理，如果N多个FD一个都没处理完，此时就进行等待。\n用IO复用模式，可以确保去读数据的时候，数据是一定存在的，他的效率比原来的阻塞IO和非阻塞IO性能都要高\n\nIO多路复用是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。不过监听FD的方式、通知的方式又有多种实现，常见的有：\n\nselect\npoll\nepoll\n\n其中select和pool相当于是当被监听的数据准备好之后，他会把你监听的FD整个数据都发给你，你需要到整个FD中去找，哪些是处理好了的，需要通过遍历的方式，所以性能也并不是那么好\n而epoll，则相当于内核准备好了之后，他会把准备好的数据，直接发给你，咱们就省去了遍历的动作。\n2.5 网络模型-IO多路复用-select方式select是Linux最早是由的I&#x2F;O多路复用技术：\n简单说，就是我们把需要处理的数据封装成FD，然后在用户态时创建一个fd的集合（这个集合的大小是要监听的那个FD的最大值+1，但是大小整体是有限制的 ），这个集合的长度大小是有限制的，同时在这个集合中，标明出来我们要控制哪些数据，\n比如要监听的数据，是1,2,5三个数据，此时会执行select函数，然后将整个fd发给内核态，内核态会去遍历用户态传递过来的数据，如果发现这里边都数据都没有就绪，就休眠，直到有数据准备好时，就会被唤醒，唤醒之后，再次遍历一遍，看看谁准备好了，然后再将处理掉没有准备好的数据，最后再将这个FD集合写回到用户态中去，此时用户态就知道了，奥，有人准备好了，但是对于用户态而言，并不知道谁处理好了，所以用户态也需要去进行遍历，然后找到对应准备好数据的节点，再去发起读请求，我们会发现，这种模式下他虽然比阻塞IO和非阻塞IO好，但是依然有些麻烦的事情， 比如说频繁的传递fd集合，频繁的去遍历FD等问题\n\n\n2.6 网络模型-IO多路复用模型-poll模式poll模式对select模式做了简单改进，但性能提升不明显，部分关键代码如下：\nIO流程：\n\n创建pollfd数组，向其中添加关注的fd信息，数组大小自定义\n调用poll函数，将pollfd数组拷贝到内核空间，转链表存储，无上限\n内核遍历fd，判断是否就绪\n数据就绪或超时后，拷贝pollfd数组到用户空间，返回就绪fd数量n\n用户进程判断n是否大于0,大于0则遍历pollfd数组，找到就绪的fd\n\n与select对比：\n\nselect模式中的fd_set大小固定为1024，而pollfd在内核中采用链表，理论上无上限\n监听FD越多，每次遍历消耗时间也越久，性能反而会下降\n\n\n2.7 网络模型-IO多路复用模型-epoll函数int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；\nint epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\n\n1. int epoll_create(int size);\n创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。\n当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。\n\n2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；\n函数是对指定描述符fd执行op操作。\n- epfd：是epoll_create()的返回值。\n- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。\n- fd：是需要监听的fd（文件描述符）\n- epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\n\nstruct epoll_event &#123;\n  __uint32_t events;  /* Epoll events */\n  epoll_data_t data;  /* User data variable */\n&#125;;\n\n//events可以是以下几个宏的集合：\nEPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；\nEPOLLOUT：表示对应的文件描述符可以写；\nEPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；\nEPOLLERR：表示对应的文件描述符发生错误；\nEPOLLHUP：表示对应的文件描述符被挂断；\nEPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。\nEPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里\n3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\n等待epfd上的io事件，最多返回maxevents个事件。\n参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。\n\nepoll模式是对select和poll的改进，它提供了三个函数：\n第一个是：eventpoll的函数，他内部包含两个东西\n一个是：\n1、红黑树-&gt; 记录的事要监听的FD\n2、一个是链表-&gt;一个链表，记录的是就绪的FD\n紧接着调用epoll_ctl操作，将要监听的数据添加到红黑树上去，并且给每个fd设置一个监听函数，这个函数会在fd数据就绪时触发，就是准备好了，现在就把fd把数据添加到list_head中去\n3、调用epoll_wait函数\n就去等待，在用户态创建一个空的events数组，当就绪之后，我们的回调函数会把数据添加到list_head中去，当调用这个函数的时候，会去检查list_head，当然这个过程需要参考配置的等待时间，可以等一定时间，也可以一直等， 如果在此过程中，检查到了list_head中有数据会将数据添加到链表中，此时将数据放入到events数组中，并且返回对应的操作的数量，用户态的此时收到响应后，从events中拿到对应准备好的数据的节点，再去调用方法去拿数据。\n小总结：\nselect模式存在的三个问题：\n\n能监听的FD最大不超过1024\n每次select都需要把所有要监听的FD都拷贝到内核空间\n每次都要遍历所有FD来判断就绪状态\n\npoll模式的问题：\n\npoll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降\n\nepoll模式中如何解决这些问题的？\n\n基于epoll实例中的红黑树保存要监听的FD，理论上无上限，而且增删改查效率都非常高\n每个FD只需要执行一次epoll_ctl添加到红黑树，以后每次epol_wait无需传递任何参数，无需重复拷贝FD到内核空间\n利用ep_poll_callback机制来监听FD状态，无需遍历所有FD，因此性能不会随监听的FD数量增多而下降\n\n2.8、网络模型-epoll中的ET和LT当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是事件通知的模式有两种：\n\nLevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。\nEdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。\n\n举个栗子：\n\n假设一个客户端socket对应的FD已经注册到了epoll实例中\n客户端socket发送了2kb的数据\n服务端调用epoll_wait，得到通知说FD就绪\n服务端从FD读取了1kb数据回到步骤3（再次调用epoll_wait，形成循环）\n\n结论\n如果我们采用LT模式，因为FD中仍有1kb数据，则第⑤步依然会返回结果，并且得到通知如果我们采用ET模式，因为第③步已经消费了FD可读事件，第⑤步FD状态没有变化，因此epoll_wait不会返回，数据无法读取，客户端响应超时。\n2.9 网络模型-基于epoll的服务器端流程我们来梳理一下这张图\n服务器启动以后，服务端会去调用epoll_create，创建一个epoll实例，epoll实例中包含两个数据\n1、红黑树（为空）：rb_root 用来去记录需要被监听的FD\n2、链表（为空）：list_head，用来存放已经就绪的FD\n创建好了之后，会去调用epoll_ctl函数，此函数会会将需要监听的数据添加到rb_root中去，并且对当前这些存在于红黑树的节点设置回调函数，当这些被监听的数据一旦准备完成，就会被调用，而调用的结果就是将红黑树的fd添加到list_head中去(但是此时并没有完成)\n3、当第二步完成后，就会调用epoll_wait函数，这个函数会去校验是否有数据准备完毕（因为数据一旦准备就绪，就会被回调函数添加到list_head中），在等待了一段时间后(可以进行配置)，如果等够了超时时间，则返回没有数据，如果有，则进一步判断当前是什么事件，如果是建立连接时间，则调用accept() 接受客户端socket，拿到建立连接的socket，然后建立起来连接，如果是其他事件，则把数据进行写出\n\n3.0 、网络模型-信号驱动信号驱动IO是与内核建立SIGIO的信号关联并设置回调，当内核有FD就绪时，会发出SIGIO信号通知用户，期间用户应用可以执行其它业务，无需阻塞等待。\n阶段一：\n\n用户进程调用sigaction，注册信号处理函数\n内核返回成功，开始监听FD\n用户进程不阻塞等待，可以执行其它业务\n当内核数据就绪后，回调用户进程的SIGIO处理函数\n\n阶段二：\n\n收到SIGIO回调信号\n调用recvfrom，读取\n内核将数据拷贝到用户空间\n用户进程处理数据\n\n\n当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出，而且内核空间与用户空间的频繁信号交互性能也较低。\n3.0.1 异步IO这种方式，不仅仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞\n他会由内核将所有数据处理完成后，由内核将数据写入到用户态中，然后才算完成，所以性能极高，不会有任何阻塞，全部都由内核完成，可以看到，异步IO模型中，用户进程在两个阶段都是非阻塞状态。\n\n3.0.2 对比最后用一幅图，来说明他们之间的区别\n\n3.1 、网络模型-Redis是单线程的吗？为什么使用单线程Redis到底是单线程还是多线程？\n\n如果仅仅聊Redis的核心业务部分（命令处理），答案是单线程\n如果是聊整个Redis，那么答案就是多线程\n\n在Redis版本迭代过程中，在两个重要的时间节点上引入了多线程的支持：\n\nRedis v4.0：引入多线程异步处理一些耗时较旧的任务，例如异步删除命令unlink\nRedis v6.0：在核心网络模型中引入 多线程，进一步提高对于多核CPU的利用率\n\n因此，对于Redis的核心网络模型，在Redis 6.0之前确实都是单线程。是利用epoll（Linux系统）这样的IO多路复用技术在事件循环中不断处理客户端情况。\n为什么Redis要选择单线程？\n\n抛开持久化不谈，Redis是纯  内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。\n多线程会导致过多的上下文切换，带来不必要的开销\n引入多线程会面临线程安全问题，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣\n\n3.2 、Redis的单线程模型-Redis单线程和多线程网络模型变更\n\n当我们的客户端想要去连接我们服务器，会去先到IO多路复用模型去进行排队，会有一个连接应答处理器，他会去接受读请求，然后又把读请求注册到具体模型中去，此时这些建立起来的连接，如果是客户端请求处理器去进行执行命令时，他会去把数据读取出来，然后把数据放入到client中， clinet去解析当前的命令转化为redis认识的命令，接下来就开始处理这些命令，从redis中的command中找到这些命令，然后就真正的去操作对应的数据了，当数据操作完成后，会去找到命令回复处理器，再由他将数据写出。\n3、Redis通信协议-RESP协议Redis是一个CS架构的软件，通信一般分两步（不包括pipeline和PubSub）：\n客户端（client）向服务端（server）发送一条命令\n服务端解析并执行命令，返回响应结果给客户端\n因此客户端发送命令的格式、服务端响应结果的格式必须有一个规范，这个规范就是通信协议。\n而在Redis中采用的是RESP（Redis Serialization Protocol）协议：\nRedis 1.2版本引入了RESP协议\nRedis 2.0版本中成为与Redis服务端通信的标准，称为RESP2\nRedis 6.0版本中，从RESP2升级到了RESP3协议，增加了更多数据类型并且支持6.0的新特性–客户端缓存\n但目前，默认使用的依然是RESP2协议，也是我们要学习的协议版本（以下简称RESP）。\n在RESP中，通过首字节的字符来区分不同数据类型，常用的数据类型包括5种：\n单行字符串：首字节是 ‘**+**’ ，后面跟上单行字符串，以CRLF（ “\\r\\n” ）结尾。例如返回”OK”： “+OK\\r\\n”\n错误（Errors）：首字节是 ‘**-**’ ，与单行字符串格式一样，只是字符串是异常信息，例如：”-Error message\\r\\n”\n数值：首字节是 ‘**:**’ ，后面跟上数字格式的字符串，以CRLF结尾。例如：”:10\\r\\n”\n多行字符串：首字节是 ‘**$**’ ，表示二进制安全的字符串，最大支持512MB：\n如果大小为0，则代表空字符串：”$0\\r\\n\\r\\n”\n如果大小为-1，则代表不存在：”$-1\\r\\n”\n数组：首字节是 ‘*****’，后面跟上数组元素个数，再跟上元素，元素数据类型不限:\n\n3.1、Redis通信协议-基于Socket自定义Redis的客户端Redis支持TCP通信，因此我们可以使用Socket来模拟客户端，与Redis服务端建立连接：\npublic class Main &#123;\n\n    static Socket s;\n    static PrintWriter writer;\n    static BufferedReader reader;\n\n    public static void main(String[] args) &#123;\n        try &#123;\n            // 1.建立连接\n            String host = \"192.168.150.101\";\n            int port = 6379;\n            s = new Socket(host, port);\n            // 2.获取输出流、输入流\n            writer = new PrintWriter(new OutputStreamWriter(s.getOutputStream(), StandardCharsets.UTF_8));\n            reader = new BufferedReader(new InputStreamReader(s.getInputStream(), StandardCharsets.UTF_8));\n\n            // 3.发出请求\n            // 3.1.获取授权 auth 123321\n            sendRequest(\"auth\", \"123321\");\n            Object obj = handleResponse();\n            System.out.println(\"obj = \" + obj);\n\n            // 3.2.set name 虎哥\n            sendRequest(\"set\", \"name\", \"虎哥\");\n            // 4.解析响应\n            obj = handleResponse();\n            System.out.println(\"obj = \" + obj);\n\n            // 3.2.set name 虎哥\n            sendRequest(\"get\", \"name\");\n            // 4.解析响应\n            obj = handleResponse();\n            System.out.println(\"obj = \" + obj);\n\n            // 3.2.set name 虎哥\n            sendRequest(\"mget\", \"name\", \"num\", \"msg\");\n            // 4.解析响应\n            obj = handleResponse();\n            System.out.println(\"obj = \" + obj);\n        &#125; catch (IOException e) &#123;\n            e.printStackTrace();\n        &#125; finally &#123;\n            // 5.释放连接\n            try &#123;\n                if (reader != null) reader.close();\n                if (writer != null) writer.close();\n                if (s != null) s.close();\n            &#125; catch (IOException e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;\n    &#125;\n\n    private static Object handleResponse() throws IOException &#123;\n        // 读取首字节\n        int prefix = reader.read();\n        // 判断数据类型标示\n        switch (prefix) &#123;\n            case '+': // 单行字符串，直接读一行\n                return reader.readLine();\n            case '-': // 异常，也读一行\n                throw new RuntimeException(reader.readLine());\n            case ':': // 数字\n                return Long.parseLong(reader.readLine());\n            case '$': // 多行字符串\n                // 先读长度\n                int len = Integer.parseInt(reader.readLine());\n                if (len == -1) &#123;\n                    return null;\n                &#125;\n                if (len == 0) &#123;\n                    return \"\";\n                &#125;\n                // 再读数据,读len个字节。我们假设没有特殊字符，所以读一行（简化）\n                return reader.readLine();\n            case '*':\n                return readBulkString();\n            default:\n                throw new RuntimeException(\"错误的数据格式！\");\n        &#125;\n    &#125;\n\n    private static Object readBulkString() throws IOException &#123;\n        // 获取数组大小\n        int len = Integer.parseInt(reader.readLine());\n        if (len &lt;= 0) &#123;\n            return null;\n        &#125;\n        // 定义集合，接收多个元素\n        List&lt;Object> list = new ArrayList&lt;>(len);\n        // 遍历，依次读取每个元素\n        for (int i = 0; i &lt; len; i++) &#123;\n            list.add(handleResponse());\n        &#125;\n        return list;\n    &#125;\n\n    // set name 虎哥\n    private static void sendRequest(String ... args) &#123;\n        writer.println(\"*\" + args.length);\n        for (String arg : args) &#123;\n            writer.println(\"$\" + arg.getBytes(StandardCharsets.UTF_8).length);\n            writer.println(arg);\n        &#125;\n        writer.flush();\n    &#125;\n&#125;\n\n\n3.2、Redis内存回收-过期key处理Redis之所以性能强，最主要的原因就是基于内存存储。然而单节点的Redis其内存大小不宜过大，会影响持久化或主从同步性能。我们可以通过修改配置文件来设置Redis的最大内存：\n\n当内存使用达到上限时，就无法存储更多数据了。为了解决这个问题，Redis提供了一些策略实现内存回收：\n内存过期策略\n在学习Redis缓存的时候我们说过，可以通过expire命令给Redis的key设置TTL（存活时间）：\n\n可以发现，当key的TTL到期以后，再次访问name返回的是nil，说明这个key已经不存在了，对应的内存也得到释放。从而起到内存回收的目的。\nRedis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在之前学习过的Dict结构中。不过在其database结构体中，有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。\n\n\n这里有两个问题需要我们思考：Redis是如何知道一个key是否过期呢？\n利用两个Dict分别记录key-value对及key-ttl对\n是不是TTL到期就立即删除了呢？\n惰性删除\n惰性删除：顾明思议并不是在TTL到期后就立刻删除，而是在访问一个key的时候，检查该key的存活时间，如果已经过期才执行删除。\n\n周期删除\n周期删除：顾明思议是通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。执行周期有两种：Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为SLOWRedis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST\n周期删除：顾明思议是通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。执行周期有两种：Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为SLOWRedis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST\nSLOW模式规则：\n\n执行频率受server.hz影响，默认为10，即每秒执行10次，每个执行周期100ms。\n执行清理耗时不超过一次执行周期的25%.默认slow模式耗时不超过25ms\n逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期\n如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束\nFAST模式规则（过期key比例小于10%不执行 ）：\n执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔不低于2ms\n执行清理耗时不超过1ms\n逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束\n\n小总结：\nRedisKey的TTL记录方式：\n在RedisDB中通过一个Dict记录每个Key的TTL时间\n过期key的删除策略：\n惰性清理：每次查找key时判断是否过期，如果过期则删除\n定期清理：定期抽样部分key，判断是否过期，如果过期则删除。定期清理的两种模式：\nSLOW模式执行频率默认为10，每次不超过25ms\nFAST模式执行频率不固定，但两次间隔不低于2ms，每次耗时不超过1ms\n3.3 Redis内存回收-内存淘汰策略内存淘汰：就是当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰：\n\n 淘汰策略\nRedis支持8种不同策略来选择要删除的key：\n\nnoeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。\nvolatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰\nallkeys-random：对全体key ，随机进行淘汰。也就是直接从db-&gt;dict中随机挑选\nvolatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db-&gt;expires中随机挑选。\nallkeys-lru： 对全体key，基于LRU算法进行淘汰\nvolatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰\nallkeys-lfu： 对全体key，基于LFU算法进行淘汰\nvolatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰比较容易混淆的有两个：\nLRU（Least Recently Used），最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。\nLFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。\n\n\n\nRedis的数据都会被封装为RedisObject结构：\n\nLFU的访问次数之所以叫做逻辑访问次数，是因为并不是每次key被访问都计数，而是通过运算：\n\n生成0~1之间的随机数R\n计算 (旧次数 * lfu_log_factor + 1)，记录为P\n如果 R &lt; P ，则计数器 + 1，且最大不超过255\n访问次数会随时间衰减，距离上一次访问时间每隔 lfu_decay_time 分钟，计数器 -1\n\n最后用一副图来描述当前的这个流程吧\n\n","slug":"Redis原理","date":"2022-07-30T08:22:44.000Z","categories_index":"","tags_index":"学习笔记,Redis","author_index":"JuneQQQ"},{"id":"fd2c15dc5d41ab5172de4dd08fd40ea9","title":"Java集合","content":"Java 集合Collection 接口 （父接口）\n\n\n\nIterator 迭代器所有实现了Iteratable接口的类都可以通过iterator()方法获取迭代器\n注意：重新获取iterator即可重置迭代器；\n增强 for 循环\n可以对 数组 和 集合 使用；\n底层使用的仍然是 iterator；\n大写 I 可以快速生成代码（Idea）。\n\nList 接口  可重复-有顺序ArrayList\n线程不安全\n\nArrayList 维护了一个 Object 类型的数组 elementData – transient Object[] elementData &#x2F;&#x2F; transient 表示该属性不会被序列化\n\n两种构造方式（构造时数组已经初始化）：\n\n无参构造： ArrayList，则初始化 elementData 容量为0，第一次添加时，则扩容至默认容量10，如需再次扩容，则扩容为当前的1.5倍（1+1&#x2F;2）;Vector（无参情况下） 扩容倍数是2，线程安全是因为每个方法头上添加了 synchronized\n指定initialCapacity大小的构造器：初始 elementData 容量为指定大小，如需扩容，则直接扩容 elementData 为当前的1.5倍\n\n\n每次添加元素时，都会触发一次扩容检查，容量不满足 size+1 就扩容\n\n源码解读如下\n\n\n\n\nVector\n线程安全\n如果无参，默认10，满后，2倍扩容；如果指定大小，满后则每次直接2倍扩容（优先使用自定义增量capacityIncrement）\n有参构造可以指定扩容大小 Vector(int initialCapacity, int capacityIncrement)\n源码解读如下\n\n====================================================\npublic synchronized boolean add(E e) &#123;\n    modCount++;\n    ensureCapacityHelper(elementCount + 1);   // 扩容检查\n    elementData[elementCount++] = e;\n    return true;\n&#125;\n====================================================\nprivate void ensureCapacityHelper(int minCapacity) &#123;\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        grow(minCapacity);    // 真正扩容方法\n&#125;\n====================================================\nprivate void grow(int minCapacity) &#123;\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    //扩容的关键算法\n    int newCapacity = oldCapacity + ((capacityIncrement > 0) ?\n                                     capacityIncrement : oldCapacity);\n    if (newCapacity - minCapacity &lt; 0)    // 扩容后仍不满足最小capacity要求\n        newCapacity = minCapacity;\n    if (newCapacity - MAX_ARRAY_SIZE > 0)    // 超过最大容量\n        newCapacity = hugeCapacity(minCapacity);\n    elementData = Arrays.copyOf(elementData, newCapacity);\n&#125;\n====================================================\n\n\n\nLinkedList\n\n底层维护了一个双向链表\n可以添加任意元素\n其中有两个属性first和last分别指向首节点和尾结点\n每个节点（Node对象），里面又维护了prev，next，item三个属性，其中通过prev指向前一个，通过next指向后一个节点，最终实现双向链表\nLinkedList 增删快，查找慢\n源码解读如下（尾插头删）\n\n-----------------------------\npublic boolean add(E e) &#123;\n        linkLast(e);\n        return true;\n    &#125;\n-----------------------------\nvoid linkLast(E e) &#123;\n        final Node&lt;E> l = last;  // 旧尾结点\n        final Node&lt;E> newNode = new Node&lt;>(l, e, null);  // 创建新节点\n        last = newNode;     // 新节点上位尾结点\n        if (l == null)\n            first = newNode; // 第一个节点 first->a  last->a\n        else\n            l.next = newNode;  // 新节点是从尾部连接的！新节点赋值->旧尾结点.next \n        size++;\n        modCount++;\n    &#125;\n-----------------------------\npublic E remove() &#123;\n        return removeFirst();  //注意是第一个\n    &#125;\npublic E removeFirst() &#123;\n        final Node&lt;E> f = first;\n        if (f == null)\n            throw new NoSuchElementException();\n        return unlinkFirst(f);\n    &#125;\n-----------------------------\nprivate E unlinkFirst(Node&lt;E> f) &#123;\n        // assert f == first &amp;&amp; f != null;\n        final E element = f.item;\n        final Node&lt;E> next = f.next;\n        f.item = null;\n        f.next = null; // help GC\n        first = next;\n        if (next == null)\n            last = null;   // 只有一个节点\n        else\n            next.prev = null;  \n        size--;\n        modCount++;\n        return element;   // 返回删除的元素\n    &#125;\n-----------------------------\n\n\n\n集合选择\nArrayList 查询快，增删慢\nLinkedList查询慢，增删快\n一般来说，程序中 80~90的业务都是查询，因此大部分情况下选择ArrayList\n也可以根据业务需要灵活选择\n\nSet 接口\nTreeSet有序，HashSet无序\n不允许重复，最多包含一个null\n\nHashSet\n\n\n\n\n\n\n\n\n如何决定元素是相同的？\n\nhashCode() 决定节点添加到数组下标的位置；\n真正地逻辑是：**(table.length -1) &amp; hash(hashCode())**\n\n\n当 hashCode() 方法算出的元素落到了某个链表上，从头到尾依次比较，有相同元素，添加失败，无相同元素，添加到链表尾部；\n可以存放null，但只能有一个（null的哈希值为0）\n\n\n\n\n\n\n\n\n\n\n\n\n源码分析\n\n底层实际上是HashMap\n底层调用的是Hashmap的API，value是占位符PRESENT – new Object()\n元素顺序取决于hash函数的结果，是一个固定的顺序\n无参构造器：default-capacity(16)  loadFactor(0.75) \n单链表长度达到9个（在添加第9个元素后立刻检查，这是由于binCount是之前的容量！）时才进入 treeifbin()方法\ntab == null || (n = tab.length) &lt; 64\n64指的是HashSet中所有的元素（包括链表上的）\n\n\nresize 扩容发生在以下三个时机：\n初始化一个HashSet，第一次添加元素时，table为null，此时扩容为长度为16的数组(无参构造，有参则初始化为指定的大小向上取2^n值)\n当前HashMap.size&gt;threshold时，成功添加第(threshold+1)个元素时，触发扩容方法\n链表的节点数大于8，若table.length&lt;64，触发扩容方法；若table.length&gt;&#x3D;64，触发树化\n\n\n不错的帖子\n从泊松分布谈起HashMap为什么默认扩容因子是0.75 - 知乎 (zhihu.com)\n2022面试题：HashMap相关问题硬核梳理_小牛呼噜噜的博客-CSDN博客\n\n\n\n// 调用链 add->put->putVal(hash->hashCode)\n---------------------------------\npublic boolean add(E e) &#123;\n    \t//PRESENT相当于一个占位符，Object[]\n        return map.put(e, PRESENT)==null;\n    &#125;\n---------------------------------\npublic V put(K key, V value) &#123;\n        return putVal(hash(key), key, value, false, true);\n    &#125;\n---------------------------------\nstatic final int hash(Object key) &#123;\n        int h;\n    \t// 由此可见，真正的哈希值是hashCode方法进一步包装的值\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n    &#125;\n---------------------------------\n/**------------------------核心算法------------------------**/\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) &#123;\n        Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i;\n    \t  // 初始化 table 数组\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n    \t  // tab[i]初始化\n        if ((p = tab[i = (n - 1) &amp; hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n        else &#123;\n          \t// tab[i]已经有节点了\n            Node&lt;K,V> e; K k;\n            // p 是 table[i] 的第一个元素（可能是Node或TreeNode，TreeNode是HashMap的静态内部类，已树化的节点）\n            // 以下代码判断是否是同一个对象\n            // CASE1:Node 第一个节点的hash、equals||地址 与加入节点相同\n            if (p.hash == hash &amp;&amp;\n                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))\n                e = p;\n            else if (p instanceof TreeNode)\n                // CASE2:p 是一颗红黑树\n                e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else &#123;\n                // CASE3:Node 有多个节点，第一个节点不能匹配，遍历链表\n                for (int binCount = 0; ; ++binCount) &#123;\n                    // 注意此处 p.next 赋给 e\n                    if ((e = p.next) == null) &#123;\n                        p.next = newNode(hash, key, value, null);\n                        // 本次添加过后链表元素达到了9个才进行扩容，因为binCount是之前的容量\n                        if (binCount >= TREEIFY_THRESHOLD - 1) \n                            //是否要进行红黑树化判断，以下是条件，不满足执行 resize() 方法\n                            // treeifyBin方法中还有判断：tab == null || (n = tab.length) &lt; 64  \n                            // 满足才能真正树化\n                            treeifyBin(tab, hash);\n                        break;\n                    &#125;\n                    // e = p.next\n                    if (e.hash == hash &amp;&amp;\n                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                        break;\n                    // p 向下指一个节点\n                    p = e;\n                &#125;\n            &#125;\n            \n            // value 替换细节\n            if (e != null) &#123;\n                //此处把k-v的v替换，value是传参进来的v\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            &#125;\n        &#125;\n        ++modCount;\n        // 添加后检查，第十三个元素添加后进入if执行扩容\n        if (++size > threshold)\n            resize();\n    \t  // 为 HashMap 子类准备的方法（如LinkedList），在本类中为空实现\n        afterNodeInsertion(evict);\n        return null;\n    &#125;\n\n/**-------------------数组扩容---------------------**/\nfinal Node&lt;K,V>[] resize() &#123;\n    Node&lt;K,V>[] oldTab = table;\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) &#123;\n        // 超过最大值就不再扩充了，就只好随你碰撞去吧\n        if (oldCap >= MAXIMUM_CAPACITY) &#123;\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        &#125;\n        // 没超过最大值，就扩充为原来的2倍\n        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;\n                 oldCap >= DEFAULT_INITIAL_CAPACITY)\n            newThr = oldThr &lt;&lt; 1; // double threshold\n    &#125;\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        newCap = oldThr;\n    else &#123;               // zero initial threshold signifies using defaults\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    &#125;\n    // 计算新的resize上限\n    if (newThr == 0) &#123;\n\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?\n                  (int)ft : Integer.MAX_VALUE);\n    &#125;\n    threshold = newThr;\n    @SuppressWarnings(&#123;\"rawtypes\"，\"unchecked\"&#125;)\n        Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap];\n    table = newTab;\n    if (oldTab != null) &#123;\n        // 把每个bucket都移动到新的buckets中\n        for (int j = 0; j &lt; oldCap; ++j) &#123;\n            Node&lt;K,V> e;\n            if ((e = oldTab[j]) != null) &#123;\n                oldTab[j] = null;\n                if (e.next == null)\n                    newTab[e.hash &amp; (newCap - 1)] = e;\n                else if (e instanceof TreeNode)\n                    ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap);\n                else &#123; // 链表优化重hash的代码块\n                    Node&lt;K,V> loHead = null, loTail = null; // 原索引存放的引用\n                    Node&lt;K,V> hiHead = null, hiTail = null; // 原索引+oldCap存放的引用\n                    Node&lt;K,V> next;\n                    do &#123;\n                        next = e.next;\n                       /*\n                       \t取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作\n                     \t （也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。\n                      */\n                        // 原索引\n                        if ((e.hash &amp; oldCap) == 0) &#123;\n                            if (loTail == null)\n                                loHead = e;\n                            else\n                                loTail.next = e; // 尾插\n                            loTail = e; // 尾插\n                        &#125; else &#123; // 原索引+oldCap\n                            if (hiTail == null)\n                                hiHead = e;\n                            else\n                                hiTail.next = e;\n                            hiTail = e;\n                        &#125;\n                    &#125; while ((e = next) != null);\n                    // 原索引放到bucket里\n                    if (loTail != null) &#123;\n                        loTail.next = null;\n                        newTab[j] = loHead;\n                    &#125;\n                    // 原索引+oldCap放到bucket里\n                    if (hiTail != null) &#123;\n                        hiTail.next = null;\n                        newTab[j + oldCap] = hiHead;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    return newTab;\n&#125;\n\n\n\n\n\nLinkedHashSet\n\n\n\n\n\n\n\n\n继承HashSet，实现Set\n\nHashMap维护对象是 Node ，LinkedHashSet维护对象是 Entry extends HashMap.Node\n底层维护了一个哈希表和双向链表\n每一个节点有pre和next属性，这样可以形成双向链表\n在添加一个元素时，先求hash值，再求索引，确定该元素在hashtable中的位置，然后将添加的元素加入到双向链表中（如果已经存在，则不添加，原则上通hashset一致）\n这样LinkedHashSet能确保插入顺序和遍历顺序一致\n源码解读\n\n/*LinkedHashSet内部类 Entry ，将来会取代Node成为LinkedHashSet的table的节点元素*/\nstatic class Entry&lt;K,V> extends HashMap.Node&lt;K,V> &#123;\n        Entry&lt;K,V> before, after;\n        Entry(int hash, K key, V value, Node&lt;K,V> next) &#123;\n            super(hash, key, value, next);\n        &#125;\n    &#125;\n\n\n\n\n\n\n\nTreeSet\n使用无参构造器时，元素仍是无序的\nTreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树\n源码解析如下\n\npublic V put(K key, V value) &#123;\n        Entry&lt;K,V> t = root;\n    \t// 第一次添加元素，注意节点对象是 Entry\n        if (t == null) &#123;\n            compare(key, key); // 此处的compare是为了检查 key 是否为空值\n            \n            root = new Entry&lt;>(key, value, null);\n            size = 1;\n            modCount++;\n            return null;\n        &#125;\n        int cmp;\n        Entry&lt;K,V> parent;\n        // split comparator and comparable paths\n        Comparator&lt;? super K> cpr = comparator;\n        if (cpr != null) &#123;\n            do &#123;\n                // 遍历所有的 key，给key找适当的位置\n                parent = t;\n                cmp = cpr.compare(key, t.key);  //绑定到定义的 compare 方法\n                if (cmp &lt; 0)\n                    t = t.left;\n                else if (cmp > 0)\n                    t = t.right;\n                else // 发现相等的 key ，用 value 的值覆盖这个 key 的 value，且方法退出\n                    return t.setValue(value);\n            &#125; while (t != null);\n        &#125;\n        else &#123;\n            if (key == null)\n                throw new NullPointerException();\n            @SuppressWarnings(\"unchecked\")\n                Comparable&lt;? super K> k = (Comparable&lt;? super K>) key;\n            do &#123;\n                parent = t;\n                cmp = k.compareTo(t.key);\n                if (cmp &lt; 0)\n                    t = t.left;\n                else if (cmp > 0)\n                    t = t.right;\n                else\n                    return t.setValue(value);\n            &#125; while (t != null);\n        &#125;\n        Entry&lt;K,V> e = new Entry&lt;>(key, value, parent);\n        if (cmp &lt; 0)\n            parent.left = e;\n        else\n            parent.right = e;\n        fixAfterInsertion(e);\n        size++;\n        modCount++;\n        return null;\n    &#125;\n\n\n\n\n\nMap 接口\nTreeMap有序，HashMap无序\nkey 不允许重复(null也不能重复），value可以重复\nk-v 最后是 HashMap$Node node &#x3D; newNode(hash , key , value , null)\nk-v 是为了方便程序员进行遍历设计的，会创建 EntrySet 集合，该集合存放的元素类型 Entry ，而一个 Entry 对象就有 k-v EntrySet&lt;Entry&lt;K,V&gt;&gt; 即： transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;\nentrySet 中，定义的类型是 Map.Entry , 但实际上存放的是 HashMap$Node , 这是因为 HashMap$Node implements Map.Entry static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;\n当把 HashMap$Node 对象存放到 entrySet 就方便我们的遍历，因为 Map.Entry 提供了重要方法 K getKey() – V getValue()\n\nMap 遍历\n增强 FOR\n迭代器 Iterator\nvalues() 方法 ，此方法返回集合 Collection ，可以使用以上两种遍历方式\nentrySet() 方法 ， 此方法返回 Set –&gt; EntrySet&lt;Map.Entry&lt;K,V&gt;&gt;  ， 可以使用 1 ，2 两种方式遍历\n\nHashMap\n\n\n\n\n当添加 key-val 时，通过 key 的哈希值得到在table的索引，然后判断该索引处是否有元素，如果没有元素则直接添加，如果有元素则继续判断该元素的 key 和准备加入的 key 是否相等，如果相等，则直接替换 val；如果不相等则需要判断是树结构还是链表结构，做出相应处理，如果添加时发现容量不够，则需要扩容。\n执行构造 new HashMap() ，初始化加载因子 loadfactor &#x3D; 0.75 &amp; hashMap$Node[] table &#x3D; null\n执行 put 调用 putVal() ，详细细节见 HashSet\n\n\n\n\n\nHashtable\n实现了 Map 集合，即存放 k-v 键值对，key不能重复\nHashtable 的键和值都不能为 null ，否则抛出 NullPointerException\nHashtable 使用方法基本上和 HashMap 一致\nHashtable 线程安全\n默认值 initialCapacity-11 loadFactor-0.75，扩容方式 2*old+1\n源码解析如下\n\n--------------------------------------------\n// 无参构造 默认大小是 11 ，loadFactor仍然是 0.75，所以threshold是 11*0.75=8\npublic Hashtable() &#123;\n        this(11, 0.75f);\n    &#125;\n--------------------------------------------\npublic synchronized V put(K key, V value) &#123;\n        // Make sure the value is not null\n        if (value == null) &#123;\n            throw new NullPointerException();\n        &#125;\n\n        // Makes sure the key is not already in the hashtable.\n        Entry&lt;?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V> entry = (Entry&lt;K,V>)tab[index];\n        for(; entry != null ; entry = entry.next) &#123;\n            if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123;\n                V old = entry.value;\n                entry.value = value;\n                return old;\n            &#125;\n        &#125;\n\n        addEntry(hash, key, value, index);\n        return null;\n    &#125;\n-------------------------------------------------------------\nprivate void addEntry(int hash, K key, V value, int index) &#123;\n        modCount++;\n\n        Entry&lt;?,?> tab[] = table;\n        if (count >= threshold) &#123;\n            // Rehash the table if the threshold is exceeded\n            rehash();\n\n            tab = table;\n            hash = key.hashCode();\n            index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        &#125;\n\n        // Creates the new entry.\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V> e = (Entry&lt;K,V>) tab[index];\n        tab[index] = new Entry&lt;>(hash, key, value, e);\n        count++;\n    &#125;\n-------------------------------------------------------------\nprotected void rehash() &#123;\n        int oldCapacity = table.length;\n        Entry&lt;?,?>[] oldMap = table;\n\n        //扩容机制如下 2*oldCapacity+1\n        int newCapacity = (oldCapacity &lt;&lt; 1) + 1;\n        if (newCapacity - MAX_ARRAY_SIZE > 0) &#123;\n            if (oldCapacity == MAX_ARRAY_SIZE)\n                // Keep running with MAX_ARRAY_SIZE buckets\n                return;\n            newCapacity = MAX_ARRAY_SIZE;\n        &#125;\n    \t//数组扩容\n        Entry&lt;?,?>[] newMap = new Entry&lt;?,?>[newCapacity];\n\n        modCount++;\n        threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1);\n        table = newMap;\n\n        for (int i = oldCapacity ; i-- > 0 ;) &#123;\n            for (Entry&lt;K,V> old = (Entry&lt;K,V>)oldMap[i] ; old != null ; ) &#123;\n                Entry&lt;K,V> e = old;\n                old = old.next;\n\n                int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity;\n                e.next = (Entry&lt;K,V>)newMap[index];\n                newMap[index] = e;\n            &#125;\n        &#125;\n    &#125;\n\n\n\nProperties\n继承自 Hashtable，仍然以 k-v 键值对保存数据\n使用方式与 Hashtable 类似\nProperties可以从 xxx.properties文件中，加载数据到其创建的对象中，并对其修改\n\nTreeMap这个类不依赖hashCode和equals\n\n使用比较器构造器\n\n&#96;&#96;&#96;javapublic TreeSet(Comparator&lt;? super E&gt; comparator) {    this(new TreeMap&lt;&gt;(comparator));}\n2. 第一次添加，把k-v封装到 Entry 对象，放入 root\n\n   - &#96;&#96;&#96;java\n     Entry&lt;K,V&gt; t &#x3D; root;\n     if (t &#x3D;&#x3D; null) &#123;\n         compare(key, key); &#x2F;&#x2F; type (and possibly null) check\n     \n         root &#x3D; new Entry&lt;&gt;(key, value, null);\n         size &#x3D; 1;\n         modCount++;\n         return null;\n     &#125;\n\n\n以后添加\n\n&#96;&#96;&#96;javaint cmp;Entry&lt;K,V&gt; parent;&#x2F;&#x2F; split comparator and comparable pathsComparator&lt;? super K&gt; cpr &#x3D; comparator;if (cpr !&#x3D; null) {do {  &#x2F;&#x2F; 遍历所有key，给key找适当的位置    parent &#x3D; t;    cmp &#x3D; cpr.compare(key, t.key); &#x2F;&#x2F;调用的是传入的比较器    if (cmp &lt; 0)        t &#x3D; t.left;    else if (cmp &gt; 0)        t &#x3D; t.right;    else          &#x2F;&#x2F; 发现已经有重复的key，覆盖value并返回        return t.setValue(value);} while (t !&#x3D; null);}\n\n\n## 集合选择\n\n1. 先判断存储的类型（一组对象或一组键值对）\n2. 一组对象：Collection接口实现类\n   1. 允许重复：List\n      - 增删多：LinkedList（底层维护了一个双向链表）\n      - 改查多：ArrayList（底层维护Object类型可变数组）\n   2. 不允许重复：Set\n      - 无序：HashSet（底层是HashMap，维护了一个哈希表，即数组+链表+红黑树）\n      - 排序：TreeSet\n      - 插入和取出顺序一致：LinkedHashSet（底层维护了数组+双向链表）\n3. 一组键值对：Map\n   - 键无序：HashMap（底层是哈希表）\n   - 键排序：TreeMap\n   - 键插入和取出顺序一致：LinkedHashMap\n   - 文件操作：Properties\n\n\n\n## Collections 工具类\n\n1. 排序相关\n   - reverse()   &#x2F;&#x2F; 反转\n   - shuffle()     &#x2F;&#x2F; 乱序\n   - sort()        &#x2F;&#x2F; 排序 ，可以定义比较器\n   - swap()     &#x2F;&#x2F; 交换\n2. 查找、替换\n   - max()   &#x2F;&#x2F; 可以定义比较器\n   - **frequency()**   &#x2F;&#x2F; 某元素出现频率\n   - copy()     &#x2F;&#x2F; 注意数组越界问题！\n   - replaceAll()  &#x2F;&#x2F; 集合中某元素替换\n\n\n\n&#96;&#96;&#96;java\n\n\n\n\n","slug":"Java集合","date":"2022-09-30T09:44:29.000Z","categories_index":"","tags_index":"Java集合","author_index":"JuneQQQ"},{"id":"6b7e4a534de9f7da91f5ad92c6f8b78c","title":"Mycat2入门","content":"1. 概述1.1 MyCat能干什么？\n读写分离\n\n\n\n数据分片\n\n\n\n\n\n\n\n\n\n\n垂直拆分（分库）、水平拆分（分表）、垂直+水平拆分（分库分表）\n\n\n\n多数据源整合\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMycat 的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的 SQL 语 句，首先对 SQL 语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此 SQL 发往后端的真实数据库，并将返回的结果做适当的处理， 最终再返回给用户\n1.2 MyCat2.0与1.6功能对比\n\n\n功能\n1.6\n2\n\n\n\n多语句\n不支持\n支持\n\n\nblob 值\n支持一部分\n支持\n\n\n全局二级索引\n不支持\n支持\n\n\n任意跨库 join(包含复杂查询)\ncatlet 支持\n支持\n\n\n关联子查询\n不支持\n支持一部分\n\n\n分库同时分表\n不支持\n支持\n\n\n存储过程\n支持固定形式的\n支持更多\n\n\n支持逻辑视图\n不支持\n支持\n\n\n支持物理视图\n支持\n支持\n\n\n批量插入\n不支持\n支持\n\n\n执行计划管理\n不支持\n支持\n\n\n路由注释\n支持\n支持\n\n\n集群功能\n支持\n支持更多\n\n\n自动 hash 分片算法\n不支持\n支持\n\n\n支持第三方监控\n支持 mycat-web\n支持普罗米斯,kafka 日志等监控\n\n\n流式合拼结果集\n支持\n支持\n\n\n范围查询\n支持\n支持\n\n\n单表映射物理表\n不支持\n支持\n\n\nXA 事务\nXA 事务\n支持,事务自动恢复\n\n\n支持 MySQL8\n需要更改mysql8的服务器配置支持\n支持\n\n\n虚拟表\n不支持\n支持\n\n\njoinClustering\n不支持\n支持\n\n\nunion all 语法\n不支持\n支持\n\n\nBKAJoin\n不支持\n支持\n\n\n优化器注释\n不支持\n支持\n\n\nER 表\n支持\n支持\n\n\n全局序列号\n支持\n支持\n\n\n保存点\n不支持\n支持\n\n\n概念解释：\n\n多语句：解析器会对 SQL 进行拆分依次执行（默认配置）；\nblob 值：BLOB (binary large object)二进制大对象，是一个可以存储二进制文件的容器；\n全局二级索引：使用全局二级索引后,能有效减少全表扫描,对于减少连接使用, 减少计算节点与存储节点的数据传输有帮助；\n关联子查询：支持不能消除关联的关联子查询；\n分库同时分表：把分库分表合一，统一规划；\n存储过程：存储过程支持多结果集返回、支持接收 affectRow；\n支持批量插入：支持 rewriteInsertBatchedStatementBatch 参数,用于提高批量插入性能（只有把 rewriteBatchedStatements 参数置为 true, MySQL 驱动才会帮你批量执行 SQL） ；\n支持执行计划管理：Mycat2 的执行计划管理主要作用是管理执行计划,加快 SQL到执行计划的转换,并且提供一个方式可以从持久层读取自定义的执行计划；\n自动 hash 分片算法：由 1.6 版本的手动配置算法，到 2.0 的自动 hash 分片；\n单表映射物理表：使用自动化建表语句创建测试的物理库物理表,它会自动生成配置文件,然后通过查看本地的配置文件,观察它的属性；\n\n映射模型区别\n\n\n\n\n1.3 MyCat 一些概念\n\n\n\n\n\n\n\n\n分库分表\n按照一定规则把数据库中的表拆分为多个带有数据库实例,物理库,物理表访问路径的分表。 \n解读：分库：一个电商项目，分为用户库、订单库等等。 分表：一张订单表数据数百万，达到 MySQL 单表瓶颈，分到多个数据库中的多张表\n\n\n\n\n\n\n\n\n\n逻辑库\n数据库代理中的数据库,它可以包含多个逻辑表。 \n解读：Mycat 里定义的库，在逻辑上存在，物理上在 MySQL 里并不存在。有可能是 多个 MySQL 数据库共同组成一个逻辑库。类似多个小孩叠罗汉穿上外套，扮演一个大人。\n\n\n\n\n\n\n\n\n\n逻辑表\n数据库代理中的表,它可以映射代理连接的数据库中的表(物理表) \n解读：Mycat 里定义的表，在逻辑上存在，可以映射真实的 MySQL 数据库的表。可以一对一，也可以一对多。 \n\n\n\n\n\n\n\n\n\n物理库、物理表\n数据库代理连接的数据库中的库、表\n\n\n\n\n\n\n\n\n\n拆分键\n即分片键,描述拆分逻辑表的数据规则的字段 \n解读：比如订单表可以按照归属的用户 id 拆分，用户 id 就是拆分键\n\n\n\n\n\n\n\n\n\n物理分表\n指已经进行数据拆分的,在数据库上面的物理表,是分片表的一个分区 \n解读：多个物理分表里的数据汇总就是逻辑表的全部数据 \n\n\n\n\n\n\n\n\n\n物理分库\n一般指包含多个物理分表的库 \n解读：参与数据分片的实际数据库\n\n\n\n\n\n\n\n\n\n分库 \n一般指通过多个数据库拆分分片表,每个数据库一个物理分表,物理分库名字相同 \n解读：分库是个动作，需要多个数据库参与。就像多个数据库是多个盘子，分库就是 把一串数据葡萄，分到各个盘子里，而查询数据时，所有盘子的葡萄又通过 Mycat2 组成了完整的一串葡萄\n\n\n\n\n\n\n\n\n\n分片表，水平分片表\n按照一定规则把数据拆分成多个分区的表,在分库分表语境下,它属于逻辑表的一种 \n解读：安按照规则拆分数据，上个例子中的那串葡萄。\n\n\n\n\n\n\n\n\n\n单表 \n没有分片,没有数据冗余的表\n\n\n\n\n\n\n\n\n\n全局表,广播表\n每个数据库实例都冗余全量数据的逻辑表，它通过表数据冗余,使分片表的分区与该表的数据在同一个数据库实例里,达到 join 运算能够直接在该数据库实例里执行.它的数据一致一般是通过数据库代理分发 SQL 实现。也有基于集群日志的实现 \n解读：例如系统中翻译字段的字典表，每个分片表都需要完整的字典数据翻译字段\n\n\n\n\n\n\n\n\n\nER表\n狭义指父子表中的子表,它的分片键指向父表的分片键,而且两表的分片算法相同广义指具有相同数据分布的一组表 \n解读：关联别的表的子表，例如：订单详情表就是订单表的 ER 表\n\n\n\n\n\n\n\n\n\n集群 \n多个数据节点组成的逻辑节点.在 mycat2 里,它是把对多个数据源地址视为一个数据源地址(名称),并提供自动故障恢复,转移,即实现高可用,负载均衡的组件。 \n解读：集群就是高可用、负载均衡的代名词 \n\n\n\n\n\n\n\n\n\n数据源 \n连接后端数据库的组件,它是数据库代理中连接后端数据库的客户端 \n解读：Mycat 通过数据源连接 MySQL 数据库 \n\n\n\n\n\n\n\n\n\n原型库(prototype)\n原型库是 Mycat2 后面的数据库，比如 mysql 库\n1.4 配置文件1.4.1  服务（server）位于mycat&#x2F;conf&#x2F;server.jso，默认配置即可\n1.4.2 用户（user）位于 mycat&#x2F;conf&#x2F;users  命名格式：{用户名}.user.json\n&#123;\n\t\"dialect\":\"mysql\",\n\t\"ip\":null,\n\t\"password\":\"123456\",\n\t\"transactionType\":\"proxy\",\n\t\"username\":\"root\"\n&#125;\n\n# 字段含义 \n# ip：可连接的ip，为null表示所有\n# username：用户名\n# password：密码 \n# isolation：设置初始化的事务隔离级别 READ_UNCOMMITTED:1 READ_COMMITTED:2 REPEATED_READ:3,默认 SERIALIZABLE:4 \n# transactionType：事务类型 可选值: proxy 本地事务,在涉及大于 1 个数据库的事务,commit 阶段失败会导致不一致,但是兼容 性最好 xa 事务,需要确认存储节点集群类型是否支持 XA 可以通过语句实现切换\nset transaction_policy = 'xa'\nset transaction_policy = 'proxy' 可以通过语句查询 SELECT @@transaction_policy\n\n1.4.3 数据源（datasource）位于 mycat&#x2F;conf&#x2F;datasources  命名方式 ：{数据源名字}.datasource.json\n&#123;\n\t\"dbType\":\"mysql\",\n\t\"idleTimeout\":60000,\n\t\"initSqls\":[],\n\t\"initSqlsGetConnection\":true,\n\t\"instanceType\":\"READ_WRITE\",\n\t\"maxCon\":1000,\n\t\"maxConnectTimeout\":3000,\n\t\"maxRetryCount\":5,\n\t\"minCon\":1,\n\t\"name\":\"prototypeDs\",\n\t\"password\":\"xxx\",\n\t\"type\":\"JDBC\",\n\t\"url\":\"jdbc:mysql://xxx?useUnicode=true&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=UTF-8\",\n\t\"user\":\"root\",\n\t\"weight\":0\n&#125;\n\n# 字段含义 \n# dbType：数据库类型，mysql \n# name：用户名 \n# password：密码 \n# type：数据源类型，默认 JDBC \n# url：访问数据库地址 \n# idleTimeout：空闲连接超时时间 \n# initSqls：初始化sql \n# initSqlsGetConnection：对于 jdbc 每次获取连接是否都执行 initSqls\n# instanceType：配置实例只读还是读写 可选值: READ_WRITE,READ,WRITE \n# weight ：负载均衡权重 \n# 连接相关配置 \"maxCon\": 1000, \"maxConnectTimeout\": 3000, \"maxRetryCount\": 5, \"minCon\": 1\n\n1.4.4 集群（cluster）位于 mycat&#x2F;conf&#x2F;clusters  命名方式 ：{集群名字}.cluster.json\n&#123;\n\t\"clusterType\":\"MASTER_SLAVE\",\n\t\"heartbeat\":&#123;\n\t\t\"heartbeatTimeout\":1000,\n\t\t\"maxRetry\":3,\n\t\t\"minSwitchTimeInterval\":300,\n\t\t\"slaveThreshold\":0\n\t&#125;,\n\t\"masters\":[\n\t\t\"prototypeDs\"  //配置多个主节点,在主挂的时候会选一个检测存活的数据源作 为主节点\n\t],\n\t\"maxCon\":200,\n\t\"name\":\"prototype\",\n\t\"readBalanceType\":\"BALANCE_ALL\",\n\t\"switchType\":\"SWITCH\"\n&#125;\n\n# clusterType：集群类型 可选值: \nSINGLE_NODE:单一节点 \nMASTER_SLAVE:普通主从 \nGARELA_CLUSTER:garela \ncluster/PXC 集群\nMHA：MHA 集群\nMGR：MGR 集群 \n# readBalanceType：查询负载均衡策略 可选值: \nBALANCE_ALL(默认值) 获取集群中所有数据源 \nBALANCE_ALL_READ 获取集群中允许读的数据源 \nBALANCE_READ_WRITE 获取集群中允许读写的数据源,但允许读的数据源优先 \nBALANCE_NONE 获取集群中允许写数据源,即主节点中选择 \n# switchType：切换类型 可选值:\nNOT_SWITCH:不进行主从切换\nSWITCH:进行主从切换\n\n1.4.5逻辑库表（schema）位于 mycat&#x2F;conf&#x2F;schemas   命名方式：{库名}.schema.json\n#库配置 \n&#123; \"schemaName\": \"mydb\", \"targetName\": \"prototype\" &#125;\n# schemaName：逻辑库名 \n# targetName：目的数据源或集群 targetName自动从prototype目标加载test库下的物理表或者视图作为单表,prototype 必须是mysql服务器 \n\n#单表配置 \n&#123; \"schemaName\": \"mysql-test\", \"normalTables\": &#123; \"role_edges\": &#123; \"createTableSQL\":null,//可选 \"locality\": &#123; \"schemaName\": \"mysql\",//物理库,可选 \"tableName\": \"role_edges\",//物理表,可选 \"targetName\": \"prototype\"//指向集群,或者数据源 &#125; &#125;...... \n\n\n\n2. 环境搭建2.1 一主一从Mycat读写分离\n\n\n\n\n\n\n\n\n已搭建一主一从MySQL服务器，下面演示Mycat环境  参考 MySQL 读写分离 | 王硕’s Blog (ws.ht)\n\n下载这两个 Index of &#x2F;2.0&#x2F;1.22-release&#x2F; (mycat.org.cn)\n\n\n1.22-release下载的jar包copy至install-template&#x2F;mycat&#x2F;bin目录下，linux注意权限问题\n\n创建mysql用户（也可以使用mycat默认用户，root-123456）\n\nCREATE USER 'mycat'@'%' IDENTIFIED BY '123456'; # 必须要赋的权限mysql8才有的 \nGRANT XA_RECOVER_ADMIN ON *.* TO 'root'@'%'; # 视情况赋权限 \nGRANT ALL PRIVILEGES ON *.* TO 'mycat'@'%'; \nflush privileges;\n\n\n配置修改\n\n# mycat\\conf\\datasources\\prototypeDs.datasource.json\n&#123;\n\t\"dbType\":\"mysql\",\n\t\"idleTimeout\":60000,\n\t\"initSqls\":[],\n\t\"initSqlsGetConnection\":true,\n\t\"instanceType\":\"READ_WRITE\",\n\t\"maxCon\":1000,\n\t\"maxConnectTimeout\":3000,\n\t\"maxRetryCount\":5,\n\t\"minCon\":1,\n\t\"name\":\"prototypeDs\",\n\t\"password\":\"XXXX\",   # √\n\t\"type\":\"JDBC\",\n\t\"url\":\"jdbc:mysql://XXXXX:58887?useUnicode=true&amp;serverTimezone=Asia/Shanghai&amp;characterEncoding=UTF-8\",   # √\n\t\"user\":\"root\",\n\t\"weight\":0\n&#125;\n\n\n启动\n\n# linux\ncd mycat/bin \n./mycat start \n./mycat status \n./mycat start 启动 \n./mycat stop 停止 \n./mycat console 前台运行 \n./mycat install 添加到系统自动启动（暂未实现） \n./mycat remove 取消随系统自动启动（暂未实现） \n./mycat restart 重启服务 \n./mycat pause 暂停 \n./mycat status 查看启动状态…\n# windows  cmd root执行\nmycat install\nmycat start\nmycat status\n\n\n测试\n\nmysql -uroot -p123456 -P 8066\n\n\n连接 Mycat 注释操作\n\n\n\n\n\n\n\n\n\n\n注：主节点和Mycat原型库是同一台MySQL，test库存在于主节点\n/*+ mycat:resetConfig&#123;&#125; */\n\n/*+ mycat:createDataSource&#123;\n    \"name\":\"master\",\n\t\"dbType\":\"mysql\",\n\t\"idleTimeout\":60000,\n\t\"initSqls\":[],\n\t\"initSqlsGetConnection\":true,\n\t\"instanceType\":\"WRITE\",\n\t\"maxCon\":1000,\n\t\"maxConnectTimeout\":3000,\n\t\"maxRetryCount\":5,\n\t\"minCon\":1,\n\t\"password\":\"L200107208017./@\",\n\t\"type\":\"JDBC\",\n\t\"url\":\"jdbc:mysql://11:3306?useUnicode=true&amp;serverTimezone=UTC&amp;characterEncoding=UTF-8\",\n\t\"user\":\"root\",\n\t\"weight\":0\n&#125; */;\n\n/*+ mycat:createDataSource&#123;\n    \"name\":\"slave\",\n\t\"dbType\":\"mysql\",\n\t\"idleTimeout\":60000,\n\t\"initSqls\":[],\n\t\"initSqlsGetConnection\":true,\n\t\"instanceType\":\"READ\",\n\t\"maxCon\":1000,\n\t\"maxConnectTimeout\":3000,\n\t\"maxRetryCount\":5,\n\t\"minCon\":1,\n\t\"password\":\"L200107208017./@\",\n\t\"type\":\"JDBC\",\n\t\"url\":\"jdbc:mysql://22:3306?useUnicode=true&amp;serverTimezone=UTC&amp;characterEncoding=UTF-8\",\n\t\"user\":\"root\",\n\t\"weight\":0\n&#125; */;\n\n\n\n/*+ mycat:createSchema&#123;\n\t\"customTables\":&#123;&#125;,\n\t\"globalTables\":&#123;&#125;,\n\t\"normalTables\":&#123;&#125;,\n\t\"schemaName\":\"test\",\n\t\"shardingTables\":&#123;&#125;,\n\t\"targetName\":\"master-slave\"\n&#125; */;\n\n/*! mycat:createCluster&#123;\n\t\"clusterType\":\"MASTER_SLAVE\",\n\t\"heartbeat\":&#123;\n\t\t\"heartbeatTimeout\":1000,\n\t\t\"maxRetry\":3,\n\t\t\"minSwitchTimeInterval\":300,\n\t\t\"slaveThreshold\":0\n\t&#125;,\n\t\"masters\":[\n\t\t\"master\" //主节点\n\t],\n\t\"maxCon\":2000,\n\t\"name\":\"master-slave\",\n\t\"readBalanceType\":\"BALANCE_ALL\",\n\t\"replicas\":[\n\t\t\"slave\" //从节点\n\t],\n\t\"switchType\":\"SWITCH\"\n&#125; */;\n\n/*+ mycat:showSchemas&#123;&#125; */;\n/*+ mycat:showDataSources&#123;&#125; */;\n/*+ mycat:showClusters&#123;&#125; */;\n\n\n测试MyCat\n\n# 把日志输出到表；开启日志记录\nSET GLOBAL log_output = 'TABLE'; SET GLOBAL general_log = 'ON';\n# 清空 mysql.general_log 日志表中的记录\nTRUNCATE TABLE mysql.general_log;\n\n\nINSERT INTO test VALUES(1, 'a');\nSELECT * FROM test;\nSELECT * FROM test;\n\n#可以看到只有主节点有insert而从节点只有select\nSELECT event_time,\n       user_host,\n       thread_id,\n       server_id,\n       command_type,\n       CAST(argument AS CHAR(500) CHARACTER SET utf8mb4) argument\nFROM mysql.general_log\nORDER BY event_time DESC;\n\n# 把日志输出到文件（默认设置）；关闭日志记录\nSET GLOBAL log_output = 'FILE'; SET GLOBAL general_log = 'OFF';\n\n\n\n\n\n3. 分库分表3.1 字典表# 字典表默认保存在 prototype 数据源中，也是就说这个数据源当做了一个公共源\ncreate database test;\nuse test;\ncreate table `aaa`(\n`id` bigint not null auto_increment,\n`user_id` varchar(100) default null,\n`traveldate` date default null,\n`fee` decimal(10,0) default null,\n`days` int default null,\n`blob` LONGBLOB,\nprimary key (`id`),\nkey `id` (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 BROADCAST;\n\n3.2","slug":"Mycat2入门","date":"2022-09-30T09:39:20.000Z","categories_index":"","tags_index":"中间件","author_index":"JuneQQQ"},{"id":"99aa4407a60ebb936774d228acd49096","title":"Kafka入门","content":"1. 环境搭建\n\n\n主机名\nIP\n\n\n\nubuntu1\n192.168.150.100\n\n\nubuntu2\n192.168.150.101\n\n\nubuntu3\n192.168.150.102\n\n\n\n\n\n\n\n\n\n\n\n注意，以下均为Kraft方式搭建，官方不建议生产环境这么做 截止2022.8.17 \n1.1 三节点原生集群搭建(Kraft)# ubuntu 22.04 TLS  直接一键安装jdk11\nsudo apt-get update\nsudo apt-get install default-jdk\n\necho 192.168.150.100 ubuntu1 >> /etc/hosts\necho 192.168.150.101 ubuntu2 >> /etc/hosts\necho 192.168.150.102 ubuntu3 >> /etc/hosts\nsource /etc/hosts\n\n#1.官网下载安装包，解压至 /opt/kafka\ntar -zxvf  \n#2.进入其config目录，修改 server.properties 文件\nvim /opt/kafka/kafka_2.12-3.2.1/config/server.properties\nnode.id=1/2/3   # 三台kafka一定要不同\nadvertised.listeners=PLAINTEXT://ubuntu2:9092  # ubuntu2是当前kafka主机名\nlog.dirs=/opt/kafka/kafka_2.12-3.2.1/data/kraft-combined-logs   # 自定义数据目录\ncontroller.quorum.voters=1@ubuntu1:9093,2@ubuntu2:9093,3@ubuntu3:9093   # 彼此连接\n\necho export KAFKA_HOME=/opt/kafka/kafka_2.12-3.2.1 >> /etc/profile \necho export PATH=$PATH:$KAFKA_HOME/bin >> /etc/profile\nsource /etc/profile\n\n# 生成集群id\nkafka-storage.sh  random-uuid\n# 集群初始化，三台节点都要执行\nkafka-storage.sh format -t _852RDWbTAeZuD9ABwgteg -c /opt/kafka/kafka_2.12-3.2.1/config/kraft/server.properties   \n# 启动\nkafka-server-start.sh -daemon /opt/kafka/kafka_2.12-3.2.1/config/kraft/server.properties\nkafka-server-stop.sh\n\n# 测试\n# 创建first主题并分配3个分区和3个副本\nkafka-topics.sh --bootstrap-server 192.168.150.100:9092 --create --topic second --partitions 3 --replication-factor 3\n# 查看主题\nkafka-topics.sh --bootstrap-server 192.168.150.101:9092 --list\n# 生产数据 1号服务器执行\nkafka-console-producer.sh --bootstrap-server ubuntu1:9092 --topic first\n# 消费数据 2号服务器执行\nkafka-console-consumer.sh --bootstrap-server ubuntu2:9092 --topic first \n\n# 一些便利性脚本\n# 首先让服务器之间免密登陆\nssh-keygen -t rsa  # 控制节点执行\nssh-copy-id -i ~/.ssh/id_rsa.pub root@ubuntu1   # 拷贝公钥->1 自己也要拷贝\nssh-copy-id -i ~/.ssh/id_rsa.pub root@ubuntu2   # 拷贝公钥->2\nssh-copy-id -i ~/.ssh/id_rsa.pub root@ubuntu3   # 拷贝公钥->3\n# 如果想要删除，干掉 /root/.ssh/authorized_keys 即可\n\n#! /bin/bash\ncase $1 in\n    \"start\")&#123;\n            for i in ubuntu1 ubuntu2 ubuntu3\n            do\n                echo \" --------启动 $i Kafka2-------\"\n                ssh $i \"kafka-server-start.sh -daemon /opt/kafka/kafka_2.12-3.2.1/config/kraft/server.properties\"\n            done\n    &#125;;;\n    \"stop\")&#123;\n            for i in ubuntu1 ubuntu2 ubuntu3\n            do\n                echo \" --------停止 $i Kafka3-------\"\n                ssh $i \"/opt/kafka/kafka_2.12-3.2.1/bin/kafka-server-stop.sh\"\n            done\n    &#125;;;\nesac\n\n\n\n1.2 三节点Docker方式集群搭建（Kraft）sudo apt  install docker-compose\n\n# 自己家网络有点问题，用服务器上传到了腾讯云，有需要的可以自己拉取\ncat &lt;&lt;EOF> /etc/docker/daemon.json\n&#123;\n   \"registry-mirrors\": [\n       \"https://mirror.ccs.tencentyun.com\"\n  ]\n&#125;\nsudo systemctl restart docker\ndocker pull myteam-p-docker.pkg.coding.net/mall-project/public/kafka:latest  # bitnami/kafka:3.2.1\ndocker tag  myteam-p-docker.pkg.coding.net/mall-project/public/kafka:latest   bitnami/kafka:latest\n\n# 三台服务器都要执行\nversion: \"3\"\nservices:\n   kafka:\n     image: 'bitnami/kafka:latest'\n     user: root\n     ports:\n       - '9092:9092'\n       - '9093:9093'\n     environment:\n       - KAFKA_ENABLE_KRAFT=yes\n       - KAFKA_CFG_PROCESS_ROLES=broker,controller\n       - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER\n       - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093\n       - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT\n       - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.150.100:9092 # 哪台机器执行，改成对应的IP\n       - KAFKA_BROKER_ID=1   # 每台kafka这里都需要改一下，不同即可\n       - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA\n       - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@192.168.150.100:9093,2@192.168.150.101:9093,3@192.168.150.102:9093\n       - ALLOW_PLAINTEXT_LISTENER=yes   # 写IP\n     volumes:\n       - /opt/docker-kafka/kraft:/bitnami/kafka:rw\n\n# 三台服务器分别执行上面yaml，注意内容\ndocker-compose up -d\n\n# 【测试】注意：由于我已经原生搭建过kafka集群，所以这一步我可以直接在容器外使用命令行！容器内互通的\n# 创建first主题并分配3个分区和3个副本\nkafka-topics.sh --bootstrap-server 192.168.150.100:9092 --create --topic second --partitions 3 --replication-factor 3\n# 查看主题\nkafka-topics.sh --bootstrap-server 192.168.150.101:9092 --list\n# 生产数据 1号服务器执行\nkafka-console-producer.sh --bootstrap-server ubuntu1:9092 --topic first\n# 消费数据 2号服务器执行\nkafka-console-consumer.sh --bootstrap-server ubuntu2:9092 --topic first \n\n1.3 Kafka-UI\n\n\n\n\n\n\n\n\ngithub：https://github.com/provectus/kafka-ui\n# kafka-ui  \ndocker run -p 8080:8080 \\\n\t-e KAFKA_CLUSTERS_0_NAME=local \\\n\t-e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=192.168.150.100:9092,192.168.150.101:9092,192.168.150.102:9092 \\\n\t-d myteam-p-docker.pkg.coding.net/mall-project/public/kafka-ui:latest\n\n\n\n2. 核心概念\n\nProducer：消息生产者，就是向 Kafka broker 发消息的客户端。 \n\nConsumer：消息消费者，向 Kafka broker 取消息的客户端。 \n\nConsumer Group（CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 \n\nBroker：一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个broker 可以容纳多个 topic。 \n\nTopic：可以理解为一个队列，生产者和消费者面向的都是一个 topic。 \n\nPartition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。  Topic与Partition是一对多的关系\n\nReplica：副本。一个 topic 的每个分区都有若干个副本，一个 Leader和若干个 Follower\n\nLeader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。 \n\nFollower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。\n\n\n2.1 基础命令\n\n\n参数\n描述\n\n\n\n–bootstrap-server &lt;String: server toconnect to&gt;\n连接的 Kafka Broker 主机名称和端口号\n\n\n–topic &lt;String: topic&gt;\n操作的 topic 名称\n\n\n–create\n创建主题\n\n\n–delete\n删除主题\n\n\n–alter\n修改主题\n\n\n–list\n查看所有主题\n\n\n–describe\n查看主题详细描述\n\n\n–partitions &lt;Integer:#of partitions&gt;\n设置分区数\n\n\n–replication-factor&lt;Integer:replication factor&gt;\n设置分区副本\n\n\n–config&lt;String: name&#x3D;value&gt;\n更新系统默认配置\n\n\n2.2 Producer2.2.1 发送流程// JavaAPI简单Demo\n// 1. 创建 kafka 生产者的配置对象\nProperties properties = new Properties();\n // 2. 给 kafka 配置对象添加配置信息：bootstrap.servers\nproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\"hadoop102:9092\");\n // key,value 序列化（必须）：key.serializer，value.serializer\nproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n               \"org.apache.kafka.common.serialization.StringSerializer\");\nproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n               \"org.apache.kafka.common.serialization.StringSerializer\");\n // 3. 创建 kafka 生产者对象\nKafkaProducer&lt;String, String> kafkaProducer = new \nKafkaProducer&lt;String, String>(properties);\n // 4. 调用 send 方法,发送消息\n for (int i = 0; i &lt; 5; i++) &#123;\n     // 注意这个ProducerRecor对象\n     kafkaProducer.send(new ProducerRecor&lt;>(\"first\",\"atguigu \" + i));\n &#125;\n // 5. 关闭资源\n kafkaProducer.close();\n\n\n2.2.2 分区规则\n\n\n\n\n\n\n\n\n主要是ProducerRecor这个类的构造方法\n\n\n\n\n\n\n\n\n\n\n自定义分区规则\n\n定义类实现 Partitioner 接口。；\n重写 partition()方法；\n加入配置类\n\n// 简单Demo\n@Override\npublic int partition(String topic, Object key, byte[]\n                     keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123;\n    // 获取消息\n    String msgValue = value.toString();\n    // 创建 partition\n    int partition;\n    // 判断消息是否包含 atguigu\n    if (msgValue.contains(\"atguigu\")) &#123;\n        partition = 0;\n    &#125; else &#123;\n        partition = 1;\n    &#125;\n    // 返回分区号\n    return partition;\n&#125;\n\n// 关闭资源\n@Override\npublic void close() &#123;&#125;\n\n// 配置方法\n@Override\npublic void configure(Map&lt;String, ?> configs) &#123;&#125;\n=====================================================\n// Properties对象指定自定义分区规则\nproperties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,\"com.kafka.producer.MyPartitioner\");\n\n\n\n2.2.3 几个调优参数好文推荐：[kafka生产者性能相关的参数理解 - 代码天地 (codetd.com)](https://www.codetd.com/article/13239209#:~:text=默认值为60s 当执行KafkaProducer.send,() 和KafkaProducer.partitionsFor ()时阻塞等待的时间，之所以会阻塞时因为可能buffer满了或者获取元数据异常，那么超过这个时间就会抛出异常。)\nbatch.size：# 批次大小，默认16k \nlinger.ms：# 等待时间，修改为5-100ms\ncompression.type：# 压缩snappy  可选值 none, gzip, snappy, lz4, or zstd\nRecordAccumulator：# 缓冲区大小，修改为64m\nretries: # 重试次数，默认Integer.MAX_VALUE 官方建议通过这个参数delivery.timeout.ms来控制重试行为。\ndelivery.timeout.ms # 调用send（）返回后报告成功或失败时间的上限 默认值为2分钟\n\n\n\n2.2.4 Ack机制消息发送方可以通过配置request.required.acks属性来保证消息的安全发送，值包括：\n0：表示不进行消息接收是否成功的确认\n1：表示当Leader落盘成功时发送确认\n-1(ALL)：表示Leader和ISR队列都落盘成功时确认\n\n\n\n\n\n\n\n\n\n官方文档说明如下：\noffsets.commit.required.acks\nacks=0 If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case, and the retries configuration will not take effect (as the client won’t generally know of any failures). The offset given back for each record will always be set to -1.\nacks=1 This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.\nacks=all This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee. This is equivalent to the acks&#x3D;-1 setting.\n\n2.2.5 数据幂等性\n\n\n\n\n\n\n\n\nenable.idempotenceWhen set to ‘true’, the producer will ensure that exactly one copy of each message is written in the stream. If ‘false’, producer retries due to broker failures, etc., may write duplicates of the retried message in the stream. Note that enabling idempotence requires max.in.flight.requests.per.connection to be less than or equal to 5 (with message ordering preserved for any allowable value), retries to be greater than 0, and acks must be ‘all’.\nIdempotence is enabled by default if no conflicting configurations are set. If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled. If idempotence is explicitly enabled and conflicting configurations are set, a ConfigException is thrown.\n解释如下\n\n幂等性必须运行在 ack&#x3D;-1 模式下；\n在没有冲突配置环境下（比如 ack &#x3D;-1），默认开启；\n幂等性判断标准：&lt;PID,Partition,SeqNumber&gt; 全部相同；\n只能保证单分区单会话条件下消息不重（也保证了消息不丢），全局唯一需要事务引入\n\n2.2.6 事务\n// 1 初始化事务\nvoid initTransactions();\n// 2 开启事务\nvoid beginTransaction() throws ProducerFencedException;\n// 3 在事务内提交已经消费的偏移量（主要用于消费者）\nvoid sendOffsetsToTransaction(Map&lt;TopicPartition, OffsetAndMetadata> offsets, String consumerGroupId) throws ProducerFencedException;\n// 4 提交事务\nvoid commitTransaction() throws ProducerFencedException;\n// 5 放弃事务（类似于回滚事务的操作）\nvoid abortTransaction() throws ProducerFencedException;\n\n注意：消息发送前必须指定了事务ID\nproperties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,\"transaction_id_0\");\n\n\n\n2.2.7 数据有序max.in.flight.requests.per.connection # 控制Producer发送窗口大小（RabbitMQ有个 basicQos方法是消费端限流，区别于这个）\n\nkafka在1.x及以后版本保证数据单分区有序，条件如下：\n\n未开启幂等性：max.in.flight.requests.per.connection需要设置为1\n开启幂等性：max.in.flight.requests.per.connection需要设置小于等于5\n原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，故无论如何，都可以保证最近5个request的数据都是有序的\n\n\n\n\n\n\n\n\n\n\n\n\nmax.in.flight.requests.per.connectionThe maximum number of unacknowledged requests the client will send on a single connection before blocking. Note that if this config is set to be greater than 1 and enable.idempotence is set to false, there is a risk of message re-ordering（个人认为这里应该翻译为乱序而不是重排序） after a failed send due to retries (i.e., if retries are enabled). Additionally, enabling idempotence requires this config value to be less than or equal to 5. If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled.\n2.3 Broker2.3.1 Zookeeper中记录的节点信息\n2.3.2 Broker 总体工作流程 &amp; Leader选举流程\n\n\nLeader上位顺序为 Replicas 中的顺序（从左到右），但必须在 Isr 中存活，\n\n\n\n\n\n\n\n\n\n\nunclean.leader.election.enableIndicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss\n该参数如果设为 true 可以让不在isr队列里的节点参加Leader选举！默认false（3.2.1），但是这个默认值在之前的版本经常变更\n2.3.3 Kafka副本\n默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘空间以及网络传输负担；\nKfaka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，Follower找Leader同步；\nKafka分区中所有副本统称为AR（Assigned Repllicas） AR &#x3D; ISR + OSR\nISR表示和Leader保持同步的Follower集合。Leader故障时，从ISR中选取新的Leader；ISR有以下几个参数\nreplica.lag.time.max.ms   默认10000 即 10秒  这个参数很有讲究，参考这篇文章 (2条消息) Kafka之ISR机制的理解_搬砖党弟中弟的博客-CSDN博客_isr机制\n\n\nOSR表示Follower与Leader副本同步时，延迟过多的副本\n\n\n\n\n\n\n\n\n\n\n\n\nreplica.lag.time.max.ms\n当follower副本将leader副本的LEO之前的日志全部同步时，则认为该follower副本已经追赶上leader副本。\n此时更新该副本的lastCaughtUpTimeMs标识。\nKafka的副本管理器（ReplicaManager）启动时会启动一个副本过期检测的定时任务，\n会定时检查当前时间与副本的lastCaughtUpTimeMs差值是否大于参数replica.lag.time.max.ms指定的值。\n所以replica.lag.time.max.ms的正确理解是：\nfollower在过去的replica.lag.time.max.ms时间内，已经追赶上leader一次了。\n2.3.3.1 Leader与Follower同步问题（LEO&#x2F;HW）\n\n\n注：小于 HW 值的offset所对应的消息被认为是“已提交”或“已备份”的消息，才对消费者可见。\n2.3.3.2  分区副本分配创建16个分区，默认分配如下（规则自行脑补，我也不会）：\n\n\n\n\n\n\n\n\n\n\n手动调整\n编写 json 手动设置，略\n2.3.3.3 Leader Rebalanceauto.leader.rebalance.enable：开启leader balancing，默认true\n当一个broker停止或者crashes时，所有本来将它作为leader的分区将会把leader转移到其他broker上去，极端情况下，会导致同一个leader管理多个分区，导致负载不均衡，同时当这个broker重启时，如果这个broker不再是任何分区的leader,kafka的client也不会从这个broker来读取消息，从而导致资源的浪费。\nkafka中有一个被称为优先副本（preferred replicas）的概念。如果一个分区有3个副本，且这3个副本的优先级别分别为0,1,2，根据优先副本的概念，0会作为leader 。当0节点的broker挂掉时，会启动1这个节点broker当做leader。当0节点的broker再次启动后，会自动恢复为此partition的leader。不会导致负载不均衡和资源浪费，这就是leader的均衡机制。\n在配置文件conf&#x2F; server.properties中配置开启（默认就是开启）：auto.leader.rebalance.enable true\n\n\n\n\n\n\n\n\n\n 解释一下 leader 均衡机制(auto.leader.rebalance.enable&#x3D;true)：\n当 partition 1 的 leader，就是 broker.id &#x3D; 1 的节点挂掉后，那么 leader 0 或 leader 2 成为 partition 1 的 leader，那么 leader 0 或 leader 2 会管理两个 partition 的读写，性能会下 降，当 leader 1 重新启动后，如果开启了 leader 均衡机制，那么 leader 1 会重新成为 partition 1 的 leader，降低 leader 0 或 leader 2 的负载\n\n\n\n\n\n\n\n\n\n下面两个参数需开启 auto.leader.rebalance.enable\nleader.imbalance.per.broker.percentage：，默认情况下，此设置设置为10，因此Kafka允许多达10%的领导者在非首选副本上，然后再次选举首选副本。\nleader.imbalance.check.interval.seconds：默认值300秒。检查leader负载是否平衡的间隔时间。\n\n\n\n\n\n\n\n\n\n开启这个参数势必有性能损耗，主要是leader重新分配的消耗，而开启这个参数好处在于请求均摊，服务负载均衡\n2.3.4 文件存储\n\nlog.segment.bytes： # 默认值 1G。 Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分成块的大小，\nlog.index.interval.bytes： # 默认 4kb。kafka 里面每当写入了 4kb 大小的日志（.log），然后就往 index 文件里面记录一个索引。 稀疏索引。\n\n\n\n\n\n2.3.4.1 文件清除策略log.retention.hours   # 优先级最低，默认168，即7天\nlog.retention.minutes   # 优先级中等，覆盖前者\nlog.retention.ms      # 优先级最高，覆盖前者，-1表示没有限制\nlog.retention.check.interval.ms # 300000=5min 检查周期，注意和上面参数有关联\nlog.retention.bytes   # The maximum size of the log before deleting it\n\nlog.cleanup.policy ：compact&#x2F;delete， 默认delete 启用数据删除策略\n\n基于时间：默认开启，以segment中所有记录的最大时间戳作为该log文件的时间戳\n基于空间：默认关闭，超过 log.retention.bytes 设置大小，删除最早的segment，默认-1，表示无穷大\n\n\n如果采用 compact 策略，那么压缩后对于相同key的不同value值，只保留最后一个版本。\n\n压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个offset大 的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。 \n2.3.4.2\nKafka 本身是分布式集群，可以采用分区技术，并行度高\n读数据采用稀疏索引，可以快速定位要消费的数据\n顺序写磁盘\nKafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M&#x2F;s，而随机写只有 100K&#x2F;s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间\n\n\n页缓存 + 零拷贝技术\n\n\nlog.flush.interval.messages ：强制页缓存刷写到磁盘的条数，默认是 long 的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。\nlog.flush.interval.ms ：每隔多久，刷数据到磁盘，默认是 null。一般不建议修改，交给系统自己管理\n2.4 Consumer2.4.1 消费者工作流程\n\n\n\n\n\n\n\n\n整体流程\n\n\n\n\n\n\n\n\n\n\ncluster-&gt;consumer\n\nmax.poll.records  # 一次拉取数据返回消息的最大条数，默认500条\nfetch.min.bytes   # 每批次最小抓取大小，默认1字节\nfetch.max.bytes # 每批次最大抓取大小 默认50m\nfetch.max.wait.ms   # 一批数据最小值未达到的超时时间，默认500ms\nmax.poll.interval.ms  # 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\n\nbootstrap.servers # 向 Kafka 集群建立初始连接用到的 host/port 列表。\nkey.deserializer   # 指定接收消息的 key 和 value 的反序列化类型。一定要写全类名。\nvalue.deserializer  # 指定接收消息的 key 和 value 的反序列化类型。一定要写全类名。\ngroup.id # 标记消费者所属的消费者组。\nenable.auto.commit # 默认值为 true，消费者会自动周期性地向服务器提交偏移量。\nauto.commit.interval.ms # 如果设置了 enable.auto.commit 的值为 true， 则该值定义了消费者偏移量向 Kafka 提交的频率，默认 5s。\nauto.offset.reset  # 当 Kafka 中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？ earliest：自动重置偏移量到最早的偏移量。 latest：默认，自动重置偏移量为最新的偏移量。 none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。 anything：向消费者抛异常。\noffsets.topic.num.partitions __consumer_offsets # 的分区数，默认是 50 个分区。\nheartbeat.interval.ms Kafka # 消费者和 coordinator 之间的心跳时间，默认 3s。该条目的值必须小于 session.timeout.ms ，也不应该高于session.timeout.ms 的 1/3。 session.timeout.ms Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超过该值，该消费者被移除，消费者组执行再平衡。\npartition.assignment.strategy # 消 费 者 分 区 分 配 策 略 ， 默 认 策 略 是 Range + CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可 以 选 择 的 策 略 包 括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky\n\n\n\n2.4.2 两种消费方式\n2.4.3 消费者组\n\n2.4.4 消费者组初始化heartbeat.interval.ms  # consumer发送心跳包的周期，默认3s\nsession.timeout.ms   # 心跳超时时间 默认45s\nmax.poll.interval.ms  # 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\n\n\n2.4.5 分区的分配以及再平衡partition.assignment.strategy 消 费 者 分 区 分 配 策 略 ， 默 认 策 略 是 Range +  CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可 以 选 择 的 策 略 包 括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky\n2.4.5.1 Range\n2.4.5.2 RoundRobin\n2.4.5.3  Sticky粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。\n\n2.4.6 Offset偏移量想要查看需要在 config&#x2F;consumer.properties 中添加配置 exclude.internal.topics=false 表示允许消费系统主题，主题名：__consumer_offsets \n2.4.6.1 自动提交\nenable.auto.commit：是否开启自动提交offset功能，默认是true\nauto.commit.interval.ms：自动提交offset的时间间隔，默认是5s\n\n当设置 enable.auto.commit 为 true，Kafka 会保证在开始调用 poll 方法时，提交上次 poll 返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。\n\n\n\n\n\n\n\n\n\n自动提交位移的一个问题在于，它可能会出现重复消费。\n如果设置 enable.auto.commit 为 true，Consumer 按照 auto.commit.interval.ms设置的值（默认5秒）自动提交一次位移。我们假设提交位移之后的 3 秒发生了 Rebalance 操作。在 Rebalance 之后，所有 Consumer 从上一次提交的位移处继续消费，但该位移已经是 3 秒前的位移数据了，故在 Rebalance 发生前 3 秒消费的所有数据都要重新再消费一次。虽然你能够通过减少 auto.commit.interval.ms 的值来提高提交频率，但这么做只能缩小重复消费的时间窗口，不可能完全消除它。这是自动提交机制的一个缺陷。\n2.4.6.2 手动提交有两个方法：\n\ncommitSync\n\ncommitAsync\n  commitAsync 不能够替代 commitSync。commitAsync 的问题在于，出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。因此，异步提交的重试其实没有意义，所以 commitAsync 是不会重试的。\n\n\n2.4.6.3 手动提交和自动提交中的 reblance 问题\n\n\n\n\n\n\n\n\n\n如果设置为手动提交，当集群满足 reblance 的条件时，集群会直接 reblance，不会等待所有消息被消费完，这会导致所有未被确认的消息会重新被消费，会出现重复消费的问题\n如果设置为自动提交，当集群满足 reblance 的条件时，集群不会马上 reblance，而是会等待所有消费者消费完当前消息，或者等待消费者超时（等待过程中会报如下 warning）， 之后才会 reblance。\n\n2.4.6.4 指定偏移量提交auto.offset.reset     earliest | latest | none   默认是 latest。 \n当 Kafka 中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办？ \n\nearliest：自动将偏移量重置为最早的偏移量，–from-beginning。 \nlatest（默认值）：自动将偏移量重置为最新偏移量。\nnone：如果未找到消费者组的先前偏移量，则向消费者抛出异常。\nanything else：throw exception to the consumer.\n\n\n\n\n\n2.4.6.5 指定时间消费\n\n\n\n\n\n\n\n\n简单Demo\nSet&lt;TopicPartition> assignment = new HashSet&lt;>();\nwhile (assignment.size() == 0) &#123;\n    kafkaConsumer.poll(Duration.ofSeconds(1));\n    // 获取消费者分区分配信息（有了分区分配信息才能开始消费）\n    assignment = kafkaConsumer.assignment();\n&#125;\nHashMap&lt;TopicPartition, Long> timestampToSearch = new  HashMap&lt;>();\n// 封装集合存储，每个分区对应一天前的数据\nfor (TopicPartition topicPartition : assignment) &#123;\n    timestampToSearch.put(topicPartition, System.currentTimeMillis() - 1 * 24 * 3600 * 1000);\n&#125;\n// 获取从 1 天前开始消费的每个分区的 offset\nMap&lt;TopicPartition, OffsetAndTimestamp> offsets = kafkaConsumer.offsetsForTimes(timestampToSearch);\n// 遍历每个分区，对每个分区设置消费时间。\nfor (TopicPartition topicPartition : assignment) &#123;\n    OffsetAndTimestamp offsetAndTimestamp =\n        offsets.get(topicPartition);\n    // 根据时间指定开始消费的位置\n    if (offsetAndTimestamp != null) &#123;\n        kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset());\n    &#125;\n&#125;\n\n\n\n\n\n3.SpringBoot整合Demo@RestController\npublic class KafkaController &#123;\n    private final static String TOPIC_NAME = \"first\";\n\n    @Autowired\n    private KafkaTemplate&lt;String, String> kafkaTemplate;\n\n    @RequestMapping(\"/send/first\")\n    public String send(@RequestParam(\"msg\") String msg) &#123;\n        kafkaTemplate.send(TOPIC_NAME, \"key\", msg);\n        return String.format(\"消息 %s 发送成功！\", msg);\n    &#125;\n\n    @RequestMapping(\"/send/second\")\n    public String send2(@RequestParam(\"msg\") String msg) &#123;\n        kafkaTemplate.send(TOPIC_NAME, \"key\", msg);\n        return String.format(\"消息 %s 发送成功！\", msg);\n    &#125;\n&#125;\n\n@Component\npublic class MyConsumer &#123;\n    @KafkaListener(topics = \"first\", groupId = \"default-group\")\n    public void firstConsumer(ConsumerRecord&lt;String, String> record, Acknowledgment ack) &#123;\n        String value = record.value();\n        System.out.println(\"first message: \" + value);\n        System.out.println(\"first record: \" + record);\n        ack.acknowledge();\n    &#125;\n\n    //配置多个消费组\n    @KafkaListener(topics = \"second\", groupId = \"default-group\")\n    public void secondConsumer(ConsumerRecord&lt;String, String> record, Acknowledgment ack) &#123;\n        String value = record.value();\n        System.out.println(\"second message: \" + value);\n        System.out.println(\"second record: \" + record);\n        ack.acknowledge();\n    &#125;\n&#125;\n\nspring:\n  application:\n    name: SpringStudy\n  kafka:\n    bootstrap-servers: 192.168.150.100:9092,192.168.150.101:9092,192.168.150.102:9092\n    producer: # 生产者\n      retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送\n      batch-size: 16384\n      buffer-memory: 33554432\n      acks: all\n      # 指定消息key和消息体的编解码方式\n      key-serializer: org.apache.kafka.common.serialization.StringSerializer\n      value-serializer: org.apache.kafka.common.serialization.StringSerializer\n    consumer:\n      group-id: default-group\n      enable-auto-commit: false\n      auto-offset-reset: earliest\n      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer\n      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer\n    listener:\n      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交\n      # RECORD\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交\n      # BATCH\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交\n      # TIME\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交\n      # COUNT\n      # TIME |　COUNT　有一个条件满足时提交\n      # COUNT_TIME\n      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交\n      # MANUAL\n      # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种\n      # MANUAL_IMMEDIATE\n      ack-mode: manual_immediate\n\n# 应用服务 WEB 访问端口\nserver:\n  port: 8080\n","slug":"Kafka入门","date":"2022-09-30T09:39:05.000Z","categories_index":"","tags_index":"学习笔记,MQ","author_index":"JuneQQQ"},{"id":"75cf46e9ea7d77c8be442b61749fec6f","title":"JUC并发编程","content":"JUC并发编程进程与线程进程\n程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理IO的\n当一个程序被运行，从磁盘加载这个程序的代码至内存，这是就开启了一个进程。\n进程就可以视为程序的一个实例。大部分程序可以同时运行多个实例进程（例如记事本、画图、浏览器等），也有的程序智能启动一个实例进程（如网易云音乐、360）\n\n线程\n一个进程之内可以分为一到多个线程\n一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给CPU执行。\nJava中，线程作为最小调度单位，进程作为资源分配的最小单位。在windows中进程是不活动的，只是作为线程的容器。\n\n进程 vs 线程\n进程基本上互相独立，而线程存在于进程内，是进程的一个子集\n进程拥有共享的资源，如内存空间等，供其内部的线程共享\n进程间通信较为复杂\n同一台计算机的继进程通信称为IPC（Inter-process communication）\n不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如HTTP\n\n\n线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一共享变量\n线程更轻量，线程上下切换成本一般上要比进程上下文切换低\n\n\n\n并发与并行单核 CPU 下，线程实际上还是 串行执行的，操作系统中有一个组件叫做任务调度器，将 CPU 的时间片（Windows 下时间片最小约为15毫秒）分给不同的线程使用，只是由于CPU在线程时间（时间片很短）的切换非常快，人类感觉是同时运行的，总结一句话就是：微观串行，宏观并行。\n一般会将 线程轮流使用 CPU的做法称为并发（concurrent）\n多核CPU下，每个核都可以调度运行线程，这时候线程是可以并行的\n\n并发（concurrent）是同一时间应对多件事情的能力\n并行（parallel）是同一时间动手做多件事情的能力\n\n应用\n\n\n\n\n\n\n\n\n案例一：异步调用\n从方法调用的角度来讲，如果\n\n需要等带结果返回，才能继续运行就是同步\n不需要等待结果，就能继续运行就是异步\n\n1）设计\n多线程可以让方法执行变为异步的（即不要干等）比如说读取磁盘文件时，假设读取操作花费了五秒钟，如果没有线程调度机制，这五秒调用者什么都干不了，其代码都得暂停\n2）结论\n\n比如在项目中，视频文件需要转换格式等操作比较费时，这是开一个新线程处理视频转换，避免阻塞主线程\n\nTomcat 的异步 servlet 也是类似的，让用户线程处理耗时较长的操作，避免阻塞 Tomcat 的工作线程\n\nUI程序中，开线程进行其他操作，避免阻塞UI线程\n\n单核CPU下，多线程不能实际提升程序运行效率，只是为了能够在不同的任务之间切换，不同线程轮流使用CPU，不至于一个线程总占用CPU，别的线程没法干活\n\n多核CPU可以并行跑多个线程，但能否提高程序运行效率还是要分情况的。\n\n有些任务，经过精心设计，将任务拆分，并行执行，当然可以提高程序的运行效率。但不是所有计算任务都能拆分（阿姆达定律）\n也不是所有的任务都需要拆分，任务的目的如果不同，谈拆分和效率没有意义\n\n\nIO操作不占用CPU，只是我们一般拷贝文件使用的是阻塞IO，这时相当于线程虽然不用CPU，但需要一直等待IO结束，没能充分利用线程。所以才有后面的【非阻塞IO】和【异步IO】优化。\n\n\nJava线程创建和运行线程\n////////////////////////////////////////\npublic static void main(String[] args) &#123;\n  Thread t = new Thread(\"t1\")&#123;\n    @Override\n    public void run()&#123;\n      log.debug(\"t\");\n    &#125;\n  &#125;;\n  //        t.setName(\"t2\");\n  t.start();\n////////////////////////////////////////\nRunnable r = new Runnable() &#123;\n            @Override\n            public void run() &#123;\n                log.debug(\"t1 running\");\n            &#125;\n        &#125;;\n        Thread t = new Thread( r, \"ThreadName\" );\n        t.start();  \n////////////////////////////////////////\n  \nnew Thread(()-> log.debug(\"Thread Running\")).start();\n  \n////////////////////////////////////////\n\n\n\n原理之Thread与Runnable的关系分析Thread源码，结论如下：\n\n传入Runnable参数写法是对Thread的成员变量target赋值，run方法调用 target.run( )\n匿名内部类的写法是直接对run方法重写，执行的Thread.run( )\n\n小结：\n\n用Runnable更容易与线程池等高级API配合\n用Runnable让任务脱离了Thread继承体系，更加灵活。\n\n前瞻：第三种创建线程方式FutureTask&lt;Integer> task = new FutureTask&lt;>(new Callable&lt;Integer>() &#123;\n    @Override\n    public Integer call() throws Exception &#123;\n        log.debug(\"running...\");\n        Thread.sleep(1000);\n        return 100;\n    &#125;\n&#125;);\nThread t = new Thread(task,\"t1\");\nt.start();\n\nlog.debug(task.get().toString()); // 该方法会等待返回值生成\n\n\n\n查看进程线程的方法Windows\n\ntasklist 查看进程 -&gt;  tasklist | findstr java\ntaskkill 杀死进程\njps   查看Java进程\n\nLinux\n\nps -ef 查看所有进程  -&gt;  ps -ef | grep java\nps -fT -p    查看某个进程的所有线程\nkill   杀死进程\ntop  按大写H切换是否显示线程\ntop -H -p  查看某个进程的所有线程\n\nJava\n\njps\t\t\t查看所有Java进程\njstack  查看某个Java进程的所有线程状态\njconsole  来查看某个Java进程中线程的运行情况（图形界面）\n\n原理之线程运行线程上下文切换（Thread Context Switch）因为以下一些原因导致CPU不再执行当前的线程，转而执行另一个线程的代码\n\n线程的CPU时间片用完\n垃圾回收\n有更高优先级的线程需要执行\n线程自己调用了 sleep  yield  wait  join  park  synchronized  lock 等方法\n\n当 Context Switch 发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条JVM指令的执行地址，是线程私有的\n\n状态包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量表、操作数栈、返回地址等\nContext Switch 频繁发生会影响性能\n\n常见方法\n\n\n方法名\nstatic 功能说明\n注意\n\n\n\nstart( )\n启动一个新线程，在新的线程运行方法中的代码\nstart 方法只是让线程进入就绪，里面代码不一定立刻运行（CPU时间片还没分给它）。每个线程对象的 start 方法只能调用一次，如果调用多次会出现 IllegalThreadStateException\n\n\nrun( )\n新线程启动后会调用的方法\n如果在构造 Thread 对象时，传递了 Runnable 参数，则线程启动后会调用 Runnable 中的 run 方法，否则默认不执行任何操作。但可以创建Thread的子类对象，来覆盖默认行为\n\n\njoin( )\n等待线程结束\n\n\n\njoin( long n )\n等待线程运行结束，最多等待 n 毫秒\n\n\n\ngetId( )\n获取线程长整型的 id\nid唯一\n\n\ngetName( )\n获取线程名\n\n\n\nsetName( )\n设置线程名\n\n\n\ngetPriority( )\n修改线程优先级\n\n\n\nsetPriority( int )\n设置线程优先级\njava 中规定线程优先级是 1~10的整数，较大的优先级能提高该线程被CPU调度的几率；越大越优先\n\n\ngetState( )\n获取线程状态\nJava 中线程状态是用6个enum表示，分别为：NEW   RUNNABLE  BLOCKED  WAITING  TIMED_WAITING  TERMINATED\n\n\nisInterrupted( )\n判断是否被打断\n不会清除打断标记\n\n\nisAlive( )\n线程是否存活（还没有运行完毕）\n\n\n\ninterrupt( )\n打断线程（仅标记，不是强制终止）\n如果被打断线程正在sleep  wait join会导致被打断的线程抛出InterruptedException，并清除打断标记；如果打断正在运行的线程，则会设置打断标记；park的线程被打断，也会设置打断标记\n\n\ninterrupted( )\nstatic 判断当前线程是否被打断\n会清除打断标记\n\n\ncurrentThread( )\nstatic 获取当前正在运行的线程\n\n\n\nsleep( long n )\nstatic 让当前执行的线程休眠 n 毫秒，休眠时让出CPU时间片给其他线程\n\n\n\nyield( )\nstatic 提示线程调度器让出线程对CPU的使用\n主要是为了测试和调试\n\n\ninterrupt()中断对LockSupport.park()的影响_anlian523的博客-CSDN博客_locksupport park 中断\n注：\n\nsleep 会补充 park 的 _counter 变量(permit)，使其为1，之后第一次park时不会阻塞！\n\nstart 与 run![截屏2021-10-11上午8.23.00](http://markdown-pic-june.oss-cn-beijing.aliyuncs.com/uPic/截屏2021-10-11 上午8.23.00.png)\nsleep 与 yieldsleep\n调用 sleep 会让当前线程从 Running 进入 Timed Waiting 状态\n其他线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep  方法会抛出 InterruptedException\n睡眠结束后的线程未必会得到执行\n建议用 TimeUnit 的 sleep 代替 Thread 的sleep来回的更好的可读性\n\n\n\nyield\n调用yield会让当前线程从 Running 进入 Runnable 状态，然后调度执行其它同优先级的线程。如果这时没有同优先级的线程，那么不能保证让当前线程暂停的效果\n具体的实现依赖于操作系统的任务调度器\n\n线程优先级\n线程优先级会提示（hint）调度器优先调度该线程，但它仅仅是一个提示，调度器可以忽略它\n如果CPU比较忙，那么优先级高的线程会获得更多的时间片，但CPU闲时，优先级几乎没作用\n\n案例：防止CPU占用100%\nThread.sleep( 1 )\nwait 实现\n\njoin\n\n\n\n\n\n\n\n\n为什么要使用 join？\n\n\n\n\n分析\n\n因为主线程和线程 t1 是并行执行的，t1线程需要1s之后才能得出r&#x3D;10\n而主线程一开始就要打印 r 的结果，所以只能打印出 r &#x3D; 0\n\n解决办法\n\n用 sleep ？\n等待时间难以确定\n\n\n用 join，加在 t1.start( )之后即可\njoin( )：等待线程结束\n\n\n\ninterrupt\n打断正在 sleep wait join 的线程打断标记为 false\n打断正在运行的线程的打断标记为 true\n\n\n\n模式之两阶段终止在一个线程T1中如何“优雅”终止T2？这里的【优雅】指的是T2一个料理后事的机会\n\n\n\n\n\n\n\n\n\n错误思路\n\n使用线程对象的 stop( ) 方法停止线程\nstop方法会真正杀死线程，如果这时线程锁住了共享资源，那么当它被杀死后就再也没有机会释放锁，其他线程将永远无法获取锁\n\n\n使用 **System.exit( int )**方法停止线程\n目的仅是停止一个线程，但这种做法会让整个程序都终止\n\n\n\n\n\n\n\n\n\n\n\n\n两阶段终止模式\n\n\npublic class Test &#123;\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;\n        TwoPhaseTermination t = new TwoPhaseTermination();\n        t.start();\n        Thread.sleep(3500);\n        t.stop();\n    &#125;\n&#125;\n\n\nclass TwoPhaseTermination &#123;\n    private Thread monitor;\n\n    // 启动监控线程\n    public void start() &#123;\n        monitor = new Thread(() -> &#123;\n            while (true) &#123;\n                Thread current = Thread.currentThread();\n//                System.out.println(current.getName());\n                if (current.isInterrupted()) &#123;\n                    System.out.println(\"Main Done\");\n                    break;\n                &#125;\n                try &#123;\n                    Thread.sleep(1000);\n                    System.out.println(\"执行监控记录\");\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                    System.out.println(\"Sleep Interrupt\");\n                    current.interrupt(); // 重新设置打断标记\n                &#125;\n            &#125;\n        &#125;);\n        monitor.start();\n    &#125;\n\n    // 停止监控线程\n    public void stop() &#123;\n        monitor.interrupt();\n    &#125;\n\n&#125;\n\n\n\n打断 park 线程打断 park 线程，不会清空打断状态 ，LockSupport.park( )方法需要打断标记为false才能生效\nprivate static void test3() throws InterruptedException &#123;\n    Thread t1 = new Thread(() -> &#123;\n        log.debug(\"park...\");\n        LockSupport.park();\n        log.debug(\"unpark...\");\n        log.debug(\"打断状态：&#123;&#125;\", Thread.currentThread().isInterrupted());\n    &#125;, \"t1\");\n    t1.start();\n\n    sleep(1);\n    t1.interrupt();\n\n&#125;\n\nprivate static void test4() &#123;\n        Thread t1 = new Thread(() -> &#123;\n            for (int i = 0; i &lt; 5; i++) &#123;\n                log.debug(\"park...\");\n                LockSupport.park();\n                log.debug(\"打断状态：&#123;&#125;\", Thread.interrupted());\n            &#125;\n        &#125;);\n        t1.start();\n        sleep(1);\n  \n        t1.interrupt();\n    &#125;\n\n\n\n\n不推荐使用的方法这些方法已过时，容易破坏同步代码块，造成线程死锁\n\nstop( )：停止线程运行\nsuspend( )：挂起（暂停）线程运行 -&gt; wait( )\nresume( )：恢复线程运行 -&gt; notify( )\n\n守护线程与主线程默认情况下，Java进程需要等待所有线程都运行结束，才会结束。有一种特殊的线程叫做守护线程，只要其它非守护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束。setDameon( )可以设置守护线程。\n\n垃圾回收线程就是一种守护线程\nTomcat 中的 Acceptor 和 Poller 线程都是守护线程，所以Tomcat接收到shutdown命令后，不会等待他们处理完当前请求\n\n线程状态从 操作系统 层面描述：五种状态\n\n\n\n【初始状态】仅是语言层面创建了线程对象，还未与操作系统关联\n【可运行状态】（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由CPU调度执行\n【运行状态】指获取了CPU时间片运行中的状态\n当CPU时间片用完，会从【运行状态】转换至【可运行状态】，会导致线程上下文的切换\n\n\n【阻塞状态】\n如果调用了阻塞API，如BIO读写文件，这时线程实际不会用到CPU，会导致线程上下文切换，进入【阻塞状态】\n等BIO操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】\n与【可运行状态】的区别是，对【阻塞状态】的线程来说只要他们一直不唤醒，调度器就一直不会考虑调度他们\n\n\n【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其他状态\n\n从 Java API 层面描述：六种状态\n\n\n\nNEW 线程刚被创建，但是还没有调用 start( )方法\nRUNNABLE 当调用了 start( ) 方法之后，注意，JavaAPI层面的 RUNNABLE 状态涵盖了 操作系统 层面的【可运行状态】、【运行状态】和【阻塞状态】（由于BIO导致的线程阻塞，在Java里无法区分，仍然认为是可运行的）\n\n小结案例public static void main(String[] args) &#123;\n    Thread t1 = new Thread(() -> &#123;\n        log.debug(\"洗水壶\");\n        sleep(1);\n        log.debug(\"烧开水\");\n        sleep(5);\n    &#125;,\"老王\");\n\n    Thread t2 = new Thread(() -> &#123;\n        log.debug(\"洗茶壶\");\n        sleep(1);\n        log.debug(\"洗茶杯\");\n        sleep(2);\n        log.debug(\"拿茶叶\");\n        sleep(1);\n        try &#123;\n            t1.join();\n        &#125; catch (InterruptedException e) &#123;\n            e.printStackTrace();\n        &#125;\n        log.debug(\"泡茶\");\n    &#125;,\"小王\");\n\n    t1.start();\n    t2.start();\n&#125;\n\n存在的缺陷\n\n上面模拟的是小王等老王的水烧开了，小王泡茶，如果反过来要实现老王等小王的茶叶拿来了，老王泡茶呢？代码最好适应两种情况\n上面两个线程其实是各执行各的，如果要模拟老王把水壶交给小王泡茶，或者模拟小王把茶叶交给老王泡茶呢？\n等待后续学习解答\n\n本章小结本章重点在于掌握\n\n线程创建\n线程重要 API，如start，run，sleep，join，interrupt 等\n线程状态\n应用方面\n异步调用：主线程执行期间，其他线程异步执行耗时操作\n提高效率：并行计算，缩短计算时间\n同步等待：join\n统筹规划：合理使用线程，得到最优效果\n\n\n原理方面\n线程运行流程：栈、栈帧、上下文切换、程序计数器\nThread 两种创建方式的源码\n\n\n模式方面\n两阶段终止\n\n\n\n共享模型之管程\n共享问题\n线程安全分析\nMonitor\nwait&#x2F;notify\n线程状态转换\n活跃性\nLock\n\n共享带来的问题临界区 Critical Section\n一个程序运行多个线程本身是没有问题的\n问题出在多个线程访问共享资源\n多个线程读共享资源其实也没有问题\n在多个线程对共享资源读写操作时发生指令交错，就会出现问题\n\n\n一段代码块如果存在对共享资源的多线程读写操作，这段代码称为临界区\n例如：对静态变量的操作\n\n\n\n竞态条件 Race Condition多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竞态条件。\nsynchronized 解决方案应用之互斥为了避免临界区的竞态条件发生，有多种手段可以达到目的。\n\n阻塞式的解决方法：synchronized 、 Lock\n非阻塞式的解决方案：原子变量\n\n本阶段使用：synchronized 来解决上述问题，俗称【对象锁】，它采用互斥的方式让同一时刻至多有一个线程能持有【对象锁】，其它线程再想获取这个【对象锁】时就会阻塞住。这样就能保证拥有锁的线程可以安全的执行临界区内的代码，不用担心上下文切换。\n注意\n\n互斥是保证临界区的竞态条件发生，同一时刻只能有一个线程执行临界区代码\n同步是由于线程执行的先后、顺序不同、需要一个线程等待其它线程运行到某个点\n\n使用synchronized(对象)&#123;\n  临界区\n&#125;\n\n\n\n思考synchronized 实际是用对象锁保证了临界区代码的原子性，临界区内的代码对外是不可分割的，不会被线程切换所打断。\n\n如果把 synchronized 放到循环外面会怎样？\n循环不可分割，相当于先执行了先拿到锁对象的线程，再执行了后者\n\n\n如果 t1 synchronized(obj1)  而 t2 synchronized(obj2) 会怎样运作？\n相当于没加锁\n\n\n如果 t1 synchronized(obj1) 而 t2 没有加会怎样？如何理解？\n仍然相当于没加锁，因为 t2 并不会因为 t1 的锁而产生阻塞\n\n\n\n方法上的 synchronized\n\n\n\n\n所谓“线程八锁”（习题）其实就是考察 synchronized 锁住的是哪一个对象\n情况1：1-&gt;2  或  2-&gt;1\n\n\n情况2：1s后 1-&gt;2  或   2-&gt; 1s 后 1\n\n\n情况3：3在1之前的位置 + 情况2   \n\n\n情况4：2 -&gt; 1（无互斥）\n\n\n情况5：2-&gt;1（Number.class &#x2F; this 无互斥）\n\n\n情况6：1s 1 -&gt;2  或 2 -&gt; 1s 1\n\n\n情况7：2  -&gt; 1s 1\n\n\n情况8：1s 1 -&gt; 2  或 2 -&gt; 1s 1\n\n\n\n\n变量的线程安全分析成员变量和静态变量是否线程安全？\n如果它们没有共享，则线程安全\n如果它们被共享了，根据它们的状态能否改变，又分为两种情况\n如果只有读操作，则线程安全\n如果有读写操作，则这段代码是临界区，需要考虑线程安全\n\n\n\n局部变量是否线程安全？\n局部变量是线程安全的\n局部变量引用的对象未必安全\n如果该对象没有逃离方法的作用访问，它是线程安全的\n如果该对象逃离方法的作用范围，需要考虑线程安全\n\n\n\n常见的线程安全类\nString\nInteger\nStringBuffer\nRandom\nVector\nHashtable\njava.util.concurrent 下的类\n\n这里说它们是线程安全的是指，多个线程调用它们同一个实例的某个方法时，是线程安全的。也可以理解为：\n\n它们每个方法是原子的\n注意它们多个方法的组合不是原子的，见后面分析\n\n线程安全类方法的组合\n\n不可变类线程安全型String、Integer 等都是不可变类，因为其内部的状态不可变，因此他们的方法都是线程安全的。\n对于 replace、subsring 等方法都是在其中生成了新的对象返回。\n实例分析\n\n\n\n\n\n\n\n\n例1\n\n\n\n\n\n\n\n\n\n\n\n例2\n\n\n\n\n\n\n\n\n\n\n\n例3\n\n\n\n\n\n\n\n\n\n\n\n例4\n\n\n \n\n\n\n\n\n\n\n\n\n\n例5\n\n\n\n\n\n\n\n\n\n\n\n例6\n\n\n\n\n\n\n\n\n\n\n\n例7\n\n\n\n\n\n\n\n\n习题\n\n\n\n\n\n\n\n\n售票窗口\npackage cn.itcast.n4.exercise;\n\nimport lombok.extern.slf4j.Slf4j;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.Vector;\n\n@Slf4j(topic = \"c.ExerciseSell\")\npublic class ExerciseSell &#123;\n    public static void main(String[] args) throws InterruptedException &#123;\n        // 模拟多人买票\n        TicketWindow window = new TicketWindow(1000);\n\n        // 所有线程的集合\n        List&lt;Thread> threadList = new ArrayList&lt;>();\n        // 卖出的票数统计\n        List&lt;Integer> amountList = new Vector&lt;>();\n        for (int i = 0; i &lt; 2000; i++) &#123;\n            Thread thread = new Thread(() -> &#123;\n                // 买票\n                int amount = window.sell(random(5));\n                // 统计买票数\n                amountList.add(amount);\n            &#125;);\n            threadList.add(thread);\n            thread.start();\n        &#125;\n\n        for (Thread thread : threadList) &#123;\n            thread.join();\n        &#125;\n\n        // 统计卖出的票数和剩余票数\n        log.debug(\"余票：&#123;&#125;\",window.getCount());\n        log.debug(\"卖出的票数：&#123;&#125;\", amountList.stream().mapToInt(i-> i).sum());\n    &#125;\n\n    // Random 为线程安全\n    static Random random = new Random();\n\n    // 随机 1~5\n    public static int random(int amount) &#123;\n        return random.nextInt(amount) + 1;\n    &#125;\n&#125;\n\n// 售票窗口\nclass TicketWindow &#123;\n    private int count;\n\n    public TicketWindow(int count) &#123;\n        this.count = count;\n    &#125;\n\n    // 获取余票数量\n    public int getCount() &#123;\n        return count;\n    &#125;\n\n    // 售票，注意这里的 synchronized\n    public synchronized int sell(int amount) &#123;\n        if (this.count >= amount) &#123;\n            this.count -= amount;\n            return amount;\n        &#125; else &#123;\n            return 0;\n        &#125;\n    &#125;\n&#125;\n\npackage cn.itcast.n4.exercise;\n\nimport lombok.extern.slf4j.Slf4j;\nimport java.util.Random;\n\n@Slf4j(topic = \"c.ExerciseTransfer\")\npublic class ExerciseTransfer &#123;\n    public static void main(String[] args) throws InterruptedException &#123;\n        Account a = new Account(1000);\n        Account b = new Account(1000);\n        Thread t1 = new Thread(() -> &#123;\n            for (int i = 0; i &lt; 1000; i++) &#123;\n                a.transfer(b, randomAmount());\n            &#125;\n        &#125;, \"t1\");\n        Thread t2 = new Thread(() -> &#123;\n            for (int i = 0; i &lt; 1000; i++) &#123;\n                b.transfer(a, randomAmount());\n            &#125;\n        &#125;, \"t2\");\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n        // 查看转账2000次后的总金额\n        log.debug(\"total:&#123;&#125;\", (a.getMoney() + b.getMoney()));\n    &#125;\n\n    // Random 为线程安全\n    static Random random = new Random();\n\n    // 随机 1~100\n    public static int randomAmount() &#123;\n        return random.nextInt(100) + 1;\n    &#125;\n&#125;\n\n// 账户\nclass Account &#123;\n    private int money;\n\n    public Account(int money) &#123;\n        this.money = money;\n    &#125;\n\n    public int getMoney() &#123;\n        return money;\n    &#125;\n\n    public void setMoney(int money) &#123;\n        this.money = money;\n    &#125;\n\n    // 转账,注意这里的 synchronized\n    public void transfer(Account target, int amount) &#123;\n        synchronized(Account.class) &#123;\n            if (this.money >= amount) &#123;\n                this.setMoney(this.getMoney() - amount);\n                target.setMoney(target.getMoney() + amount);\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\nMonitor 概念Java 对象头\n\n\n\nMonitor（重量级锁）Monitor被翻译为监视器或管程，由操作系统提供。\n每个Java对象都可以关联一个Monitor对象，如果使用 synchronized 给对向上锁（重量级）之后，该对象头的Mark Word中就被设置指向Monitor对象的指针\nMonitor结构如下\n\n\n\n刚开始 Monitor 中 Owner 为 null\n当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2，Monitor 中只能有一个 Owner\n在 Thread-2 上锁的过程中，如果 Thread-3，Thread-4，Thread-5 也来执行 synchronized(obj) ，就会进入 EntryList 从而变为BLOCKED状态\nThread-2 执行完同步代码块中的内容，然后唤醒 EntryList 中等带的线程来竞争锁。\n图中的 WaitSet 中的 Thread-0，Thread-1 是之前获得过锁，但不满足进入 WAITING 状态的线程，后面将 wait-notify 时会分析\n\n注意：\n\nsynchronized 必须是进入同一个对象的Monitor才有上述效果\n不加 synchronized 的对象不会关联监视器，不遵从以上规则\n\nsynchronized 字节码\n\n后面是异常解锁相关字节码\nsynchronized 原理 ※轻量级锁轻量级锁的使用场景：如果一个对象有多个线程访问，但线程访问的时间是错开的（也就是没有竞争），那么可以使用轻量级锁来优化。\n轻量级锁对使用者是透明的，语法仍然是 synchronized\n假设有两个同步块，利用一个对象加锁\n\n\n\n创建锁记录（Lock Record）对象，每个线程的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的 Mark Word\n\n\n\n\n让锁记录中 Object reference 指向锁对象，并尝试用 cas 替换 Object 的Mark Word，将 Mark Wrod 的值存入锁记录\n\n\n\n\n如果 cas 替换成功，对象头中存储了 锁记录地址和状态 00，表示由该线程给对象加上轻量级锁\n\n\n\n\n如果 cas 替换失败，有两种情况\n如果是其他线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程\n如果是自己执行了 synchronized 锁重入，那么再添一条 Lock Record 作为重入的计数\n\n\n\n\n\n\n当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重入计数减一\n\n\n\n\n当退出 synchronized 代码块时（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象头\n成功，则解锁成功\n失败，说明轻量级锁进行了锁膨胀已经升级为重量级锁，进入重量级锁解锁流程\n\n\n\n锁膨胀如果在尝试加轻量级锁的过程中，CAS操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有竞争力），这时需要进行锁膨胀，将轻量级锁变为重量级锁。\n\n当 Thread-1 进行轻量级加锁时，Thread-0已经对该对象加了轻量级锁\n\n\n\n\n这时 Thread-1 加轻量级锁失败，进入锁膨胀流程\n即为 Object 对象申请Monitor锁，让Object指向重量级锁地址\n然后自己进入Monitor的EntryList BLOCKED\n\n\n\n\n\n\n当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中BLOCKED线程\n\n自旋优化重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞。\n自旋重试成功的情况\n\n\n\n线程1（CPU1 上）\n对象Mark\n线程2（CPU2 上）\n\n\n\n-\n10（重量锁）\n-\n\n\n访问同步块，获取 monitor\n10（重量锁）重量锁指针\n-\n\n\n成功（加锁）\n10（重量锁）重量锁指针\n-\n\n\n执行同步代码块\n10（重量锁）重量锁指针\n-\n\n\n执行同步代码块\n10（重量锁）重量锁指针\n访问同步块，获取 monitor\n\n\n执行同步代码块\n10（重量锁）重量锁指针\n自旋重试\n\n\n执行完毕\n10（重量锁）重量锁指针\n自旋重试\n\n\n成功（解锁）\n01（无锁）\n自旋重试\n\n\n-\n10（重量锁）重量锁指针\n成功（加锁）\n\n\n-\n10（重量锁）重量锁指针\n执行同步块\n\n\n-\n…\n…\n\n\n自旋重试失败的情况\n\n\n\n线程1（CPU1 上）\n对象Mark\n线程2（CPU2 上）\n\n\n\n-\n10（重量锁）\n-\n\n\n访问同步块，获取 monitor\n10（重量锁）重量锁指针\n-\n\n\n成功（加锁）\n10（重量锁）重量锁指针\n-\n\n\n执行同步代码块\n10（重量锁）重量锁指针\n-\n\n\n执行同步块\n10（重量锁）重量锁指针\n访问同步块，获取 monitor\n\n\n执行同步块\n10（重量锁）重量锁指针\n自旋重试\n\n\n执行同步块\n10（重量锁）重量锁指针\n自旋重试\n\n\n执行同步块\n10（重量锁）重量锁指针\n自旋重试\n\n\n执行同步块\n10（重量锁）重量锁指针\n阻塞\n\n\n-\n…\n…\n\n\n\n在Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。\n自旋会占用CPU时间，单核CPU自旋就是浪费，多核CPU自旋才能发挥优势。\nJava7之后不能控制是否开启自旋功能\n\n偏向锁轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行CAS操作。\nJava6中引入了偏向锁来做进一步优化：只有第一次使用CAS将线程ID设置到对象的Mark Word头，之后发现这个线程ID是自己的就表示没有竞争，不用重新CAS。以后只要不发生竞争，这个对象就归该线程所有。\n偏向锁是对轻量级锁的一种优化。\n\n\n偏向状态看一下之前的对象头格式\n\n\n一个对象创建时：\n\n如果开启了偏向锁（默认开启），那么对象创建后，markword值为 0x05 即最后3位为 101，这时它的 thread、epoch、age都为0\n偏向锁是默认延迟的，不会在程序启动时立即生效，如果想避免延迟，可以添加VM参数：-XX:BiasedLockingStartupDelay=0 来禁用延迟\n如果没有开启偏向锁，那么对象创建后，markword 值为0x01即最后3位为001（Normal），这时它的hashcode、age都为0，第一次用到hashcode时才会赋值\n禁用偏向锁：-XX:-UseBiasedLocking，另外三种情况也会禁用偏向锁：\n调用 hashCode( )方法会撤销偏向锁，因为位置不够存放 hashcode。轻量级锁 hashcode 会存放在线程栈帧锁记录里，重量级锁会放在 monitor 对象中\n当有其它线程使用偏向锁对象时，会将偏向锁升级为轻量级锁\n调用 wait &#x2F; notify（重量级锁专属方法）\n\n\n\n批量重偏向如果对象被多个线程访问，但没有竞争（使用时间不同），这时偏向了线程T1的对象仍有机会重新偏向T2，重偏向会重置对象的Thread ID，这里针对的是一个类的对象\n当撤销偏向锁阈值超过20次后，JVM会这样觉得，我是不是偏向错了呢？于是会在给这些对象加锁时重新偏向至加锁线程\n撤销一个线程的偏向锁20次，会重偏向新线程。 \n批量撤销当撤销偏向锁阈值超过40次后，JVM会这样觉得，自己却是偏向错了，根本就不该偏向。于是整个类的所有对象都会变为不可偏向（001-Normal）的，新建的对象也是不可偏向的。  \nhttps://www.bilibili.com/video/BV16J411h7Rd?p=86&amp;spm_id_from=pageDriver\n锁消除\n\n\n\n\n\nwait  notify原理之 wait&#x2F;notify\n\n\nOwner 线程发现条件不满足，调用 wait 方法，即可进入 WaitSet变为WAITING状态\nBLOCKED和WAITING的线程都处于【阻塞状态】，不占用CPU时间片\nBLOCKED线程会在Owner线程释放锁时唤醒\nWAITING线程会在Owner线程调用 notify 或 notifyAll 时唤醒，但唤醒后并不意味着立刻获得锁，仍需进入EntryList重新竞争\n\nAPI 介绍\nobj.wait( )：让进入 object 监视器的线程到 WaitSet 等待\nobj.notify( ) ：在 object 上正在 WaitSet 等待的线程中挑一个唤醒\nobj.notifyAll( ) ：让 object 上正在 WaitSet 等待的线程全部唤醒\n\n它们都是线程间协作的手段，都属于 Object 对象的方法。必须获得此对象的锁，才能调用这些方法\n正确使用姿势sleep( long n )和 wait( long n )的区别\n\nsleep 是Thread方法，而 wait 是 Object 的方法\nsleep 不需要强制和 synchronized 配合使用，但 wait 需要和 synchronized 一起使用\nsleep 在睡眠同时，不会释放锁对象，但 wait 会释放\n\nsynchronized(lock)&#123;\n  while(条件不成立)&#123;\n    lock.wait();\n  &#125;\n  // TODO\n&#125;\n// 另一个线程\nsynchronized(lock)&#123;\n  lock.notifyAll();\n&#125;\n\n\n\n同步模式之保护性暂停（Guarded Suspension）用一个线程等待另一个线程的执行结果\n\n有一个结果需要从一个线程传递到另一个线程，让他们关联同一个GuardedObject\n如果有结果不断从一个线程到另一个线程，那么可以使用消息队列（见生产者&#x2F;消费者）\nJDK中，join的实现、Future的实现，都是基于此模式\n因为要等待另一方的结果，因此归类到同步模式\n\n\n\n\npublic class Test &#123;\n    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;\n        GuardedObject g = new GuardedObject();\n        new Thread(()->&#123;\n            g.complete(null);\n        &#125;,\"t0\").start();\n\n        new Thread(()->&#123;\n            System.out.println(\"wait result\");\n            List&lt;String > result =(List&lt;String>)g.get(1000);\n            System.out.println(result);\n        &#125;,\"t1\").start();\n        new Thread(()->&#123;\n            System.out.println(\"begin\");\n            List&lt;String> download = null;\n            try &#123;\n                download = Downloader.download();\n                g.complete(download);\n            &#125; catch (IOException e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;,\"t2\").start();\n\n    &#125;\n  class GuardedObject&#123;\n    private Object response;\n\n    // 设置超时时间\n    public Object get(long timeout)&#123;\n      synchronized (this) &#123;\n        // 记录时间\n        long begin = System.currentTimeMillis();\n        long passedTime = 0 ;\n        // while 防止虚假唤醒步骤之一（同时代码块内也要做相关处理）\n        while (this.response==null)&#123;\n          long waitTime = timeout - passedTime;\n          if(waitTime &lt;= 0)&#123;\n            break;\n          &#125;\n          try &#123;\n            // 防止虚假唤醒步骤之二：每次醒来等待的最大时间都不同\n            this.wait(waitTime);\n          &#125; catch (InterruptedException e) &#123;\n            e.printStackTrace();\n          &#125;\n          passedTime = System.currentTimeMillis() - begin;\n        &#125;\n        return response;\n      &#125;\n    &#125;\n    public void complete(Object o)&#123;\n      synchronized (this)&#123;\n        this.response = o;\n        this.notifyAll();\n      &#125;\n    &#125;\n  &#125;\n&#125;\n\n\n\n\n\nimport lombok.extern.slf4j.Slf4j;\nimport java.util.*;\nimport java.util.concurrent.ExecutionException;\n\npublic class Test &#123;\n    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;\n        for (int i = 0; i &lt; 3; i++) &#123;\n            new People().start();\n        &#125;\n        Sleeper.sleep(1);\n\n        for (Integer id : Mailboxes.getIds()) &#123;\n            new Postman(id,\"内容\" + id).start();\n        &#125;\n    &#125;\n&#125;\n\n@Slf4j(topic = \"c.People\")\nclass People extends Thread &#123;\n    @Override\n    public void run() &#123;\n        // 收信\n        GuardedObject guardedObject = Mailboxes.createGuardedObject();\n        log.debug(\"开始收信id：&#123;&#125;\", guardedObject.getId());\n        Object mail = guardedObject.get(5000);\n        log.debug(\"收到信id：&#123;&#125;，内容:&#123;&#125;\", guardedObject.getId(), mail);\n    &#125;\n&#125;\n\n@Slf4j(topic = \"c.Postman\")\nclass Postman extends Thread &#123;\n    private int id;\n    private String mail;\n\n    public Postman(int id, String mail) &#123;\n        this.id = id;\n        this.mail = mail;\n    &#125;\n\n    @Override\n    public void run() &#123;\n        // 发信\n        GuardedObject guardObject = Mailboxes.getGuardObject(id);\n        log.debug(\"送信 id:&#123;&#125;, 内容:&#123;&#125;\", id, mail);\n        guardObject.complete(mail);\n\n    &#125;\n&#125;\n\nclass Mailboxes &#123;\n    private static Map&lt;Integer, GuardedObject> boxes = new Hashtable&lt;>();\n    private static int id = 1;\n\n    public static GuardedObject getGuardObject(int id) &#123;\n        // TODO 这里有问题\n        return boxes.remove(id);\n    &#125;\n  \n    // 产生 GuardedObject 的唯一 id\n    private static synchronized int generateId() &#123;\n        return id++;\n    &#125;\n\n    public static GuardedObject createGuardedObject() &#123;\n        GuardedObject g = new GuardedObject(generateId());\n        // map 线程安全，不需要 synchronized\n        boxes.put(g.getId(), g);\n        return g;\n    &#125;\n\n    public static Set&lt;Integer> getIds() &#123;\n        // map 线程安全，不需要 synchronized\n        return boxes.keySet();\n    &#125;\n&#125;\n\nclass GuardedObject &#123;\n    // 标识 Guarded Object\n    private int id;\n\n    public int getId() &#123;\n        return id;\n    &#125;\n\n    public GuardedObject(int id) &#123;\n        this.id = id;\n    &#125;\n\n    private Object response;\n\n    // 设置超时时间\n    public Object get(long timeout) &#123;\n        synchronized (this) &#123;\n            // 记录时间\n            long begin = System.currentTimeMillis();\n            long passedTime = 0;\n            // while 防止虚假唤醒步骤之一（同时代码块内也要做相关处理）\n            while (this.response == null) &#123;\n                long waitTime = timeout - passedTime;\n                if (waitTime &lt;= 0) &#123;\n                    break;\n                &#125;\n                try &#123;\n                    // 防止虚假唤醒步骤之二：每次醒来等待的时间都不同\n                    this.wait(waitTime);\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n                passedTime = System.currentTimeMillis() - begin;\n            &#125;\n            return response;\n        &#125;\n    &#125;\n\n    public void complete(Object o) &#123;\n        synchronized (this) &#123;\n            this.response = o;\n            this.notifyAll();\n        &#125;\n    &#125;\n&#125;\n\n\n\n异步模式之生产者 &#x2F; 消费者\n与前面的保护性暂停中的 GuardObject 不同，不需要产生结果和消费结果的线程一一对应\n消费队列可以用来平衡生产和消费的线程资源\n生产者仅负责产生结果数据，不关心数据该如何处理，而消费者专心处理结果\n消息队列是由容量限制的，满时不会再加入数据，空时不会再消耗数据\nJDK 中各种阻塞队列，采用的就是这种模式\n\n\n\n@Slf4j(topic = \"c.Test1\")\npublic class Test1 &#123;\n    public static void main(String[] args) &#123;\n        MessageQueue queue = new MessageQueue(2);\n        for (int i = 0; i &lt; 3; i++) &#123;\n            int finalI = i;\n            new Thread(() -> &#123;\n                queue.put(new Message(finalI, \"值\" + finalI));\n            &#125;, \"生产者\" + i).start();\n        &#125;\n\n        new Thread(() -> &#123;\n            while (true)&#123;\n                Sleeper.sleep(1);\n                queue.take();\n            &#125;\n        &#125;, \"消费者\").start();\n\n    &#125;\n&#125;\n\n// 消息队列类，java 线程之间通信\n@Slf4j(topic = \"c.M\")\nclass MessageQueue &#123;\n    // 队列集合、容量\n    private LinkedList&lt;Message> list = new LinkedList&lt;>();\n    private int capacity;\n\n    public MessageQueue(int capacity) &#123;\n        this.capacity = capacity;\n    &#125;\n\n    // 取消息\n    public Message take() &#123;\n        // 检查队列是否为空\n        synchronized (list) &#123;\n            while (list.isEmpty()) &#123;\n                log.debug(\"队列空，消费线程等待\");\n                try &#123;\n                    list.wait();\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n            // 头部返回，尾部进入\n            Message message = list.removeFirst();\n            log.debug(\"已消费消息\");\n            list.notifyAll();\n            return message;\n        &#125;\n    &#125;\n\n    // 存消息\n    public void put(Message message) &#123;\n        synchronized (list) &#123;\n            while (list.size() == capacity) &#123;\n                log.debug(\"队列满，生产者程等待\");\n                try &#123;\n                    list.wait();\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n            list.addLast(message);\n            log.debug(\"已生产新的消息\");\n            list.notifyAll();\n        &#125;\n    &#125;\n&#125;\n\nfinal class Message &#123;\n    private int id;\n    private Object value;\n\n    public int getId() &#123;\n        return id;\n    &#125;\n\n    public Object getValue() &#123;\n        return value;\n    &#125;\n\n    public Message(int id, Object value) &#123;\n        this.id = id;\n        this.value = value;\n    &#125;\n&#125;\n\n\n\npark &amp; unpark基本使用\nLockSupport.park();  // 暂停当前线程\nLockSupport.unpark( [Thread t] );   // 恢复某个线程的运行\n\n\nwait notify notifyAll 必须配合 Object Monitor 一起使用，而 unpark 不必\npark &amp; unpark 是以线程为单位来【阻塞】和【唤醒】线程，而 notify 只能随机唤醒一个等待线程， notifyAll 是唤醒所有等待线程，就不那么【精确】\npark &amp; unpark 可以先 unpark ，而 wait &amp; notify 不能先 notify\n\n原理\n每一个线程都有自己的一个 Parker 对象，由三部分组成 _counter  _cond _mutex ，打个比喻\n\n线程就像一个旅人，Parker 就像他随身携带的背包，条件变量就好比背包中的帐篷，_counter 就好比背包中的备用干粮（0为耗尽，1为充足）\n调用 park 就是要看需不需要停下来歇息\n如果备用干粮耗尽，那么钻进帐篷休息\n如果备用干粮充足，那么不需要停留，继续前进\n\n\n调用 unpark，就好比补充干粮\n如果这时线程还在帐篷，就唤醒让他继续前进\n如果这时线程还在继续运行，那么下次他调用 park 时，仅是消耗掉备用干粮，不需要停留继续前进\n因为背包空间有限，多次调用 unpark 只会补充一份备用干粮\n\n\n\n\n\n\n\n\n当前线程调用 Unsafe.park( ) 方法\n检查 _counter，本情况为0，这时获得 _mutex 互斥锁\n线程进入 _cond 条件变量阻塞\n设置 _counter &#x3D; 0\n\n\n\n\n调用 Unsafe.unpark(Thread_0)方法，设置 _counter 为1\n唤醒 _cond 条件变量中的 Thread_0\nThread_0 恢复运行\n设置 _counter 为0\n\n重新理解线程状态转换\n\n \n\n假设有线程 Thread t\n情况1 New –&gt; RUNNABLE\n\n当调用 t.start( )方法时，由 NEW –&gt; RUNNBALE\n\n情况2 RUNNABLE &lt;–&gt; WAITING\nt 线程用 synchronized(obj) 获得了锁对象后\n\n调用 obj.wait( ) 方法时，t线程从 RUNNABLE –&gt; WAITING\n调用 obj.notify( ) ，obj.notifyAll( )，t.interrupt( )时\n竞争锁成功，t 线程从 WAITING –&gt; RUNNABLE\n竞争锁失败，t 线程从 WITING –&gt; BLOCKED\n竞争锁：notifyAll导致\n\n\n\n\n\n情况3 RUNNABLE &lt;–&gt; WAITING\n\n当前线程调用 t.join( ) 方法时，当前线程从RUNNABLE –&gt; WAITING\n注意事项当前线程在 t 线程对象的监视器上等待\n\n\nt 线程运行结束，或调用了当前线程的 Interrupt( ) 时，当前线程从 WAITING –&gt; RUNNABLE\n\n情况4 RUNNABLE &lt;–&gt; WAITING\n\n当前线程调用 LockSupport.park( ) 方法会让当前线程从 RUNNABLE –&gt; WAITING\n调用 LockSupport.unpark( 目标线程 )或调用了目标线程的 interrupt( )，会让目标线程从 WAITING –&gt; RUNNABLE\n\n情况5 RUNNABLE &lt;–&gt; TIMED_WAITING\nt 线程用 synchronized( obj ) 获取了锁对象后\n\n调用 obj.wait(long n) 方法时，t 线程从RUNNABLE –&gt; TIMED_WAITING\nt 线程等待时间超过了n毫秒，或调用obj.notify( ), obj.notifyAll( ), t.interrupt( )时\n竞争锁成功，t 线程从 TIMED_WAITING –&gt; RUNNABLE\n竞争锁失败，t 线程从 TIMED_WAITING –&gt; BLOCKED\n\n\n\n情况6 RUNNABLE &lt;–&gt; TIMED_WAITING\n\n当前线程调用 t.join(long n) 方法时，当前线程从 RUNNABLE –&gt; TIMED_WAITING\n注意是 当前线程 在 t 线程对象的监视器上等待\n\n\n当前线程等待时间超过了 n 毫秒，或 t 线程运行结束，或调用了当前线程的 interrupt( ) 时，当前线程从 TIMED_WAITING –&gt; RUNNABLE\n\n情况7 RUNNABLE &lt;–&gt; TIMED_WAITING\n\n当前线程调用 Thread.sleep(long n)，当前线程从 RUNNABLE –&gt; TIMED_WAITING\n当前线程等待时间超过了 n 毫秒，当前线程从TIMED_WAITING –&gt; RUNNABLE\n\n情况8 RUNNABLE &lt;–&gt; TIMED_WAITING\n\n当前线程调用 LockSupport.parkNanos(long nanos)或LockSupport.parkUntil(long millis)时，当前线程从 RUNNABLE –&gt; TIMED_WAITING\n调用 LockSupport.unpark( 目标线程 )或调用了线程的 interrupt( )，或是等待超时，会让目标线程从TIMED_WAITING –&gt; RUNNABLE\n\n情况9 RUNNABLE &lt;–&gt; BLOCKED\n\nt 线程用 synchronized(obj) 获取了对象锁时如果竞争失败，从RUNNABLE –&gt; BLOCKED\n持有 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有BLOCKED的线程重新竞争，如果其中 t 线程竞争成功，从BLOCKED –&gt; RUNNABLE，其它失败的线程仍然BLOCKED\n\n情况10 RUNNABLE –&gt; TERMINATED\n当前线程所有代码运行完毕，进入 TERMINATED\n多把锁\n\n将锁的粒度细分\n\n好处：可以增强并发度\n坏处：如果一个线程同时获得多把锁，就容易发生死锁\n\n活跃性死锁t1线程获得A对象锁，接下来想获得B对象的锁t2线程获得B对象锁，接下来想获得A对象的锁\n定位死锁\njconsole &#x2F; jps -&gt; jstack\n\npublic class TestDeadLock &#123;\n    public static void main(String[] args) &#123;\n        Chopstick c1 = new Chopstick(\"1\");\n        Chopstick c2 = new Chopstick(\"2\");\n        Chopstick c3 = new Chopstick(\"3\");\n        Chopstick c4 = new Chopstick(\"4\");\n        Chopstick c5 = new Chopstick(\"5\");\n        new Philosopher(\"苏格拉底\", c1, c2).start();\n        new Philosopher(\"柏拉图\", c2, c3).start();\n        new Philosopher(\"亚里士多德\", c3, c4).start();\n        new Philosopher(\"赫拉克利特\", c4, c5).start();\n        new Philosopher(\"阿基米德\", c1, c5).start();\n    &#125;\n&#125;\n\n@Slf4j(topic = \"c.Philosopher\")\nclass Philosopher extends Thread &#123;\n    Chopstick left;\n    Chopstick right;\n\n    public Philosopher(String name, Chopstick left, Chopstick right) &#123;\n        super(name);\n        this.left = left;\n        this.right = right;\n    &#125;\n\n    @Override\n    public void run() &#123;\n        while (true) &#123;\n            //　尝试获得左手筷子\n            synchronized (left) &#123;\n                // 尝试获得右手筷子\n                synchronized (right) &#123;\n                    eat();\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n\n    Random random = new Random();\n    private void eat() &#123;\n        log.debug(\"eating...\");\n        Sleeper.sleep(0.5);\n    &#125;\n&#125;\n\nclass Chopstick&#123;\n    String name;\n\n    public Chopstick(String name) &#123;\n        this.name = name;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return \"筷子&#123;\" + name + '&#125;';\n    &#125;\n&#125;\n\n\n\n活锁活锁出现在两个线程相互改变对方的结束条件，最后谁也无法结束，\n\n\n饥饿由于优先级太低，始终得不到CPU调度执行，也不能够结束\nReentrantLock相对于 synchronized 它具备如下特点\n\n可中断\n可以设置超时时间\n可以设置为公平锁\n支持多个条件变量\n\n与 synchronized 一样，都支持可重入\n基本语法\n// 获取锁\nreentrantLock.lock();\ntry&#123;\n  // 临界区\n&#125;finally&#123;\n  // 释放锁\n  reentrantLock.unlock();\n&#125;\n\n\n\n可重入同一个线程如果首次获得了这把锁，那么因为它是这把锁的持有者，因此有权利再次获取这把锁。如果是不可重入锁，那么第二次获得锁时，自己也会被锁挡住\npublic static void main(String[] args) &#123;\n    m1();\n&#125;\npublic static void m1() &#123;\n    lock.lock();\n    try &#123;\n        System.out.println(\"in m1\");\n        m2();\n    &#125; finally &#123;\n        lock.unlock();\n    &#125;\n&#125;\npublic static void m2() &#123;\n    lock.lock();\n    try &#123;\n        System.out.println(\"in m2\");\n    &#125; finally &#123;\n        lock.unlock();\n    &#125;\n&#125;\n\n可打断@Slf4j(topic = \"c.001\")\npublic class Test001 &#123;\n    private static ReentrantLock lock = new ReentrantLock();\n\n    public static void main(String[] args) &#123;\n        Thread t1 = new Thread(() -> &#123;\n            try &#123;\n                log.debug(\"尝试获取锁\");\n                lock.lockInterruptibly();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n                log.debug(\"没有获得锁，返回\");\n                return;\n            &#125;\n            try &#123;\n                log.debug(\"获取到锁\");\n            &#125; finally &#123;\n                lock.unlock();\n            &#125;\n        &#125;,\"t1\");\n\n        lock.lock();\n        t1.start();\n\n        Sleeper.sleep(1);\n        log.debug(\"打断 t1\");\n        t1.interrupt();\n    &#125;\n&#125;\n\n锁超时立刻失败\npublic static void main(String[] args) &#123;\n    Thread t1 = new Thread(() -> &#123;\n        log.debug(\"尝试获得锁\");\n        try &#123;\n            if (! lock.tryLock(2, TimeUnit.SECONDS)) &#123;\n                log.debug(\"获取不到锁\");\n                return;\n            &#125;\n        &#125; catch (InterruptedException e) &#123;\n            e.printStackTrace();\n            log.debug(\"获取不到锁\");\n            return;\n        &#125;\n        try &#123;\n            log.debug(\"获得到锁\");\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;, \"t1\");\n\n    lock.lock();\n    log.debug(\"获得到锁\");\n    t1.start();\n    sleep(1);\n    log.debug(\"释放了锁\");\n    lock.unlock();\n&#125;\n\n\n\n* 哲学家问题的改进public class TestDeadLock &#123;\n    public static void main(String[] args) &#123;\n        Chopstick c1 = new Chopstick(\"1\");\n        Chopstick c2 = new Chopstick(\"2\");\n        Chopstick c3 = new Chopstick(\"3\");\n        Chopstick c4 = new Chopstick(\"4\");\n        Chopstick c5 = new Chopstick(\"5\");\n        new Philosopher(\"苏格拉底\", c1, c2).start();\n        new Philosopher(\"柏拉图\", c2, c3).start();\n        new Philosopher(\"亚里士多德\", c3, c4).start();\n        new Philosopher(\"赫拉克利特\", c4, c5).start();\n        new Philosopher(\"阿基米德\", c5,c1).start();\n    &#125;\n&#125;\n\n@Slf4j(topic = \"c.Philosopher\")\nclass Philosopher extends Thread &#123;\n    Chopstick left;\n    Chopstick right;\n\n    public Philosopher(String name, Chopstick left, Chopstick right) &#123;\n        super(name);\n        this.left = left;\n        this.right = right;\n    &#125;\n\n    @Override\n    public void run() &#123;\n        while (true) &#123;\n            if(left.tryLock())&#123;\n                try&#123;\n                    if(right.tryLock())&#123;\n                        try&#123;\n                            eat();\n                        &#125;finally &#123;\n                            right.unlock();\n                        &#125;\n                    &#125;\n                &#125;finally &#123;\n                   left.unlock();\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n\n    Random random = new Random();\n    private void eat() &#123;\n        log.debug(\"eating...\");\n        Sleeper.sleep(0.5);\n    &#125;\n&#125;\n\nclass Chopstick extends ReentrantLock &#123;\n    String name;\n\n    public Chopstick(String name) &#123;\n        this.name = name;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return \"筷子&#123;\" + name + '&#125;';\n    &#125;\n&#125;\n\n\n\n公平锁ReentrantLock 默认是不公平的，但是公平锁一般没有必要，会降低并发度\n条件变量synchronized 中也有条件变量，就是我们所讲的那个 WaitSet 休息室，当条件不满足时进入 WaitSet 等待；Reentrantock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比\n\nsynchronized 是那些不满足条件的线程都在一间休息室等待消息\nReentrantLock 支持多件休息室，有专门等烟的休息室、专门早餐的休息室、唤醒时也是按照休息室来唤醒\n\n使用流程 await( ) \n\n前需要获得锁\n执行后，会释放锁\n执行方法的线程被唤醒（或打断、超时）取重新竞争 lock 锁\n竞争 lock 锁成功后，从 await 后继续执行\n\n@Slf4j(topic = \"c.Test24\")\npublic class Test24 &#123;\n    static final Object room = new Object();\n    static boolean hasCigarette = false;\n    static boolean hasTakeout = false;\n    static ReentrantLock ROOM = new ReentrantLock();\n    // 等待烟的休息室\n    static Condition waitCigaretteSet = ROOM.newCondition();\n    // 等外卖的休息室\n    static Condition waitTakeoutSet = ROOM.newCondition();\n\n    public static void main(String[] args) &#123;\n\n        new Thread(() -> &#123;\n            ROOM.lock();\n            try &#123;\n                log.debug(\"有烟没？[&#123;&#125;]\", hasCigarette);\n                while (!hasCigarette) &#123;\n                    log.debug(\"没烟，先歇会！\");\n                    try &#123;\n                        waitCigaretteSet.await();\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                &#125;\n                log.debug(\"可以开始干活了\");\n            &#125; finally &#123;\n                ROOM.unlock();\n            &#125;\n        &#125;, \"小南\").start();\n\n        new Thread(() -> &#123;\n            ROOM.lock();\n            try &#123;\n                log.debug(\"外卖送到没？[&#123;&#125;]\", hasTakeout);\n                while (!hasTakeout) &#123;\n                    log.debug(\"没外卖，先歇会！\");\n                    try &#123;\n                        waitTakeoutSet.await();\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                &#125;\n                log.debug(\"可以开始干活了\");\n            &#125; finally &#123;\n                ROOM.unlock();\n            &#125;\n        &#125;, \"小女\").start();\n\n        sleep(1);\n        new Thread(() -> &#123;\n            ROOM.lock();\n            try &#123;\n                hasTakeout = true;\n                waitTakeoutSet.signal();\n            &#125; finally &#123;\n                ROOM.unlock();\n            &#125;\n        &#125;, \"送外卖的\").start();\n\n        sleep(1);\n        new Thread(() -> &#123;\n            ROOM.lock();\n            try &#123;\n                hasCigarette = true;\n                waitCigaretteSet.signal();\n            &#125; finally &#123;\n                ROOM.unlock();\n            &#125;\n        &#125;, \"送烟的\").start();\n    &#125;\n&#125;\n\n\n\n同步模式之顺序控制\n\n\n\n\n\n\n\n\n顺序运行\n// 方式之一：wait/notify\n@Slf4j(topic = \"c.002\")\npublic class Test002 &#123;\n    static final Object lock = new Object();\n    static boolean t2runned = false;\n\n    public static void main(String[] args) &#123;\n        Thread t1 = new Thread(()->&#123;\n            synchronized (lock)&#123;\n                while (!t2runned)&#123;\n                    try &#123;\n                        lock.wait();\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                    log.debug(\"t1 running\");\n                &#125;\n            &#125;\n        &#125;,\"t1\");\n        Thread t2 = new Thread(()->&#123;\n            synchronized (lock)&#123;\n                log.debug(\"t2 running\");\n                t2runned = true;\n                lock.notify();\n            &#125;\n        &#125;,\"t2\");\n\n        t1.start();\n        t2.start();\n    &#125;\n&#125;\n\n// 方式之二：park/unpark\n@Slf4j(topic = \"c.002\")\npublic class Test002 &#123;\n    public static void main(String[] args) &#123;\n        Thread t1 = new Thread(() -> &#123;\n            LockSupport.park();\n            log.debug(\"1 running\");\n        &#125;, \"t1\");\n        Thread t2 = new Thread(() -> &#123;\n            log.debug(\"2 running\");\n            LockSupport.unpark(t1);\n        &#125;, \"t2\");\n        t1.start();\n        t2.start();\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n交替执行\n// 方式之一：wait/notifyAll\n@Slf4j(topic = \"c.002\")\npublic class WaitNotify &#123;\n    // 等待标记 1-a-2 2-b-3 3-c-1\n    private int flag;\n    // 循环次数\n    private int loopNumber;\n\n    public WaitNotify(int flag, int loopNumber) &#123;\n        this.flag = flag;\n        this.loopNumber = loopNumber;\n    &#125;\n    public void print(String str, int waitFlag, int nextFlag) &#123;\n        for (int i = 0; i &lt; loopNumber; i++) &#123;\n            synchronized (this)&#123;\n                while (flag!=waitFlag)&#123;\n                    try &#123;\n                        this.wait();\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                &#125;\n                System.out.print(str);\n                flag = nextFlag;\n                // 唤醒所有线程\n                this.notifyAll();\n            &#125;\n        &#125;\n    &#125;\n\n    public static void main(String[] args) &#123;\n        WaitNotify w = new WaitNotify(1,5);\n        new Thread(()->&#123;\n            w.print(\"a\",1,2);\n        &#125;).start();\n        new Thread(()->&#123;\n            w.print(\"b\",2,3);\n        &#125;).start();\n        new Thread(()->&#123;\n            w.print(\"c\",3,1);\n        &#125;).start();\n    &#125;\n&#125;\n\n// 方式之二：ReentrantLock - Condition\nclass AwaitSignal extends ReentrantLock&#123;\n    private int loopNumber;\n\n    public AwaitSignal(int loopNumber) &#123;\n        this.loopNumber = loopNumber;\n    &#125;\n\n    public void print(String str,Condition current,Condition next)&#123;\n        for (int i = 0; i &lt; loopNumber; i++) &#123;\n            lock();\n            try&#123;\n                current.await();\n                System.out.print(str);\n                next.signal();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n            &#125; finally &#123;\n                unlock();\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n@Slf4j(topic = \"003\")\npublic class Test003 &#123;\n    public static void main(String[] args) throws InterruptedException &#123;\n        AwaitSignal awaitSignal = new AwaitSignal(5);\n        Condition a = awaitSignal.newCondition();\n        Condition b = awaitSignal.newCondition();\n        Condition c = awaitSignal.newCondition();\n        new Thread(()->&#123;\n            awaitSignal.print(\"a\",a,b);\n        &#125;).start();\n        new Thread(()->&#123;\n            awaitSignal.print(\"b\",b,c);\n        &#125;).start();\n        new Thread(()->&#123;\n            awaitSignal.print(\"c\",c,a);\n        &#125;).start();\n\n        Thread.sleep(1000);\n        awaitSignal.lock();\n        try &#123;\n            a.signal();\n        &#125;finally &#123;\n            awaitSignal.unlock();\n        &#125;\n    &#125;\n&#125;\n\n// 方式之三：park/unpark\nclass ParkUnpark&#123;\n    private int loopNumber;\n\n    public ParkUnpark(int loopNumber) &#123;\n        this.loopNumber = loopNumber;\n    &#125;\n\n    public void print(String str, Thread next)&#123;\n        for (int i = 0; i &lt; loopNumber; i++) &#123;\n            LockSupport.park();\n            System.out.print(str);\n            LockSupport.unpark(next);\n        &#125;\n    &#125;\n&#125;\n\n\n@Slf4j(topic = \"004\")\npublic class Test004 &#123;\n    static Thread t1;\n    static Thread t2;\n    static Thread t3;\n    public static void main(String[] args) &#123;\n        ParkUnpark pu = new ParkUnpark(5);\n        t1 = new Thread(()->&#123;\n            pu.print(\"a\",t2);\n        &#125;);\n        t2 = new Thread(()->&#123;\n            pu.print(\"b\",t3);\n        &#125;);\n        t3 = new Thread(()->&#123;\n            pu.print(\"c\",t1);\n        &#125;);\n        t1.start();\n        t2.start();\n        t3.start();\n        LockSupport.unpark(t1);\n    &#125;\n&#125;\n\n\n\n共享模型之内存上一章讲解的Monitro主要关注的是访问共享变量时，保证临界区代码的原子性。这一章我深入学习共享变量在多线程间的【可见性】问题与多条指令执行时的【有序性】问题\nJava 内存模型JMM 即 Java Memory Model，它定义了主存、工作内存抽象概念，底层对应着CPU寄存器、缓存、硬件内存、CPU指令优化等。\nJMM体现在以下几个方面\n\n原子性：保证指令不会受到线程上下文切换的影响\n可见性：保证指令不会受CPU缓存的影响\n有序性：保证指令不会受CPU指令并行优化的影响\n\n可见性退不出的循环先来看一个现象，main 线程对 run 变量的修改对于 t 线程不可见，导致了 t线程无法停止：\n\n\n为什么？原因如下：\n\n初始状态，t 线程刚开始从主存中读取了 run 的值到工作内存\n\n\n\n\n因为 t 线程要频繁从主存中读取 run 的值，JIT编译器会将 run 的值缓存至自己工作内存中的高速缓存中，减少对主存 run 的访问，提高效率\n\n\n\n\n1s之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量的值，结果永远是旧值\n\n\n\n解决方法\n\n\n\n\n\n\n\n\n\n方式之一\n// 易变 volatile\n// 它可以用来修饰[成员变量]和[静态成员]变量，避免从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作volatile变量都是直接操作主存\nvolatile static boolean run = true \n  ...\n\n\n\n\n\n\n\n\n\n\n方式之二\n\n\n\n\n可见性 vs 原子性前面的例子体现的实际就是可见性，它保证的是多个线程之间，一个线程对 volatile 变量的修改对另外一个线程可见，不能保证原子性，仅用在一个写线程，多个读线程的情况。\n字节码理解：\n\n\n比较之前举的线程安全的例子：两个线程一个 i++ 一个 i–,只能保证看到最新值，不能解决指令交错\n注意：\nsynchronized 语句块既可以保证代码块的原子性，也同时保证代码块内变量的可见性。但缺点是 synchronized 是属于重量级操作，性能相对更低。\n如果在前面示例的死循环中加入 System.out.println( ) 会发现即使不加 volatile 修饰符，线程 t 也能正确看到对 run 变量修改了，那么因为其源码中有使用 synchronized 关键字\n终止模式之两阶段终止模式 - 改进 &amp; 犹豫模式Balking（犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回\n@Slf4j(topic = \"c.005\")\npublic class TwoPhraseTermination &#123;\n    private volatile boolean stop = false;\n    private boolean starting = false; // 犹豫模式改进\n    private Thread monitorThread;\n\n    public void start() &#123;\n        ////// 犹豫模式改进 ////////\n        synchronized (this) &#123;\n            if (starting) &#123;\n                return;\n            &#125;\n            starting = true;\n        &#125;\n        ////// 犹豫模式改进 ////////\n        monitorThread = new Thread(() -> &#123;\n            while (true) &#123;\n                Thread current = Thread.currentThread();\n                if (stop) &#123;\n                    log.debug(\"料理后事\");\n                    break;\n                &#125;\n                try &#123;\n                    Thread.sleep(1000);\n                    log.debug(\"执行监控记录\");\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n        &#125;, \"monitor\");\n        monitorThread.start();\n    &#125;\n\n    public void stop() &#123;\n        stop = true;\n        monitorThread.interrupt();\n    &#125;\n\n    public static void main(String[] args) throws InterruptedException &#123;\n        TwoPhraseTermination t = new TwoPhraseTermination();\n        t.start();\n\n        Thread.sleep(10000);\n        log.debug(\"停止监控\");\n        t.stop();\n        t.stop();\n        t.stop();\n        t.stop();\n    &#125;\n&#125;\n\n\n\nBalking 应用@Service\n@Slf4j\npublic class MonitorService &#123;\n\n    private volatile boolean stop;\n    private volatile boolean starting;\n    private Thread monitorThread;\n\n    public void start() &#123;\n        // 缩小同步范围，提升性能\n        synchronized (this) &#123;\n            log.info(\"该监控线程已启动?(&#123;&#125;)\", starting);\n            if (starting) &#123;\n                return;\n            &#125;\n            starting = true;\n        &#125;\n        // 由于之前的 balking 模式，以下代码只可能被一个线程执行，因此无需互斥\n        monitorThread = new Thread(() -> &#123;\n            while (!stop) &#123;\n                report();\n                sleep(2);\n            &#125;\n            // 这里的监控线程只可能启动一个，因此只需要用 volatile 保证 starting 的可见性\n            log.info(\"监控线程已停止...\");\n            starting = false;\n        &#125;);\n\n        stop = false;\n        log.info(\"监控线程已启动...\");\n        monitorThread.start();\n    &#125;\n\n    private void report() &#123;...&#125;\n\n    private void sleep(long seconds) &#123;...&#125;\n\n    public synchronized void stop() &#123;\n        stop = true;\n        // 不加打断需要等到下一次 sleep 结束才能退出循环，这里是为了更快结束\n        monitorThread.interrupt();\n    &#125;\n\n&#125;\n\n它经常用来实现线程安全的单例\npublic final class Singleton&#123;\n\tprivate Singleton()&#123;&#125;\n  private static Sigleton INSTANCE = null;\n  public static synchronized Singleton getInstace()&#123;\n      if(INSTANCE!=null)&#123;\n        \treturn INSTANCE;\n      &#125;\n    \tINSTANCE = new Singleton();\n  \t  return INSTANCE;\n  &#125;\n&#125;\n\n对比一下保护性暂停模式：保护性暂停模式用于在一个线程等待另一个线程的执行结果，当条件不满足时线程等待。\n有序性JVM会在不影响正确性的前提下，可以调整语句的执行顺序，思考下面一段代码\nstatic int i;\nstatic int j;\n// 在某个线程内执行如下赋值操作\ni = ...;\nj = ...;\n\n可以看到，至于是先执行 i 还是 j，对最终的结果不会产生影响。所以，上面代码真正执行时，可以使\ni = ...;\nj = ...;\n//  或  //\nj = ...;\ni = ...;\n\n这种特性称之为【指令重排】，多线程下【指令重排】会影响正确性，为什么要有指令重排这项优化呢？可以从CPU执行指令的原理来理解。\n\n\n\n\n原理之 volatilevolatile 的底层原理是内存屏障（Memory Barrier&#x2F;Fence）\n\n对 volatile 变量的写指令后会加入写屏障\n对 volatile 变量的读指令前会加入读屏障\n\n\n如何保证可见性\n写屏障（sfence）保证在该写屏障之前的，对共享变量的改动，都同步到主存当中\n\n&#96;&#96;&#96;javapublic void actor2(I_Result r){  num &#x3D; 2;  ready &#x3D; true; &#x2F;&#x2F; ready是 volatile 赋值带写屏障}\n\n- 而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据\n\n- &#96;&#96;&#96;java\n  public void actor1(I_Result r)&#123;\n    &#x2F;&#x2F; 读屏障\n    &#x2F;&#x2F; ready 是 volatile 读取值带读屏障\n    if(ready)&#123;\n      r.r1 &#x3D; num + num;\n    &#125;else&#123;\n      r.r1 &#x3D; 1;\n    &#125;\n  &#125;\n\nDouble-check locking 问题以著名的 double-check locking 单例模式为例\n\n\n以上的实现特点是：\n\n懒惰实例化\n首次使用 getInstacne( ) 才使用 synchronized 加锁，后续使用时无需加锁\n有隐含的，但很关键的一点：第一个if使用了INSTANCE变量，是在同步块之外\n\n但在多线程环境下，以上代码是有问题的，getInstance方法对应的字节码如下：\n\n\n其中\n\n17表示创建对象，将对象引用入栈\n20表示复制一份对象引用\n21表示利用一个对象引用，调用构造方法\n24表示利用一个对象引用，赋值给 static INSTANCE\n\n也许JVM会优化为：先执行24，再执行21\n\n\n关键在于：getstatic 这行代码在 monitor 控制之外，它就像之前举例中不守规则的人，可以越过 monitor 读取 INSTANCE 变量的值\n这时 t1 还未完全将构造方法执行完毕，如果在构造方法中要执行很多初始化操作，那么 t2 拿到的将是一个未初始化完毕的单例\n解决办法对 INSTANCE 使用 volatile 修饰即可，可以禁用指令重排，但要注意在JDK5以上的版本 volatile 才会真正有效\nhanppens-beforehanppens-before 规定了对共享变量的写操作对其他线程的读操作可见，它是可见性与有序性的一套规则总结，抛开以下 happens-before 规则，JMM并不能保证一个线程对共享变量的写，对于其它线程对该共享变量的读可见\n\n线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量\n\nstatic int x;\nstatic Object m = new Object();\nnew Thread(()->&#123;\n  synchronized(m)&#123;\n    x = 10;\n  &#125;\n&#125;,\"t1\").start();\nnew Thread(()->&#123;\n  synchronized(m)&#123;\n    System.out.println(x)\n  &#125;\n&#125;,\"t2\").start();\n\n\n线程对 volatile 变量的写，对接下来其它线程对该变量的读可见\n\n\n\n\n线程 start 前对变量的写，对该线程开始后对该变量的读可见\n\n\n\n\n线程结束前对变量的写，对其他线程得知它结束后的读可见（比如其它线程调用 t1.isAlive( ) 或 t1.join( ) 等待它结束）\n\n\n\n\n线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过t2.interrupted &#x2F; t2.isInterrupted）\n\n\n\n\n对变量默认值（0, false, null）的写，对其它线程对该变量的读可见\n具有传递性，如果 x hb -&gt; y 并且 y hb -&gt; z 那么有 x hb -&gt; z ，配合 volatile 的防指令重排，有下面的例子\n\nvolatile static int x;\nstatic int y;\nnew Thread(()->&#123;\n  y = 10;\n  x = 20;\n&#125;,\"t1\").start();\nnew Thread(()->&#123;\n  // x = 20 对 t2 可见，同时 y=10 也对 t2 可见\n  System.out.println(x);\n&#125;,\"t2\").start();\n\n\n\n习题balking 模式习题\n\n线程安全单例习题单例模式有很多实现方法，饿汉、懒汉、静态内部类、枚举类，试分析每种实现下获取单例对象（即调用 getInstance）时的线程安全，并思考注释中的问题\n\n饿汉式：类加载就会导致该单实例对象被创建\n懒汉式：类加载不会导致该单实例对象被创建，而是首次使用对象时才会创建\n\n实现1：\n\n\nhttps://www.bilibili.com/video/BV16J411h7Rd?p=155&amp;spm_id_from=pageDriver\n本章小结本章重点讲解了JMM中的\n\n可见性-由JVM缓存优化引起\n有序性-由JVM指令重排优化引起\nhappens-before规则\n原理方面\nCPU指令执行\nvolatile\n\n\n模式方面\n两阶段终止模式的 volatile 改进\n同步模式之 balking\n\n\n\n共享模型之无锁\nCAS 与 volatile\n原子整数\n原子引用\n原子累加器\nUnsafe\n\nCAS 与 volatile前面看到的 AtomicInteger 的解决方法，内部并没有采用锁来保护共享变量的线程安全，那么它是如何实现的？\npublic void withdraw(Integer amount)&#123;\n  \twhile(true)&#123;\n      int prev = balance.get();\n      int next = prev - amount;\n      if(balance.compareAndSet(prev, next))&#123;\n        brea;\n      &#125;\n  \t&#125;\n\t  //////// ↓↓\n\t\t// getAndAdd( -1 * amount );\n    ////////\n&#125;\n\n\n\n注意：\n其实CAS底层是 lock cmpxchg 指令（X86架构），在单核CPU和多核CPU下都能够保证【比较-交换】的原子性\n\n在多核状态下，某个核执行到 lock 的指令时，CPU会让总线锁住，当这个核把此指令执行完毕，再开启总线。这个过程不会被线程的调度机制所打断，保证了多个线程对内存模型操作的准确性，是原子的。\n\nvolatile获取共享变量时，为了保证变量的可见性，需要使用 volatile 修饰\n它可以用来修饰成员变量和静态成员变量，可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。即一个线程对 volatile 变量的修改，对另一个线程可见。\n注意：\nvolatile 仅仅保证了共享变量的可见性，让其它线程能够看到最新值，但不能解决指令交错问题（不能保证原子性）\nCAS必须借助 volatile 才能读取到共享变量的最新值来实现【比较并交换】\n为什么无锁效率高\n无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的情况下，发生上下文切换，进入阻塞，打个比喻：\n\n\n\nCAS 特点结合 CAS 和 volatile 可以实现无锁并发，适用于线程数少、多核CPU场景下。\n\nCAS 是基于乐观锁的思想：最乐观的估计，不怕别的线程来修改共享变量，就算修改了也没关系，可以尝试。\nsynchronized 是基于悲观锁的思想：最悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。\nCAS 体现的是无锁并发、无阻塞并发\n因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的关键因素之一\n但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响\n\n\n\n原子整数J.U.C并发包提供了：\n\nAtomicBoolean\nAtomicInteger\nAtomicLong\n\n以 AtomicInteger 为例\nAtomicInteger i = new AtomicInteger(5);\ni.incrementAndGet(); // ++i   return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\ni.getAndIncrement(); // i++   return unsafe.getAndAddInt(this, valueOffset, 1);\n\ni.getAndAdd(5);\ni.addAndGet(5);\n\ni.updateAndGet(x -> x * 10)\ni.getAndUpdate(x -> x * 10)\n//////////原理///////////////\nwhile(true)&#123;\n  \tint prev = i.get();\n  \tint next = prev * 10; // 此处可以改成 IntUnaryOperator的 applyAsInt 方法实现自定义计算\n  \t// int next = operator.applyAsInt(prev);\n  \tif(i.compareAndSet(prev, next))&#123;\n\t      break;\n    &#125;\n&#125;\n/////////////////////////////\n\n\n\n原子引用\nAtomicReference\nAtomicMarkableReference\nAtomicStampedReference\n\n\n\n主线程仅能判断出共享变量的值与最初值A是否相同，不能感知到这种A-&gt;B-&gt;A的改动，如果主线程希望：\n只有有其他线程【动过了】共享变量，那么自己的CAS就算失败，这时，仅比较值是不够的，需要再加一个版本号\nAtomicStampedReference\n\nAtomicStampedReference 可以给原子引用加上版本号，追踪原子引用整个变化过程，如：A-&gt;B-&gt;A-&gt;C，通过AtomicStampedReference，我们可以知道，引用变量途中更改了几次。\n但有时候，并不关心引用变量更改了几次，只是单纯地关心是否更改过，所以就需要AtomicMarkableReference\nAtomicMarkableReference\n\n\n\n原子数组\nAtomicIntegerArray\nAtomicLongArray\nAtomicReferenceArray\n\n有如下方法\n\n\n\n\n字段更新器\nAtomicReferenceFieldUpdater\nAtomicIntegerFieldUpdater\nAtomicLongFieldUpdater\n\n利用字段更新器，可以针对对象的某个字段（Field）进行原子操作只能配合 volatile 修饰的字段使用，否则会出现异常\n原子累加器\nLongAdder\nDoubleAdder\n\n\n\n\n\n性能提升的原因如下：有竞争时，设置多个累加单元，Thread-0累加Cell[0]，而Thread-1累加Cell[1]…最后将结果汇总，这样他们在累加时操作不同的Cell变量，因此减少了CAS重试失败，从而提高性能\n* 源码之 LongAdderLongAdder 是并发大师@Author Doug Lea 的作品，设计的非常精巧\nLongAdder 类有几个关键字段\n// 累加单元数组，懒惰初始化\ntransient volatile Cell[] cells;\n// 基础值，如果没有竞争，则用CAS累加这个字段\ntransient volatile long base;\n// 在 cells 创建或扩容时，置为1，表示加锁\ntransient volatile int cellsBusy;\n\nCAS 锁\n\n\n\n\n*  原理之伪共享其中 Cell 即为累加单元\n// 防止缓存行为伪共享\n@sun.misc.Contended\nstatic final class Cell&#123;\n  \tvolatile long value;\n  \tCell(long x)&#123;value = x;&#125;\n  // 重要的方法，用CAS方式进行累加，prev表示旧值，next表示新值\n  \tfinal boolean cas(long prev,long next)&#123;\n    \treturn UNSAFE.compareAndSwapLong(this, vauleOffset, prev ,next);\n    // 省略不重要代码\n  &#125;\n&#125;\n\n\n\n\n\n因为CPU与内存的速度差异很大，需要靠预读数据至缓存来提升效率\n而缓存以缓存行为单位，每个缓存行对应着一块内存，一般是64byte（8个long）\n缓存的加入会造成数据副本的产生，即同一份数据会缓存在不同核心的缓存行中\nCPU要保证数据一致性，如果某个CPU核心修改了数据，其它的CPU核心对应的整个缓存行必须失效\n\n\n因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 为 24字节（16字节对象头和8字节value），因此缓存行可以存下2个Cell对象。这样问题来了：\n\nCore-0要修改 Cell[0]\nCore-1要修改 Cell[1]\n\n无论谁修改成功，都会导致对方的Core缓存行失效。\n@sun.misc.Contended 用来解决这个问题，它的原理是在使用此注解的对象或字段的前后各增加128字节大小的 padding，从而让CPU将对象预读至缓存时占用不同的缓存行，这样，不会造成对方缓存行的失效\n\n\nLongAdder 源码解析\n\nhttps://www.bilibili.com/video/BV16J411h7Rd?p=180&amp;spm_id_from=pageDriver\n// increment 方法为入口\npublic void increment() &#123;\n  \tadd(1L);\n&#125;\n////////////////\npublic void add(long x) &#123;\n    Cell[] as; long b, v; int m; Cell a;\n    if ((as = cells) != null || !casBase(b = base, b + x)) &#123;\n      boolean uncontended = true;\n      if (as == null || (m = as.length - 1) &lt; 0 ||\n          (a = as[getProbe() &amp; m]) == null ||\n          !(uncontended = a.cas(v = a.value, v + x)))\n        longAccumulate(x, null, uncontended);\n    &#125;\n&#125;\n\n![截屏2021-10-16下午6.56.57](http://markdown-pic-june.oss-cn-beijing.aliyuncs.com/uPic/截屏2021-10-16 下午6.56.57.png)\n\n\n![截屏2021-10-16下午6.59.40](http://markdown-pic-june.oss-cn-beijing.aliyuncs.com/uPic/截屏2021-10-16 下午6.59.40.png)\n![截屏2021-10-16下午7.16.11](http://markdown-pic-june.oss-cn-beijing.aliyuncs.com/uPic/截屏2021-10-16 下午7.16.11.png)\n![截屏2021-10-16下午7.16.11](http://markdown-pic-june.oss-cn-beijing.aliyuncs.com/uPic/截屏2021-10-16 下午7.16.11.png)\n\n\n\n\n\n\nUnsafeUnsafe 对象提供了非常底层的、操作内存、线程的方法，Unsafe对象不能直接调用，只能通过反射获得。\nField u = Unsafe.class.getDeclaredField(\"theUnsafe\");\nu.setAccessible(true);\nUnsafe unsafe = (Unsafe) u.get(null); //静态成员变量用null\n\nUnsafe CAS 操作// 获取域的偏移地址\nlong nameOffset = unsafe.objectFieldOffset(Student1.class.getDeclaredField(\"name\"));\nlong ageOffset = unsafe.objectFieldOffset(Student1.class.getDeclaredField(\"age\"));\n// 执行cas操作\nStudent1 s = new Student1();\nunsafe.compareAndSwapInt(s,ageOffset,0,111);\nunsafe.compareAndSwapObject(s, nameOffset, null,\"你好\");\n// 验证\nSystem.out.println(s);\n\n\n\n本章小结\nCAS 与 volatile\nAPI\n原子整数\n原子引用\n原子数组\n字段更新器\n原子累加器\n\n\nUnsafe\n原理方面\nLongAdder 源码\n伪共享\n\n\n\n\n-共享变量之不可变日期转换的问题问题提出下面代码在运行时，由于 SimpleDateFormat 不是线程安全的\nSimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd\");\nfor(int i = 0;i&lt;10;i++)&#123;\n  \tnew Thread(()->&#123;\n      try&#123;\n        System.out.println(sdf.parse(\"1951-04-21\"));\n      &#125;catch(Exception e)&#123;\n        System.out.println(e);\n      &#125;\n    &#125;).start();\n&#125;\n\n解决// 替换为JDK8的新日期格式化对象 DateTimeFormatter\nDateTimeFormatter t = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\");\n\n\n\n不可变设计 String 就是一个例子\n\n\nfinal 的使用发现该类、类中所有属性都是 final 的\n\n属性用 final 修饰保证了该属性是只读的，不能修改\n类用 final 修饰保证了该类中的方法不能覆盖，防止子类无意间破坏不可变性\n\n保护性拷贝通过创建副本对象来避免共享的手段称之为【保护性拷贝】（defensive copy）\n享元模式 Flyweight Pattern当需要重用数量有限的同一类对象时\n体现在JDK中 Boolean、Byte、short、Integer、Long、Character 等包装类提供了 valueOf( )方法，例如Long的valueOf会缓存-128~127之间的Long对象，在这个范围之间会重用对象，大于这个范围，才会创建新的Long对象：\npublic static Long valueOf(long l) &#123;\n    final int offset = 128;\n    if (l >= -128 &amp;&amp; l &lt;= 127) &#123; // will cache\n        return LongCache.cache[(int)l + offset];\n    &#125;\n    return new Long(l);\n&#125;\n\n注意：\n\nBtye、Short、Long 缓存范围都是-128~127\nCharacter 缓存范围是 0~127\nInteger 默认范围是 -128~127，最小值不能变，最大值可以通过调整虚拟机参数 -Djava.lang.Integer.IntegerCache.high 来改变\nBoolean 缓存了 TRUE 和 FALSE\n\n简单实现例如：一个线上商城应用，QPS达到数千，如果每次都重新创建和关闭数据库连接，性能会受到极大影响。这时预先创建好一批连接，放入连接池。一次请求到达后，从连接池获取连接，使用完毕后再还回连接池，这样既节约了连接的创建和关闭时间，也实现了连接的重用，不至于让庞大的连接数压跨数据库。\npublic class Test3 &#123;\n    public static void main(String[] args) &#123;\n        Pool pool = new Pool(2);\n        for (int i = 0; i &lt; 5; i++) &#123;\n            new Thread(() -> &#123;\n                Connection conn = pool.borrow();\n                try &#123;\n                    Thread.sleep(new Random().nextInt(1000));\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n                pool.free(conn);\n            &#125;).start();\n        &#125;\n    &#125;\n&#125;\n\n@Slf4j(topic = \"c.Pool\")\nclass Pool &#123;\n    // 1. 连接池大小\n    private final int poolSize;\n    // 2. 连接对象数组\n    private Connection[] connections;\n    // 3. 连接状态数组 0 表示空闲， 1 表示繁忙\n    private AtomicIntegerArray states;\n  \n  \tprivate Semaphore semaphore;\n    // 4. 构造方法初始化\n    public Pool(int poolSize) &#123;\n      \tthis.semaphore = new Semaphore(poolSize);\n        this.poolSize = poolSize;\n        this.connections = new Connection[poolSize];\n        this.states = new AtomicIntegerArray(new int[poolSize]);\n        for (int i = 0; i &lt; poolSize; i++) &#123;\n            connections[i] = new MockConnection(\"连接\" + (i+1));\n        &#125;\n    &#125;\n    // 5. 借连接\n    public Connection borrow() &#123;\n        while(true) &#123;\n            for (int i = 0; i &lt; poolSize; i++) &#123;\n                // 获取空闲连接\n                if(states.get(i) == 0) &#123;\n                    if (states.compareAndSet(i, 0, 1)) &#123;\n                        log.debug(\"borrow &#123;&#125;\", connections[i]);\n                        return connections[i];\n                    &#125;\n                &#125;\n            &#125;\n            // 如果没有空闲连接，当前线程进入等待\n            synchronized (this) &#123;\n                try &#123;\n                    log.debug(\"wait...\");\n                    this.wait();\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    // 6. 归还连接\n    public void free(Connection conn) &#123;\n        for (int i = 0; i &lt; poolSize; i++) &#123;\n            if (connections[i] == conn) &#123;\n                states.set(i, 0);\n                synchronized (this) &#123;\n                    log.debug(\"free &#123;&#125;\", conn);\n                    this.notifyAll();\n                &#125;\n                break;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n以上实现没有考虑：\n\n连接的动态增长和收缩\n连接保活（可用性检测）\n等待超时处理\n分布式 hash\n\n对于关系型数据库，有比较成熟的连接池实现，如C3P0、Druid等对于更通用的对象池，可以考虑使用Apache common pool，例如Redis连接池可以参考 jedis 中关于连接池的实现\n无状态在web阶段学习时，设计Servlet时为了保证其线程安全，都会有这样的建议，不要为Servlet设置成员变量，这种没有任何成员变量的类是线程安全的：因为成员变量保存的数据称为状态信息，因此没有成员变量就称之为【无状态】\nfinal 原理设置 final 变量\n理解了 volatile ，再对比 final 的实现就比较简单了\npublic class TestFinal&#123;\n  final int a = 20;\n&#125;\n\n字节码\n\n\n发现 fianl 变量的赋值也会通过 putfield 指令来完成，同样在这条指令之后也会加入写屏障，保证在其他线程读到他的值时不会出现为0的情况\n本章小结\n不可变类的使用\n不可变类的设计\n原理方面\nfinal\n\n\n模式方面\n享元模式\n\n\n\n\n-共享模型之工具线程池自定义线程池\n\n@Slf4j(topic = \"c.TestPool\")\npublic class TestPool &#123;\n    public static void main(String[] args) &#123;\n        ThreadPool threadPool = new ThreadPool(1,\n                1000, TimeUnit.MILLISECONDS, 1, (queue, task)->&#123;\n            // 1. 死等\n//            queue.put(task);\n            // 2) 带超时等待\n//            queue.offer(task, 1500, TimeUnit.MILLISECONDS);\n            // 3) 让调用者放弃任务执行\n//            log.debug(\"放弃&#123;&#125;\", task);\n            // 4) 让调用者抛出异常\n//            throw new RuntimeException(\"任务执行失败 \" + task);\n            // 5) 让调用者自己执行任务\n            task.run();\n        &#125;);\n        for (int i = 0; i &lt; 4; i++) &#123;\n            int j = i;\n            threadPool.execute(() -> &#123;\n                try &#123;\n                    Thread.sleep(1000L);\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n                log.debug(\"&#123;&#125;\", j);\n            &#125;);\n        &#125;\n    &#125;\n&#125;\n\n@FunctionalInterface // 拒绝策略\ninterface RejectPolicy&lt;T> &#123;\n    void reject(BlockingQueue&lt;T> queue, T task);\n&#125;\n\n@Slf4j(topic = \"c.ThreadPool\")\nclass ThreadPool &#123;\n    // 任务队列\n    private BlockingQueue&lt;Runnable> taskQueue;\n\n    // 线程集合\n    private HashSet&lt;Worker> workers = new HashSet&lt;>();\n\n    // 核心线程数\n    private int coreSize;\n\n    // 获取任务时的超时时间\n    private long timeout;\n    private TimeUnit timeUnit;\n  \n\t\t// 拒绝策略\n    private RejectPolicy&lt;Runnable> rejectPolicy;\n\n    // 执行任务\n    public void execute(Runnable task) &#123;\n        // 当任务数没有超过 coreSize 时，直接交给 worker 对象执行\n        // 如果任务数超过 coreSize 时，加入任务队列暂存\n        synchronized (workers) &#123;\n            if(workers.size() &lt; coreSize) &#123;\n                Worker worker = new Worker(task);\n                log.debug(\"新增 worker&#123;&#125;, &#123;&#125;\", worker, task);\n                workers.add(worker);\n                worker.start();\n            &#125; else &#123;\n//                taskQueue.put(task);\n                // 1) 死等\n                // 2) 带超时等待\n                // 3) 让调用者放弃任务执行\n                // 4) 让调用者抛出异常\n                // 5) 让调用者自己执行任务\n                taskQueue.tryPut(rejectPolicy, task);\n            &#125;\n        &#125;\n    &#125;\n\n    public ThreadPool(int coreSize, long timeout, TimeUnit timeUnit, int queueCapcity, RejectPolicy&lt;Runnable> rejectPolicy) &#123;\n        this.coreSize = coreSize;\n        this.timeout = timeout;\n        this.timeUnit = timeUnit;\n        this.taskQueue = new BlockingQueue&lt;>(queueCapcity);\n        this.rejectPolicy = rejectPolicy;\n    &#125;\n\n    class Worker extends Thread&#123;\n        private Runnable task;\n\n        public Worker(Runnable task) &#123;\n            this.task = task;\n        &#125;\n\n        @Override\n        public void run() &#123;\n            // 执行任务\n            // 1) 当 task 不为空，执行任务\n            // 2) 当 task 执行完毕，再接着从任务队列获取任务并执行\n//            while(task != null || (task = taskQueue.take()) != null) &#123;\n            while(task != null || (task = taskQueue.poll(timeout, timeUnit)) != null) &#123;\n                try &#123;\n                    log.debug(\"正在执行...&#123;&#125;\", task);\n                    task.run();\n                &#125; catch (Exception e) &#123;\n                    e.printStackTrace();\n                &#125; finally &#123;\n                    task = null;\n                &#125;\n            &#125;\n            synchronized (workers) &#123;\n                log.debug(\"worker 被移除&#123;&#125;\", this);\n                workers.remove(this);\n            &#125;\n        &#125;\n    &#125;\n&#125;\n@Slf4j(topic = \"c.BlockingQueue\")\nclass BlockingQueue&lt;T> &#123;\n    // 1. 任务队列\n    private Deque&lt;T> queue = new ArrayDeque&lt;>();\n\n    // 2. 锁\n    private ReentrantLock lock = new ReentrantLock();\n\n    // 3. 生产者条件变量\n    private Condition fullWaitSet = lock.newCondition();\n\n    // 4. 消费者条件变量\n    private Condition emptyWaitSet = lock.newCondition();\n\n    // 5. 容量\n    private int capcity;\n\n    public BlockingQueue(int capcity) &#123;\n        this.capcity = capcity;\n    &#125;\n\n    // 带超时阻塞获取\n    public T poll(long timeout, TimeUnit unit) &#123;\n        lock.lock();\n        try &#123;\n            // 将 timeout 统一转换为 纳秒\n            long nanos = unit.toNanos(timeout);\n            while (queue.isEmpty()) &#123;\n                try &#123;\n                    // 返回值是剩余时间\n                    if (nanos &lt;= 0) &#123;\n                        return null;\n                    &#125;\n                  \t// nanos每次唤醒后减少->虚假唤醒\n                    nanos = emptyWaitSet.awaitNanos(nanos);\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n            T t = queue.removeFirst();\n            fullWaitSet.signal();\n            return t;\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;\n\n    // 阻塞获取\n    public T take() &#123;\n        lock.lock();\n        try &#123;\n            while (queue.isEmpty()) &#123;\n                try &#123;\n                    emptyWaitSet.await();\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n            T t = queue.removeFirst();\n            fullWaitSet.signal();\n            return t;\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;\n\n    // 阻塞添加\n    public void put(T task) &#123;\n        lock.lock();\n        try &#123;\n            while (queue.size() == capcity) &#123;\n                try &#123;\n                    log.debug(\"等待加入任务队列 &#123;&#125; ...\", task);\n                    fullWaitSet.await();\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n            log.debug(\"加入任务队列 &#123;&#125;\", task);\n            queue.addLast(task);\n            emptyWaitSet.signal();\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;\n\n    // 带超时时间阻塞添加\n    public boolean offer(T task, long timeout, TimeUnit timeUnit) &#123;\n        lock.lock();\n        try &#123;\n            long nanos = timeUnit.toNanos(timeout);\n            while (queue.size() == capcity) &#123;\n                try &#123;\n                    if(nanos &lt;= 0) &#123;\n                        return false;\n                    &#125;\n                    log.debug(\"等待加入任务队列 &#123;&#125; ...\", task);\n                    nanos = fullWaitSet.awaitNanos(nanos);\n                &#125; catch (InterruptedException e) &#123;\n                    e.printStackTrace();\n                &#125;\n            &#125;\n            log.debug(\"加入任务队列 &#123;&#125;\", task);\n            queue.addLast(task);\n            emptyWaitSet.signal();\n            return true;\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;\n\n    public int size() &#123;\n        lock.lock();\n        try &#123;\n            return queue.size();\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;\n\n    public void tryPut(RejectPolicy&lt;T> rejectPolicy, T task) &#123;\n        lock.lock();\n        try &#123;\n            // 判断队列是否满\n            if(queue.size() == capcity) &#123;\n                rejectPolicy.reject(this, task);\n            &#125; else &#123;  // 有空闲\n                log.debug(\"加入任务队列 &#123;&#125;\", task);\n                queue.addLast(task);\n                emptyWaitSet.signal();\n            &#125;\n        &#125; finally &#123;\n            lock.unlock();\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\nThreadPoolExcutor\n\n线程池状态ThreadPoolExcutor 使用 int 的高3位来表示线程池状态，低29位表示线程数量\n\n\n\n状态名\n高3位\n接收新任务\n处理阻塞队列任务\n说明\n\n\n\nRUNNING\n111\nY\nY\n\n\n\nSHUTDOWN\n000\nN\nY\n不会接收新任务，但会处理阻塞队列剩余任务\n\n\nSTOP\n001\nN\nN\n会中断正在进行的任务，并抛弃阻塞队列任务\n\n\nTIDYING\n010\n-\n-\n任务全部执行完毕，活动线程为0即将进入中介\n\n\nTERMINATED\n001\n-\n-\n终结状态\n\n\n从数字上比较：TERMINATED&gt;TIDYING&gt;STOP&gt;SHUTDOWN&gt;RUNNING\n这些信息存储在一个原子变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 cas 原子操作进行赋值\n\n\n\n\n构造方法public ThreadPoolExcutor(int corPooSize,\n                        int maximumPooSize,\n                        int long keepAliveTime,\n                        TimeUnit, unit,\n                        BlockingQueue&lt;Runnable> workQueue,\n                        ThreadFactory threadFactory,\n                        RejectedExcutionHandler handler)\n\n\ncorePoolSize：核心线程数目（最多保留的线程数）\nmaximumPoolSize：最大线程数目\nkeepAliveTime：生存时间-针对救急线程\nunit：时间单位-针对救急线程\nworkQueue：阻塞队列\nthreadFactory：线程工厂-可以为线程创建时起个好名字\nhandler：拒绝策略\n\n工作方式：\n\n\n\n\n\n如果线程到达 maximumPoolSize 仍然有新任务，这时会执行拒绝策略。JDK提供了四种实现，其他著名框架也提供了实现。\nAbortPolicy 让调用者抛出 RejectedExecutionException 异常，默认\nCallerRunsPolicy 让调用者运行任务\nDiscardPolicy 放弃本次任务\nDiscardOldestPolicy 放弃队列中最早的任务，本任务取而代之\nDubbo实现：在抛出 RejectedExecutionException 异常之前会记录日志，并 dump 线程栈信息，方便定位问题。\nNetty实现：创建一个新线程执行任务\nActiveMQ实现：带超时等待（60s）尝试放入队列\nPinPoint实现：拒绝策略链\n\n\n当高峰过去后，超过 corePoolSize 的救急线程如果一段时间没有任务做，需要结束节省资源，这个时间由 keepAliveTime 和 unit 来控制。\n\n根据这个构造方法，JDK Executors 类中提供了众多的工厂方法来创建各种用途的线程池\nnewFixedThreadPoolpublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123;\n \t\treturn new ThreadPoolExecutor(nThreads, nThreads,\n                                0L, TimeUnit.MILLISECONDS,\n                                new LinkedBlockingQueue&lt;Runnable>(),\n                                threadFactory);\n&#125;\n\n\n核心线程数 &#x3D; 最大线程数（没有救急线程），因此无需超时时间\n阻塞队列是无界的，可以放任意数量的任务\n适用于任务量已知，相对耗时的任务\n\nnewCachedThreadPoolpublic static ExecutorService newCachedThreadPool() &#123;\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue&lt;Runnable>());\n&#125;\n\n\n核心线程数是0，最大线程数是Integer.MAX_VALUE，救急线程的空闲生存时间是60s，意味着：\n全部线程都是救急线程（60s回收）\n就几线程可以无限创建\n\n\n队列采用了 SynchronousQueue ，其特点是：没有容量，没有线程来取是放不进去的（放的线程会阻塞）\n整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲1分钟后释放线程。\n适合任务数比较密集，但每个任务执行时间较短的情况\n\nnewSingleThreadExecutorpublic static ExecutorService newSingleThreadExecutor() &#123;\n    return new FinalizableDelegatedExecutorService\n        (new ThreadPoolExecutor(1, 1,\n                                0L, TimeUnit.MILLISECONDS,\n                                new LinkedBlockingQueue&lt;Runnable>()));\n&#125;\n\n\n自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会创建一个线程，保证池的正常工作\nExecutors.newSingleThreadExecutor( )线程个数始终为1，不能修改\nFinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因此不能调用 ThreadPoolExecutor 中特有的方法\n\n\nExecutors.newFixedThreadPool(1)初始时为1，以后还可以修改\n对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorepoolSize 等方法进行修改\n\n\n\n提交任务\n\n\n\n关闭线程池/*\n\t线程池状态变为 SHUTDOWN\n\t- 不会接收新任务\n\t- 但已提交任务会执行完\n\t- 此方法不会阻塞调用线程的执行\n*/\nvoid shutdown();\n\n\n\n/*\n\t线程池状态变为 STOP\n\t- 不会接收新任务\n\t- 会将队列中的任务返回\n\t- 并用 interrupt 的方式中断正在执行的任务\n*/\nList&lt;Runnable> shutdownNow();\n\n// 不在RUNNING状态的线程池，此方法就返回true\nboolean isShutdown();\n// 线程池状态是否是 TERMINATED\nboolean isTerminated();\n// 调用 shutdown 后，由于调用线程并不会等待所有任务运行结束，因此如果它想在线程池 TERMINATED 后做些事情，可以调用此方法等待\nboolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;\n\n\n\n异步模式之工作线程定义让有限的工作线程（Worker Thread）来轮流异步处理无限多的任务。也可以将其归类为分工模式，它的典型实现就是线程池，也体现了经典设计模式中的享元模式。\n注意，不同任务类型应该使用不同的线程池，这样能够避免饥饿，能提升效率\n饥饿固定大小线程池会有饥饿现象\n\n两个工人是同一个线程池中的两个线程\n他们要做的事情是：为客人点餐和到后厨做菜，这是两个阶段的工作\n客人点餐：必须先点完餐，等菜做好，上菜，在此期间处理点餐的工人必须等待\n后厨做菜：没啥说的，做就对了\n\n\n比如工人A处理了点餐任务，接着工人B把菜做好，然后上菜，他们配合挺好\n但现在同时来了两个客人，这时候工人A和B都去处理点餐了，这时没人做饭了-&gt;“死锁”\n\n创建多少线程池合适\n过小会导致程序不能充分地利用系统资源、容易导致饥饿\n过大会导致更多的线程上下文切换，占用更多内存\n\nCPU 密集型运算\n通常采用 CPU 核数 + 1 能够实现最优的CPU利用率， +1 是保证当前线程由于页缺失故障（操作系统）或其它原因导致暂停时，额外的这个线程就能顶上去，保证CPU时钟周期不被浪费\nI&#x2F;O 密集型运算\nCPU 不总是处于繁忙状态，例如，当你执行业务计算时，这时候会使用CPU资源，但执行IO操作、远程RPC调用时、数据库操作时，这时候CPU就闲下来了，可以利用多线程提高它的利用率。\n经验公式如下：\n线程数 &#x3D; 核数 * 期望 CPU利用率 * 总时间（CPU计算时间+等待时间）&#x2F; CPU计算时间\n例如4核CPu计算时间是50%，其它等待时间是50%，期望CPU被100%利用，套用公式： 4*100%*100%&#x2F;50%&#x3D;8\n4核CPu计算时间是10%，其它等待时间是90%，期望CPU被100%利用，套用公式：\nScheduledExecutorService在【任务调度线程池】功能加入之前，可以使用 java.util.Timer 来实现定时功能，Timer 的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将影响到之后的任务。\nScheduledExecutorService pool = Executors.newScheduledThreadPool(2);\n\n捕获异常\ntry - catch\nFuture - get( )获取结果（封装有异常信息）\n\n具体应用// 如何让每周四18:00:00定时执行任务？\nScheduledExecutorService pool = Executors.newScheduledThreadPool(1);\n\nLocalDateTime now = LocalDateTime.now();\nLocalDateTime p = now.withHour(18).withMinute(0).withSecond(0).withNano(0).with(DayOfWeek.THURSDAY);\n\nif(now.compareTo(p)>0)&#123;\n  p = p.plusWeeks(1);\n&#125;\n\nlong initialDelay = Duration.between(now, p).toMillis();\nlong period = 1000 * 60 * 60 * 24 * 7;\n\npool.scheduleAtFixedRate(() -> &#123;\n  System.out.println(\"running\");\n&#125;, initialDelay, period, TimeUnit.MILLISECONDS);\n\n\n\nTomcat 线程池Tomcat 在哪里用到了线程池呢？\n\n\n\nLimitLatch：用来限流，可以控制最大连接个数，类似于JUC中的 Semaphore\nAcceptor：负责【接受新的Socket连接】\nPoller：只负责监听 SocketChannel 是否有【可读的IO事件】\n一旦可读，封装一个任务对象（SocketProcessor），提交给Executor线程池处理\n\n\nExecutor：线程池中的工作线程最终负责【处理请求】\n\nTomcat 线程池扩展了 ThreadPoolExecutor，行为稍有不同\n\n如果线程总数达到 maximumPoolSize\n这时不会立刻抛出 RejectedExecutionException 异常\n而是再次尝试将任务放入队列，如果仍然失败，才抛出 RejectedExecutionException\n\n\n\nConnector 配置\n\n\n配置项\n默认值\n说明\n\n\n\nacceptorThreadCount\n1\nacceptor 线程数量\n\n\npollerThreadCount\n1\npoller 线程数量\n\n\nminSpareThreads\n10\n核心线程数，即 corePoolSize\n\n\nmaxThreads\n200\n最大线程数，即 maximumPoolSize\n\n\nexecutor\n-\nExecutor 名称，用来引用下面的 Executor\n\n\nExecutor 线程配置（优先级更高）\n\n\n配置项\n默认值\n说明\n\n\n\nthreadPriority\n5\n线程优先级\n\n\ndaemon\ntrue\n是否守护线程\n\n\nminSpareThreads\n25\n核心线程数，即 corePoolSize\n\n\nmaxThreads\n200\n最大线程数，即 maximumPoolSize\n\n\nmaxIdleTime\n60000\n线程生存时间，单位是毫秒，默认值1分钟\n\n\nmaxQueueSize\nInteger.MAX_VALUE\n队列长度\n\n\nprestartminSpareThreads\nfalse\n核心线程是否在服务器启动时启动\n\n\n\n\n\n\n\n\nFork&#x2F;Join概念Fork&#x2F;Join 是JDK1.7加入的新的线程池实现，它体现的是一种分治思想，适用于能够进行任务拆分的CPU密集型运算\n所谓任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序，斐波那契数列、都可以用分值思想进行求解\nFork&#x2F;Join 在分支的基础上加入了多线程，可以把每个人物的分解和合并交给不同的线程来完成，进一步提升了运算效率\nFork&#x2F;Join 默认会创建与CPU核心数相同的线程池\n使用提交给 Fork&#x2F;Join 线程池的任务需要继承 RecursiveTask（有返回值）或 RecusiveAction（没有返回值）\n// begin - end 求和\n@Override\nprotected Integer compute() &#123;\n    if (begin == end) &#123;\n        return begin;\n    &#125;\n    if (end - begin == 1) &#123;\n        return end + begin;\n    &#125;\n    int mid = (end + begin) / 2;\n    MyTask009 t1 = new MyTask009(begin, mid);\n    t1.fork();\n    MyTask009 t2 = new MyTask009(mid + 1, end);\n    t2.fork();\n    return t1.join() + t2.join();\n&#125;\n\n\n\nJ.U.CAQS原理概述全称 AbstractQueuedSynchronizer，是阻塞式锁和同步器工具的框架\n特点：\n\n用 stat 属性来表示资源的状态（分独占模式和共享模式），子类需要定义如何维护这个状态，控制如何获取锁和释放锁\ngetState - 获取 state 状态\nsetState - 设置 state 状态\ncompareAndSetState - 乐观锁机制设置 state 状态\n独占模式只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源\n\n\n提供了基于FIFO的等待队列，类似于 Monitor 的 EntryList\n条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet\n\n子类主要实现这样一些方法（默认抛出UnsupportedOperationException）\n\ntryAcquire\ntryRelease\ntryAcquireShared\ntryReleaseShared\nisHeldExclusively\n\nReentrantLock 原理\n\n非公平锁实现原理加锁解锁流程public ReentrantLock()&#123;\n  \t// NonfairSync 继承自 AQS\n\t  sync = new NonfairSync(); \n&#125;\n\n没有竞争时\n\n\n第一个竞争出现时\n\n\nThread - 1 执行了：\n\nCAS 尝试将 state 由 0 改为 1 ，结果失败\n进入 tryAcquire( ) 逻辑，这时 state 已经是1，结果仍然失败\n接下来进入 addWaiter 逻辑，构造 Node 队列\n图中黄色三角表示该 Node 的 WaitStatus 状态，其中0为默认正常状态\nNode的创建是懒惰的\n其中第一个Node称为Dummy（哑元）或哨兵，用来占位，并不关联线程\n\n\n\n\n\n当前线程进入acquireQueued逻辑（会在一个死循环中不断尝试获得锁，失败后进入 park 阻塞）\n\n如果自己是紧邻着 head（第二个Node），那么再次 tryAcquire 尝试获得锁，当然这时 state 仍未1，失败\n进入 shouldParkAfterFailedAcquire 逻辑，将前驱 node，即 head 的waitStatus改为-1，这次返回false\n\n\n\n\nshouldParkAfterFailedAcquire 执行完毕回到 acquireQueued，再次 tryAcquire 尝试获得锁，当然这时 state 仍为 1，失败\n当再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱node的WaitStatus已经是-1，这次返回true\n进入 parkAndCheckInterrupt，Thread-1 park（灰色表示）\n\n\n\n再次有多个线程经历上述过程竞争失败，变成这个样子 ↓\n\n\nThread - 0 释放锁，进入 tryRelaese 流程，如果成功\n\n设置 exclusiveOwnerThread 为 null\nstate &#x3D; 0\n\n\n\n当前队列不为 null，并且 head 的 WaitStatus &#x3D; -1，进入 unparkSuccessor 流程\n找到队列中离 head 最近的一个 Node（没取消的），unpark 恢复其运行，本例中即为 Thread-1\n回到 Thread-1 的 acquireQueued 流程\n\n\n如果加锁成功（没有竞争），会设置\n\nexclusiveOwnerThread 为 Thread-1，state &#x3D; 1\nhead 指向刚刚 Thread-1 所在的 Node，该 Node 清空 Thread\n原本的 head 因为从链表断开，从而可被垃圾回收\n\n如果此时有其他线程来竞争（非公平的体现），例如这时有Thread-4来了\n\n如果不巧又被Thread-4占了先\n\nThread-4 被设置为 exclusiveOwnerThread，state &#x3D; 1\nThread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞\n\n可重入原理https://www.bilibili.com/video/BV16J411h7Rd?p=242\n\n\n\n\n\n\n可打断原理不可打断模式在此模式下，即使它被打断，仍会驻留在AQS队列中，等获得锁后方能继续运行（是继续运行！只是打断标记被设置为 true）\n\n\n\n\n\n\n可打断模式\n\n\n\n公平锁实现原理非公平\n\n\n公平\n\n\n\n\n\n\n条件变量实现原理每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject\nawait 流程开始 Thread-0 持有锁，进入 ConditionObject 的 addConditionWaiter 流程，创建新的 Node 状态为 -2（Node.CONDITION)，关联 Thread-0，加入等待队列尾部\n\n\n接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁\n\n\nunpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程，那么 Thread-1 竞争成功\n\n\npark 阻塞 Thread-0\n\n\nsignal 流程假设 Thread-1 要来唤醒 Thread-0\n\n\n进入 ConditionObject 的 doSignal 流程，取得等待队列中第一个 Node，即 Thread-0 所在Node\n\n\n执行 transferForSignal 流程，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为0，Thread-3的 waitStatus 改为 -1\n\n\nThread-1 释放锁，进入 unlock 流程，略\n读写锁ReentrantReadWriteLock当读操作远远高于写操作时，这时候使用读写锁让读-读可以并发，提高性能。类似于数据库中的 select … from … lock in share mode\n提供一个数据容器类内部分别使用读锁保护数据的 read( ) 方法，写锁保护数据的 write( ) 方法\nReentrantReadWriteLock rw = new ReentrantReadWriteLock();\nReentrantReadWriteLock.ReadLock readLock = rw.readLock();\nReentrantReadWriteLock.WriteLock writeLock = rw.writeLock();\n\n注意事项：\n\n读锁不支持条件变量\n重入时升级不支持：即持有读锁的情况下区获取写锁，会导致获取写锁永久等待\n重入时降级支持：即持有写锁的情况下去获取读锁\n\n应用之缓存缓存更新策略先清缓存\n\n\n先更新数据库\n\n\n\n\npublic class TestGenericDao &#123;\n    public static void main(String[] args) &#123;\n        GenericDao dao = new GenericDaoCached();\n        System.out.println(\"============> 查询\");\n        String sql = \"select * from emp where empno = ?\";\n        int empno = 7369;\n        Emp emp = dao.queryOne(Emp.class, sql, empno);\n        System.out.println(emp);\n        emp = dao.queryOne(Emp.class, sql, empno);\n        System.out.println(emp);\n        emp = dao.queryOne(Emp.class, sql, empno);\n        System.out.println(emp);\n\n        System.out.println(\"============> 更新\");\n        dao.update(\"update emp set sal = ? where empno = ?\", 800, empno);\n        emp = dao.queryOne(Emp.class, sql, empno);\n        System.out.println(emp);\n    &#125;\n&#125;\n\nclass GenericDaoCached extends GenericDao &#123;\n    private GenericDao dao = new GenericDao();\n    private Map&lt;SqlPair, Object> map = new HashMap&lt;>();\n    private ReentrantReadWriteLock rw = new ReentrantReadWriteLock();\n\n    @Override\n    public &lt;T> List&lt;T> queryList(Class&lt;T> beanClass, String sql, Object... args) &#123;\n        return dao.queryList(beanClass, sql, args);\n    &#125;\n\n    @Override\n    public &lt;T> T queryOne(Class&lt;T> beanClass, String sql, Object... args) &#123;\n        // 先从缓存中找，找到直接返回\n        SqlPair key = new SqlPair(sql, args);;\n        rw.readLock().lock();\n        try &#123;\n            T value = (T) map.get(key);\n            if(value != null) &#123;\n                return value;\n            &#125;\n        &#125; finally &#123;\n            rw.readLock().unlock();\n        &#125;\n        rw.writeLock().lock(); // 唯一线程进入\n        try &#123;\n            // 解锁后，多个线程进入\n            T value = (T) map.get(key);\n            if(value == null) &#123;\n                // 缓存中没有，查询数据库\n                value = dao.queryOne(beanClass, sql, args);\n                map.put(key, value);\n            &#125;\n            return value;\n        &#125; finally &#123;\n            rw.writeLock().unlock();\n        &#125;\n    &#125;\n\n    @Override\n    public int update(String sql, Object... args) &#123;\n        rw.writeLock().lock();\n        try &#123;\n            // 先更新库\n            int update = dao.update(sql, args);\n            // 清空缓存\n            map.clear();\n            return update;\n        &#125; finally &#123;\n            rw.writeLock().unlock();\n        &#125;\n    &#125;\n\n    class SqlPair &#123;\n        private String sql;\n        private Object[] args;\n\n        public SqlPair(String sql, Object[] args) &#123;\n            this.sql = sql;\n            this.args = args;\n        &#125;\n        @Override\n        public boolean equals(Object o) &#123;\n            if (this == o) &#123;\n                return true;\n            &#125;\n            if (o == null || getClass() != o.getClass()) &#123;\n                return false;\n            &#125;\n            SqlPair sqlPair = (SqlPair) o;\n            return Objects.equals(sql, sqlPair.sql) &amp;&amp;\n                    Arrays.equals(args, sqlPair.args);\n        &#125;\n        @Override\n        public int hashCode() &#123;\n            int result = Objects.hash(sql);\n            result = 31 * result + Arrays.hashCode(args);\n            return result;\n        &#125;\n    &#125;\n\n&#125;\n\n注意：\n\n以上实现体现的是读写锁的应用，保证缓存和数据库的一致性，但下面的问题没有考虑\n适合读多写少，如果写操作比较频繁，以上实现性能低\n没有考虑缓存容量\n没有考虑缓存过期\n只适合单机\n并发性还是低，目前只会用一把锁\n更新方法太简单粗暴，清空了所有 key\n\n\n\n读写锁原理图解流程读写锁用的是同一个 Sync 同步器，因此等待队列，state 等也是同一个\nt1 w.lock  t2 r.lock\n\nt1成功上锁，流程与ReentrantLock加锁相比没有特殊之处，不同是写锁状态占了 state 的低 16 位，而读锁使用的是 state 的高16位\n\n\n\n\n\n\nt2 执行 r.lock，这时进入读锁的 sync.acquireShared(1)流程，首先会进入 tryAcquireShared 流程。如果有写锁占据，那么 tryAcquireShared 返回 -1 表示失败\n\n\n-1：失败\n0：成功，但后继节点不会继续唤醒\n正数：成功，数值是几表示有几个后继节点需要唤醒，读锁返回1\n\n\n\n\n\n\n\n\n\n\n这时会进入 sync.doAcquireShared(1)流程，首先也是调用 addWaiter 添加节点，不同之处在于节点被设置为 Node.SHARED 模式而非 Node.EXCLUSIVE 模式，注意此时 t2 仍然处于活跃状态\n\n\n\n\nt2 会看看自己的节点是不是老二，如果是，还会在此调用 tryAcquireShared(1) 来尝试获取锁\n如果没有成功，会继续执行，把前驱结点的 WaitStatus 改为 -1（shouldParkAfterFailedAcquire方法，这次返回false，下次true），再 for(;;) 循环一次尝试 tryAcquireShared(1)如果还不成功，那么在 parkAndCheckInterrupt( )处 park\n\n\n\nt3 r.lock , t4 w.lock\n在这种情况下，假设又有 t3 加读锁和 t4 加写锁，这期间 t1 仍然持有锁，就变成了下面的样子\n\n\nt1 w.unlock\n这时会走到写锁的 sync.release(1) 流程，调用 sync.tryRelease(1)成功，变成下面的样子\n\n\n接下来执行唤醒流程 sync.unparkSuccessor，即让老二恢复运行，这时 t2 在 doacquireShared 内 parkAndCheckInterrupt( ) 处恢复运行\n这回再来一次 for(;;) 执行 tryAcquireShared 成功则让读锁计数加一\n\n\n这时 t2 已经恢复运行，接下来 t2 调用 setHeadAndPropagate(node, 1)，它原本所在节点被设置为头结点\n\n\n这回再来一次 for(;;)执行 tryAcquireShared 成功则让读锁计数加一\n\n\n这时 t3 已经恢复运行，接下来 t3 调用 setHeadAndPropagate(node, 1)，它原本所在节点被设置为头结点\n\n\n下一个节点已经不是 Shared 状态了\nt2 r.unlock, t3 r.unlock\nt2 进入 sync.releaseShared(1)中，调用 tryReleaseShared(1)让计数减一，但由于计数还不为零\n\n\nt3 进入了 sync.releaseShared(1) 中，调用 tryReleaseShared(1)让计数减一，这回计数为零了，进入 doReleaseShared( )将头结点从 -1 改为 0 并唤醒老二，即\n\n\n之后 t4 在 acquireQuqued 中 parkAndCheckInterrupt 处 恢复运行，再次 for(;;)这次自己是老二，并且没有其他竞争，tryAcquire(1)成功，修改投机诶单，流程结束\n\n\n\n\nStampedLockSince JDK 8，是为了进一步优化读性能，它的特点是在使用读锁，写锁时都必须配合【戳】使用\n加解读锁\nlong stamp = lock.readLock();\nlock.unlockRead(stamp);\n\n加解写锁\nlong stamp = lock.writeLock();\nlock.unlockWrite(stamp);\n\n乐观锁，StampedLock 支持 tryOptimisticRead( )方法（乐观读），读取完毕后需要做一次戳校验如果校验通过，表示这期间确实没有写操作，数据可以安全使用，如果校验没通过，需要重新获取读锁，保证数据安全。\nlong stamp = lock.tryOptimisticRead();\n// 验戳\nif(!lock.validate(stamp))&#123;\n    // 锁升级\n&#125;\n\n\nStampedLock 不支持条件变量\nStampedLock 不支持可重入\n\nSemaphore信号量，用来限制能同时访问共享资源的线程上限。\n应用\n使用 Semaphore 限流，在访问高峰期，让请求线程阻塞，高峰期过去再释放许可，当然它只适合限制单机线程数量，并且仅是限制线程数，而不是限制资源数（例如连接数，请对比 Tomcat LimitLatch 的实现）\n用 Semaphore 实现简单连接池，对比【享元模式】下的实现（用 wait notify），性能和可读性显然更好，注意下面的实现中线程数和数据库连接池数是相等的\n\n// 5. 借连接\npublic Connection borrow() &#123;\n    // 获取许可\n    try &#123;\n        semaphore.acquire(); // 没有许可的线程，在此等待\n    &#125; catch (InterruptedException e) &#123;\n        e.printStackTrace();\n    &#125;\n    for (int i = 0; i &lt; poolSize; i++) &#123;\n        // 获取空闲连接\n        if(states.get(i) == 0) &#123;\n            if (states.compareAndSet(i, 0, 1)) &#123;\n                log.debug(\"borrow &#123;&#125;\", connections[i]);\n                return connections[i];\n            &#125;\n        &#125;\n    &#125;\n    // 不会执行到这里\n    return null;\n&#125;\n// 6. 归还连接\npublic void free(Connection conn) &#123;\n    for (int i = 0; i &lt; poolSize; i++) &#123;\n        if (connections[i] == conn) &#123;\n            states.set(i, 0);\n            log.debug(\"free &#123;&#125;\", conn);\n            semaphore.release();\n            break;\n        &#125;\n    &#125;\n&#125;\n\n原理Semaphore 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后停车场显示空余车位减一\n刚开始，permits( state ) 为3，这时5个线程来获取资源\n  \n\n假设其中 Thread-1, Thread-2, Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入AQS队列park阻塞\n\n\n这时 Thread-4 释放了 permits，状态如下\n\n\n接下来 Thread-0 竞争成功，permits 再次设置为0，设置自己为 head 节点，断开原来的 head 节点，unpark 接下来的 Thread-3 节点，但由于 permits 是0，因此 Thread-3 在尝试不成功后再次进入 park 状态\n\n\n\n\n\n\nCountdownLatch用来进行线程同步协作，等待所有线程完成倒计时\n其中构造参数用来初始化等待计数值，await( )用来等待计数归零，countDown( )用来让计数减一\n* 应用之同步等待多线程准备完毕\n\n* 应用之同步等待多个远程调用结束\n\n↓改进↓\n\n\n\n↓改进↓\n\n\n\n\n\nCyclicBarrier循环栅栏，用来进行线程协作，等待线程满足某个计数。构造时设置【计数个数】，每个线程执行到某个需要“同步”的时刻调用await( )方法进行等待，当等待的线程数满足【计数个数】时，继续执行\n注意：\n【线程池线程数】需要与【计数个数】相同\n线程安全集合类概述\n线程安全集合可以分为三大类：\n\n遗留的线程安全集合如 Hashtable，Vector\n使用 Collections 装饰的线程安全集合（Synchronized版本），如：\nCollections.syncrhonizedCollection\nCollections.synchronizedList\nCollections.synchronizedMap\nCollections.synchronizedSet\nCollections.synchronizedNavigableMap\nCollections.synchronizedNavigableSet\nCollections.synchronizedSortedMap\nCollections.synchronizedSortedSet\n\n\njava.util.concurrent.*\n\n重点介绍 java.util.concurrent.* 下的线程安全集合类，可以发现他们有规律，里面包含三类关键词 Blocking、CopyOnWrite、Concurrent\n\nBlocking 大部实现基于锁，并提供用来阻塞的方法\nCopyOnWrite 之类容器修改开销相对较重\nConcurrent 类型的容器\n内部很多操作使用 cas 优化，一般可以提供较高吞吐量\n弱一致性\n遍历时弱一致性，例如，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍历，这是内容是旧的\n求大小弱一致性，size 操作未必是100%准确\n读取弱一致性\n\n\n\n\n\n遍历时如果发生了修改，对于非安全容器来讲，使用 fail-fast 机制也就是让遍历立刻失效，抛出 ConcurrentModificationException，不再继续遍历\nConcurrenthashMap JDK8public class TestWordCount &#123;\n    public static void main(String[] args) &#123;\n        demo(\n                // 创建 map 集合\n                // 创建 ConcurrentHashMap 对不对？\n                () -> new ConcurrentHashMap&lt;String, LongAdder>(8,0.75f,8),\n\n                (map, words) -> &#123;\n                    for (String word : words) &#123;\n                        // 如果缺少一个 key，则计算生成一个 value , 然后将  key value 放入 map\n                        //                  a      0\n                        LongAdder value = map.computeIfAbsent(word, key -> new LongAdder());\n                        // 执行累加,初始值为0\n                        value.increment(); // 2\n\n                        /*// 检查 key 有没有\n                        Integer counter = map.get(word);\n                        int newValue = counter == null ? 1 : counter + 1;\n                        // 没有 则 put\n                        map.put(word, newValue);*/\n                    &#125;\n                &#125;\n        );\n    &#125;\n\n    private static &lt;V> void demo(Supplier&lt;Map&lt;String, V>> supplier, BiConsumer&lt;Map&lt;String, V>, List&lt;String>> consumer) &#123;\n        Map&lt;String, V> counterMap = supplier.get();\n        // key value\n        // a   200\n        // b   200\n        List&lt;Thread> ts = new ArrayList&lt;>();\n        for (int i = 1; i &lt;= 26; i++) &#123;\n            int idx = i;\n            Thread thread = new Thread(() -> &#123;\n                List&lt;String> words = readFromFile(idx);\n                consumer.accept(counterMap, words);\n            &#125;);\n            ts.add(thread);\n        &#125;\n\n        ts.forEach(t -> t.start());\n        ts.forEach(t -> &#123;\n            try &#123;\n                t.join();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;);\n\n        System.out.println(counterMap);\n    &#125;\n&#125;\n\n\n\nCurrentHashMap 原理https://www.bilibili.com/video/BV15b4y117RJ?p=90&amp;t=1.2\n\n\n\n重要属性和内部类\n// 默认为 0\n// 当初始化时, 为 -1\n// 当扩容时, 为 -(1 + 扩容线程数)\n// 当初始化或扩容完成后，为 下一次的扩容的阈值大小\nprivate transient volatile int sizeCtl;\n\n// 整个 ConcurrentHashMap 就是一个 Node[]\nstatic class Node&lt;K,V> implements Map.Entry&lt;K,V> &#123;&#125;\n\n// hash 表\ntransient volatile Node&lt;K,V>[] table;\n\n// 扩容时的 新 hash 表\nprivate transient volatile Node&lt;K,V>[] nextTable;\n\n// 扩容时如果某个 bin 迁移完毕, 用 ForwardingNode 作为旧 table bin 的头结点\nstatic final class ForwardingNode&lt;K,V> extends Node&lt;K,V> &#123;&#125;\n\n// 用在 compute 以及 computeIfAbsent 时, 用来占位, 计算完成后替换为普通 Node\nstatic final class ReservationNode&lt;K,V> extends Node&lt;K,V> &#123;&#125;\n\n// 作为 treebin 的头节点, 存储 root 和 first\nstatic final class TreeBin&lt;K,V> extends Node&lt;K,V> &#123;&#125;\n\n// 作为 treebin 的节点, 存储 parent, left, right\nstatic final class TreeNode&lt;K,V> extends Node&lt;K,V> &#123;&#125;\n\n重要方法\n// 获取 Node[] 中第 i 个 Node\nstatic final &lt;K,V> Node&lt;K,V> tabAt(Node&lt;K,V>[] tab, int i)\n// cas 修改 Node[] 中第 i 个 Node 的值, c 为旧值, v 为新值\nstatic final &lt;K,V> boolean casTabAt(Node&lt;K,V>[] tab, int i, Node&lt;K,V> c, Node&lt;K,V> v)\n// 直接修改 Node[] 中第 i 个 Node 的值, v 为新值\nstatic final &lt;K,V> void setTabAt(Node&lt;K,V>[] tab, int i, Node&lt;K,V> v)\n\n构造器分析\n可以看到实现了懒惰初始化，在构造方法中仅仅计算了 table 的大小，以后在第一次使用时才会真正创建\npublic ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123;\n  if (!(loadFactor > 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)\n      throw new IllegalArgumentException();\n  if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins\n      initialCapacity = concurrencyLevel; // as estimated threads\n  long size = (long)(1.0 + (long)initialCapacity / loadFactor);\n  // tableSizeFor 仍然是保证计算的大小是 2^n, 即 16,32,64 ... \n  int cap = (size >= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size);\n\tthis.sizeCtl = cap; \n&#125;\n\nget 流程\n\n\nput 流程\n\n\n\n\n\n\n\n\n\n\nsize 计算流程\nsiez 计算实际发生在 put，remove 改变集合元素的操作之中，注意：计算结果仍然有误差\n\n没有竞争发生，向 baseCount 累加计数\n有竞争发生，新建 counterCells，向其中一个 cell 累加计数\ncounterCells 初始化有两个 cell\n如果计数竞争比较激烈，会创建新的cell来累加计数\n\n\n\ntransfer 流程\nhttps://www.bilibili.com/video/BV16J411h7Rd?p=289&amp;t=36.5\nConcurrenthashMap JDK7它维护了一个 segment 数组，每个 segment 对应一把锁\n\n优点：如果多个线程访问不同的 segment，实际是没有冲突的，这与JDK8中是类似的\n缺点：Segments 数组默认大小为16，这个是固定不可变的，并且不是懒惰初始化\n\n在JDK1.7版本中，ConcurrentHashMap的数据结构是由一个Segment数组和多个HashEntry组成，如下图所示：\n\n\n构造器分析\npublic ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123;\n        if (!(loadFactor > 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)\n            throw new IllegalArgumentException();\n        if (concurrencyLevel > MAX_SEGMENTS)\n            concurrencyLevel = MAX_SEGMENTS;\n// ssize 必须是 2^n, 即 2, 4, 8, 16 ... 表示了 segments 数组的大小\n        int sshift = 0;\n        int ssize = 1;\n        while (ssize &lt; concurrencyLevel) &#123;\n            ++sshift;\n            ssize &lt;&lt;= 1;\n        &#125;\n// segmentShift 默认是 32 - 4 = 28\n        this.segmentShift = 32 - sshift;\n// segmentMask 默认是 15 即 0000 0000 0000 1111\n        this.segmentMask = ssize - 1;\n        if (initialCapacity > MAXIMUM_CAPACITY)\n            initialCapacity = MAXIMUM_CAPACITY;\n        int c = initialCapacity / ssize;\n        if (c * ssize &lt; initialCapacity)\n            ++c;\n        int cap = MIN_SEGMENT_TABLE_CAPACITY;\n        while (cap &lt; c)\n            cap &lt;&lt;= 1;\n// 创建 segments and segments[0]\n        Segment&lt;K, V> s0 =\n                new Segment&lt;K, V>(loadFactor, (int) (cap * loadFactor),\n                        (HashEntry&lt;K, V>[]) new HashEntry[cap]);\n        Segment&lt;K, V>[] ss = (Segment&lt;K, V>[]) new Segment[ssize];\n        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]\n        this.segments = ss;\n    &#125;\n\n\n\nput 流程\nput操作的步骤：\n\n首先，计算key的hash值\n其次，根据hash值找到需要操作的Segment的数组位置\nSegment为空，调用ensureSegment()方法；否则，直接调用查询到的Segment的put方法插入值\n\npublic V put(K key, V value) &#123;\n    Segment&lt;K,V> s;\n    // concurrentHashMap不允许key/value为空\n    if (value == null)\n        throw new NullPointerException();\n    int hash = hash(key);\n    // 计算出 segment 下标\n    int j = (hash >>> segmentShift) &amp; segmentMask;\n\n    // 获得 segment 对象, 判断是否为 null, 是则创建该 segment\n    if ((s = (Segment&lt;K,V>)UNSAFE.getObject\n            (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) &#123;\n        // 这时不能确定是否真的为 null, 因为其它线程也发现该 segment 为 null,\n        // 因此在 ensureSegment 里用 cas 方式保证该 segment 安全性\n        s = ensureSegment(j);\n    &#125;\n    // 进入 segment 的put 流程\n    return s.put(key, hash, value, false);\n&#125;\n\nsegment 继承了可重入所（ReentrantLock），其put方法如下\nfinal V put(K key, int hash, V value, boolean onlyIfAbsent) &#123;\n    // 尝试加锁\n    HashEntry&lt;K,V> node = tryLock() ? null :\n            // 如果不成功, 进入 scanAndLockForPut 流程\n            // 如果是多核 cpu 最多 tryLock 64 次, 进入 lock 流程\n            // 在尝试期间, 还可以顺便看该节点在链表中有没有, 如果没有顺便创建出来\n            scanAndLockForPut(key, hash, value);\n\n    // 执行到这里 segment 已经被成功加锁, 可以安全执行\n    V oldValue;\n    try &#123;\n        HashEntry&lt;K,V>[] tab = table;\n        // 再利用 hash 值，求应该放置的数组下标\n        int index = (tab.length - 1) &amp; hash;\n        // 返回数组中对应位置的元素（链表头部）\n        HashEntry&lt;K,V> first = entryAt(tab, index);\n        for (HashEntry&lt;K,V> e = first;;) &#123;\n            if (e != null) &#123;\n                // 如果已经存在值，覆盖旧值\n                K k;\n                if ((k = e.key) == key ||\n                        (e.hash == hash &amp;&amp; key.equals(k))) &#123;\n                    oldValue = e.value;\n                    if (!onlyIfAbsent) &#123;\n                        e.value = value;\n                        ++modCount;\n                    &#125;\n                    break;\n                &#125;\n                e = e.next;\n            &#125;\n            else &#123;\n                // 新增\n                // 1) 之前等待锁时, node 已经被创建, next 指向链表头\n                if (node != null) // 非空，则表示为新创建的值\n                    node.setNext(first);\n                else\n                    // 2) 创建新 node\n                    node = new HashEntry&lt;K,V>(hash, key, value, first);\n                int c = count + 1;\n                // 3) 如果超过了该 segment 的阈值，这个 segment 需要扩容\n                if (c > threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)\n                    rehash(node);\n                else\n                    // 将 node 作为链表头，头插法\n                    setEntryAt(tab, index, node);\n                ++modCount;\n                count = c;\n                oldValue = null;\n                break;\n            &#125;\n        &#125;\n    &#125; finally &#123;\n        unlock(); // 最终释放锁\n    &#125;\n    return oldValue;\n&#125;\n\n\n\nrehash 流程（扩容方法）\n发生在 put 中，因为此时已经获得了锁，所以不需要考虑线程安全\nprivate void rehash(HashEntry&lt;K, V> node) &#123;\n        HashEntry&lt;K, V>[] oldTable = table;\n        int oldCapacity = oldTable.length;\n        int newCapacity = oldCapacity &lt;&lt; 1;\n        threshold = (int) (newCapacity * loadFactor);\n        HashEntry&lt;K, V>[] newTable =\n                (HashEntry&lt;K, V>[]) new HashEntry[newCapacity];\n        int sizeMask = newCapacity - 1;\n        for (int i = 0; i &lt; oldCapacity; i++) &#123;\n            HashEntry&lt;K, V> e = oldTable[i];\n            if (e != null) &#123;\n                HashEntry&lt;K, V> next = e.next;\n                int idx = e.hash &amp; sizeMask;\n                if (next == null) // Single node on list\n                    newTable[idx] = e;\n                else &#123; // Reuse consecutive sequence at same slot\n                    HashEntry&lt;K, V> lastRun = e;\n                    北京市昌平区建材城西路金燕龙办公楼一层 电话：400 - 618 - 9090\n                    int lastIdx = idx;\n// 过一遍链表, 尽可能把 rehash 后 idx 不变的节点重用\n                    for (HashEntry&lt;K, V> last = next;\n                         last != null;\n                         last = last.next) &#123;\n                        int k = last.hash &amp; sizeMask;\n                        if (k != lastIdx) &#123;\n                            lastIdx = k;\n                            lastRun = last;\n                        &#125;\n                    &#125;\n                    newTable[lastIdx] = lastRun;\n// 剩余节点需要新建\n                    for (HashEntry&lt;K, V> p = e; p != lastRun; p = p.next) &#123;\n                        V v = p.value;\n                        int h = p.hash;\n                        int k = h &amp; sizeMask;\n                        HashEntry&lt;K, V> n = newTable[k];\n                        newTable[k] = new HashEntry&lt;K, V>(h, p.key, v, n);\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n// 扩容完成, 才加入新的节点\n        int nodeIndex = node.hash &amp; sizeMask; // add the new node\n        node.setNext(newTable[nodeIndex]);\n        newTable[nodeIndex] = node;\n// 替换为新的 HashEntry table\n        table = newTable;\n    &#125;\n\n\n\nget 流程\nget 时并未加锁，用了UNSAFE方法保证了可见性，扩容过程中，get 先发生就从旧表取内容，get后发生就从新表取内容\npublic V get(Object key) &#123;\n    Segment&lt;K,V> s; // manually integrate access methods to reduce overhead\n    HashEntry&lt;K,V>[] tab;\n    // 1. hash 值\n    int h = hash(key);\n    long u = (((h >>> segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE;\n    // 2. 根据 hash 找到对应的 segment\n    if ((s = (Segment&lt;K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp;\n        (tab = s.table) != null) &#123;\n        // 3. 找到segment 内部数组相应位置的链表，遍历\n        for (HashEntry&lt;K,V> e = (HashEntry&lt;K,V>) UNSAFE.getObjectVolatile\n                 (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE);\n             e != null; e = e.next) &#123;\n            K k;\n            if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k)))\n                return e.value;\n        &#125;\n    &#125;\n    return null;\n&#125;\n\n\n\nsize 计算流程\n\n计算元素个数前，先不加锁计算两次，如果前后结果一样，认为个数正确返回\n如果不一样，进行重试，次数超过3，将所有 segment 锁住，重新计算个数返回\n\npublic int size() &#123;\n// Try a few times to get accurate count. On failure due to\n// continuous async changes in table, resort to locking.\n        final Segment&lt;K, V>[] segments = this.segments;\n        int size;\n        boolean overflow; // true if size overflows 32 bits\n        long sum; // sum of modCounts\n        long last = 0L; // previous sum\n        int retries = -1; // first iteration isn't retry\n        try &#123;\n            for (; ; ) &#123;\n                if (retries++ == RETRIES_BEFORE_LOCK) &#123;\n// 超过重试次数, 需要创建所有 segment 并加锁\n                    for (int j = 0; j &lt; segments.length; ++j)\n                        ensureSegment(j).lock(); // force creation\n                &#125;\n                sum = 0L;\n                size = 0;\n                overflow = false;\n                for (int j = 0; j &lt; segments.length; ++j) &#123;\n                    Segment&lt;K, V> seg = segmentAt(segments, j);\n                    if (seg != null) &#123;\n                        sum += seg.modCount;\n                        int c = seg.count;\n                        if (c &lt; 0 || (size += c) &lt; 0)\n                            overflow = true;\n                    &#125;\n                &#125;\n                if (sum == last)\n                    break;\n                last = sum;\n            &#125;\n        &#125; finally &#123;\n            if (retries > RETRIES_BEFORE_LOCK) &#123;\n                for (int j = 0; j &lt; segments.length; ++j)\n                    segmentAt(segments, j).unlock();\n            &#125;\n        &#125;\n        return overflow ? Integer.MAX_VALUE : size;\n    &#125;\n\n\n\n\n\nLinkedBlockingQueue基本的入队出队\n\n\n\n\n\n\n\n\n入队\npublic class LinkedBlockingQueue&lt;E> extends AbstractQueue&lt;E>\n            implements BlockingQueue&lt;E>, java.io.Serializable &#123;\n        static class Node&lt;E> &#123;\n            E item;\n            /**\n             * 下列三种情况之一\n             * - 真正的后继节点\n             * - 自己, 发生在出队时\n             * - null, 表示是没有后继节点, 是最后了\n             */\n            Node&lt;E> next;\n\n            Node(E x) &#123;\n                item = x;\n            &#125;\n        &#125;\n    &#125;\n\n初始化链表 last &#x3D; head &#x3D; new Node(null); Dummy 节点用来占位，item为null\n\n\n当一个节点入队 last &#x3D; last.next &#x3D; node;\n\n\n再来一个节点入队 last &#x3D; last.next &#x3D; node;\n\n\n\n\n\n\n\n\n\n\n\n出队\nNode&lt;E> h = head;\nNode&lt;E> first = h.next; h.next = h; // help GC\nhead = first; E x = first.item;\nfirst.item = null;\nreturn x;\n\nh &#x3D; head\n\n\nfirst &#x3D; h.next\n\n\nh.next &#x3D; h\n\n\nhead &#x3D; first\n\n\nE x = first.item;\nfirst.item = null;\nreturn x;\n\n\n\n\n\n加锁分析高明之处在于用了两把锁和 dummy 节点\n\n同一把锁，同一时刻，最多只允许有一个线程（生产者或消费者，二选一）执行\n用两把锁，同一时刻，可以允许两个线程同时运行（一个生产者与一个消费者）运行\n消费者与消费者线程仍然串行\n生产者与生产者线程仍然串行\n\n\n\n线程安全分析\n\n当节点总数大于 2 时（包括 dummy 节点），putLock 保证的是 last 节点的线程安全，takeLock保证的是 head 节点的线程安全。两把锁保证了入队和出队没有竞争\n当节点总数等于 2 时（即一个 dummy 节点，一个正常节点），这时候，仍然是两把锁锁两个对象，不会竞争\n当节点总数等于 1 时（就一个 dummy 节点）这时 take 线程会被 notEmpty 条件阻塞，有竞争，有阻塞\n\n// 用于 put（阻塞） offer（非阻塞）\nprivate final ReentrantLock putLock = new ReentrantLock();\n// 用户 take（阻塞） poll（非阻塞）\nprivate final ReentrantLock takeLock = new ReentrantLock();\n\nput 操作\npublic void put(E e) throws InterruptedException &#123;\n        if (e == null) throw new NullPointerException();\n        int c = -1;\n        Node&lt;E> node = new Node&lt;E>(e);\n        final ReentrantLock putLock = this.putLock;\n\t\t\t\t// count 用来维护元素计数\n        final AtomicInteger count = this.count;\n        putLock.lockInterruptibly();\n        try &#123;\n\t\t\t\t\t\t// 满了等待\n            while (count.get() == capacity) &#123;\n\t\t\t\t\t\t\t// 倒过来读就好: 等待 notFull\n                notFull.await();\n            &#125;\n\t\t\t\t\t\t// 有空位, 入队且计数加一\n            enqueue(node);\n            c = count.getAndIncrement();\n\t\t\t\t\t\t// 除了自己 put 以外, 队列还有空位, 由自己叫醒其他 put 线程\n            if (c + 1 &lt; capacity)\n                notFull.signal();\n        &#125; finally &#123;\n            putLock.unlock();\n        &#125;\n\t\t\t\t// 如果队列中有一个元素, 叫醒 take 线程\n        if (c == 0)\n\t\t\t\t// 这里调用的是 notEmpty.signal() 而不是 notEmpty.signalAll() 是为了减少竞争\n            signalNotEmpty();\n    &#125;\n\n\n\ntake 操作\npublic E take() throws InterruptedException &#123;\n        E x;\n        int c = -1;\n        final AtomicInteger count = this.count;\n        final ReentrantLock takeLock = this.takeLock;\n        takeLock.lockInterruptibly();\n        try &#123;\n            while (count.get() == 0) &#123;\n                notEmpty.await();\n            &#125;\n            x = dequeue();\n            c = count.getAndDecrement();\n            if (c > 1)\n                notEmpty.signal();\n        &#125; finally &#123;\n            takeLock.unlock();\n        &#125;\n// 如果队列中只有一个空位时, 叫醒 put 线程\n// 如果有多个线程进行出队, 第一个线程满足 c == capacity, 但后续线程 c &lt; capacity\n        if (c == capacity)\n// 这里调用的是 notFull.signal() 而不是 notFull.signalAll() 是为了减少竞争\n            signalNotFull();\n        return x;\n    &#125;\n\n性能比较\n主要列举LinkedBlockingQueue 与 ArrayBlockingQueue 的性能比较\n\nLinked 支持有界，Array 强制有界\nLinked 链表实现，Array 数组实现\nLinked 是懒惰的，而 Array 需要提前初始化 Node 数组\nLinked 每次入队会生成新的 Node，而 Array 的Node是提前创建好的\nLinked 两把锁，Array一把锁\n\nConcurrentLinkedQuqueConcurrentLinkedQueue 的设计与 LinkedBlockingQueue 非常像，也是\n\n两把【锁】，同一时刻，可以允许两个线程同时（一个生产者与一个消费者）执行\ndummy 节点的引入让两把【锁】将来锁住的是不同对象，避免竞争\n只是【锁】使用了CAS来实现\n\n事实上，ConcurrentLinkedQueue 应用还是非常广泛的\n例如之前的 Tomcat 的 Connector 结构，Acceptor 作为生产者向 Poller 消费者传递事件信息时，正是采用了 ConcurrentLinkedQueue 将 SocketChannel 给 Poller 使用\n\n\n\n\n\n\nCopyOnWriteArrayListCopyOnWriteArraySet 是它的马甲\n底层实现采用了写入时拷贝的思想，增删改操作底层会将数组拷贝一份，更改操作在新数组上执行，这时不影响其他的线程读并发，读写分离\n\n\n\n\n\n\n\n\n\n\n\n以上源码是JDK11，在JDK8中使用的是可重入锁而不是 synchronized\n其它读操作并未加锁\n\n\n适合【读多写少】的应用场景\nget 弱一致性\n\n\n弱一致性并非完全不好\n\n数据库的MVCC都是弱一致性的表现\n并发高和一致性是矛盾的，需要权衡\n\nThreadLocalThreadLocal、Thread、ThreadLocalMap联系\n\n\n","slug":"JUC并发编程","date":"2022-09-30T09:38:55.000Z","categories_index":"","tags_index":"学习笔记,JUC","author_index":"JuneQQQ"},{"id":"d286e43e20ffc8862d83a0fa7399e8da","title":"JVM调优入门","content":"性能监控与调优第一章-概述大厂面试题\n\n\n\n\n\n背景说明生产环境的问题\n\n生产环境发生内存溢出如何处理？\n生产环境应该给服务器分配多少内存合适？\n如何应对垃圾回收器的性能调优？\n生产环境CPU负载飙高如何处理？\n生产环境应该给分配多少线程合适？\n不加log，如何确定请求是否执行了某一代码？\n不加log，如何实时查看某个方法的入参与返回值？\n\n调优目的\n\n防止出现OOM\n解决OOM\n减少Full GC出现概率\n\n性能优化的步骤第一步（发现问题）：性能监控一种以非强行或者入侵方式收集或查看应用运营性数据的活动。\n监控通常是指一种在生产、质量评估或者开发环境下实施的带有预防或主动性的活动。\n当应用相关干系人提出性能问题却没有足够多的线索时，首先我们需要进行性能监控，其次是性能分析。\n第二步（排查问题）：性能分析一种以侵入方式收集运行性能数据的活动，它会影响应用的吞吐量或者响应性。\n性能分析是针对性能问题的答复结果，关注的范围通常比性能监控更加集中。\n性能分析很少在生产环境下进行，通常是在质量评估、系统测试或者开发环境下进行，是性能监控之后的步骤。\n第三步（解决问题）：性能调优一种为改善应用响应性或吞吐量而更改参数、源代码、属性配置的活动，性能调优是在性能监控、性能分析之后的活动。\n性能测评指标\n\n\n\n\n\n\n\n\n停顿时间（响应时间)\n提交请求和返回请求的响应之间使用的时间，一般比较关注平均响应时间\n常用操作的响应时间表：\n\n\n在垃圾回收环节中：\n暂停时间：执行垃圾收集时，程序的工作线程被暂停的时间。-XX:MaxGCPauseMillis\n\n\n\n\n\n\n\n\n\n吞吐量 \n在GC中：运行用户代码的时间占总运行时间的比例（总运行时间：程序的运行时间 + 内存回收时间）；吞吐量为 1 - 1&#x2F;(1+n)-XX:GCTimeRatio=n\n\n\n\n\n\n\n\n\n\n并发数\n同一时刻，对服务器有实际交互的请求数\n\n\n\n\n\n\n\n\n\n内存占用\nJava堆区所占的内存大小\n第二章-JVM监控及诊断工具（命令行篇）概述性能诊断是软件工程师在日常工作中需要经常面对和解决的问题，在用户体验至上的今天，解决好应用的性能问题能带来巨大的收益。\njps：查看正在运行的 Java 进程 pid\n\n\n\njstat：查看JVM统计信息jstat -&lt;option&gt; [-t][-h&lt;lines&gt;]&lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]\noption参数\n\n垃圾回收相关\n-gc：显示GC相关的堆信息。包括Eden区、两个Survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息。\n-gccapacity：显示内容与-gc基本相同，但输出主要关注Java堆各个区域用到的最大、最小空间\n-gcutil：显示内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比\n-gccause：与上面功能一样，但是会额外输出导致最后一次或当前正在发生的GC产生的原因。\n-gcnew：显示新生代GC状况\n-gcnewcapacity：显示内容与上面基本相同，输出主要关注使用到的最大、最小空间\n-geold：显示老年代GC状况\n-gcoldcapacity：显示内容与-gcold基本相同，输出主要关注使用到的最大、最小空间\n-gcpermcapacity：显示永久代使用到的最大、最下空间\n\n\nJIT相关\n-compiler：显示JIT编译器编译过的方法、耗时等信息\n-printcompilation：输出已经被JIT编译的方法\n\n\n\njinfo：实时查看和修改JVM配置参数\njinfo -flag 具体参数 PID   查看某个java进程的具体参数的值\njinfo -floag [+|-]具体参数  PID       修改该参数的值，针对boolean类型\njinfo -floag 具体参数&#x3D;n  PID        修改该参数的值，针对数值类型\njava -XX:+PrintFlagsInitial    查看所有JVM参数启动的初始值\njava -XX:+PrintFlagsFinal     查看所有JVM参数的最终值\n\njmap：导出内存映像文件&amp;内存使用情况\n-dump：生成Java堆转储快照-dump文件，-dump:live 只保存堆中存活的对象\n\n-heap：输出整个堆空间的详细信息，包括GC的使用、堆配置信息，以及内存的使用信息等，-heap:live 只保存堆中存活的对象\n\n-histo：输出堆中对象的统计信息，包括类、实例数量和合计容量\n\n-permstat：以ClassLoader为统计口径输出永久代的内存状况信息（仅linux&#x2F;solaris）\n\n-finalizerinfo：显示在F-Queue中等带Finalizer线程执行finalize方法的对象（仅linux&#x2F;solaris）\n\n-F：当虚拟机进程对-dump选项没有任何响应时，可以使用此选项强制生成dump文件（仅linux&#x2F;solaris）\n\n-h | -help：jmap工具使用帮助命令\n\n-J  ：传递参数给jmap启动的jvm\n\n手动生成：\n\njmap -dump:live,format&#x3D;b,file&#x3D;  \n\n\n自动生成\n\n-XX:+HeapDumpOnOutOfMemoryError     设置开启\n-XX:+HeapDumpPath&#x3D;&lt;filename.hrof&gt;      指定位置\n\n\n\njhat：JDK自带堆分析工具略。请使用图形化分析工具\njstack：打印JVM中线程快照jstack option pid\n\n-F：当正常输出的请求不被响应时，强制输出线程堆栈\n-l：除堆栈外，显示关于锁的附加信息\n-m：如果调用到本地方法的话，可以显示C&#x2F;C++的堆栈\n-h：帮助操作\n\njcmd：多功能命令行\njcm -l：列出所有JVM进程\njcmd pid help：针对指定的进程，列出支持的所有命令\njcmd pid 具体命令：显示指定进程的指令命令的数据\n\n第三章-JVM监控及诊断工具（图形界面）Visual VM远程连接\n\n确定远程服务器的ip地址\n添加JMX（通过JMX技术具体监控远端服务器的哪个Java进程）\n修改 bin&#x2F;catalina.sh 文件，连接远程的tomcat\n在 ..&#x2F;conf 中添加jmxremote.access 和 jmxremote.password 文件\n将服务器地址改为公网ip地址\n设置阿里云安全策略和防火墙策略\n启动tomcat，查看tomcat启动日志和端口监听\nJMX中输出端口号、用户名、密码登录\n\n补充：内存泄漏案例\n\n\n\n\n\n\n\n\n\n静态集合类\n\n\n\n\n\n\n\n\n\n\n\n\n\n单例模式\n\n单例模式，和静态集合导致内存泄漏的原因类似，因为单例的静态特性，其生命周期和JVM生命周期一样长，所以如果单例对象持有外部对象的引用，那么这个对象不会被回收，造成内存泄漏。\n\n\n\n\n\n\n\n\n\n3-内部类持有外部类\n内部类持有外部类，如果一个外部类的实例对象方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象不会被垃圾回收，造成内存泄漏。\n\n\n\n\n\n\n\n\n\n4-各种连接，如数据库连接、网络连接和IO连接\n\n\n\n\n\n\n\n\n\n\n\n5-变量（对象）不合理的作用域\n\n\n\n\n\n\n\n\n\n\n\n6-改变哈希值\n当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了。否则，对象修改后的哈希值与最初存储进HashSet集合时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄漏。\n这也是String为什么被设置成了不可变类型，我们可以放心地把String存入HashSet，或者把String当做HashMap的key值。\n\n\n\n\n\n\n\n\n\n7-缓存泄漏\n内存泄漏的另外一个常见来源是缓存，一旦把对象引用放到缓存中，就很容易遗忘。对于这个问题，可以使用WeakHashMap代表缓存，此种Map的特点是，当除了自身有对key的引用外，此key没有其他引用那么此map会自动丢弃此值。\n\n\n\n\n\n\n\n\n\n8-监听器和回调\n内存泄漏第三个常见来源是监听器和其他回调，如果客户端在你实现的API中注册回调，却没有显式地取消，那么就会聚集。\n需要确保回调即被当做垃圾回收的最佳方法是只保存它的弱引用，例如将它们保存为 WeakHashMap 中的键。\n\n第四章-分析GC日志01-GC日志参数 见附录\n02-GC日志格式复习：GC分类针对HotSpot VM的实现，它里面的GC按照回收区域又分为两大类型：一种是部分收集（Partial GC），一种是整堆收集（Full GC）\n\n部分收集：不是完整收集整个Java堆的垃圾。其中又分为：\n新生代收集（Minor GC &#x2F; Young GC）：只是新生代（Eden\\S1,S1）的垃圾收集\n老年代收集（Major GC &#x2F; Old GC）：只是老代的垃圾收集\n目前，只有CMS GC会有单独收集老年代的行为。\n注意，很多时候Major GC 和 Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收\n\n\n混合收集（Mixed GC）：收集整个新生代以及老年代的垃圾。\n目前，只有G1 GC会有这种行为\n\n\n\n\n整堆收集（Full GC）：收集整个java堆和方法区的垃圾\n\nGC日志分类MinorGC\n\nFullGC\n\n03-GC日志分析工具垃圾收集器\nSerial -&gt; Default   New  Generation  -&gt; [DefNew]\nParNew -&gt; Parallel New Generation -&gt; [ParNew] \nParallel Scavenge -&gt; [PSYoungGen]\nParallel Old Generation -&gt; [ParOldGen]\nG1 -&gt; garabage-first heap\nAllocation Failure -&gt; 表名本次引起GC的原因是年轻代中没有足够的空间能够存储新的数据了\n\nGC前后情况通过图示，我们可以发现GC日志的规律一般都是：GC前内存占用 -&gt; GC后内存占用（该区域内存总大小）\n\n\n中括号内：GC回收前年轻代堆大小，回收后大小，（年轻代堆总大小）括号外：GC回收前年轻代和老年代的大小，回收后大小，（年轻大和老年代总大小）\nGC时间GC日志中有三个时间：user、sys、real\n\nuser - 进程执行用户态代码（核心之外）所使用的时间。这是执行此进程所使用的实际CPU时间，其他进程和此进程阻塞的时间并不包括在内。在垃圾收集的情况下，表示GC线程执行所使用的CPU总时间。\nsys - 进程在内核态消耗的CPU时间，即 在内核执行系统调用或等待系统事件所使用的的CPU时间\nreal - 程序从开始到结束所使用的时钟时间。这个时间包括其他进程使用的时间片和进程阻塞的时间（比如等带 I&#x2F;O 完成）。对于并行GC，这个数字应该接近（用户时间 + 系统时间）除以垃圾收集器使用的线程数。\n\n由于多核的原因，一般的GC事件中，real time要小于 sys+user 的，因为一般是多个线程并发的去做GC，所以real time是要小于sys + user的。如果 real &gt; sys + user 的话，则你的应用可能存在以下问题：IO负载非常重或者CPU不够用。\n","slug":"JVM调优入门","date":"2022-09-30T09:38:43.000Z","categories_index":"","tags_index":"JVM,学习笔记","author_index":"JuneQQQ"},{"id":"1f9dc448d62e7f280399f2b271c23383","title":"JVM运行时参数","content":"JVM运行时参数01-JVM 参数选项类型类型一：标准参数选项\n特点\n以 - 开头\n比较稳定，以后基本不会变化\n可以用 java 或 java -help 看到可选项\n\n\n\n类型二：-X参数选项\n特点\n非标准化参数\n功能比较稳定\n以 -X 开头\nJVM 的 JIT 编译模式的选项\n可以通过 java -X 查看可选项\n\n\n特别的，以下三个等价，都是 -XX类型参数\n-Xms 设置初始堆大小\n-XX:InitialHeapSize\n\n\n-Xmx 设置最大堆大小\n-XX:MaxHeapSize\n\n\n-Xss 设置Java线程堆栈大小\n-XX:ThreadStackSize\n\n\n\n\n\n类型三：-XX参数选项\n特点\n非标准化参数\n使用最多的参数类型\n这类选项属于实验型，不稳定\n以 -XX 开头\n用于开发和调试JVM\n\n\n分类\nboolean\n-XX:+\n-XX:-\n\n\n非 boolean\n数值型：-XX:&#x3D;\n非数值型格式：-XX:&#x3D;\n\n\n\n\n特别的，-XX:+PrintFlagsFinal：\n输出所有有参数的名称和默认值\n默认不包括 Diagnostic 和 Expermental 的参数\n可以配合以下两个指令使用\n-XX:+UnlockDiagnosticVMOptions\n-XX:UnlockExperimentalVMOptions\n\n\n\n\n\n02-添加JVM参数选项直接运行 jar 包java -Xms50m -Xmx50m -XX:+PrintGCDetails -jar xx.jar\n通过 Tomcat\nLinux系统下可以在 tomcat&#x2F;bin&#x2F;catalina.sh 添加如下配置：\nJAVA_OPTS=&quot;-Xms512M -Xmx1024M&quot;\n\n\nWindows系统下在 catalina.bat 中添加如下配置\nset &quot;JAVA_OPTS=-Xms512M -Xmx1024M&quot;\n\n\n\n程序运行过程中\n使用 jinfo -flag &#x3D;     \n使用 jinfo -flag [ +|- ] \n\n03-常用的JVM参数选项打印设置的XX选项及值\n-XX:+PrintCommandLineFlags\n可以让程序运行前打印出用户手动设置或JVM自动设置的XX选项\n\n\n-XX:+PrintFlagsInitial\n表示打印出所有XX选项的默认值\n\n\n-XX:+PrintFlagsFinal\n表示打印出XX选项在程序运行时生效的值\n\n\n-XX:+PrintVMOptions\n打印JVM的参数\n\n\n\n堆、栈、方法区等内存大小设置栈\n-Xss128k\n设置每个线程的栈大小为128k\n等价于-XX:ThreadStackSize=128k\n\n\n\n堆内存\n-Xms3550m\n等价于-XX:InitialHeapSize\n设置JVM初始堆内存为3550m\n\n\n-Xmx3550m\n等价于-XX:MaxHeapSize\n设置JVM最大最内存为3550m\n\n\n-Xmn2g\n设置年轻代大小为2G\n官方推荐配置为整个堆大小的3&#x2F;8\n\n\n-XX:NewSize=1024m\n设置年轻代初始值为1024m\n\n\n-XX:MaxNewSize=1024m\n设置年轻代最大值为1024m\n\n\n-XX:SurvivorRatio=8\n设置年轻代中Eden与一个Survivor的比例，默认8\n\n\n-XX:+UseAdaptiveSizePolicy\n自动选择各区的大小比例\n\n\n-XX:NewRatio=4\n设置老年代与年轻代的比值\n\n\n-XX:PretenureSizeThreadshold=1024\n设置让大于此阈值的对象直接分配在老年代，单位字节\n只对Serial、ParNew收集器有效\n\n\n-XX:MaxTenuringThrehold=15\n新生代每次MinorGC之后，还存活的对象年龄+1，当对象的年龄大于此设定值时晋升老年代，默认15\n\n\n-XX:StringTableSize=1009\n设置StringTableSize 大小，当系统中字符串较多时，扩大此值可以提升性能\n\n\n\nOutOfMemory 相关的选项\n-XX:+HeapDumpOnOutOfMemoryError\n表示在内存出现OOM的时候，把Heap转存（Dump）到文件便于后续分析\n\n\n-XX:+HeapDumpBeforeFullGC\n表示出现Full GC之前，生成Heap转储文件\n\n\n-XX:+HeapDumpPath=&lt;path&gt;\n指定heap转存文件的路径\n\n\n-XX:OnOutOfMemoryError\n指定一个可行性程序或者脚本的路径，当发生OOM的时候，执行该脚本\n\n\n\n\n\n\n\n垃圾回收器相关选项\n\n查看默认垃圾收集器\n-XX:+PrintCommandLineFlags\n查看命令行相关参数\n\n\njinfo  -flag  相关垃圾回收器参数  进程ID\n\nSerial 回收器Serial收集器作为HotSpot中Client模式下的默认新生代垃圾收集器。Serial Old是运行在Client模式下默认的老年代垃圾回收器。\n\n-XX:+UseSerialGC：使用该GC\n\nParNew 回收器\n-XX:+UseParNewGC：手动指定使用ParNew收集器执行内存回收任务。它表示年轻代使用并行收集器，不影响老年代。\n\n-XX:ParallelGCThreads=n：限制线程数量，默认开启和CPU数据相同的线程数。\n\n\nParallel 回收器\n-XX:+UseParallelGC：手动指定年轻代使用Parallel并行收集器执行内存回收任务\n-XX:+UseParallelOldGC：手动指定老年代都是使用并行回收收集器。\n分别适用于老年代和新生代，JDK 8 默认开启\n\n\n-XX:ParallelGCThreads：设置年轻代并行收集器的线程数。一般地，最好与CPU数量相等，以避免过多的线程数影响垃圾收集性能。\n默认情况下，当CPU数量小于8个，ParallelGCThreads的值等于CPU数量\n当CPU数量大于8个，ParallelGCThreads的值等于 3+[ 5*CPU_Count &#x2F;8 ]\n\n\n-XX:MaxGCPauseMillis：设置垃圾收集器最大停顿时间（STW），单位毫秒\n为了尽可能的把停顿时间控制在MaxGCPauseMillis内，收集器在工作时会调整Java堆大小或者其他一些参数。\n对于用户来讲，停顿时间越短体验越好，但是在服务器端，我们注重高并发，整体的吞吐量，所以服务器端适合Parallel，进行控制\n该参数使用需谨慎\n\n\n-XX:GCTimeRatio：垃圾收集时间占总时间的比例。用于衡量吞吐量的大小\n取值范围（0,100）。默认99，也就是垃圾回收时间不超过1%\n与前一个参数有一定的矛盾性，暂停时间越长，Ratio参数就越容易超过设定的比例。\n\n\n-XX:+UseAdaptiveSizePolicy：设置Parallel Scavenge收集器具有自适应调节策略\n这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数会被自动调整，已达到在堆大小、吞吐量和停顿时间的平衡点。\n在手动调优比较苦难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMillis），让虚拟机自己完成调优工作。\n\n\n\nCMS 回收器\n-XX:+UseConcMarkSweepGC：手动指定使用CMS收集器执行内存回收任务。\n开启该参数后会自动将-XX:+UseParNewGC打开\n\n\n-XX:CMSlnitiatingOccupanyFraction：设置堆内存使用的阈值，一旦达到该阈值，便开始进行回收。\nJDK5及以前的版本默认68；JDK6及以上的版本默认92\n如果内存增长缓慢，则可以设置一稍大的值，大的阈值可以有效降低CMS的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。反之，如果应用程序内存使用率增长很快，则应该降低这个阈值，以避免频繁触发老年代串行收集器。因此通过该选项便可以有效降低Full GC的执行次数。\n\n\n-XX:+UseCMSCompactAtFullCollection：用于指定在执行完Full GC后对内存空间进行压缩整理，以避免内存碎片的产生。不过由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变长了。\n-XX:CMSFullGCBeforeCompaction：设置在执行多少次Full GC后对内存空间进行压缩整理\n-XX:ParallelCMSThreads：设置CMS的线程数量\nCMS默认启动的线程数是 （ParallelGCThreads+3）&#x2F; 4，ParallelGCThreads是年轻代并行收集器的线程数。当CPU资源比较紧张时，受CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕\n\n\n\n特别说明\n\nJDK 9：CMS被标记 deprecated\nJDK 14：删除CMS垃圾收集器\n\nG1 回收器\n-XX:MaxGCPauseMillis：设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不保证达到），默认200ms\n-XX:ParallelGCThread：设置STW时线程数的值，最多为8\n-XX:ConcGCThreads：设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGCThreads）的1&#x2F;4左右\n-XX:InitiatingHeapOccupancyPercent：设置触发并发GC周期的Java堆占用率阈值。超过此值，触发GC，默认45\n-XX:G1NewSizePercent   -XX:G1MaxNewSizePercent：新生代占用整个堆内存的最小百分比（默认5%）、最大百分比（默认60%）\n-XX:G1ReservePercent=10：保留内存区域，防止 to space（Survivor中的to区）溢出\n\n\n\n\n\nGC日志相关选项常用参数\n-verbose:gc\n输出gc日志信息，默认输出到标准输出。\n\n\n-XX:+PrintGC\n等同于-verbose:gc\n表示打开简化的GC日志\n\n\n-XX:+PrintGCDetails\n在发生垃圾回收时打印内存回收详细的日志，并在进程退出时输出当前内存各区域分配情况\n\n\n-XX:+PrintGCTimeStamps\n输出GC发生时的时间戳\n\n\n-XX:+PrintGCDataStamps\n输出GC发生时的时间戳（形如 2013-05-04T21:53:59.234+0800）\n\n\n-XX:+PrintHeapAtGC\n每一次GC前和GC后，都打印堆信息\n\n\n-Xloggc:\n把GC日志写入到一个文件中去，而不是打印到标准输出中\n\n\n\n其他参数\n-XX:+DisableExplicitGC\n禁止hotspot执行System.gc( )，默认禁用\n\n\n-XX:ReservedCodeCacheSize&#x3D;[g|m|k]\n-XX:InitialCodeCacheSize&#x3D;[g|m|k]\n指定代码缓存的大小\n\n\n-XX:+UseCodeCacheFlushing\n使用该参数让JVM放弃一些被编译的代码，避免代码缓存占满时JVM切换到interpreted-only情况\n\n\n-XX:+DoEscapeAnalysis\n开启逃逸分析\n\n\n-XX:+UseBiasedLocking\n开启偏向锁\n\n\n-XX:+UseLargePages\n开启使用大页面\n\n\n-XX:+UseTLAB\n使用TLAB，默认打开\n\n\n-XX:+PrintTLAB\n打印TLAB的使用情况\n\n\n-XX:TLABSize\n设置TLAB大小\n\n\n\n04-通过Java代码获取JVM参数Java提供了 java.lang.management 包用于监视和管理Java虚拟机和Java运行时中的其他组件，它允许本地和远程监控和管理运行的Java虚拟机。其中ManagementFactory这个类还是挺常用的。另外还有Runtime类也可以获取一些内存、CPU核数等相关的数据。\n","slug":"JVM运行时参数","date":"2022-09-30T09:38:36.000Z","categories_index":"","tags_index":"JVM,学习笔记","author_index":"JuneQQQ"},{"id":"d216cb7f62edb6d66c0218a494244405","title":"Vue基础","content":"1. Vue基础1.1 Demo&lt;!-- 准备好一个容器 --&gt;\n&lt;div id&#x3D;&quot;demo&quot;&gt;\n\t&lt;h1&gt;&#123;&#123;name.toUpperCase()&#125;&#125;，&#123;&#123;address&#125;&#125;&lt;&#x2F;h1&gt;\n&lt;&#x2F;div&gt;\n\n&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;vue@2.7.10&#x2F;dist&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;\n&lt;script type&#x3D;&quot;text&#x2F;javascript&quot; &gt;\n\tVue.config.productionTip &#x3D; false &#x2F;&#x2F;阻止 vue 在启动时生成生产提示。\n\n\t&#x2F;&#x2F;创建Vue实例\n\tnew Vue(&#123;\n\t\tel:&#39;#demo&#39;, &#x2F;&#x2F;el用于指定当前Vue实例为哪个容器服务，值通常为css选择器字符串。\n\t\tdata:&#123; &#x2F;&#x2F;data中用于存储数据，数据供el所指定的容器去使用，值我们暂时先写成一个对象。\n\t\t\tname:&#39;hello,world&#39;,\n\t\t\taddress:&#39;北京&#39;\n\t\t&#125;\n\t&#125;);\n&lt;&#x2F;script&gt;\n\n\n\n1.2 容器绑定&lt;script&gt;\n   \t&#x2F;&#x2F; 第一种 \n\tconst vm &#x3D; new Vue(&#123;\n\t\tel:&#39;#root&#39;,\n\t\tdata:&#123;\n\t\t\tname:&#39;jack&#39;,\n        &#125;\n\t&#125;)\n    \n    &#x2F;&#x2F; 第二种\n    vm.$mount(&#39;#root&#39;)\n&#x2F;&#x2F;   setTimeout(()&#x3D;&gt;&#123;\n&#x2F;&#x2F;      v.$mount(&#39;#root&#39;)\n&#x2F;&#x2F;   &#125;,1000);\n&lt;&#x2F;script&gt;\n\n\n\n1.3 数据绑定\n单向绑定(v-bind)：数据-&gt;视图\n双向绑定(v-model)：数据 ↔ 视图\n双向绑定一般都应用在表单类元素上（如：input、select等）\n\n\n\n&lt;div id&#x3D;&quot;root&quot;&gt;\n\t&lt;!-- 普通写法 单向数据绑定 --&gt;\n    单向数据绑定：&lt;input type&#x3D;&quot;text&quot; v-bind:value&#x3D;&quot;name&quot;&gt;&lt;br&#x2F;&gt;\n    双向数据绑定：&lt;input type&#x3D;&quot;text&quot; v-model:value&#x3D;&quot;name&quot;&gt;&lt;br&#x2F;&gt;\n    \n    &lt;!-- 简写 v-model:value 可以简写为 v-model，因为v-model默认收集的就是value值--&gt;\n    单向数据绑定：&lt;input type&#x3D;&quot;text&quot; :value&#x3D;&quot;name&quot;&gt;&lt;br&#x2F;&gt;\n    双向数据绑定：&lt;input type&#x3D;&quot;text&quot; v-model&#x3D;&quot;name&quot;&gt;&lt;br&#x2F;&gt;\n&lt;&#x2F;div&gt;\n\n&lt;script&gt;\n    new Vue(&#123;\n\t\tel:&#39;#root&#39;,\n        &#x2F;&#x2F; 第一种\n\t\tdata:&#123;\n\t\t\tname:&#39;jack&#39;,\n        &#125;\n        &#x2F;&#x2F; 第二种，启用组件时需要采用这种写法\n        data() &#123;\n        \treturn &#123;\n                name: &#39;jack&#39;\n            &#125;\n    \t&#125;\n\t&#125;)\n&lt;&#x2F;script&gt;\n\n\n\n1.4 数据代理\n1.5 事件处理\n\n\n\n\n\n\n\n\nDemo如下\n&lt;!-- 准备好一个容器--&gt;\n&lt;div id&#x3D;&quot;root&quot;&gt;\n    &lt;h2&gt;欢迎来到&#123;&#123;name&#125;&#125;学习&lt;&#x2F;h2&gt;\n    &lt;!-- &lt;button v-on:click&#x3D;&quot;showInfo&quot;&gt;点我提示信息&lt;&#x2F;button&gt; --&gt;\n    &lt;button @click&#x3D;&quot;showInfo1&quot;&gt;点我提示信息1（不传参）&lt;&#x2F;button&gt;\n    &lt;!-- 主动传事件本身 --&gt;\n    &lt;button @click&#x3D;&quot;showInfo2($event,66)&quot;&gt;点我提示信息2（传参）&lt;&#x2F;button&gt;\n&lt;&#x2F;div&gt;\n\n&lt;script&gt;\n\tconst vm &#x3D; new Vue(&#123;\n        el:&#39;#root&#39;,\n        data:&#123;\n            name:&#39;vue&#39;,\n        &#125;,\n        methods:&#123;\n            &#x2F;&#x2F; 如果vue模板没有写event，会自动传 event 给函数\n            showInfo1(event)&#123;\n                &#x2F;&#x2F; console.log(event.target.innerText)\n                &#x2F;&#x2F; console.log(this) &#x2F;&#x2F;此处的this是vm\n                alert(&#39;同学你好！&#39;)\n            &#125;,\n            showInfo2(event,number)&#123;\n                console.log(event,number)\n                &#x2F;&#x2F; console.log(event.target.innerText)\n                &#x2F;&#x2F; console.log(this) &#x2F;&#x2F;此处的this是vm\n                alert(&#39;同学你好！！&#39;)\n            &#125;\n        &#125;\n\t&#125;);\n&lt;&#x2F;script&gt;\n\n\n\n1.5.1 事件修饰符\nprevent：阻止默认事件（常用）；\nstop：阻止事件冒泡（常用）；\nonce：事件只触发一次（常用）；\ncapture：使用事件的捕获模式（提前在捕获阶段触发事件，即由外向内触发事件）；\nself：只有event.target是当前操作的元素才触发事件；\npassive：事件的默认行为立即执行，无需等待事件回调执行完毕；\n\n1.5.2 键盘事件1.5.2.1 常用按键别名\n回车 &#x3D;&gt; enter\n删除 &#x3D;&gt; delete\n退出 &#x3D;&gt; esc\n空格 &#x3D;&gt; space\n上下左右 &#x3D;&gt; up down left right\n换行 &#x3D;&gt; tab (特殊，必须配合keydown去使用)\n其他四个特殊按键：ctrl alt shift meta\nkeyup：必须搭配其他按键比如 ctrl + y，随后释放其他键，事件才触发\nkeydown：正常事件触发\n\n\n\n1.5.2.2 其他按键别名查看1.首先查看键名，传入event参数\nconsole.log(event.target.value)  \n2.转换，如\nCapsLock &#x3D;&gt; caps-lock  &#x3D;&gt; @keyup.caps-lock&#x3D;&quot;showInfo&quot;\n\n也可以自定义别名\nVue.config.keyCodes.huiche&#x3D;13  &#x2F;&#x2F; 自定义了一个回车别名：huiche\n\n\n\n1.6 计算属性与侦听属性1.6.1 计算属性&lt;!-- 准备好一个容器--&gt;\n&lt;div id&#x3D;&quot;root&quot;&gt;\n    姓：&lt;input type&#x3D;&quot;text&quot; v-model&#x3D;&quot;firstName&quot;&gt;\n    名：&lt;input type&#x3D;&quot;text&quot; v-model&#x3D;&quot;lastName&quot;&gt; \n    全名：&lt;span&gt;&#123;&#123;fullName&#125;&#125;&lt;&#x2F;span&gt;\n&lt;&#x2F;div&gt;\n\n&lt;script&gt;\n\tconst vm &#x3D; new Vue(&#123;\n        el:&#39;#root&#39;,\n        data:&#123;\n            firstName:&#39;张&#39;,\n            lastName:&#39;三&#39;,\n        &#125;\n        computed:&#123;\n            &#x2F;** 简写形式\n            fullName()&#123;\n            \t  return this.firstName + &#39;-&#39; + this.lastName\n            &#125;\n            **&#x2F;\n      \n            fullName:&#123;\n                &#x2F;&#x2F;get有什么作用？当有人读取fullName时，get就会被调用，且返回值就作为fullName的值\n                &#x2F;&#x2F;get什么时候调用？1.初次读取fullName时。2.所依赖的数据发生变化时。\n                get()&#123;\n                    console.log(&#39;get被调用了&#39;)\n                    return this.firstName + &#39;-&#39; + this.lastName\n                &#125;,\n                &#x2F;&#x2F;set什么时候调用? 当fullName被修改时。\n                &#x2F;&#x2F; 可以主动在控制台修改fullName来查看情况\n                set(value)&#123;\n                    console.log(&#39;set&#39;,value)\n                    const arr &#x3D; value.split(&#39;-&#39;)\n                    this.firstName &#x3D; arr[0]\n                    this.lastName &#x3D; arr[1]\n                &#125;\n            &#125;\n        &#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n\n\n\n1.6.2 侦听属性// 第一种写法\nwatch:&#123;\n            isHot:&#123;\n                immediate: true, // 初始化时让handler调用一下\n                // handler什么时候调用？当isHot发生改变时。\n                handler(newValue, oldValue)&#123;\n                    console.log('isHot被修改了',newValue,oldValue)\n                &#125;\n            &#125;\n&#125; \n// 第二种写法\nvm.$watch('isHot',&#123;\n        immediate:true, //初始化时让handler调用一下\n        //handler什么时候调用？当isHot发生改变时。\n        // deep:true,\n        handler(newValue,oldValue)&#123;\n            console.log('isHot被修改了',newValue,oldValue)\n        &#125;\n&#125;)\n\n深度监视：\n\n(1).Vue中的watch默认不监测对象内部值的改变（一层）\n(2).配置deep:true可以监测对象内部值改变（多层）\n\n\n\n\n\n\n\n\n\n\n备注：\n(1).Vue自身可以监测对象内部值的改变，但Vue提供的watch默认不可以\n(2).使用watch时根据数据的具体结构，决定是否采用深度监视\n// 简写\nwatch:&#123;\n       isHot(newValue, oldValue) &#123;\n\t\t\t\t\t console.log('isHot被修改了', newValue, oldValue, this)\n\t\t\t&#125; \n&#125;\n\n// 写外面\nvm.$watch('isHot',&#123;同第二种写法&#125;)\nvm.$wathch('isHot',function(newValue,oldValue)&#123;函数内容&#125;)\n\n1.6.3 总结\ncomputed能完成的功能，watch都可以完成\nwatch能完成的功能，computed不一定能完成，例如：watch可以进行异步操作\n\n\n\n\n\n\n\n\n\n\n两个重要的小原则：\n1.所被Vue管理的函数，最好写成普通函数，这样this的指向才是vm 或 组件实例对象\n2.所有不被Vue所管理的函数（定时器的回调函数、ajax的回调函数等、Promise的回调函数），最好写成箭头函数，这样this的指向才是vm 或 组件实例对象\n1.7 绑定样式&#x2F;&#x2F; 字符串-直接写\n&lt;div class&#x3D;&quot;basic&quot; :class&#x3D;&quot;mood&quot; @click&#x3D;&quot;changeMood&quot;&gt;&#123;&#123;name&#125;&#125;&lt;&#x2F;div&gt;\n&#x2F;&#x2F; 数组写法\n&lt;div class&#x3D;&quot;basic&quot; :class&#x3D;&quot;classArr&quot;&gt;&#123;&#123;name&#125;&#125;&lt;&#x2F;div&gt;\n&lt;script&gt;\n\tconst vm &#x3D; new Vue(&#123;\n        el:&#39;#root&#39;,\n        data:&#123;\n            classArr: [&#39;atguigu1&#39;,&#39;atguigu2&#39;,&#39;atguigu3&#39;]\n        &#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n&#x2F;&#x2F; 对象写法\n&lt;div class&#x3D;&quot;basic&quot; :class&#x3D;&quot;classObj&quot;&gt;&#123;&#123;name&#125;&#125;&lt;&#x2F;div&gt;\n&lt;script&gt;\n\tconst vm &#x3D; new Vue(&#123;\n        el:&#39;#root&#39;,\n        data:&#123;\n            classObj:&#123;\n                atguigu1:false,\n                atguigu2:false,\n\t\t\t&#125;\n        &#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n\n\n\n\n\n1.8 条件渲染\nv-if：不展示的DOM元素直接被移除\n使用 可以省略掉产生的占位标签\n\n\nv-show：不展示的DOM元素未被移除，仅仅是使用样式隐藏掉(display:none)\n\n1.9 循环\n\n\n\n\n\n\n\n\nDemo\n&lt;div id&#x3D;&quot;root&quot;&gt;\n    &lt;!-- 遍历数组 --&gt;\n    &lt;h2&gt;人员列表（遍历数组）&lt;&#x2F;h2&gt;\n    &lt;ul&gt;\n        &lt;li v-for&#x3D;&quot;(p,index) of persons&quot; :key&#x3D;&quot;index&quot;&gt;\n            &#123;&#123;p.name&#125;&#125;-&#123;&#123;p.age&#125;&#125;\n        &lt;&#x2F;li&gt;\n    &lt;&#x2F;ul&gt;\n\n    &lt;!-- 遍历对象 --&gt;\n    &lt;h2&gt;汽车信息（遍历对象）&lt;&#x2F;h2&gt;\n    &lt;ul&gt;\n        &lt;li v-for&#x3D;&quot;(value,k) of car&quot; :key&#x3D;&quot;k&quot;&gt;\n            &#123;&#123;k&#125;&#125;-&#123;&#123;value&#125;&#125;\n        &lt;&#x2F;li&gt;\n    &lt;&#x2F;ul&gt;\n\n    &lt;!-- 遍历字符串 --&gt;\n    &lt;h2&gt;测试遍历字符串（用得少）&lt;&#x2F;h2&gt;\n    &lt;ul&gt;\n        &lt;li v-for&#x3D;&quot;(char,index) of str&quot; :key&#x3D;&quot;index&quot;&gt;\n            &#123;&#123;char&#125;&#125;-&#123;&#123;index&#125;&#125;\n        &lt;&#x2F;li&gt;\n    &lt;&#x2F;ul&gt;\n\n    &lt;!-- 遍历指定次数 --&gt;\n    &lt;h2&gt;测试遍历指定次数（用得少）&lt;&#x2F;h2&gt;\n    &lt;ul&gt;\n        &lt;li v-for&#x3D;&quot;(number,index) of 5&quot; :key&#x3D;&quot;index&quot;&gt;\n            &#123;&#123;index&#125;&#125;-&#123;&#123;number&#125;&#125;\n        &lt;&#x2F;li&gt;\n    &lt;&#x2F;ul&gt;\n&lt;&#x2F;div&gt;\n\n&lt;script&gt;\n\tconst vm &#x3D; new Vue(&#123;\n        el:&#39;#root&#39;,\n        data: &#123;\n\t\t\tpersons: [\n\t\t\t\t&#123; id: &#39;001&#39;, name: &#39;张三&#39;, age: 18 &#125;,\n\t\t\t\t&#123; id: &#39;002&#39;, name: &#39;李四&#39;, age: 19 &#125;,\n\t\t\t\t&#123; id: &#39;003&#39;, name: &#39;王五&#39;, age: 20 &#125;\n\t\t\t],\n\t\t\tcar: &#123;\n\t\t\t\tname: &#39;奥迪A8&#39;,\n\t\t\t\tprice: &#39;70万&#39;,\n\t\t\t\tcolor: &#39;黑色&#39;\n\t\t\t&#125;,\n\t\t\tstr: &#39;hello&#39;\n\t\t&#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n\n\n\n1.9.1 key原理vue&#x2F;vue基础用法&amp;基础原理整理.md · 格雷狐思&#x2F;笔记 - 码云 - 开源中国 (gitee.com)\n1.9.2 列表过滤\n使用 Watch\n\n&#x2F;&#x2F; 核心逻辑 ，keyword作为搜索框关键词\ndata:&#123;\n\tpersons:[\n\t\t\tp1...   &#x2F;&#x2F; data\n\t\t\tp2...\n\t\t\tp3...\n  ],\n  filterPersons:[]\n&#125;,\nwatch:&#123;\n\tkeyword(v)&#123;\n\t\t\tthis.filterPersons &#x3D; this.persons.filter((p)&#x3D;&gt;&#123; return p.name.index.indexOf(val)!&#x3D;-1 &#125;)\n  &#125;\n&#125;\n\n\n使用 Computed\n\ndata:&#123;...&#125;,  //数据同上，但是不必写filterPersons\ncomputed:&#123;\n\t\tfilterPersons()&#123;\n\t\t\t\treturn this.persons.filter((p=>&#123; return p.name.indexOf(this.keyword)!==-1 &#125;))\n\t\t&#125;\n&#125;\n\n\n添加排序逻辑\n\ndata:&#123;...&#125;,  //数据同上，但是不必写filterPersons\ncomputed:&#123;\n\t\tfilterPersons()&#123;\n\t\t\t\tconst arr = this.persons.filter((p=>&#123; return p.name.indexOf(this.keyword)!==-1 &#125;))\n        if(this.sortType)&#123; \n           // 非0进入\n           arr.sort((p1,p2)=>&#123;\n           \t\treturn this.sortType ===1 ? p2.age - p1.age : p1.age - p2.age  \n           &#125;)\n        &#125;\n        return arr\n\t\t&#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n注：\n\n对于数组类型修改必须使用以下方式\npush()  pop()  shift()  unshift() splice() sort() reverse()  vm.$set()\n例如：this.persons.splice(0,1,{id:’001’,name:’马老师’,age:50,sex:’男’})&#96;  vue.$set(vm.student.hobby,0,’打游戏’)  \nvue.$set 不能作用与根对象vm\n列表渲染 | Vue.js (vuejs.org)\n\n\n\n1.9.3 表单Demo&lt;!-- 准备好一个容器--&gt;\n&lt;div id&#x3D;&quot;root&quot;&gt;\n    &lt;form @submit.prevent&#x3D;&quot;demo&quot;&gt;\n        爱好：\n        学习&lt;input type&#x3D;&quot;checkbox&quot; v-model&#x3D;&quot;userInfo.hobby&quot; value&#x3D;&quot;study&quot;&gt;\n        打游戏&lt;input type&#x3D;&quot;checkbox&quot; v-model&#x3D;&quot;userInfo.hobby&quot; value&#x3D;&quot;game&quot;&gt;\n        吃饭&lt;input type&#x3D;&quot;checkbox&quot; v-model&#x3D;&quot;userInfo.hobby&quot; value&#x3D;&quot;eat&quot;&gt;\n        &lt;br&#x2F;&gt;&lt;br&#x2F;&gt;\n        所属校区\n        &lt;select v-model&#x3D;&quot;userInfo.city&quot;&gt;\n            &lt;option value&#x3D;&quot;&quot;&gt;请选择校区&lt;&#x2F;option&gt;\n            &lt;option value&#x3D;&quot;beijing&quot;&gt;北京&lt;&#x2F;option&gt;\n            &lt;option value&#x3D;&quot;shanghai&quot;&gt;上海&lt;&#x2F;option&gt;\n            &lt;option value&#x3D;&quot;shenzhen&quot;&gt;深圳&lt;&#x2F;option&gt;\n            &lt;option value&#x3D;&quot;wuhan&quot;&gt;武汉&lt;&#x2F;option&gt;\n        &lt;&#x2F;select&gt;\n        &lt;br&#x2F;&gt;&lt;br&#x2F;&gt;\n        其他信息：\n        &lt;textarea v-model.lazy&#x3D;&quot;userInfo.other&quot;&gt;&lt;&#x2F;textarea&gt; &lt;br&#x2F;&gt;&lt;br&#x2F;&gt;\n        &lt;input type&#x3D;&quot;checkbox&quot; v-model&#x3D;&quot;userInfo.agree&quot;&gt;阅读并接受&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;www.atguigu.com&quot;&gt;《用户协议》&lt;&#x2F;a&gt;\n        &lt;button&gt;提交&lt;&#x2F;button&gt;\n    &lt;&#x2F;form&gt;\n&lt;&#x2F;div&gt;\n\n&lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt;\n    Vue.config.productionTip &#x3D; false\n\n    new Vue(&#123;\n        el:&#39;#root&#39;,\n        data:&#123;\n            userInfo:&#123;\n                hobby:[],\n                city:&#39;beijing&#39;,\n                other:&#39;&#39;,\n                agree:&#39;&#39;\n            &#125;\n        &#125;,\n        methods: &#123;\n            demo()&#123;\n                console.log(JSON.stringify(this.userInfo))\n            &#125;\n        &#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n\n\n\n\n\n1.10 内置指令\nv-text\nv-html：存在XSS安全隐患\nv-cloak：Vue实例创建完毕并接管容器后，会删掉v-cloak属性，使用css配合v-cloak可以解决网速慢时页面展示出的问题。\nv-once：以后数据的改变不会引起v-once所在结构的更新，可以用于优化性能。\nv-pre：仅渲染一次，数据变更不会引起相关属性改变\n\n1.11 生命周期\n1.12 组件1.12.1 基本使用1.12.1.1 非文件组件定义&lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt;\n\t\tconst school &#x3D; Vue.extend(&#123;\n        template:&#96;\n\t\t\t\t&lt;div class&#x3D;&quot;demo&quot;&gt;\n\t\t\t\t\t&lt;h2&gt;学校名称：&#123;&#123;schoolName&#125;&#125;&lt;&#x2F;h2&gt;\n\t\t\t\t\t&lt;h2&gt;学校地址：&#123;&#123;address&#125;&#125;&lt;&#x2F;h2&gt;\n\t\t\t\t\t&lt;button @click&#x3D;&quot;showName&quot;&gt;点我提示学校名&lt;&#x2F;button&gt;\t\n    &lt;&#x2F;div&gt;\n\t\t\t&#96;,\n        &#x2F;&#x2F; el:&#39;#root&#39;, &#x2F;&#x2F;组件定义时，一定不要写el配置项，因为最终所有的组件都要被一个vm管理，由vm决定服务于哪个容器。\n        data()&#123;\n            return &#123;\n                schoolName:&#39;尚硅谷&#39;,\n                address:&#39;北京昌平&#39;\n            &#125;\n        &#125;,\n        methods: &#123;\n            showName()&#123;\n                alert(this.schoolName)\n            &#125;\n        &#125;,\n    &#125;)\n    const student &#x3D; Vue.extend(&#123;\n        template:&#96;\n\t\t\t\t&lt;div&gt;\n\t\t\t\t\t&lt;h2&gt;学生姓名：&#123;&#123;studentName&#125;&#125;&lt;&#x2F;h2&gt;\n\t\t\t\t\t&lt;h2&gt;学生年龄：&#123;&#123;age&#125;&#125;&lt;&#x2F;h2&gt;\n    \t\t&lt;&#x2F;div&gt;\n\t\t\t&#96;,\n        data()&#123;\n            return &#123;\n                studentName:&#39;张三&#39;,\n                age:18\n            &#125;\n        &#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n\n注册\n全局注册\n\n&lt;script&gt;\n\t&#x2F;&#x2F;第二步：全局注册组件\n\tVue.component(&#39;hello&#39;, hello)\n&lt;&#x2F;script&gt;\n\n\n局部注册\n\n&lt;script&gt;\n\t&#x2F;&#x2F;创建vm\n    new Vue(&#123;\n        el: &#39;#root&#39;,\n        data: &#123;\n            msg:&#39;你好啊！&#39;\n        &#125;,\n        &#x2F;&#x2F;第二步：注册组件（局部注册）\n        components: &#123;\n            school: school,\n            student: student\n            &#x2F;&#x2F; ES6简写形式\n            &#x2F;&#x2F; school,\n            &#x2F;&#x2F; student\n        &#125;\n    &#125;)\n&lt;&#x2F;script&gt;\n\n应用&lt;!-- 准备好一个容器--&gt;\n&lt;div id&#x3D;&quot;root&quot;&gt;\n    &lt;hello&gt;&lt;&#x2F;hello&gt;\n    &lt;hr&gt;\n    &lt;h1&gt;&#123;&#123;msg&#125;&#125;&lt;&#x2F;h1&gt;\n    &lt;hr&gt;\n    &lt;!-- 第三步：编写组件标签 --&gt;\n    &lt;school&gt;&lt;&#x2F;school&gt;\n    &lt;hr&gt;\n    &lt;!-- 第三步：编写组件标签 --&gt;\n    &lt;student&gt;&lt;&#x2F;student&gt;\n&lt;&#x2F;div&gt;\n\n几个注意点：\n\n\n\n\n\n\n\n\n关于组件名：\n\n一个单词组成：\n\n\n第一种写法(首字母小写)：school\n第二种写法(首字母大写)：School\n\n\n多个单词组成：\n\n\n第一种写法(kebab-case命名)：my-school\n第二种写法(CamelCase命名)：MySchool (需要Vue脚手架支持)\n\n\nname 属性可以指定组件在开发者工具中显示的名字（而不是编码时使用的名字）\n\n\n1.12.1.2 文件组件\n\n\n\n\n\n\n\n\nSchool.vue\n&lt;template&gt;\n\t&lt;div class&#x3D;&quot;demo&quot;&gt;\n\t\t&lt;h2&gt;学校名称：&#123;&#123;name&#125;&#125;&lt;&#x2F;h2&gt;\n\t\t&lt;h2&gt;学校地址：&#123;&#123;address&#125;&#125;&lt;&#x2F;h2&gt;\n\t\t&lt;button @click&#x3D;&quot;showName&quot;&gt;点我提示学校名&lt;&#x2F;button&gt;\t\n\t&lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\n\t export default &#123;\n\t\tname:&#39;School&#39;,\n\t\tdata()&#123;\n\t\t\treturn &#123;\n\t\t\t\tname:&#39;尚硅谷&#39;,\n\t\t\t\taddress:&#39;北京昌平&#39;\n\t\t\t&#125;\n\t\t&#125;,\n\t\tmethods: &#123;\n\t\t\tshowName()&#123;\n\t\t\t\talert(this.name)\n\t\t\t&#125;\n\t\t&#125;,\n\t&#125;\n&lt;&#x2F;script&gt;\n\n&lt;style&gt;\n\t.demo&#123;\n\t\tbackground-color: orange;\n\t&#125;\n&lt;&#x2F;style&gt;\n\n\n\n\n\n\n\n\n\n\nStudent.vue\n&lt;template&gt;\n\t&lt;div&gt;\n\t\t&lt;h2&gt;学生姓名：&#123;&#123;name&#125;&#125;&lt;&#x2F;h2&gt;\n\t\t&lt;h2&gt;学生年龄：&#123;&#123;age&#125;&#125;&lt;&#x2F;h2&gt;\n\t&lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\n\t export default &#123;\n\t\tname:&#39;Student&#39;,\n\t\tdata()&#123;\n\t\t\treturn &#123;\n\t\t\t\tname:&#39;张三&#39;,\n\t\t\t\tage:18\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n&lt;&#x2F;script&gt;\n\n\n\n\n\n\n\n\n\n\nApp.vue  汇总\n&lt;template&gt;\n\t&lt;div&gt;\n\t\t&lt;School&gt;&lt;&#x2F;School&gt;\n\t\t&lt;Student&gt;&lt;&#x2F;Student&gt;\n\t&lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\n\t&#x2F;&#x2F;引入组件\n\timport School from &#39;.&#x2F;School.vue&#39;\n\timport Student from &#39;.&#x2F;Student.vue&#39;\n\n\texport default &#123;\n\t\tname:&#39;App&#39;,\n\t\tcomponents:&#123;\n\t\t\tSchool,\n\t\t\tStudent\n\t\t&#125;\n\t&#125;\n&lt;&#x2F;script&gt;\n\n\n\n\n\n\n\n\n\n\nmain.js\nimport App from &#39;.&#x2F;App.vue&#39;\n\nnew Vue(&#123;\n\tel:&#39;#root&#39;,\n\ttemplate:&#96;&lt;App&gt;&lt;&#x2F;App&gt;&#96;,\n\tcomponents:&#123;App&#125;,\n&#125;)\n\n\n\n\n\n\n\n\n\n\nindex.html\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n\t&lt;head&gt;\n\t\t&lt;meta charset&#x3D;&quot;UTF-8&quot; &#x2F;&gt;\n\t\t&lt;title&gt;练习一下单文件组件的语法&lt;&#x2F;title&gt;\n\t&lt;&#x2F;head&gt;\n\t&lt;body&gt;\n\t\t&lt;!-- 准备一个容器 --&gt;\n\t\t&lt;div id&#x3D;&quot;root&quot;&gt;&lt;&#x2F;div&gt;\n        &lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;..&#x2F;js&#x2F;vue.js&quot;&gt;&lt;&#x2F;script&gt;\n\t\t&lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;.&#x2F;main.js&quot;&gt;&lt;&#x2F;script&gt;\n\t&lt;&#x2F;body&gt;\n&lt;&#x2F;html&gt;\n\n\n\n1.13 插槽学习Vue3 第十七章（插槽slot）_小满zs的博客-CSDN博客_vue3 组件slot\n2. Vue32.0 安装npm init vue@latest\ncd &lt;your-project-name>\nnpm install\nnpm run dev\n\n\n\n2.1 Composition API2.1.1 Setup&lt;template&gt;\n  &lt;h1&gt;博主的信息&lt;&#x2F;h1&gt;\n  &lt;h2&gt;姓名：&#123;&#123;name&#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h2&gt;年龄：&#123;&#123;age&#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h2&gt;性别：&#123;&#123;gender&#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;button @click&#x3D;&quot;sayInfo&quot;&gt;显示信息&lt;&#x2F;button&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\n&#x2F;&#x2F; import &#123;h&#125; from &#39;vue&#39;\nexport default &#123;\n  name: &quot;App&quot;,\n  &#x2F;&#x2F;此处只是测试一下setup，暂时不考虑响应式的问题。\n  setup()&#123;\n    &#x2F;&#x2F; 数据\n    let name &#x3D; &quot;june&quot;\n    let age &#x3D; 18\n    let gender &#x3D; &quot;男&quot;\n\n    &#x2F;&#x2F; 方法\n    function sayInfo()&#123;\n      alert(&#96;你好$&#123;name&#125;，你太厉害了吧&#96;)\n    &#125;\n    return &#123;\n      name,age, gender,sayInfo\n    &#125;\n    &#x2F;&#x2F; return ()&#x3D;&gt; h(&#39;h1&#39;,&#39;juneyyds&#39;)\n  &#125;\n&#125;;\n&lt;&#x2F;script&gt;\n\n2.1.2 ref 函数\n作用: 定义一个响应式的数据\n\n语法: \nconst xxx &#x3D; ref(initValue)\n\n\n创建一个包含响应式数据的引用对象（reference对象，简称ref对象）。\nJS中操作数据： xxx.value\n模板中读取数据: 不需要.value，直接：&lt;div&gt;&#123;&#123;xxx&#125;&#125;&lt;/div&gt;\n\n\n备注：\n\n接收的数据可以是：基本类型、也可以是对象类型。\n基本类型的数据：响应式依靠的是类上的getter与setter完成的（我们等下看下源码你就知道了）。\n对象类型的数据：内部 “ 求助 ” 了Vue3.0中的一个新函数—— reactive函数。\n\n\n\n2.1.3 reactive 函数\n作用: 定义一个对象类型的响应式数据（基本类型不要用它，要用ref函数）\n语法：const 代理对象= reactive(源对象)接收一个对象（或数组），返回一个代理对象（Proxy的实例对象，简称proxy对象）\nreactive定义的响应式数据是“深层次的”。\n内部基于 ES6 的 Proxy 实现，通过代理对象操作源对象内部数据进行操作。\n\n&lt;template&gt;\n  &lt;h1&gt;博主的信息&lt;&#x2F;h1&gt;\n  &lt;h2&gt;姓名：&#123;&#123; june.name &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h2&gt;年龄：&#123;&#123; june.age &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h2&gt;职业： &#123;&#123; june.job.type &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h2&gt;工资：&#123;&#123; june.job.salary &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h2&gt;爱好：&#123;&#123; june.hobby &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;h3&gt;测试数据：&#123;&#123; june.job.a.b.c &#125;&#125;&lt;&#x2F;h3&gt;\n  &lt;button @click&#x3D;&quot;changeInfo&quot;&gt;修改信息&lt;&#x2F;button&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\nimport &#123; reactive &#125; from &quot;vue&quot;;\nexport default &#123;\n  name: &quot;App&quot;,\n  setup() &#123;\n    &#x2F;&#x2F; 数据\n    let june &#x3D; reactive(&#123;\n      name: &quot;june&quot;,\n      age: 18,\n      hobby: [&quot;写博客&quot;, &quot;学习&quot;, &quot;看书&quot;],\n      job: &#123;\n        type: &quot;前端工程师&quot;,\n        salary: &quot;30K&quot;,\n        a: &#123;\n          b: &#123;\n            c: 666,\n          &#125;,\n        &#125;,\n      &#125;,\n    &#125;);\n\n    &#x2F;&#x2F; 方法\n    function changeInfo() &#123;\n      june.name &#x3D; &quot;三十年后的june&quot;;\n      june.age &#x3D; 48;\n      june.job.type &#x3D; &quot;工程师&quot;;\n      june.job.salary &#x3D; &quot;200K&quot;;\n      june.job.a.b.c &#x3D; 888;\n      &#x2F;&#x2F; 直接通过数组下标修改，可以触发响应式\n      june.hobby[0] &#x3D; &quot;写小说&quot;;\n    &#125;\n    return &#123;\n      june,\n      changeInfo,\n    &#125;;\n  &#125;,\n&#125;;\n&lt;&#x2F;script&gt;\n\n\n\n2.1.4 Vue3.0中的响应式原理Vue2.x的响应式\n实现原理\n\n对象类型：通过Object.defineProperty()对属性的读取、修改进行拦截（数据劫持）。\n\n数组类型：通过重写更新数组的一系列方法来实现拦截。（对数组的变更方法进行了包裹）。\nObject.defineProperty(data, 'count', &#123;\n    get () &#123;&#125;, \n    set () &#123;&#125;\n&#125;)\n复制代码\n\n\n存在问题\n\n新增属性、删除属性, 界面不会更新。\n直接通过下标修改数组, 界面不会自动更新。\n\n\n解决方案\n\n使用Vue.set、Vue.delete或者vm.$set、vm.$delete这些API\n\n\n\n模拟Vue2中实现响应式\n//源数据\nlet person = &#123;\n\tname:'张三',\n\tage:18\n&#125;\n//模拟Vue2中实现响应式\nlet p = &#123;&#125;\nObject.defineProperty(p,'name',&#123;\n\tconfigurable:true,\n\tget()&#123; //有人读取name时调用\n\t\treturn person.name\n\t&#125;,\n\tset(value)&#123; //有人修改name时调用\n\t\tconsole.log('有人修改了name属性，我发现了，我要去更新界面！')\n\t\tperson.name = value\n\t&#125;\n&#125;)\nObject.defineProperty(p,'age',&#123;\n\tget()&#123; //有人读取age时调用\n\t\treturn person.age\n\t&#125;,\n\tset(value)&#123; //有人修改age时调用\n\t\tconsole.log('有人修改了age属性，我发现了，我要去更新界面！')\n\t\tperson.age = value\n\t&#125;\n&#125;)\n\nVue3.0的响应式上面例子中看到数组可以通过下标进行修改，我们再测试下增加属性和删除属性在Vue3中好不好使\n&lt;template>\n  &lt;h1>博主的信息&lt;/h1>\n  &lt;h2>姓名：&#123;&#123; june.name &#125;&#125;&lt;/h2>\n  &lt;h2 v-show=\"june.age\">年龄：&#123;&#123; june.age &#125;&#125;&lt;/h2>\n  &lt;h2 v-show=\"june.gender\">性别：&#123;&#123; june.gender &#125;&#125;&lt;/h2>\n  &lt;h2>职业： &#123;&#123; june.job.type &#125;&#125;&lt;/h2>\n  &lt;h2>工资：&#123;&#123; june.job.salary &#125;&#125;&lt;/h2>\n  &lt;h2>爱好：&#123;&#123; june.hobby &#125;&#125;&lt;/h2>\n  &lt;h3>测试数据：&#123;&#123; june.job.a.b.c &#125;&#125;&lt;/h3>\n  &lt;button @click=\"changeInfo\">修改信息&lt;/button>\n  &lt;button @click=\"addGender\">增加性别&lt;/button>\n  &lt;button @click=\"deleteAge\">删除年龄&lt;/button>\n&lt;/template>\n\n&lt;script>\nimport &#123; reactive &#125; from \"vue\";\nexport default &#123;\n  name: \"App\",\n  setup() &#123;\n    // 数据\n    let june = reactive(&#123;\n      name: \"june\",\n      age: 18,\n      hobby: [\"写博客\", \"学习\", \"看书\"],\n      job: &#123;\n        type: \"前端工程师\",\n        salary: \"30K\",\n        a: &#123;\n          b: &#123;\n            c: 666,\n          &#125;,\n        &#125;,\n      &#125;,\n    &#125;);\n\n    // 方法\n    function changeInfo() &#123;\n      june.name = \"三十年后的june\";\n      june.age = 48;\n      june.job.type = \"工程师\";\n      june.job.salary = \"200K\";\n      june.a.b.c = 888;\n      june.hobby[0] = \"写小说\";\n    &#125;\n\n    function addGender() &#123;\n      june.gender = \"男\";\n    &#125;\n    function deleteAge() &#123;\n      delete june.age;\n    &#125;\n\n    return &#123;\n      june,\n      changeInfo,\n      addGender,\n      deleteAge,\n    &#125;;\n  &#125;,\n&#125;;\n&lt;/script>\n\n\n实现原理\n通过Proxy（代理）:  拦截对象中任意属性的变化, 包括：属性值的读写、属性的添加、属性的删除等。\n通过Reflect（反射）:  对源对象的属性进行操作。\nMDN文档中描述的Proxy与Reflect：\nProxy：developer.mozilla.org&#x2F;zh-CN&#x2F;docs&#x2F;…\nReflect：developer.mozilla.org&#x2F;zh-CN&#x2F;docs&#x2F;…\n\n\n\n\n\n模拟Vue3中实现响应式\nlet person = &#123;\n\tname:'june',\n\tage:18\n&#125;\n\nconst p = new Proxy(person,&#123;\n\t//有人读取p的某个属性时调用\n\tget(target,propName)&#123;\n\t\tconsole.log(`有人读取了p身上的$&#123;propName&#125;属性`)\n       // return target[propName]\n\t\treturn Reflect.get(target,propName)\n\t&#125;,\n\t//有人修改p的某个属性、或给p追加某个属性时调用\n\tset(target,propName,value)&#123;\n\t\tconsole.log(`有人修改了p身上的$&#123;propName&#125;属性，我要去更新界面了！`)\n        // target[propName] = value\n\t\treturn Reflect.set(target,propName,value)\n\t&#125;,\n\t//有人删除p的某个属性时调用\n\tdeleteProperty(target,propName)&#123;\n\t\tconsole.log(`有人删除了p身上的$&#123;propName&#125;属性，我要去更新界面了！`)\n\t\t// return delete target[propName]\n       return Reflect.deleteProperty(target,propName)\n\t&#125;\n&#125;)\n\n\n\n2.1.5 reactive对比ref\n从定义数据角度对比\nref用来定义：基本类型数据。\nreactive用来定义：对象（或数组）类型数据。\n备注：ref也可以用来定义对象（或数组）类型数据, 它内部会自动通过reactive转为代理对象。\n\n\n从原理角度对比\nref通过类中的的getter与setter来实现响应式（数据劫持）。\nreactive通过使用Proxy来实现响应式（数据劫持）, 并通过Reflect操作源对象内部的数据。\n\n\n从使用角度对比\nref定义的数据：操作数据需要.value，读取数据时模板中直接读取不需要.value。\nreactive定义的数据：操作数据与读取数据：均不需要.value。\n\n\n\n2.1.6 setup的两个注意点\nsetup执行的时机\n在beforeCreate之前执行一次，this是undefined。\n\n\nsetup的参数\n\n将setup接收的两个参数(props, context)打印在控制台，如下\n\nprops：值为对象，包含：组件外部传递过来，且组件内部声明接收了的属性。\ncontext：上下文对象\n\nattrs: 值为对象，包含：组件外部传递过来，但没有在props配置中声明的属性, 相当于 this.$attrs。\nslots: 收到的插槽内容, 相当于 this.$slots。\nemit: 分发自定义事件的函数, 相当于 this.$emit。\n\n2.1.7 父子组件通信父组件向子组件传递属性参数\n\n\n\n\n\n\n\n\n父组件\n&lt;template>\n  &lt;h1>博主的信息&lt;/h1>\n  &lt;HelloWorld msg=\"你好啊\" school=\"ABC\">&lt;/HelloWorld>\n&lt;/template>\n\n&lt;script>\nimport HelloWorld from \"./components/HelloWorld.vue\";\nexport default &#123;\n  name: \"App\",\n  components: &#123; HelloWorld &#125;,\n&#125;;\n&lt;/script>\n\n&lt;style>&lt;/style>\n\n\n\n\n\n\n\n\n\n\n子组件\n&lt;template>\n  &lt;h2>姓名：&#123;&#123; yk.name &#125;&#125;&lt;/h2>\n&lt;/template>\n\n&lt;script>\nimport &#123; reactive &#125; from \"@vue/reactivity\";\nexport default &#123;\n  name: \"HelloWorld\",\n  props: ['msg'], // 不写全会报警告\n  setup(props, context) &#123;\n    let yk = reactive(&#123;\n      name: \"YK菌\",\n    &#125;);\n    console.log('props-----',props);\n    console.log()\n    console.log('context.attrs-----', context.attrs)\n    return &#123; yk &#125;;\n  &#125;,\n&#125;;\n&lt;/script>\n\n自定义事件&lt;template>\n  &lt;h1>博主的信息&lt;/h1>\n  &lt;HelloWorld @hello=\"showHelloMsg\">&lt;/HelloWorld>\n&lt;/template>\n\n&lt;script>\nimport HelloWorld from \"./components/HelloWorld.vue\";\nexport default &#123;\n  name: \"App\",\n  setup() &#123;\n    function showHelloMsg(value) &#123;\n      alert(`你好啊，你触发了hello事件，我收到的参数是:$&#123;value&#125;！`);\n    &#125;\n    return &#123; showHelloMsg &#125;;\n  &#125;,\n  components: &#123; HelloWorld &#125;,\n&#125;;\n&lt;/script>\n\n&lt;template>\n  &lt;h2>姓名：&#123;&#123; yk.name &#125;&#125;&lt;/h2>\n  &lt;button @click=\"test\">测试触发一下HelloWorld组件的Hello事件&lt;/button>\n&lt;/template>\n\n&lt;script>\nimport &#123; reactive &#125; from \"@vue/reactivity\";\nexport default &#123;\n  name: \"HelloWorld\",\n  emits:[\"hello\"], // 不写能执行，但是会报警告\n  setup(props, context) &#123;\n    let yk = reactive(&#123;\n      name: \"YK菌\",\n    &#125;);\n    function test() &#123;\n      context.emit(\"hello\", \"**子组件的信息**\");\n    &#125;\n    return &#123; yk,test &#125;;\n  &#125;,\n&#125;;\n&lt;/script>\n\n插槽\n\n\n\n\n\n\n\n\n默认插槽\n&lt;template&gt;\n  &lt;h2&gt;姓名：&#123;&#123; yk.name &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;slot&gt;&lt;&#x2F;slot&gt;\n&lt;&#x2F;template&gt;\n\n&lt;template&gt;\n  &lt;h1&gt;博主的信息&lt;&#x2F;h1&gt;\n  &lt;HelloWorld&gt;\n    &lt;span&gt;June，你好&lt;&#x2F;span&gt;\n  &lt;&#x2F;HelloWorld&gt;\n&lt;&#x2F;template&gt;\n\n\n\n\n\n\n\n\n\n\n具名插槽\n&lt;template>\n  &lt;h1>博主的信息&lt;/h1>\n  &lt;HelloWorld>\n\t&lt;template v-slot:ykMsg>\n\t\t&lt;span>YK菌，你好&lt;/span>\n\t&lt;/template>\n  &lt;/HelloWorld>\n&lt;/template>\n\n&lt;template&gt;\n  &lt;h2&gt;姓名：&#123;&#123; yk.name &#125;&#125;&lt;&#x2F;h2&gt;\n  &lt;slot name&#x3D;&quot;ykMsg&quot;&gt;&lt;&#x2F;slot&gt;\n&lt;&#x2F;template&gt;\n\n\n\n2.1.8 计算属性与监视2.1.8.1 computed\n\n\n\n\n\n\n\n\n与Vue2.x中computed配置功能一致\n\nimport &#123;computed&#125; from 'vue'\n\nsetup()&#123;\n    ...\n\t//计算属性 —— 简写\n    let fullName = computed(()=>&#123;\n        return person.firstName + '-' + person.lastName\n    &#125;)\n    //计算属性 —— 完整\n    let fullName = computed(&#123;\n        get()&#123;\n            return person.firstName + '-' + person.lastName\n        &#125;,\n        set(value)&#123;\n            const nameArr = value.split('-')\n            person.firstName = nameArr[0]\n            person.lastName = nameArr[1]\n        &#125;\n    &#125;)\n&#125;\n\n2.1.8.2 watch\n\n\n\n\n\n\n\n\n\n与Vue2.x中watch配置功能一致\n两个注意点：\n监视reactive定义的响应式数据时：oldValue无法正确获取、强制开启了深度监视（deep配置失效）。\n监视reactive定义的响应式数据中某个属性时：deep配置有效。\n\n\n\n情况一：监视ref定义的响应式数据\n//情况一：监视ref定义的响应式数据\nwatch(sum,(newValue,oldValue)=>&#123;\n\tconsole.log('sum变化了',newValue,oldValue)\n&#125;,&#123;immediate:true&#125;)\n\n如果用ref定义了一个对象\nwatch(person.value,(newValue,oldValue)=>&#123;\n\tconsole.log('person变化了',newValue,oldValue)\n&#125;) \n\n或者这样\nwatch(person,(newValue,oldValue)=>&#123;\n\tconsole.log('person变化了',newValue,oldValue)\n&#125;,&#123;deep: true&#125;) \n\n情况二：监视多个ref定义的响应式数据\n//情况二：监视多个ref定义的响应式数据\nwatch([sum,msg],(newValue,oldValue)=>&#123;\n\tconsole.log('sum或msg变化了',newValue,oldValue)\n&#125;) \n\n情况三：监视reactive定义的响应式数据\n\n若watch监视的是reactive定义的响应式数据，则无法正确获得oldValue！！\n若watch监视的是reactive定义的响应式数据，则强制开启了深度监视\n\nwatch(person,(newValue,oldValue)=>&#123;\n\tconsole.log('person变化了',newValue,oldValue)\n&#125;,&#123;immediate:true,deep:false&#125;) //此处的deep配置不再奏效\n\n情况四：监视reactive定义的响应式数据中的某个属性\n//情况四：监视reactive定义的响应式数据中的某个属性，此方式可以查看到新值旧值变化\nwatch(()=>person.job,(newValue,oldValue)=>&#123;\n\tconsole.log('person的job变化了',newValue,oldValue)\n&#125;,&#123;immediate:true,deep:true&#125;) \n\n情况五：监视reactive定义的响应式数据中的某些属性\n//情况五：监视reactive定义的响应式数据中的某些属性\nwatch([()=>person.job,()=>person.name],(newValue,oldValue)=>&#123;\n\tconsole.log('person的job变化了',newValue,oldValue)\n&#125;,&#123;immediate:true,deep:true&#125;)\n\n特殊情况\n//特殊情况\nwatch(()=>person.job,(newValue,oldValue)=>&#123;\n    console.log('person的job变化了',newValue,oldValue)\n&#125;,&#123;deep:true&#125;) //此处由于监视的是reactive素定义的对象中的某个属性，所以deep配置有效\n\n2.1.8.3 watchEffect\nwatch的套路是：既要指明监视的属性，也要指明监视的回调。\nwatchEffect的套路是：不用指明监视哪个属性，监视的回调中用到哪个属性，那就监视哪个属性。\nwatchEffect有点像computed：\n但computed注重的计算出来的值（回调函数的返回值），所以必须要写返回值。\n而watchEffect更注重的是过程（回调函数的函数体），所以不用写返回值。\n\n\n\n//watchEffect所指定的回调中用到的数据只要发生变化，则直接重新执行回调。\nwatchEffect(()=>&#123;\n    const x1 = sum.value\n    const x2 = person.age\n    console.log('watchEffect配置的回调执行了')\n&#125;)\n\n\n\n2.2 其它 Composition API2.2.1 shallowReactive 与 shallowRef\nshallowReactive：只处理对象最外层属性的响应式（浅响应式）。\nshallowRef：只处理基本数据类型的响应式, 不进行对象的响应式处理。\n什么时候使用?\n如果有一个对象数据，结构比较深, 但变化时只是外层属性变化 &#x3D;&#x3D;&#x3D;&gt; shallowReactive。\n如果有一个对象数据，后续功能不会修改该对象中的属性，而是生新的对象来替换 &#x3D;&#x3D;&#x3D;&gt; shallowRef。\n\n\n\n2.2.2 customRef\n作用：创建一个自定义的 ref，并对其依赖项跟踪和更新触发进行显式控制。\n案例：实现防抖效果\n\n&lt;template>\n  &lt;input type=\"text\" v-model=\"keyWord\" />\n  &lt;h3>&#123;&#123; keyWord &#125;&#125;&lt;/h3>\n&lt;/template>\n\n&lt;script>\nimport &#123; customRef &#125; from \"vue\";\nexport default &#123;\n  name: \"App\",\n  setup() &#123;\n    //自定义一个ref——名为：myRef\n    function myRef(value, delay) &#123;\n      let timer;\n      return customRef((track, trigger) => &#123;\n        return &#123;\n          get() &#123;\n            console.log(`有人从myRef这个容器中读取数据了，我把$&#123;value&#125;给他了`);\n            track(); // 通知Vue追踪value的变化（提前和get商量一下，让他认为这个value是有用的）\n            return value;\n          &#125;,\n          set(newValue) &#123;\n            console.log(`有人把myRef这个容器中数据改为了：$&#123;newValue&#125;`);\n            clearTimeout(timer);\n            timer = setTimeout(() => &#123;\n              value = newValue;\n              trigger(); // 通知Vue去重新解析模板\n            &#125;, delay);\n          &#125;,\n        &#125;;\n      &#125;);\n    &#125;\n\n    // let keyWord = ref('hello') //使用Vue提供的ref\n    let keyWord = myRef(\"hello\", 500); //使用程序员自定义的ref\n\n    return &#123; keyWord &#125;;\n  &#125;,\n&#125;;\n&lt;/script>\n\n\n\n2.2.3 provide 与 inject\n作用：实现祖组件 -&gt; 孙组件 通信\n套路：父组件有一个 provide 选项来提供数据，后代组件有一个 inject 选项来开始使用这些数据\n具体写法：\n\n祖组件中：\nsetup()&#123;\n\t......\n    let car = reactive(&#123;name:'奔驰',price:'40万'&#125;)\n    provide('car',car) // 给自己的后代组件传递数据\n    ......\n&#125;\n\n后代组件中：\nsetup(props,context)&#123;\n\t......\n    const car = inject('car') // 拿到祖先的数据\n    return &#123;car&#125;\n\t......\n&#125;\n\n2.2.4 响应式数据的判断\nisRef: 检查一个值是否为一个 ref 对象\nisReactive: 检查一个对象是否是由 reactive 创建的响应式代理\nisReadonly: 检查一个对象是否是由 readonly 创建的只读代理\nisProxy: 检查一个对象是否是由 reactive 或者 readonly 方法创建的代理\n\nComposition API 差不多就介绍完了，此时回去再看那个动图，就会感觉Vue3真香！\n2.2.5 Teleport\n什么是Teleport？—— Teleport 是一种能够将我们的组件html结构移动到指定位置的技术。\n\n&lt;teleport to=\"移动位置\">\n\t&lt;div v-if=\"isShow\" class=\"mask\">\n\t\t&lt;div class=\"dialog\">\n\t\t\t&lt;h3>我是一个弹窗&lt;/h3>\n\t\t\t&lt;button @click=\"isShow = false\">关闭弹窗&lt;/button>\n\t\t&lt;/div>\n\t&lt;/div>\n&lt;/teleport>\n复制代码\n\n以一个弹窗组件为示例来看看\n我们来个嵌套的盒子，然后在最里面的盒子设置弹窗\nApp\n&lt;template>\n  &lt;div class=\"app\">\n    &lt;h3>我是App组件&lt;/h3>\n    &lt;Child />\n  &lt;/div>\n&lt;/template>\n\n&lt;script>\nimport Child from \"./components/Child\";\nexport default &#123;\n  name: \"App\",\n  components: &#123; Child &#125;,\n&#125;;\n&lt;/script>\n\n&lt;style>\n.app &#123;\n  background-color: gray;\n  padding: 10px;\n&#125;\n&lt;/style>\n\n复制代码\n\nChild\n&lt;template>\n  &lt;div class=\"child\">\n    &lt;h3>我是Child组件&lt;/h3>\n    &lt;Son />\n  &lt;/div>\n&lt;/template>\n\n&lt;script>\nimport Son from \"./Son\";\nexport default &#123;\n  name: \"Child\",\n  components: &#123; Son &#125;,\n&#125;;\n&lt;/script>\n\n&lt;style>\n.child &#123;\n  background-color: skyblue;\n  padding: 10px;\n&#125;\n&lt;/style>\n\n复制代码\n\nSon\n&lt;template>\n  &lt;div class=\"son\">\n    &lt;h3>我是Son组件&lt;/h3>\n    &lt;Dialog />\n  &lt;/div>\n&lt;/template>\n\n&lt;script>\nimport Dialog from \"./Dialog.vue\";\nexport default &#123;\n  name: \"Son\",\n  components: &#123; Dialog &#125;,\n&#125;;\n&lt;/script>\n\n&lt;style>\n.son &#123;\n  position: relative;\n  background-color: orange;\n  padding: 10px;\n&#125;\n&lt;/style>\n\n复制代码\n\nDialog\n&lt;template>\n  &lt;div>\n    &lt;button @click=\"isShow = true\">点我弹个窗&lt;/button>\n    &lt;div v-if=\"isShow\" class=\"mask\">\n      &lt;div class=\"dialog\">\n        &lt;h3>我是一个弹窗&lt;/h3>\n        &lt;h4>一些内容&lt;/h4>\n        &lt;h4>一些内容&lt;/h4>\n        &lt;h4>一些内容&lt;/h4>\n        &lt;button @click=\"isShow = false\">关闭弹窗&lt;/button>\n      &lt;/div>\n    &lt;/div>\n  &lt;/div>\n&lt;/template>\n\n&lt;script>\nimport &#123; ref &#125; from \"vue\";\nexport default &#123;\n  name: \"Dialog\",\n  setup() &#123;\n    let isShow = ref(false);\n    return &#123; isShow &#125;;\n  &#125;,\n&#125;;\n&lt;/script>\n\n&lt;style>\n.mask &#123;\n  position: absolute;\n  top: 0;\n  bottom: 0;\n  left: 0;\n  right: 0;\n  background-color: rgba(0, 0, 0, 0.5);\n&#125;\n.dialog &#123;\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  transform: translate(-50%, -50%);\n  text-align: center;\n  width: 300px;\n  height: 300px;\n  background-color: green;\n&#125;\n&lt;/style>\n\n复制代码\n\n我故意给最里面的盒子加了定位，因为相对定位会找他外层最近的定位盒子进行定位，所以效果就是这样了，我们希望这个弹窗是在body下呈现的\n \n我们在Dialog组件中加一个teleport标签\n&lt;template>\n  &lt;div>\n    &lt;button @click=\"isShow = true\">点我弹个窗&lt;/button>\n    &lt;teleport to=\"body\">\n    &lt;div v-if=\"isShow\" class=\"mask\">\n      &lt;div class=\"dialog\">\n        &lt;h3>我是一个弹窗&lt;/h3>\n        &lt;h4>一些内容&lt;/h4>\n        &lt;h4>一些内容&lt;/h4>\n        &lt;h4>一些内容&lt;/h4>\n        &lt;button @click=\"isShow = false\">关闭弹窗&lt;/button>\n      &lt;/div>\n    &lt;/div>\n    &lt;/teleport>\n  &lt;/div>\n&lt;/template>\n复制代码\n\n这样就好了  \n2.2.6 Suspense\n等待异步组件时渲染一些额外内容，让应用有更好的用户体验\n使用步骤：\n异步引入组件\n\n\n\nimport &#123;defineAsyncComponent&#125; from 'vue'\nconst Child = defineAsyncComponent(()=>import('./components/Child.vue'))\n复制代码\n\n使用Suspense包裹组件，并配置好default与 fallback\n&lt;template>\n\t&lt;div class=\"app\">\n\t\t&lt;h3>我是App组件&lt;/h3>\n\t\t&lt;Suspense>\n\t\t\t&lt;template v-slot:default>\n\t\t\t\t&lt;Child/>\n\t\t\t&lt;/template>\n\t\t\t&lt;template v-slot:fallback>\n\t\t\t\t&lt;h3>加载中.....&lt;/h3>\n\t\t\t&lt;/template>\n\t\t&lt;/Suspense>\n\t&lt;/div>\n&lt;/template>\n复制代码\n\ndefault：就是组件要显示的内容\nfallback：就是组件没加载完全的“备胎”\n2.3 其他更新2.3.1 Vue3生命周期\n\n\n\n\nVue3.0中可以继续使用Vue2.x中的生命周期钩子，但有有两个被更名：\nbeforeDestroy改名为 beforeUnmount\ndestroyed改名为 unmounted\n\n\n\n可以直接已配置项的形式使用生命周期钩子，也可以使用组合式API的形式使用，尽量统一\n一般来说，组合式API里的钩子会比配置项的钩子先执行，组合式API的钩子名字有变化\n\nVue3.0也提供了 Composition API 形式的生命周期钩子，与Vue2.x中钩子对应关系如下：\nbeforeCreate&#x3D;&#x3D;&#x3D;&gt;setup()\ncreated&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;setup()\nbeforeMount &#x3D;&#x3D;&#x3D;&gt;onBeforeMount\nmounted&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;onMounted\nbeforeUpdate&#x3D;&#x3D;&#x3D;&gt;onBeforeUpdate\nupdated &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;onUpdated\nbeforeUnmount &#x3D;&#x3D;&gt;onBeforeUnmount\nunmounted &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;onUnmounted\n\n\n\n2.3.2 自定义hook函数（重点）\n什么是hook？—— 本质是一个函数，把setup函数中使用的Composition API进行了封装。\n类似于vue2.x中的mixin。\n自定义hook的优势: 复用代码, 让setup中的逻辑更清楚易懂。\n\n创建一个hooks文件夹，里面创建文件usePoint.js\nimport &#123; reactive, onMounted, onBeforeUnmount &#125; from \"vue\";\nexport default function() &#123;\n  //实现鼠标“打点”相关的数据\n  let point = reactive(&#123;\n    x: 0,\n    y: 0,\n  &#125;);\n\n  //实现鼠标“打点”相关的方法\n  function savePoint(event) &#123;\n    point.x = event.pageX;\n    point.y = event.pageY;\n    console.log(event.pageX, event.pageY);\n  &#125;\n\n  //实现鼠标“打点”相关的生命周期钩子\n  onMounted(() => &#123;\n    window.addEventListener(\"click\", savePoint);\n  &#125;);\n\n  onBeforeUnmount(() => &#123;\n    window.removeEventListener(\"click\", savePoint);\n  &#125;);\n\n  return point;\n&#125;\n\n组件使用\n&lt;template&gt;\n\t&lt;h2&gt;我是HelloWorld组件&lt;&#x2F;h2&gt;\n\t&lt;h2&gt;当前点击时鼠标的坐标为：x：&#123;&#123;point.x&#125;&#125;，y：&#123;&#123;point.y&#125;&#125;&lt;&#x2F;h2&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\n\timport usePoint from &#39;..&#x2F;hooks&#x2F;usePoint&#39;\n\texport default &#123;\n\t\tname:&#39;HelloWorld&#39;,\n\t\tsetup()&#123;\n\t\t\tconst point &#x3D; usePoint()\n\t\t\treturn &#123;point&#125;\n\t\t&#125;\n\t&#125;\n&lt;&#x2F;script&gt;\n\n\n\n2.3.3 toRef\n作用：创建一个 ref 对象，其value值指向另一个对象中的某个属性。\n语法：const name = toRef(person,&#39;name&#39;)\n应用:   要将响应式对象中的某个属性单独提供给外部使用时。\n扩展：toRefs与toRef功能一致，但可以批量创建多个 ref 对象，语法：toRefs(person)\n\n&lt;template&gt;\n\t&lt;h4&gt;&#123;&#123;person&#125;&#125;&lt;&#x2F;h4&gt;\n\t&lt;h2&gt;姓名：&#123;&#123;name&#125;&#125;&lt;&#x2F;h2&gt;\n\t&lt;h2&gt;年龄：&#123;&#123;age&#125;&#125;&lt;&#x2F;h2&gt;\n\t&lt;h2&gt;薪资：&#123;&#123;job.j1.salary&#125;&#125;K&lt;&#x2F;h2&gt;\n\t&lt;button @click&#x3D;&quot;name+&#x3D;&#39;~&#39;&quot;&gt;修改姓名&lt;&#x2F;button&gt;\n\t&lt;button @click&#x3D;&quot;age++&quot;&gt;增长年龄&lt;&#x2F;button&gt;\n\t&lt;button @click&#x3D;&quot;job.j1.salary++&quot;&gt;涨薪&lt;&#x2F;button&gt;\n&lt;&#x2F;template&gt;\n\n&lt;script&gt;\n\timport &#123;ref,reactive,toRef,toRefs&#125; from &#39;vue&#39;\n\texport default &#123;\n\t\tname: &#39;Demo&#39;,\n\t\tsetup()&#123;\n\t\t\t&#x2F;&#x2F;数据\n\t\t\tlet person &#x3D; reactive(&#123;\n\t\t\t\tname:&#39;张三&#39;,\n\t\t\t\tage:18,\n\t\t\t\tjob:&#123;\n\t\t\t\t\tj1:&#123;\n\t\t\t\t\t\tsalary:20\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;)\n\n\t\t\t&#x2F;&#x2F; const name1 &#x3D; person.name\n\t\t\t&#x2F;&#x2F; console.log(&#39;%%%&#39;,name1)\n\n\t\t\t&#x2F;&#x2F; const name2 &#x3D; toRef(person,&#39;name&#39;)\n\t\t\t&#x2F;&#x2F; console.log(&#39;####&#39;,name2)\n\n\t\t\tconst x &#x3D; toRefs(person)\n\t\t\tconsole.log(&#39;******&#39;,x)\n\n\t\t\treturn &#123;\n\t\t\t\tperson,\n\t\t\t\t&#x2F;&#x2F; name:toRef(person,&#39;name&#39;),\n\t\t\t\t&#x2F;&#x2F; age:toRef(person,&#39;age&#39;),\n\t\t\t\t&#x2F;&#x2F; salary:toRef(person.job.j1,&#39;salary&#39;),\n\t\t\t\t...toRefs(person)\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n&lt;&#x2F;script&gt;\n\n\n\n2.3.4 全局API的转移\nVue 2.x 有许多全局 API 和配置。\n例如：注册全局组件、注册全局指令等。\n\n\n\n//注册全局组件\nVue.component('MyButton', &#123;\n  data: () => (&#123;\n    count: 0\n  &#125;),\n  template: '&lt;button @click=\"count++\">Clicked &#123;&#123; count &#125;&#125; times.&lt;/button>'\n&#125;)\n\n//注册全局指令\nVue.directive('focus', &#123;\n  inserted: el => el.focus()\n&#125;\n复制代码\n\nVue3.0中对这些API做出了调整：\n\n将全局的API，即：Vue.xxx调整到应用实例（app）上\n\n\n\n2.x 全局 API（Vue）\n3.x 实例 API (app)\n\n\n\nVue.config.xxxx\napp.config.xxxx\n\n\nVue.config.productionTip\n移除\n\n\nVue.component\napp.component\n\n\nVue.directive\napp.directive\n\n\nVue.mixin\napp.mixin\n\n\nVue.use\napp.use\n\n\nVue.prototype\napp.config.globalProperties\n\n\n\n\n2.3.5 杂项① data选项应始终被声明为一个函数② 过渡类名的更改Vue2.x写法\n.v-enter,\n.v-leave-to &#123;\n  opacity: 0;\n&#125;\n.v-leave,\n.v-enter-to &#123;\n  opacity: 1;\n&#125;\n复制代码\n\nVue3.x写法\n.v-enter-from,\n.v-leave-to &#123;\n  opacity: 0;\n&#125;\n\n.v-leave-from,\n.v-enter-to &#123;\n  opacity: 1;\n&#125;\n复制代码\n\n③ 移除keyCode作为 v-on 的修饰符，同时也不再支持config.keyCodes④ 移除v-on.native修饰符\n父组件中绑定事件\n\n&lt;my-component\n  v-on:close=\"handleComponentEvent\"\n  v-on:click=\"handleNativeClickEvent\"\n/>\n复制代码\n\n子组件中声明自定义事件\n&lt;script>\n  export default &#123;\n    emits: ['close']\n  &#125;\n&lt;/script>\n复制代码\n\n⑤ 移除过滤器（filter）\n\n\n\n\n\n\n\n\n过滤器虽然这看起来很方便，但它需要一个自定义语法，打破大括号内表达式是 “只是 JavaScript” 的假设，这不仅有学习成本，而且有实现成本！建议用方法调用或计算属性去替换过滤器。\n\n2.4 路由2.4.1 安装npm install vue-router@4   // vue3-@4  vue2-@3\n\n2.4.2 Demo// index.ts\nimport &#123; createRouter, createWebHistory &#125; from 'vue-router'\n\nconst router = createRouter(&#123;\n  history: createWebHistory(import.meta.env.BASE_URL),\n  routes: [\n    &#123;\n      path:\"/c1\",\n      component:()=>import('../components/c1.vue')   // &lt;h1>111111111&lt;/h1>\n    &#125;,\n    &#123;\n      path:\"/c2\",\n      component:()=>import('../components/c2.vue')    // &lt;h2>2222222222&lt;/h2>\n    &#125;\n  ]\n&#125;)\n\nexport default router\n\n\n\n&#x2F;&#x2F; app.vue\n&lt;template&gt;\n  &lt;h1&gt;ddd&lt;&#x2F;h1&gt;\n  &lt;RouterView&gt;&lt;&#x2F;RouterView&gt;\n  &lt;RouterLink to&#x3D;&quot;c1&quot;&gt;toC1&lt;&#x2F;RouterLink&gt;\n  &lt;RouterLink to&#x3D;&quot;c2&quot;&gt;toC2&lt;&#x2F;RouterLink&gt;\n&lt;&#x2F;template&gt;\n\n// main.ts 记得挂载\nimport &#123; createApp &#125; from 'vue'\nimport App from './App.vue'\nimport router from './router'\ncreateApp(App).use(router).mount('#app')\n\n\n\n\n\n\n\n\n\n\n2-3 对应关系\nvue2 mode history vue3 createWebHistory\nvue2 mode  hash  vue3  createWebHashHistory\nvue2 mode abstact vue3  createMemoryHistory\n2.4.3 命名路由除了 path 之外，你还可以为任何路由提供 name。这有以下优点：\n\n没有硬编码的 URL\nparams 的自动编码&#x2F;解码。\n防止你在 url 中出现打字错误。\n绕过路径排序（如显示一个）\n\nconst routes:Array&lt;RouteRecordRaw> = [\n    &#123;\n        path:\"/\",\n        name:\"Login\",\n        component:()=> import('../components/login.vue')\n    &#125;,\n    &#123;\n        path:\"/reg\",\n        name:\"Reg\",\n        component:()=> import('../components/reg.vue')\n    &#125;\n]\n\n&lt;h1&gt;小满最骚&lt;&#x2F;h1&gt;\n&lt;div&gt;\n  &lt;router-link :to&#x3D;&quot;&#123;name:&#39;Login&#39;&#125;&quot;&gt;Login&lt;&#x2F;router-link&gt;  here\n&lt;router-link style&#x3D;&quot;margin-left:10px&quot; :to&#x3D;&quot;&#123;name:&#39;Reg&#39;&#125;&quot;&gt;Reg&lt;&#x2F;router-link&gt;\n&lt;&#x2F;div&gt;\n&lt;hr &#x2F;&gt;\n\n2.4.4 编程式导航\n字符串模式\n\nimport &#123; useRouter &#125; from 'vue-router'\nconst router = useRouter()\n \nconst toPage = () => &#123;\n  router.push('/reg')\n&#125;\n\n\n对象模式\n\nimport &#123; useRouter &#125; from 'vue-router'\nconst router = useRouter()\n \nconst toPage = () => &#123;\n  router.push(&#123;\n    path: '/reg'\n  &#125;)\n&#125;\n\n\n命名路由模式\n\nimport &#123; useRouter &#125; from 'vue-router'\nconst router = useRouter()\n \nconst toPage = () => &#123;\n  router.push(&#123;\n    name: 'Reg'\n  &#125;)\n&#125;\n\n\na标签跳转\n\n&lt;a href&#x3D;&quot;&#x2F;reg&quot;&gt;rrr&lt;&#x2F;a&gt;   这种会使页面刷新\n\n\n\n2.4.5 历史记录&#x2F;&#x2F; 不留下历史记录 replace\n&lt;router-link replace to&#x3D;&quot;&#x2F;&quot;&gt;Login&lt;&#x2F;router-link&gt;\n&lt;router-link replace style&#x3D;&quot;margin-left:10px&quot; to&#x3D;&quot;&#x2F;reg&quot;&gt;Reg&lt;&#x2F;router-link&gt;\n&lt;button @click&#x3D;&quot;toPage(&#39;&#x2F;&#39;)&quot;&gt;Login&lt;&#x2F;button&gt;\n&lt;button @click&#x3D;&quot;toPage(&#39;&#x2F;reg&#39;)&quot;&gt;Reg&lt;&#x2F;button&gt;\n&#x2F;&#x2F; js\n&lt;script&gt;\nimport &#123; useRouter &#125; from &#39;vue-router&#39;\nconst router &#x3D; useRouter()\n \nconst toPage &#x3D; (url: string) &#x3D;&gt; &#123;\n  router.replace(url)\n&#125;\n&lt;&#x2F;script&gt;\n\n&#x2F;&#x2F; 前进&#x2F;后退k步\n&lt;script&gt;\nconst next &#x3D; () &#x3D;&gt; &#123;\n  &#x2F;&#x2F;前进 数量不限于1\n  router.go(1)\n&#125;\n \nconst prev &#x3D; () &#x3D;&gt; &#123;\n  &#x2F;&#x2F;后退\n  router.back()\n&#125;\n&lt;&#x2F;script&gt;\n\n2.4.6 路由传参Query 传参// 传值\nconst toDetail = (item: Item) => &#123;\n    router.push(&#123;\n        path: '/reg',\n      // name: 'Reg',\n        query: item\n    &#125;)\n&#125;\n\n// 取值\nimport &#123; useRoute &#125; from 'vue-router';\nconst route = useRoute()\n\n&lt;div>品牌：&#123;&#123; route.query?.name &#125;&#125;&lt;/div>\n&lt;div>价格：&#123;&#123; route.query?.price &#125;&#125;&lt;/div>\n&lt;div>ID：&#123;&#123; route.query?.id &#125;&#125;&lt;/div>\n\nParams传参// 编程式导航 使用router push 或者 replace 的时候 改为对象形式并且只能使用name，path无效，然后传入params\nconst toDetail = (item: Item) => &#123;\n    router.push(&#123;\n        name: 'Reg',\n        params: item\n    &#125;)\n&#125;\n// 取值\nimport &#123; useRoute &#125; from 'vue-router';\nconst route = useRoute()\n\n&lt;div>品牌：&#123;&#123; route.params?.name &#125;&#125;&lt;/div>\n&lt;div>价格：&#123;&#123; route.params?.price &#125;&#125;&lt;/div>\n&lt;div>ID：&#123;&#123; route.params?.id &#125;&#125;&lt;/div>\n\n// 2022-8-22 已废弃，推荐使用pinia存储 即 state代替param\n// https://github.com/vuejs/router/blob/main/packages/router/CHANGELOG.md#414-2022-08-22\n\n动态路由传参const routes:Array&lt;RouteRecordRaw> = [\n    &#123;\n        path:\"/\",\n        name:\"Login\",\n        component:()=> import('../components/login.vue')\n    &#125;,\n    &#123;\n        //动态路由参数\n        path:\"/reg/:id\",\n        name:\"Reg\",\n        component:()=> import('../components/reg.vue')\n    &#125;\n]\n\n\nconst toDetail = (item: Item) => &#123;\n    router.push(&#123;\n        name: 'Reg',\n        params: &#123;\n            id: item.id\n        &#125;\n    &#125;)\n&#125;\n\n// 第一种方式\nimport &#123; useRoute &#125; from 'vue-router';\nimport &#123; data &#125; from './list.json'\nconst route = useRoute()\n \nconst item = data.find(v => v.id === Number(route.params.id))\n\n// 第二种方式\nimport router from \"@/router\";\nconst test = () => &#123;\n  console.log(router.currentRoute.value.query.keyword)\n  console.log(route.query)\n&#125;\n\n\n\n\n\n\n\n\n\n\n区别\n\nquery 传参配置的是 path，而 params 传参配置的是name，在 params中配置 path 无效\nquery 在路由配置不需要设置参数，而 params 必须设置\nquery 传递的参数会显示在地址栏中\nparams传参刷新会无效，但是 query 会保存传递过来的值，刷新不变 ;\n\n2.4.7 嵌套路由// 一些应用程序的 UI 由多层嵌套的组件组成。在这种情况下，URL 的片段通常对应于特定的嵌套组件结构，例如：\nconst routes: Array&lt;RouteRecordRaw> = [\n    &#123;\n        path: \"/user\",\n        component: () => import('../components/footer.vue'),\n        children: [\n            &#123;\n                path: \"\",    // /user  匹配\n                name: \"Login\",\n                component: () => import('../components/login.vue')\n            &#125;,\n            &#123;\n                path: \"reg\",\n                name: \"Reg\",    // /user/reg 匹配\n                component: () => import('../components/reg.vue')\n            &#125;\n        ]\n    &#125;,\n]\n\n\n\n2.4.8 命名视图import &#123; createRouter, createWebHistory, RouteRecordRaw &#125; from 'vue-router'\n \n \nconst routes: Array&lt;RouteRecordRaw> = [\n    &#123;\n        path: \"/\",\n        components: &#123;\n            default: () => import('../components/layout/menu.vue'),\n            header: () => import('../components/layout/header.vue'),\n            content: () => import('../components/layout/content.vue'),\n        &#125;\n    &#125;,\n]\n \nconst router = createRouter(&#123;\n    history: createWebHistory(),\n    routes\n&#125;)\n \nexport default router\n\n&lt;div&gt;\n  &lt;router-view&gt;&lt;&#x2F;router-view&gt;\n  &lt;router-view name&#x3D;&quot;header&quot;&gt;&lt;&#x2F;router-view&gt;\n  &lt;router-view name&#x3D;&quot;content&quot;&gt;&lt;&#x2F;router-view&gt;\n&lt;&#x2F;div&gt;\n\n\n\n2.4.9 重定向-别名\n字符串形式配置，访问&#x2F; 重定向到 &#x2F;user （地址栏显示&#x2F;,内容为&#x2F;user路由的内容）\n\nconst routes: Array&lt;RouteRecordRaw> = [\n    &#123;\n        path:'/',\n        component:()=> import('../components/root.vue'),\n        redirect:'/user1',\n      \talias: ['/root','/root2'],   // root root2 也都会匹配这个路径，执行对应的逻辑\n        children:[\n            &#123;\n                path:'/user1',\n                components:&#123;\n                    default:()=> import('../components/A.vue')\n                &#125;\n            &#125;,\n            &#123;\n                path:'/user2',\n                components:&#123;\n                    bbb:()=> import('../components/B.vue'),\n                    ccc:()=> import('../components/C.vue')\n                &#125;\n            &#125;\n        ]\n    &#125;\n]\n\n\n对象形式配置\n\nconst routes: Array&lt;RouteRecordRaw> = [\n    &#123;\n        path: '/',\n        component: () => import('../components/root.vue'),\n        redirect: &#123; path: '/user1' &#125;,\n        children: [\n            &#123;\n                path: '/user1',\n                components: &#123;\n                    default: () => import('../components/A.vue')\n                &#125;\n            &#125;,\n            &#123;\n                path: '/user2',\n                components: &#123;\n                    bbb: () => import('../components/B.vue'),\n                    ccc: () => import('../components/C.vue')\n                &#125;\n            &#125;\n        ]\n    &#125;\n]\n\n\n函数式（参数转发&#x2F;修改）\n\nconst routes: Array&lt;RouteRecordRaw> = [\n    &#123;\n        path: '/',\n        component: () => import('../components/root.vue'),\n        redirect: (to) => &#123;\n            return &#123;\n                path: '/user1',\n                query: to.query\n            &#125;\n        &#125;,\n        children: [\n            &#123;\n                path: '/user1',\n                components: &#123;\n                    default: () => import('../components/A.vue')\n                &#125;\n            &#125;,\n            &#123;\n                path: '/user2',\n                components: &#123;\n                    bbb: () => import('../components/B.vue'),\n                    ccc: () => import('../components/C.vue')\n                &#125;\n            &#125;\n        ]\n    &#125;\n]\n\n\n\n2.4.10 导航守卫// 首先启用e-plus\nnpm i element-plus  // 项目安装\n// 启用按需引入\nhttps://element-plus.gitee.io/zh-CN/guide/quickstart.html#%E6%8C%89%E9%9C%80%E5%AF%BC%E5%85%A5\n\n前置守卫// \nrouter.beforeEach((to, form, next) => &#123;\n    console.log(to, form);\n    next()\n&#125;)\n\nto: Route， 即将要进入的目标 路由对象；\nfrom: Route，当前导航正要离开的路由；\nnext(): 进行管道中的下一个钩子。如果全部钩子执行完了，则导航的状态就是 confirmed (确认的)。\nnext(false): 中断当前的导航。如果浏览器的 URL 改变了 (可能是用户手动或者浏览器后退按钮)，那么 URL 地址会重置到 from 路由对应的地址。\nnext('/') 或者 next(&#123; path: '/' &#125;): 跳转到一个不同的地址。当前的导航被中断，然后进行一个新的导航。\n\n// 鉴权DEMO\nconst whileList = ['/']\n \nrouter.beforeEach((to, from, next) => &#123;\n    let token = localStorage.getItem('token')\n    //白名单 有值 或者登陆过存储了token信息可以跳转 否则就去登录页面\n    if (whileList.includes(to.path) || token) &#123;\n        next()\n    &#125; else &#123;\n        next(&#123;\n            path:'/'\n        &#125;)\n    &#125;\n&#125;)\n\n后置守卫// 使用场景一般可以用来做loadingBar\nrouter.afterEach((to,from)=>&#123;\n    Vnode.component?.exposed?.endLoading()\n&#125;)\n\n&lt;template>\n    &lt;div class=\"wraps\">\n        &lt;div ref=\"bar\" class=\"bar\">&lt;/div>\n    &lt;/div>\n&lt;/template>\n    \n&lt;script setup lang='ts'>\nimport &#123; ref, onMounted &#125; from 'vue'\nlet speed = ref&lt;number>(1)\nlet bar = ref&lt;HTMLElement>()\nlet timer = ref&lt;number>(0)\nconst startLoading = () => &#123;\n\t  // lodingbar\n    let dom = bar.value as HTMLElement;\n    speed.value = 1\n    timer.value = window.requestAnimationFrame(function fn() &#123;\n        if (speed.value &lt; 90) &#123;\n            speed.value += 1;\n            dom.style.width = speed.value + '%'\n            timer.value = window.requestAnimationFrame(fn)\n        &#125; else &#123;\n            speed.value = 1;\n            window.cancelAnimationFrame(timer.value)\n        &#125;\n    &#125;)\n \n&#125;\n \nconst endLoading = () => &#123;\n    let dom = bar.value as HTMLElement;\n    setTimeout(() => &#123;\n        window.requestAnimationFrame(() => &#123;\n            speed.value = 100;\n            dom.style.width = speed.value + '%'\n        &#125;)\n    &#125;, 500)\n \n&#125;\n \n \ndefineExpose(&#123;\n    startLoading,\n    endLoading\n&#125;)\n&lt;/script>\n    \n&lt;style scoped lang=\"less\">\n.wraps &#123;\n    position: fixed;\n    top: 0;\n    width: 100%;\n    height: 2px;\n    .bar &#123;\n        height: inherit;\n        width: 0;\n        background: blue;\n    &#125;\n&#125;\n&lt;/style>\n\nimport loadingBar from './components/loadingBar.vue'\nconst Vnode = createVNode(loadingBar)\nrender(Vnode, document.body)\nconsole.log(Vnode);\n \nrouter.beforeEach((to, from, next) => &#123;\n    Vnode.component?.exposed?.startLoading()\n&#125;)\n \nrouter.afterEach((to, from) => &#123;\n    Vnode.component?.exposed?.endLoading()\n&#125;)\n\n2.4.11 路由元信息通过路由记录的 meta 属性可以定义路由的元信息。使用路由元信息可以在路由中附加自定义的数据，例如：\n\n权限校验标识。\n路由组件的过渡名称。\n路由组件持久化缓存 (keep-alive) 的相关配置。\n标题名称\n\n我们可以在导航守卫或者是路由对象中访问路由的元信息数据。\nconst router = createRouter(&#123;\n  history: createWebHistory(import.meta.env.BASE_URL),\n  routes: [\n    &#123;\n      path: '/',\n      component: () => import('@/views/Login.vue'),\n      meta: &#123;\n        title: \"登录\"\n      &#125;\n    &#125;,\n    &#123;\n      path: '/index',\n      component: () => import('@/views/Index.vue'),\n      meta: &#123;\n        title: \"首页\",\n      &#125;\n    &#125;\n  ]\n&#125;)\n\n// 如果不使用扩展 将会是unknow 类型\ndeclare module 'vue-router' &#123;\n  interface RouteMeta &#123;\n    title?: string\n  &#125;\n&#125;\n\n2.4.12  路由过渡效果想要在你的路径组件上使用转场，并对导航进行动画处理，你需要使用 v-slot API\n&lt;router-view #default&#x3D;&quot;&#123;route,Component&#125;&quot;&gt;\n  &lt;transition  :enter-active-class&#x3D;&quot;&#96;animate__animated $&#123;route.meta.transition&#125;&#96;&quot;&gt;\n    &lt;component :is&#x3D;&quot;Component&quot;&gt;&lt;&#x2F;component&gt;\n&lt;&#x2F;transition&gt;\n&lt;&#x2F;router-view&gt;\n\n上面的用法会对所有的路由使用相同的过渡。如果你想让每个路由的组件有不同的过渡，你可以将元信息和动态的 name 结合在一起，放在 上：\ndeclare module 'vue-router'&#123;\n     interface RouteMeta &#123;\n        title:string,\n        transition:string,\n     &#125;\n&#125;\n \nconst router = createRouter(&#123;\n  history: createWebHistory(import.meta.env.BASE_URL),\n  routes: [\n    &#123;\n      path: '/',\n      component: () => import('@/views/Login.vue'),\n      meta:&#123;\n         title:\"登录页面\",\n         transition:\"animate__fadeInUp\",\n      &#125;\n    &#125;,\n    &#123;\n      path: '/index',\n      component: () => import('@/views/Index.vue'),\n      meta:&#123;\n         title:\"首页！！！\",\n         transition:\"animate__bounceIn\",\n      &#125;\n    &#125;\n  ]\n&#125;)\n\n\n\n\n\n\n\n\n\n\n以上使用了 animate.css  -&gt;  npm install animate.css -S\n2.4.13 滚动行为使用前端路由，当切换到新路由时，想要页面滚到顶部，或者是保持原先的滚动位置，就像重新加载页面那样。vue-router 可以自定义路由切换时页面如何滚动。\n当创建一个 Router 实例，你可以提供一个 scrollBehavior 方法\nconst router = createRouter(&#123;\n  history: createWebHistory(),\n  scrollBehavior: (to, from, savePosition) => &#123;\n    console.log(to, '==============>', savePosition);\n    return new Promise((r) => &#123;\n      setTimeout(() => &#123;\n        r(&#123;\n          top: 10000\n        &#125;)\n      &#125;, 2000);\n    &#125;)\n  &#125;,\n\nscrollBehavior 方法接收 to 和 from 路由对象。第三个参数 savedPosition 当且仅当 popstate 导航 (通过浏览器的 前进&#x2F;后退 按钮触发) 时才可用。\nscrollBehavior 返回滚动位置的对象信息，长这样：\n\n{ left: number, top: number }\n\nconst router = createRouter(&#123;\n  history: createWebHistory(),\n  scrollBehavior: (to, from, savePosition) => &#123;\n    return &#123;\n       top:200\n    &#125;\n  &#125;,\n\n2.4.14 动态路由我们一般使用动态路由都是后台会返回一个路由表前端通过调接口拿到后处理(后端处理路由);主要使用的方法就是router.addRoute\n添加路由 动态路由主要通过两个函数实现。router.addRoute() 和 router.removeRoute()。它们只注册一个新的路由，也就是说，如果新增加的路由与当前位置相匹配，就需要你用 router.push() 或 router.replace() 来手动导航，才能显示该新路由\nrouter.addRoute(&#123; path: '/about', component: About &#125;)\n\n删除路由有几个不同的方法来删除现有的路由：\n\n通过添加一个名称冲突的路由。如果添加与现有途径名称相同的途径，会先删除路由，再添加路由：\n\nrouter.addRoute(&#123; path: '/about', name: 'about', component: About &#125;)\n// 这将会删除之前已经添加的路由，因为他们具有相同的名字且名字必须是唯一的\nrouter.addRoute(&#123; path: '/other', name: 'about', component: Other &#125;)\n\n\n通过调用 router.addRoute() 返回的回调：\n\nconst removeRoute = router.addRoute(routeRecord)\nremoveRoute() // 删除路由如果存在的话\n\n当路由没有名称时，这很有用。\n\n通过使用 router.removeRoute() 按名称删除路由：\n\nrouter.addRoute(&#123; path: '/about', name: 'about', component: About &#125;)\n// 删除路由\nrouter.removeRoute('about')\n\n需要注意的是，如果你想使用这个功能，但又想避免名字的冲突，可以在路由中使用 Symbol 作为名字。当路由被删除时，所有的别名和子路由也会被同时删除\n查看现有路由Vue Router 提供了两个功能来查看现有的路由：\n\nrouter.hasRoute()：检查路由是否存在。\nrouter.getRoutes()：获取一个包含所有路由记录的数组。\n\nDEMOconst initRouter = async () => &#123;\n    const result = await axios.get('http://localhost:9999/login', &#123; params: formInline &#125;);\n    result.data.route.forEach((v: any) => &#123;\n        router.addRoute(&#123;\n            path: v.path,\n            name: v.name,\n                                    //这儿不能使用@\n            component: () => import(`../views/$&#123;v.component&#125;`)\n        &#125;)\n        router.push('/index')\n    &#125;)\n    console.log(router.getRoutes());\n \n&#125;\n\n\n\n2.5 Pinia\n\n\n\n\n\n\n\n\npinia_小满zs的博客-CSDN博客\n2.5.1 StateState | Pinia 中文文档 (web3doc.top)\n\nState 是允许直接修改值的 例如current++\n批量修改State的值 storeName.$path(&#123;k1:v1,k2:v2&#125;)\n函数式修改【推荐】\n\n&lt;template&gt;\n     &lt;div&gt;\n         &lt;button @click&#x3D;&quot;Add&quot;&gt;+&lt;&#x2F;button&gt;\n          &lt;div&gt;\n             &#123;&#123;Test.current&#125;&#125;\n          &lt;&#x2F;div&gt;\n          &lt;div&gt;\n            &#123;&#123;Test.age&#125;&#125;\n          &lt;&#x2F;div&gt;\n     &lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n \n&lt;script setup lang&#x3D;&#39;ts&#39;&gt;\nimport &#123;useTestStore&#125; from &#39;.&#x2F;store&#39;\nconst Test &#x3D; useTestStore()\nconst Add &#x3D; () &#x3D;&gt; &#123;\n    Test.$patch((state)&#x3D;&gt;&#123;\n       state.current++;\n       state.age &#x3D; 40\n    &#125;)\n&#125;\n \n&lt;&#x2F;script&gt;\n \n&lt;style&gt;\n \n&lt;&#x2F;style&gt;\n\n\n通过原始对象修改\n\n&lt;template>\n     &lt;div>\n         &lt;button @click=\"Add\">+&lt;/button>\n          &lt;div>\n             &#123;&#123;Test.current&#125;&#125;\n          &lt;/div>\n          &lt;div>\n            &#123;&#123;Test.age&#125;&#125;\n          &lt;/div>\n     &lt;/div>\n&lt;/template>\n \n&lt;script setup lang='ts'>\nimport &#123;useTestStore&#125; from './store'\nconst Test = useTestStore()\nconst Add = () => &#123;\n    Test.$state = &#123;\n       current:10,\n       age:30\n    &#125;    \n&#125;\n \n&lt;/script>\n \n&lt;style>\n \n&lt;/style>\n\n\n通过action修改\n\nimport &#123; defineStore &#125; from 'pinia'\nimport &#123; Names &#125; from './store-naspace'\nexport const useTestStore = defineStore(Names.TEST, &#123;\n     state:()=>&#123;\n         return &#123;\n            current:1,\n            age:30\n         &#125;\n     &#125;,\n \n     actions:&#123;\n         setCurrent () &#123;\n             this.current++\n         &#125;\n     &#125;\n&#125;)\n\n&lt;template&gt;\n     &lt;div&gt;\n         &lt;button @click&#x3D;&quot;Add&quot;&gt;+&lt;&#x2F;button&gt;\n          &lt;div&gt;\n             &#123;&#123;Test.current&#125;&#125;\n          &lt;&#x2F;div&gt;\n          &lt;div&gt;\n            &#123;&#123;Test.age&#125;&#125;\n          &lt;&#x2F;div&gt;\n     &lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n \n&lt;script setup lang&#x3D;&#39;ts&#39;&gt;\nimport &#123;useTestStore&#125; from &#39;.&#x2F;store&#39;\nconst Test &#x3D; useTestStore()\nconst Add &#x3D; () &#x3D;&gt; &#123;\n     Test.setCurrent()\n&#125;\n \n&lt;&#x2F;script&gt;\n \n&lt;style&gt;\n \n&lt;&#x2F;style&gt;\n\n2.5.2 解构store// 直接结构是不具有响应式的，需要使用内置api \nimport &#123; storeToRefs &#125; from 'pinia'\nconst Test = useTestStore()\nconst &#123; current, name &#125; = storeToRefs(Test)\n\n2.5.3 Actions&amp;GetterAction 支持同步&amp;异步\n\n\n\n\n\n\n\n\n1.同步-直接调用\nimport &#123; defineStore &#125; from 'pinia'\nimport &#123; Names &#125; from './store-naspace'\nexport const useTestStore = defineStore(Names.TEST, &#123;\n    state: () => (&#123;\n        counter: 0,\n    &#125;),\n    actions: &#123;\n        increment() &#123;\n            this.counter++\n        &#125;,\n        randomizeCounter() &#123;\n            this.counter = Math.round(100 * Math.random())\n        &#125;,\n    &#125;,\n&#125;)\n\n\n&lt;template&gt;\n     &lt;div&gt;\n         &lt;button @click&#x3D;&quot;Add&quot;&gt;+&lt;&#x2F;button&gt;\n          &lt;div&gt;\n             &#123;&#123;Test.counter&#125;&#125;\n          &lt;&#x2F;div&gt;    \n     &lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n \n&lt;script setup lang&#x3D;&#39;ts&#39;&gt;\nimport &#123;useTestStore&#125; from &#39;.&#x2F;store&#39;\nconst Test &#x3D; useTestStore()\nconst Add &#x3D; () &#x3D;&gt; &#123;\n     Test.randomizeCounter()\n&#125;\n \n&lt;&#x2F;script&gt;\n \n&lt;style&gt;\n \n&lt;&#x2F;style&gt;\n\n\n\n\n\n\n\n\n\n\n2.异步-结合 async await\nimport &#123; defineStore &#125; from 'pinia'\nimport &#123; Names &#125; from './store-naspace'\n \ntype Result = &#123;\n    name: string\n    isChu: boolean\n&#125;\n \nconst Login = (): Promise&lt;Result> => &#123;\n    return new Promise((resolve) => &#123;\n        setTimeout(() => &#123;\n            resolve(&#123;\n                name: '小满',\n                isChu: true\n            &#125;)\n        &#125;, 3000)\n    &#125;)\n&#125;\n \nexport const useTestStore = defineStore(Names.TEST, &#123;\n    state: () => (&#123;\n        user: &lt;Result>&#123;&#125;,\n        name: \"123\"\n    &#125;),\n    actions: &#123;\n        async getLoginInfo() &#123;\n            const result = await Login()\n            this.user = result;\n        &#125;\n    &#125;,\n&#125;)\n\n&lt;template&gt;\n     &lt;div&gt;\n         &lt;button @click&#x3D;&quot;Add&quot;&gt;test&lt;&#x2F;button&gt;\n          &lt;div&gt;\n             &#123;&#123;Test.user&#125;&#125;\n          &lt;&#x2F;div&gt;    \n     &lt;&#x2F;div&gt;\n&lt;&#x2F;template&gt;\n \n&lt;script setup lang&#x3D;&#39;ts&#39;&gt;\nimport &#123;useTestStore&#125; from &#39;.&#x2F;store&#39;\nconst Test &#x3D; useTestStore()\nconst Add &#x3D; () &#x3D;&gt; &#123;\n     Test.getLoginInfo()\n&#125;\n \n&lt;&#x2F;script&gt;\n \n&lt;style&gt;\n \n&lt;&#x2F;style&gt;\n\n2.5.4 其他API\n$reset 恢复初始状态\n$subscribe  订阅state变更\n\nTest.$subscribe((args,state)=>&#123;\n   console.log(args,state);\n&#125;)\n\n//如果你的组件卸载之后还想继续调用请设置第二个参数\nTest.$subscribe((args,state)=>&#123;\n   console.log(args,state);\n   \n&#125;,&#123;\n  detached:true\n&#125;)\n\n\n\n$onAction  监听action方法调用\n\nTest.$subscribe((args,state)=>&#123;\n   console.log(args,state);\n   \n&#125;,&#123;\n  detached:true\n&#125;)\n\n\n2.5.5 Pinia插件const __piniaKey = '__PINIAKEY__'\n//定义兜底变量\ntype Options = &#123;\n    key?: string\n&#125;\n//定义入参类型\n//将数据存在本地\nconst setStorage = (key: string, value: any): void => &#123;\n    localStorage.setItem(key, JSON.stringify(value))\n&#125;\n//存缓存中读取\nconst getStorage = (key: string) => &#123;\n    return (localStorage.getItem(key) ? JSON.parse(localStorage.getItem(key) as string) : &#123;&#125;)\n&#125;\n//利用函数柯丽华接受用户入参\nconst piniaPlugin = (options: Options) => &#123;\n//将函数返回给pinia  让pinia  调用 注入 context\n    return (context: PiniaPluginContext) => &#123;\n\n        const &#123;store&#125; = context;\n\n        const data = getStorage(`$&#123;options?.key ?? __piniaKey&#125;-$&#123;store.$id&#125;`)\n\n        store.$subscribe(() => &#123;\n\n            setStorage(`$&#123;options?.key ?? __piniaKey&#125;-$&#123;store.$id&#125;`, toRaw(store.$state));\n\n        &#125;)\n\n//返回值覆盖pinia 原始值\n        return &#123;\n            ...data\n        &#125;\n    &#125;\n&#125;\n//初始化pinia\nconst pinia = createPinia()\n//注册pinia 插件\npinia.use(piniaPlugin(&#123;\n    key: \"pinia\"\n\n&#125;))\n\n\n\n\n\n2.6 VUE3生命周期3. Typescritp 语法3.1 入门3.1.1 安装sudo npm install -g typescript\ntsc -v\n\n# 如果想要直接本地运行ts代码\nsudo npm install -g ts-node\nts-node -v\n\n3.1.2 基本使用# html中无法直接引入ts文件，需要转为js\ntsc tsFileName\n\n\n\n3.1.3 基本数据类型\n\n\n\n\n\n\n\n\nBoolean、Number、String、null、undefined 以及 ES6 的  Symbol 和 ES10 的 BigInt\n1.字符串let a: string = '123'\n//普通声明\n//也可以使用es6的字符串模板\nlet str: string = `dddd$&#123;a&#125;`  // 其中 ` 用来定义 ES6 中的模板字符串，$&#123;expr&#125; 用来在模板字符串中嵌入表达式。\n\n2.数字类型支持十六进制、十进制、八进制和二进制；\nlet notANumber: number = NaN;//Nan\nlet infinityNumber: number = Infinity;//无穷大\nlet num: number = 123;//普通数字\nlet decimal: number = 6;//十进制\nlet hex: number = 0xf00d;//十六进制\nlet binary: number = 0b1010;//二进制\nlet octal: number = 0o744;//八进制s\n\n3.布尔类型注意，使用构造函数 Boolean 创造的对象不是布尔值\n// let createdBoolean: boolean = new Boolean(1)\n//这样会报错 应为事实上 new Boolean() 返回的是一个 Boolean 对象 \nlet createdBoolean: Boolean = new Boolean(1)  // 正确写法\n\nlet booleand: boolean = true //可以直接使用布尔值\nlet booleand2: boolean = Boolean(1) //也可以通过函数返回布尔值\n\n4.空值类型 voidfunction voidFn(): void &#123;\n    console.log('test void')\n&#125;\n// void 类型的用法，主要是用在我们不希望调用者关心函数返回值的情况下，比如通常的异步回调函数\n// void也可以定义undefined 和 null类型\nlet u: void = undefined\nlet n: void = null;\n\n5.Null和undefined类型let u: undefined = undefined;//定义undefined\nlet n: null = null;//定义null\n\n// void 和 undefined 和 null 最大的区别\n与 void 的区别是，undefined 和 null 是所有类型的子类型。也就是说 undefined 类型的变量，可以赋值给 string 类型的变量\n\n//这样写会报错 void类型不可以分给其他类型\n// let test: void = undefined\n// let num2: string = \"1\"\n// num2 = test\n\n//这样是没问题的\nlet test: null = null\nlet num2: string = \"1\"\nnum2 = test\n \n//或者这样的\nlet test: undefined = undefined\nlet num2: string = \"1\"\nnum2 = test\n\n\n\n\n\n\n\n\n\n\n&#x2F;&#x2F; 如果开启了严格模式  tsconfig.json\n{ “compilerOptions”:{     “strict”: true }}\n&#x2F;&#x2F; null 不能 赋予 void 类型\n6.Any和Unknown类型// 1.没有强制限定哪种类型，随时切换类型都可以 我们可以对 any 进行任何操作，不需要检查类型\nlet anys:any = 123\nanys = '123'\nanys = true\n\n// 2.声明变量的时候没有指定任意类型默认为any,弊端如果使用any 就失去了TS类型检测的作用\nlet anys;\nanys = '123'\nanys = true\n\n// 3.TypeScript 3.0中引入的 unknown 类型也被认为是 top type ，但它更安全。与 any 一样，所有类型都可以分配给unknown,unknow类型比any更加严格当 你要使用any 的时候可以尝试使用unknow\n//unknown 可以定义任何类型的值\nlet value: unknown;\n \nvalue = true;             // OK\nvalue = 42;               // OK\nvalue = \"Hello World\";    // OK\nvalue = [];               // OK\nvalue = &#123;&#125;;               // OK\nvalue = null;             // OK\nvalue = undefined;        // OK\nvalue = Symbol(\"type\");   // OK\n \n//这样写会报错unknow类型不能作为子类型只能作为父类型 any可以作为父类型和子类型\n//unknown类型不能赋值给其他类型\nlet names:unknown = '123'\nlet names2:string = names\n \n//这样就没问题 any类型是可以的\nlet names:any = '123'\nlet names2:string = names   \n \n//unknown可赋值对象只有unknown 和 any\nlet bbb:unknown = '123'\nlet aaa:any= '456'\n \naaa = bbb\n \n// 注\n如果是any类型在对象没有这个属性的时候还在获取是不会报错的\nlet obj:any = &#123;b:1&#125;\nobj.a\n \n如果是unknow 是不能调用属性和方法\nlet obj:unknown = &#123;b:1,ccc:():number=>213&#125;\nobj.b\nobj.ccc()\n\n7.对象类型\n在typescript中，我们定义对象的方式要用关键字interface（接口），我的理解是使用interface来定义一种约束，让数据的结构满足约束的格式。定义方式如下：\n//这样写是会报错的 因为我们在person定义了a，b但是对象里面缺少b属性\n//使用接口约束的时候不能多一个属性也不能少一个属性\n//必须与接口保持一致\ninterface Person &#123;\n    b:string,\n    a:string\n&#125;\n \nconst person:Person  = &#123;\n    a:\"213\"\n&#125;\n\n//重名interface  可以合并\ninterface A&#123;name:string&#125;\ninterface A&#123;age:number&#125;\nvar x:A=&#123;name:'xx',age:20&#125;\n//继承\ninterface A&#123;\n    name:string\n&#125;\n \ninterface B extends A&#123;\n    age:number\n&#125;\n \nlet obj:B = &#123;\n    age:18,\n    name:\"string\"\n&#125;\n\n// 可选属性 使用?操作符\n//可选属性的含义是该属性可以不存在\n//所以说这样写也是没问题的\ninterface Person &#123;\n    b?:string,\n    a:string\n&#125;\n \nconst person:Person  = &#123;\n    a:\"213\"\n&#125;\n// 任意属性 [propName: string]\n// 需要注意的是，一旦定义了任意属性，那么确定属性和可选属性的类型都必须是它的类型的子集：\n//在这个例子当中我们看到接口中并没有定义C但是并没有报错\n//应为我们定义了[propName: string]: any;\n//允许添加新的任意属性\ninterface Person &#123;\n    b?:string,\n    a:string,\n    [propName: string]: any;\n&#125;\n \nconst person:Person  = &#123;\n    a:\"213\",\n    c:\"123\"\n&#125;\n\n// 只读属性 readonly\ninterface Person &#123;\n    b?: string,\n    readonly a: string,\n    [propName: string]: any;  // 对已规定的类型进行限制，并声明其他任意数量的属性定义\n&#125;\n \nconst person: Person = &#123;\n    a: \"213\",\n    c: \"123\"\n&#125;\n//这样写是会报错的\n//应为a是只读的不允许重新赋值\nperson.a = 123\n\n\n// 函数\ninterface Person &#123;\n    b?: string,\n    readonly a: string,\n    [propName: string]: any;\n    cb():void\n&#125;\n \nconst person: Person = &#123;\n    a: \"213\",\n    c: \"123\",\n    cb:()=>&#123;\n        console.log(123)\n    &#125;\n&#125;\n\n7.Array//类型加中括号\nlet arr:number[] = [123]\n// 或通过泛型定义\nlet arr:Array&lt;number> = [1,2,3,4,5]\n// let arr:number[] = [1,2,3,'1'] //这样会报错定义了数字类型出现字符串是不允许的\n//操作方法添加也是不允许的\nlet arr:number[] = [1,2,3,]\n// arr.unshift('1')\n \n \nvar arr: number[] = [1, 2, 3]; //数字类型的数组\nvar arr2: string[] = [\"1\", \"2\"]; //字符串类型的数组\nvar arr3: any[] = [1, \"2\", true]; //任意类型的数组\n\n// 用接口表示数组\ninterface NumberArray &#123;\n    [index: number]: number;\n&#125;\nlet fibonacci: NumberArray = [1, 1, 2, 3, 5];\n//表示：只要索引的类型是数字时，那么值的类型必须是数字\n// 联合数组\nlet arr: Array&lt;number|string> = [1,2,3,'4']\n// 多维数组\nlet data:number[][] = [[1,2], [3,4]];\n\n// 方法任意参数\nfunction Arr(...args:any): void &#123;\n    console.log(arguments)\n    //错误的arguments 是类数组不能这样定义\n    let arr:number[] = arguments\n&#125;\nArr(111, 222, 333)\n\nfunction Arr(...args:any): void &#123;\n    console.log(arguments) \n    //ts内置对象IArguments 定义\n    let arr:IArguments = arguments\n&#125;\nArr(111, 222, 333)\n\n//其中 IArguments 是 TypeScript 中定义好了的类型，它实际上就是：\ninterface IArguments &#123;\n[index: number]: any;\nlength: number;\ncallee: Function;\n&#125;\n\n8.元组// 元组就是数组的变种\n// 元组（Tuple）是固定数量的不同类型的元素的组合。\n// 元组与集合的不同之处在于，元组中的元素类型可以是不同的，而且数量固定。元组的好处在于可以把多个元素作为一个单元传递。如果一个方法需要返回多个值，可以把这多个值作为元组返回，而不需要创建额外的类来表示。\n// 典型应用：excel\nlet excel: [string, string, number, string][] = [\n    ['title', 'name', 1, '123'],\n    ['title', 'name', 1, '123'],\n    ['title', 'name', 1, '123'],\n    ['title', 'name', 1, '123'],\n    ['title', 'name', 1, '123'],\n]\n\n9.枚举// 数字枚举\nenum Types&#123;\n   Red,\n   Green,\n   BLue\n&#125;\n//等于如下形式，默认就是从0开始的 可以不写值，所以可以通过下标访问\nenum Types&#123;\n   Red = 0,\n   Green = 1,\n   BLue = 2\n&#125;\n// 指定初始值 1,2,3\nenum Types&#123;\n   Red = 1,\n   Green,\n   BLue\n&#125;\n\n// 字符串枚举\nenum Types&#123;\n   Red = 'red',\n   Green = 'green',\n   BLue = 'blue'\n&#125;\n\n// 异构枚举\nenum Types&#123;\n   No = \"No\",\n   Yes = 1,\n&#125;\n\n// 接口枚举\nenum Types &#123;\n  yyds,\n  dddd\n&#125;\ninterface A &#123;\n  red:Types.yyds\n&#125;\n\nlet obj:A = &#123;\n  red:Types.yyds\n&#125;\n\n\n// const枚举\nconst enum Types&#123;\n   No = \"No\",\n   Yes = 1,\n&#125;\n\n10.Never// 返回never的函数必须存在无法达到的终点\n// 因为必定抛出异常，所以 error 将不会有返回值\nfunction error(message: string): never &#123;\n    throw new Error(message);\n&#125;\n \n// 因为存在死循环，所以 loop 将不会有返回值\nfunction loop(): never &#123;\n    while (true) &#123;\n    &#125;\n&#125;\n\n// 一个例子\ninterface A &#123;\n    type: \"foo\"\n&#125;\n \ninterface B &#123;\n    type: \"bar\"\n&#125;\ntype All = A | B ;\nfunction handleValue(val: All) &#123;\n    switch (val.type) &#123;\n        case 'foo':\n            break;\n        case 'bar':\n            break\n        default:\n            //兜底逻辑 一般是不会进入这儿如果进来了就是程序异常了\n            \n            const exhaustiveCheck:never = val;\n            break\n    &#125;\n&#125;\n\n11.Symbollet sym1 = Symbol();\nlet sym2 = Symbol(\"key\"); // 可选的字符串key\n\nconst s1 = Symbol()\nconst s2 = Symbol()\n// s1 === s2 =>false\n\nlet sym = Symbol();\n \nlet obj = &#123;\n    [sym]: \"value\"\n&#125;;\n \nconsole.log(obj[sym]); // \"value\"\n\n\nconst symbol1 = Symbol('666')\nconst symbol2 = Symbol('777')\nconst obj1= &#123;\n   [symbol1]: '小满',\n   [symbol2]: '二蛋',\n   age: 19,\n   sex: '女'\n&#125;\n\n// 以下方式无法拿到symbol对象\n// 1 for in 遍历\nfor (const key in obj1) &#123;\n   // 注意在console看key,是不是没有遍历到symbol1\n   console.log(key)\n&#125;\n// 2 Object.keys 遍历\nObject.keys(obj1)\nconsole.log(Object.keys(obj1))\n// 3 getOwnPropertyNames\nconsole.log(Object.getOwnPropertyNames(obj1))\n// 4 JSON.stringfy\nconsole.log(JSON.stringify(obj1))\n\n// 可以通过以下方式拿到\n// 1 拿到具体的symbol 属性,对象中有几个就会拿到几个\nObject.getOwnPropertySymbols(obj1)\nconsole.log(Object.getOwnPropertySymbols(obj1))\n// 2 es6 的 Reflect 拿到对象的所有属性\nReflect.ownKeys(obj1)\nconsole.log(Reflect.ownKeys(obj1))\n\nvar arr = [1,2,3,4];\nlet iterator = arr[Symbol.iterator]();\n \nconsole.log(iterator.next());  //&#123; value: 1, done: false &#125;\nconsole.log(iterator.next());  //&#123; value: 2, done: false &#125;\nconsole.log(iterator.next());  //&#123; value: 3, done: false &#125;\nconsole.log(iterator.next());  //&#123; value: 4, done: false &#125;\nconsole.log(iterator.next());  //&#123; value: undefined, done: true &#125;\n\ninterface Item &#123;\n    age: number,\n    name: string\n&#125;\n \nconst array: Array&lt;Item> = [&#123; age: 123, name: \"1\" &#125;, &#123; age: 123, name: \"2\" &#125;, &#123; age: 123, name: \"3\" &#125;]\n \ntype mapTypes = string | number\nconst map:Map&lt;mapTypes,mapTypes> = new Map()\n \nmap.set('1','王爷')\nmap.set('2','陆北')\n \nconst obj = &#123;\n    aaa:123,\n    bbb:456\n&#125;\n \nlet set:Set&lt;number> = new Set([1,2,3,4,5,6])\n// let it:Iterator&lt;Item> = array[Symbol.iterator]()\nconst gen = (erg:any): void => &#123;\n    let it: Iterator&lt;any> = erg[Symbol.iterator]()\n    let next:any= &#123; done: false &#125;\n    while (!next.done) &#123;\n        next =  it.next()\n        if (!next.done) &#123;\n            console.log(next.value)\n        &#125;\n    &#125;\n&#125;\ngen(array)\n\n\n\n\n\n\n\n3.1.2 函数//注意，参数不能多传，也不能少传 必须按照约定的类型来\nconst fn = (name: string, age:number): string => &#123;\n    return name + age\n&#125;\nfn('张三',18)\n\n// 可选参数?\nconst fn = (name: string, age?:number): string => &#123;\n    return name + age\n&#125;\nfn('张三')\n\n// 默认值\nconst fn = (name: string = \"我是默认值\"): string => &#123;\n    return name\n&#125;\nfn()\n// 接口定义函数\n//定义参数 num 和 num2  ：后面定义返回值的类型\ninterface Add &#123;\n    (num:  number, num2: number): number\n&#125;\n \nconst fn: Add = (num: number, num2: number): number => &#123;\n    return num + num2\n&#125;\nfn(5, 5)\n \ninterface User&#123;\n    name: string;\n    age: number;\n&#125;\nfunction getUserInfo(user: User): User &#123;\n  return user\n&#125;\n// 不定参数\nconst fn = (array:number[],...items:any[]):any[] => &#123;\n       console.log(array,items)\n       return items\n&#125;\n \nlet a:number[] = [1,2,3]\nfn(a,'4','5','6')\n\n// 函数重载\n// 重载是方法名字相同，而参数不同，返回类型可以相同也可以不同。\n// 如果参数类型不同，则参数类型应设置为 any。\n// 参数数量不同你可以将不同的参数设置为可选。\nfunction fn(params: number): void\n \nfunction fn(params: string, params2: number): void\n \nfunction fn(params: any, params2?: any): void &#123;\n \n    console.log(params)\n \n    console.log(params2)\n \n&#125;\n\nfn(123)\nfn('123',456)\n\n\n\n3.1.3 联合类型|类型断言|交叉类型1.联合类型//例如我们的手机号通常是13XXXXXXX 为数字类型 这时候产品说需要支持座机\n//所以我们就可以使用联合类型支持座机字符串\nlet myPhone: number | string  = '010-820'\n \n//这样写是会报错的应为我们的联合类型只有数字和字符串并没有布尔值\nlet myPhone: number | string  = true\n\n// 函数中掺入联合类型\nconst fn = (something:number | boolean):boolean => &#123;\n     return !!something\n&#125;\n\n2.交叉类型interface People &#123;\n  age: number,\n  height： number\n&#125;\ninterface Man&#123;\n  sex: string\n&#125;\n// 将传入参数封装为一个对象\nconst xiaoman = (man: People &amp; Man) => &#123;\n  console.log(man.age)\n  console.log(man.height)\n  console.log(man.sex)\n&#125;\nxiaoman(&#123;age: 18,height: 180,sex: 'male'&#125;);\n\n3.断言类型interface A &#123;\n       run: string\n&#125;\n \ninterface B &#123;\n       build: string\n&#125;\n \nconst fn = (type: A | B): string => &#123;\n       return type.run\n&#125;\n// 这样写是有警告的应为B的接口上面是没有定义run这个属性的\n// 可以使用类型断言来推断他传入的是A接口的值\ninterface A &#123;\n       run: string\n&#125;\n \ninterface B &#123;\n       build: string\n&#125;\n \nconst fn = (type: A | B): string => &#123;\n       return (type as A).run\n&#125;\n\n// 临时断言\n// window.abc = 123 //这样写会报错因为window没有abc这个东西\n(window as any).abc = 123 //可以使用any临时断言在 any 类型的变量上，访问任何属性都是允许的。\n\n// as const\n// 常量\nconst names = '小满'\nnames = 'aa' //无法修改\nlet names2 = '小满' as const\nnames2 = 'aa' //无法修改\n\n// 数组\nlet a1 = [10, 20] as const;\nconst a2 = [10, 20];\na1.unshift(30); // 错误，此时已经断言字面量为[10, 20],数据无法做任何修改\na2.unshift(30); // 通过，没有修改指针\n\n// 断言失效\nfunction toBoolean(something: any): boolean &#123;\n    return something as boolean;\n&#125;\n \ntoBoolean(1); // 返回值为 1\n\n\n\n3.1.4 内置对象\n\n\n\n\n\n\n\n\nBoolean、Number、string、RegExp、Date、Error、DOM、BOM\nlet b: Boolean = new Boolean(1)\nconsole.log(b)\nlet n: Number = new Number(true)\nconsole.log(n)\nlet s: String = new String('哔哩哔哩关注小满zs')\nconsole.log(s)\nlet d: Date = new Date()\nconsole.log(d)\nlet r: RegExp = /^1/\nconsole.log(r)\nlet e: Error = new Error(\"error!\")\nconsole.log(e)\n\n\n\n\n\n\n\n\n\n\n DOM和BOM\nlet body: HTMLElement = document.body;\nlet allDiv: NodeList = document.querySelectorAll('div');\n//读取div 这种需要类型断言 或者加个判断应为读不到返回null\nlet div:HTMLElement = document.querySelector('div') as HTMLDivElement\ndocument.addEventListener('click', function (e: MouseEvent) &#123;\n    \n&#125;);\n//dom元素的映射表\ninterface HTMLElementTagNameMap &#123;\n    \"a\": HTMLAnchorElement;\n    \"abbr\": HTMLElement;\n    \"address\": HTMLElement;\n    \"applet\": HTMLAppletElement;\n    \"area\": HTMLAreaElement;\n    \"article\": HTMLElement;\n    \"aside\": HTMLElement;\n    \"audio\": HTMLAudioElement;\n    \"b\": HTMLElement;\n    \"base\": HTMLBaseElement;\n    \"bdi\": HTMLElement;\n    \"bdo\": HTMLElement;\n    \"blockquote\": HTMLQuoteElement;\n    \"body\": HTMLBodyElement;\n    \"br\": HTMLBRElement;\n    \"button\": HTMLButtonElement;\n    \"canvas\": HTMLCanvasElement;\n    \"caption\": HTMLTableCaptionElement;\n    \"cite\": HTMLElement;\n    \"code\": HTMLElement;\n    \"col\": HTMLTableColElement;\n    \"colgroup\": HTMLTableColElement;\n    \"data\": HTMLDataElement;\n    \"datalist\": HTMLDataListElement;\n    \"dd\": HTMLElement;\n    \"del\": HTMLModElement;\n    \"details\": HTMLDetailsElement;\n    \"dfn\": HTMLElement;\n    \"dialog\": HTMLDialogElement;\n    \"dir\": HTMLDirectoryElement;\n    \"div\": HTMLDivElement;\n    \"dl\": HTMLDListElement;\n    \"dt\": HTMLElement;\n    \"em\": HTMLElement;\n    \"embed\": HTMLEmbedElement;\n    \"fieldset\": HTMLFieldSetElement;\n    \"figcaption\": HTMLElement;\n    \"figure\": HTMLElement;\n    \"font\": HTMLFontElement;\n    \"footer\": HTMLElement;\n    \"form\": HTMLFormElement;\n    \"frame\": HTMLFrameElement;\n    \"frameset\": HTMLFrameSetElement;\n    \"h1\": HTMLHeadingElement;\n    \"h2\": HTMLHeadingElement;\n    \"h3\": HTMLHeadingElement;\n    \"h4\": HTMLHeadingElement;\n    \"h5\": HTMLHeadingElement;\n    \"h6\": HTMLHeadingElement;\n    \"head\": HTMLHeadElement;\n    \"header\": HTMLElement;\n    \"hgroup\": HTMLElement;\n    \"hr\": HTMLHRElement;\n    \"html\": HTMLHtmlElement;\n    \"i\": HTMLElement;\n    \"iframe\": HTMLIFrameElement;\n    \"img\": HTMLImageElement;\n    \"input\": HTMLInputElement;\n    \"ins\": HTMLModElement;\n    \"kbd\": HTMLElement;\n    \"label\": HTMLLabelElement;\n    \"legend\": HTMLLegendElement;\n    \"li\": HTMLLIElement;\n    \"link\": HTMLLinkElement;\n    \"main\": HTMLElement;\n    \"map\": HTMLMapElement;\n    \"mark\": HTMLElement;\n    \"marquee\": HTMLMarqueeElement;\n    \"menu\": HTMLMenuElement;\n    \"meta\": HTMLMetaElement;\n    \"meter\": HTMLMeterElement;\n    \"nav\": HTMLElement;\n    \"noscript\": HTMLElement;\n    \"object\": HTMLObjectElement;\n    \"ol\": HTMLOListElement;\n    \"optgroup\": HTMLOptGroupElement;\n    \"option\": HTMLOptionElement;\n    \"output\": HTMLOutputElement;\n    \"p\": HTMLParagraphElement;\n    \"param\": HTMLParamElement;\n    \"picture\": HTMLPictureElement;\n    \"pre\": HTMLPreElement;\n    \"progress\": HTMLProgressElement;\n    \"q\": HTMLQuoteElement;\n    \"rp\": HTMLElement;\n    \"rt\": HTMLElement;\n    \"ruby\": HTMLElement;\n    \"s\": HTMLElement;\n    \"samp\": HTMLElement;\n    \"script\": HTMLScriptElement;\n    \"section\": HTMLElement;\n    \"select\": HTMLSelectElement;\n    \"slot\": HTMLSlotElement;\n    \"small\": HTMLElement;\n    \"source\": HTMLSourceElement;\n    \"span\": HTMLSpanElement;\n    \"strong\": HTMLElement;\n    \"style\": HTMLStyleElement;\n    \"sub\": HTMLElement;\n    \"summary\": HTMLElement;\n    \"sup\": HTMLElement;\n    \"table\": HTMLTableElement;\n    \"tbody\": HTMLTableSectionElement;\n    \"td\": HTMLTableDataCellElement;\n    \"template\": HTMLTemplateElement;\n    \"textarea\": HTMLTextAreaElement;\n    \"tfoot\": HTMLTableSectionElement;\n    \"th\": HTMLTableHeaderCellElement;\n    \"thead\": HTMLTableSectionElement;\n    \"time\": HTMLTimeElement;\n    \"title\": HTMLTitleElement;\n    \"tr\": HTMLTableRowElement;\n    \"track\": HTMLTrackElement;\n    \"u\": HTMLElement;\n    \"ul\": HTMLUListElement;\n    \"var\": HTMLElement;\n    \"video\": HTMLVideoElement;\n    \"wbr\": HTMLElement;\n&#125;\n\nfunction promise():Promise&lt;number>&#123;\n   return new Promise&lt;number>((resolve,reject)=>&#123;\n       resolve(1)\n   &#125;)\n&#125;\n \npromise().then(res=>&#123;\n    console.log(res)\n&#125;)\n\n\n\n3.1.5 Class//定义类\nclass Person &#123;\n    constructor () &#123;\n \n    &#125;\n    run () &#123;\n        \n    &#125;\n&#125;\n\nclass Person&#123;\n  name: string   \n  age: number   // 如果定义了而没有使用会报错\n  constructor(name:string,age:number)&#123;\n    \tthis.name = name\n    \tthis.age = age\n  &#125;\n  run()&#123;\n    \n  &#125;\n&#125;\n\n\n\n\n\n当前类\n子类\n实例\n\n\n\nprivate\n√\n\n\n\n\nprotected\n√\n√\n\n\n\npublic（默认）\n√\n√\n√\n\n\n\ninterface PersonClass &#123;\n    get(type: boolean): boolean\n&#125;\n\ninterface PersonClass2&#123;\n    set():void,\n    asd:string\n&#125;\n\nclass A &#123;\n    name: string\n    constructor() &#123;\n        this.name = \"123\"\n    &#125;\n&#125;\n\nclass Person extends A implements PersonClass,PersonClass2 &#123;\n    asd: string\n    constructor() &#123;\n        super()\n        this.asd = '123'\n    &#125;\n\n    set () &#123;\n\n    &#125;\n\n    get(type: boolean): boolean &#123;\n        return false;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\n\n抽象类\nabstract class A &#123;\n   public name:string\n   \n&#125;\n \nnew A()\n\n\n\n\n\n3.1.6 类型别名// 基本类型别名\ntype str = string\nlet s:str = \"我是小满\"\nconsole.log(s);\n// 函数类型别名\ntype str = () => string\nlet s: str = () => \"我是小满\"\nconsole.log(s);\n// 联合类型别名\ntype str = string | number\nlet s: str = 123\nlet s2: str = '123'\nconsole.log(s,s2);\n// 值 别名\ntype value = boolean | 0 | '213'\nlet s:value = true //变量s的值  只能是上面value定义的值\n\n\n\n\n\n3.1.7 tsconfig.json\n\n\n\n\n\n\n\n\ntsc –init\n\"compilerOptions\": &#123;\n  \"incremental\": true, // TS编译器在第一次编译之后会生成一个存储编译信息的文件，第二次编译会在第一次的基础上进行增量编译，可以提高编译的速度\n  \"tsBuildInfoFile\": \"./buildFile\", // 增量编译文件的存储位置\n  \"diagnostics\": true, // 打印诊断信息 \n  \"target\": \"ES5\", // 目标语言的版本\n  \"module\": \"CommonJS\", // 生成代码的模板标准\n  \"outFile\": \"./app.js\", // 将多个相互依赖的文件生成一个文件，可以用在AMD模块中，即开启时应设置\"module\": \"AMD\",\n  \"lib\": [\"DOM\", \"ES2015\", \"ScriptHost\", \"ES2019.Array\"], // TS需要引用的库，即声明文件，es5 默认引用dom、es5、scripthost,如需要使用es的高级版本特性，通常都需要配置，如es8的数组新特性需要引入\"ES2019.Array\",\n  \"allowJS\": true, // 允许编译器编译JS，JSX文件\n  \"checkJs\": true, // 允许在JS文件中报错，通常与allowJS一起使用\n  \"outDir\": \"./dist\", // 指定输出目录\n  \"rootDir\": \"./\", // 指定输出文件目录(用于输出)，用于控制输出目录结构\n  \"declaration\": true, // 生成声明文件，开启后会自动生成声明文件\n  \"declarationDir\": \"./file\", // 指定生成声明文件存放目录\n  \"emitDeclarationOnly\": true, // 只生成声明文件，而不会生成js文件\n  \"sourceMap\": true, // 生成目标文件的sourceMap文件\n  \"inlineSourceMap\": true, // 生成目标文件的inline SourceMap，inline SourceMap会包含在生成的js文件中\n  \"declarationMap\": true, // 为声明文件生成sourceMap\n  \"typeRoots\": [], // 声明文件目录，默认时node_modules/@types\n  \"types\": [], // 加载的声明文件包\n  \"removeComments\":true, // 删除注释 \n  \"noEmit\": true, // 不输出文件,即编译后不会生成任何js文件\n  \"noEmitOnError\": true, // 发送错误时不输出任何文件\n  \"noEmitHelpers\": true, // 不生成helper函数，减小体积，需要额外安装，常配合importHelpers一起使用\n  \"importHelpers\": true, // 通过tslib引入helper函数，文件必须是模块\n  \"downlevelIteration\": true, // 降级遍历器实现，如果目标源是es3/5，那么遍历器会有降级的实现\n  \"strict\": true, // 开启所有严格的类型检查\n  \"alwaysStrict\": true, // 在代码中注入'use strict'\n  \"noImplicitAny\": true, // 不允许隐式的any类型\n  \"strictNullChecks\": true, // 不允许把null、undefined赋值给其他类型的变量\n  \"strictFunctionTypes\": true, // 不允许函数参数双向协变\n  \"strictPropertyInitialization\": true, // 类的实例属性必须初始化\n  \"strictBindCallApply\": true, // 严格的bind/call/apply检查\n  \"noImplicitThis\": true, // 不允许this有隐式的any类型\n  \"noUnusedLocals\": true, // 检查只声明、未使用的局部变量(只提示不报错)\n  \"noUnusedParameters\": true, // 检查未使用的函数参数(只提示不报错)\n  \"noFallthroughCasesInSwitch\": true, // 防止switch语句贯穿(即如果没有break语句后面不会执行)\n  \"noImplicitReturns\": true, //每个分支都会有返回值\n  \"esModuleInterop\": true, // 允许export=导出，由import from 导入\n  \"allowUmdGlobalAccess\": true, // 允许在模块中全局变量的方式访问umd模块\n  \"moduleResolution\": \"node\", // 模块解析策略，ts默认用node的解析策略，即相对的方式导入\n  \"baseUrl\": \"./\", // 解析非相对模块的基地址，默认是当前目录\n  \"paths\": &#123; // 路径映射，相对于baseUrl\n    // 如使用jq时不想使用默认版本，而需要手动指定版本，可进行如下配置\n    \"jquery\": [\"node_modules/jquery/dist/jquery.min.js\"]\n  &#125;,\n  \"rootDirs\": [\"src\",\"out\"], // 将多个目录放在一个虚拟目录下，用于运行时，即编译后引入文件的位置可能发生变化，这也设置可以虚拟src和out在同一个目录下，不用再去改变路径也不会报错\n  \"listEmittedFiles\": true, // 打印输出文件\n  \"listFiles\": true// 打印编译的文件(包括引用的声明文件)\n&#125;\n \n// 指定一个匹配列表（属于自动指定该路径下的所有ts相关文件）\n\"include\": [\n   \"src/**/*\"\n],\n// 指定一个排除列表（include的反向操作）\n \"exclude\": [\n   \"demo.ts\"\n],\n// 指定哪些文件使用该配置（属于手动一个个指定文件）\n \"files\": [\n   \"demo.ts\"\n]\n\n\n\n3.1.8 命名空间// 重名会自动合并\nnamespace a &#123;    // 需要导出则在 namespace 前加入 export  对应的引入：import &#123;X&#125; from './xxx/xxx'\n    export const Time: number = 1000\n    export const fn = &lt;T>(arg: T): T => &#123;\n        return arg\n    &#125;\n    fn(Time)\n&#125;\n \n \nnamespace b &#123;\n     export const Time: number = 1000\n     export const fn = &lt;T>(arg: T): T => &#123;\n        return arg\n    &#125;\n    fn(Time)\n&#125;\n \na.Time\nb.Time\n\n// 简化\nnamespace A  &#123;\n    export namespace B &#123;\n        export const C = 1\n    &#125;\n&#125;\n \nimport X = A.B.C\nconsole.log(X);\n","slug":"Vue基础","date":"2022-09-30T09:34:43.000Z","categories_index":"","tags_index":"前端,框架","author_index":"JuneQQQ"},{"id":"cd53cdbf97b8f99c953dd3eda45eed25","title":"SpringMVC","content":"SpringMVC概述基于Spring的一个框架，实际上就是Spring的一个模块，是专门做web开发的，理解是Servlet的一个升级。SpringMVC中有一个对象是Servlet：DispatherServlet，负责接受用户的所有请求，用户把请求给了DispatherServlet，之后DispatherServlet把请求转发给我们的Controller对象，最后是Controller对象处理请求。\n入门案例添加依赖&lt;!--Servlet-->\n&lt;dependency>\n    &lt;groupId>javax.servlet&lt;/groupId>\n    &lt;artifactId>javax.servlet-api&lt;/artifactId>\n    &lt;version>4.0.1&lt;/version>\n    &lt;scope>provided&lt;/scope>\n&lt;/dependency>\n&lt;!--SpringMVC-->\n&lt;dependency>\n    &lt;groupId>org.springframework&lt;/groupId>\n    &lt;artifactId>spring-webmvc&lt;/artifactId>\n    &lt;version>5.2.6.RELEASE&lt;/version>\n&lt;/dependency>\n\n配置 web.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n\n    &lt;!--Servlet配置-->\n    &lt;servlet>\n        &lt;servlet-name>TestServlet&lt;/servlet-name>\n        &lt;servlet-class>com.example.SpringStudy2.controller.TestServlet&lt;/servlet-class>\n    &lt;/servlet>\n    &lt;servlet-mapping>\n        &lt;servlet-name>TestServlet&lt;/servlet-name>\n        &lt;url-pattern>/testServlet&lt;/url-pattern>\n    &lt;/servlet-mapping>\n\n    &lt;!--配置监听器，用来唯一一次创建Spring容器-->\n    &lt;context-param>\n        &lt;param-name>contextConfigLocation&lt;/param-name>\n        &lt;param-value>classpath:spring.xml&lt;/param-value>\n    &lt;/context-param>\n    &lt;listener>\n        &lt;listener-class>org.springframework.web.context.ContextLoaderListener&lt;/listener-class>\n    &lt;/listener>\n\n    &lt;!--声明注册SpringMVC核心对象DispatcherServlet\n        为什么要创建它？\n        DispatcherServlet在创建过程中，会同时创建SpringMVC容器对象，\n        读取SpringMVC的配置文件，把这个配置文件中的对象都创建好，当\n        用户发起请求时，就可以直接使用对象了\n    -->\n    &lt;servlet>\n        &lt;servlet-name>springmvc&lt;/servlet-name>\n        &lt;servlet-class>org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class>\n        &lt;!--自定义SpringMVC配置文件位置-->\n        &lt;init-param>\n            &lt;param-name>contextConfigLocation&lt;/param-name>\n            &lt;!--SpringMVC配置文件位置-->\n            &lt;param-value>classpath:springmvc.xml&lt;/param-value>\n        &lt;/init-param>\n\n        &lt;!--在tomcat启动后，创建Servlet对象,>0-->\n        &lt;load-on-startup>1&lt;/load-on-startup>\n    &lt;/servlet>\n    \n    &lt;servlet-mapping>\n        &lt;servlet-name>springmvc&lt;/servlet-name>\n        &lt;!--有两种值\n            1.使用扩展名方式：*.xxxx,*.do,*.mvc, xxxx是自定义的扩展名\n            2.使用斜杠'/'：它会替代tomcat中的default，导致静态资源不能访问\n        -->\n        \n        &lt;url-pattern>*.do&lt;/url-pattern>\n    &lt;/servlet-mapping>\n\n&lt;/web-app>\n\n配置springmvc.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\">\n    &lt;!--注解扫描开启,@Controller-->\n    &lt;context:component-scan base-package=\"com.example.SpringStudy2.controller\"/>\n    \n    &lt;!--default-servlet-handler和@RequestMapping注解有冲突，需要加入以下标签-->\n    &lt;mvc:annotation-driven/>\n    &lt;!--第一种处理静态资源的方式：\n   \t\t需要在springmvc配置文件加入 &lt;mvc:default-servlet-handler>\n   \t\t原理是加入这个标签后，框架会创建控制器对象DefaultServletHttpRequestHandler（类似我们自己创建的MyController）\n  \t\tDefaultServletHttpRequestHandler这个对象可以把接受到的请求转发给tomcat的default这个servlet\n  \t-->\n    &lt;mvc:default-servlet-handler/>\n    \n    &lt;!--选一个-->\n    \n    &lt;!--第二种处理静态资源方式：\n        &lt;mvc:resources/> 加入后框架会创建ResourceHttpRequestHandler这个处理器对象\n        让这个对象处理静态资源的访问，不依赖tomcat服务器\n        mapping：访问静态资源的uri地址，使用通配符**\n        location：静态资源在项目中的目录位置\n        images/**：表示 images/p1.jpg ， images/user/logo.gif , images/order/history/list.png\n    -->\n    &lt;mvc:resources mapping=\"/images/**\" location=\"/pic/\"/>\n    &lt;mvc:resources mapping=\"/html/**\" location=\"/html/\"/>\n    &lt;mvc:resources mapping=\"/js/**\" location=\"/js/\"/>\n    &lt;!--改进版-->\n    &lt;mvc:resources mapping=\"/static/**\" location=\"/static/\"/>\n&lt;/beans>\n\n\n\n处理流程\n客户端发起 some.do 请求\ntomcat(web.xml –&gt; url-pattern 知道 *.do 的请求给DispatcherServlet )\nDispatcherServlet (根据 springmvc.xml 配置知道 some.do –&gt; doSome() )\nDispatcherServlet把 some.do 转发给MyController的 doSome() 方法\n框架执行 doSome() 把得到的 ModelAndView 进行处理 ，转发到 show.jsp\n\n\n@RequestMapping属性method表示客户端请求的方式限制，它的值是RequestMethod类枚举值，如RequestMethod.GET，RequestMethod.POST；不指定则没有限制。\n指定模块名称&lt;!--springmvc.xml-->\n&lt;!--视图解析器（指明资源文件路径）-->\n&lt;!--\"/WEB-INF\" + \"xxx\" + \".jsp\"-->\n&lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n    &lt;!--前缀：视图文件的路径-->\n    &lt;property name=\"prefix\" value=\"/WEB-INF/\"/>\n    &lt;!--后缀：视图文件扩展名-->\n    &lt;property name=\"suffix\" value=\".jsp\"/>\n&lt;/bean>\n&lt;!--Controller可以只写xxx部分-->\n\n\n\n定义在类之上代表其方法的公共前缀\n处理方法的参数处理器方法可包含以下四类参数，这些参数会在系统调用时由系统自动赋值，即可以直接在方法内部使用。\n\nHttpServletRequest\nHttpServletResponse\nHttpSession\n请求中所携带的请求参数\n\n逐个接受参数要求处理器（控制器）方法形参名和请求中参数名必须一致；\n原理\n使用request对象接受请求参数\nString strName &#x3D; request.getParameter(“name”);\nString strAge &#x3D; request.getParameter(“age”);\n\n\nSpringMVC框架通过对DispatcherServlet调用MyController的doSome()方法，调用方法时，按名称对应，把接受的参数赋值给形参 doSome( strName , Integer.valueOf(strAge) ) 框架会提供类型转换功能，能把String转为 int , long , float , double 等类型\n\n参数校正@RequestParam(“真正名”) String 形参；解决请求参数名和处理器方法形参名不一样的问题；定义在处理器方法参数之前。\n\nvalue：请求中的参数名称\nrequired：默认true，表示请求中必须包含此参数\n\n注意\n400的状态码一般是类型转换错误\n\nPOST请求中文乱码问题\n\n&lt;!--web.xml--&gt;\n&lt;!--注册声明过滤器，解决POST乱码问题--&gt;\n&lt;filter&gt;\n    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;\n    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;\n    &lt;!--设置项目中使用的字符编码--&gt;\n    &lt;init-param&gt;\n        &lt;param-name&gt;encoding&lt;/param-name&gt;\n        &lt;param-value&gt;utf-8&lt;/param-value&gt;\n    &lt;/init-param&gt;\n    &lt;init-param&gt;\n        &lt;!--强制请求对象使用encoding编码--&gt;\n        &lt;param-name&gt;forceRequestEncoding&lt;/param-name&gt;\n        &lt;param-value&gt;true&lt;/param-value&gt;\n    &lt;/init-param&gt;\n    &lt;init-param&gt;\n        &lt;!--强制请求对象使用encoding编码--&gt;\n        &lt;param-name&gt;forceResponseEncoding&lt;/param-name&gt;\n        &lt;param-value&gt;true&lt;/param-value&gt;\n    &lt;/init-param&gt;\n&lt;/filter&gt;\n&lt;filter-mapping&gt;\n    &lt;!--匹配所有请求--&gt;\n    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;\n    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n&lt;/filter-mapping&gt;\n\n\n\n### 对象接受参数\n\n原理是调用其同名set方法\n\n\n\n## 控制器返回值\n\n1. &#96;ModelAndView&#96;：有数据和视图，对视图执行forward\n\n2. &#96;String&#96;：只有视图，对视图执行forward；返回值即转发的路径，注意写法\n\n   - 也可以返回字符串数据，需要加上@ResponseBody注解\n   - 且在@RequestMapping注解中设置属性 produces&#x3D;&quot;text&#x2F;plain;charset&#x3D;utf-8&quot;\n\n3. &#96;void&#96;：空；在处理AJAX时，可以使用void返回值\n\n4. &#96;Object&#96;：例如String，Integer，Map，List，Student等等都是对象，对象有属性，属性就是数据，返回Object表示数据，和视图无关；可以表示相应的数据，响应ajax请求\n\n   - 原理：\n\n   - &#96;&#96;&#96;tex\n     springmvc处理器方法返回Object，可以转为json输出到浏览器，响应ajax的内部原理\n     &lt;mvc:annotation-driven&gt; 注解驱动\n     注解驱动实现的功能是 完成java对象到json，xml，text，二进制等数据格式的转换。\n     &lt;mvc:annotation-driven&gt;加入到springmvc配置文件后，会自动创建HttpMessageConverter接口的七个实现类对象，包括\n     MappingJackson2HttpMessageConverter(使用jackson工具库中的ObjectMapper实现java对象转为json)\n     \n     HttpMessageConverter接口：消息转换器\n     功能定义了java转为json，xml等数据格式的方法。这个接口有很多的实现类。这些实现类完成java对象到json，java对象到xml，java对象到二进制数据的转换\n     \n     下面两个方法是控制器类把结果输出给浏览器时使用的：\n     \n     boolean canWrite(Class&lt;?&gt; var1 , @Nullable MediaType var2);\n     \t用来检查处理器方法的返回值，能不能转为var2表示的数据格式\n     void write(T var1 , @Nullable MediaType var2 , HttpOutputMessage var3);\n     \t把处理器方法的返回值对象，调用jackson中的ObjectMapper转为json字符串\n     \t\n     返回对象框架的处理流程：\n     1.框架会把Student类型，调用框架中的 ArrayList&lt;HttpMessageConverter&gt; 中每个类的 canWrite() 方法，检查那个HttpMessageConverter接口的实现类能处理Student类型的数据--MappingJackson2HttpMessageConverter\n     2.框架会调用实现类的write()，MappingJackson2HttpMessageConverter的write()方法，把李四同学的student对象转为json，调用Jackson的ObjectMapper实现转为json\n     3.框架会调用@ResponseBody把2的结果输出到浏览器，ajax请求完成\n\n\n使用步骤\n\n&#96;&#96;&#96;tex1.加入json的工具库依赖，springmvc默认使用jackson2.在springmvc配置文件之间加入mvc:annotation-driven注解驱动String json &#x3D; om.writeValueAsString(student);3.在处理器方法的上面加上   @ResponseBodyresponse.setContentType(“application&#x2F;json;charset-utf-8”);PrintWriter pw &#x3D; response.getWriter();pw.println(json);\n\n- &#96;&#96;&#96;xml\n  &lt;!--JSON--&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;com.fasterxml.jackson.core&lt;&#x2F;groupId&gt;\n      &lt;artifactId&gt;jackson-core&lt;&#x2F;artifactId&gt;\n      &lt;version&gt;2.12.1&lt;&#x2F;version&gt;\n  &lt;&#x2F;dependency&gt;\n  &lt;dependency&gt;\n      &lt;groupId&gt;com.fasterxml.jackson.core&lt;&#x2F;groupId&gt;\n      &lt;artifactId&gt;jackson-databind&lt;&#x2F;artifactId&gt;\n      &lt;version&gt;2.12.1&lt;&#x2F;version&gt;\n  &lt;&#x2F;dependency&gt;\n\n\n\n前端页面路径在jsp，html中使用的地址，都是在前端页面中的地址，都是相对地址。\n地址分类\n绝对地址，带有协议名称的是绝对地址，如http://www.baidu.com  ftp://202.122.23.1\n相对地址，没有协议开头，例如  user&#x2F;some.do ， &#x2F;user&#x2F;some.do。相对地址不能独立使用，必须有一个参考地址，通过参考地址+相对地址本身才能指定资源\n\n用前置 “ &#x2F; “ 不用？不加 “ &#x2F; “访问的是：http://localhost:8080/page/index.jsp\n路径：http://localhost:8080/page/\n资源：index.jsp\n在index.jsp发起 user&#x2F;some.do 请求，访问地址变为 http://localhost:8080/page/user/some.do，当地址没有斜杠开头，例如 user&#x2F;some.do ，当点击链接时，访问地址是当前页面路径加上链接的地址。 \nhttp://localhost:8080/page/  + user&#x2F;some.do\n加 “ &#x2F; “访问的是：http://localhost:8080/page/index.jsp\n路径：http://localhost:8080/page\n资源：index.jsp\n点击 &#x2F;user&#x2F;some.do 访问地址变为 http://localhost:8080/user/some.do\n参考地址是当前服务器地址，也就是  http://localhost:8080\n\n加入 ${pageContext.request.contextPath} 代替项目虚拟路径写法，例如 &lt;a href&#x3D;” ${pageContext.request.contextPath}&#x2F;user&#x2F;some.do “\n\n加入一个base 标签，是html中的标签，表示当前页面中访问地址的基地址。页面中所有没有以 “ &#x2F; “开头的地址，都是以base标签中的地址为参考地址，使用base中的地址 + 写的路径(不带 &#x2F; ) 组成实际访问路径\n\n&#96;&#96;&#96;jsp\n\n\n\n\n\n## SSM整合开发\n\nSSM编程，即&#96;SpringMVC&#96; + &#96;Spring&#96;  + &#96;MyBatis&#96; 整合，是当前最为流行的JavaEE开发技术架构。其实SSM整合的实质，仅仅就是将&#96;MyBatis&#96;整合入&#96;Spring&#96;。因为&#96;SpringMVC&#96;原本就是Spring&#96;的一部分&#96;，不用专门整合。SSM整合实现方式分为两种：基于XML、基于注解；\n\nSpringMVC：视图层、界面层，负责接受请求，显示处理结果；\n\nSpring：业务层，管理service，dao，工具类对象的\n\nMyBatis：持久层，负责访问数据库\n\nSSM整合也叫做SSI（IBatis），整合中有容器。\n\n1. 第一个容器叫做&#96;SpringMVC&#96;容器，管理&#96;Controller&#96;控制器对象的。\n2. 第二个容器&#96;Spring&#96;容器，管理&#96;Service&#96;，&#96;Dao&#96;，工具类对象的\n\n我们要做的是把使用对象交给合适的容器创建，管理。把&#96;Controller&#96;还有web开发的相关对象，交给&#96;SpringMVC&#96;容器，这些web用的对象写在SpringMVC配置文件中；service，dao对象定义在&#96;Spring&#96;的配置文件中，让&#96;spring&#96;管理这些对象\n\n&#96;SpringMVC&#96;容器和&#96;Spring&#96;容器是有关系的，关系已经确定好了\n&#96;SpringMVC&#96;容器是&#96;Spring&#96;容器的子容器，类似于Java中的继承。子可以访问父的内容，在子容器中的&#96;Controller&#96;可以访问父容器中的&#96;Service&#96;对象，就可以实现&#96;Controller&#96;使用&#96;Service&#96;对象\n\n实现步骤：\n\n1. 创建数据库\n2. 新建&#96;maven web&#96;项目\n3. 加入依赖\n   - SpringMVC ，Spring，MyBatis三个框架依赖，jackson依赖，mysql驱动，druid连接池，jsp，servlet依赖\n4. 写&#96;web.xml&#96;\n   1. 注册&#96;DispatcherServlet&#96;，目的：\n      1. 创建&#96;SpringMVC&#96;容器对象，才能创建&#96;Controller&#96;类对象\n      2. 创建的是&#96;Servlet&#96;，才能接受用户的请求。\n   2. 注册&#96;Spring&#96;的监听器：&#96;ContextLoaderListener&#96;，目的：创建&#96;Spring&#96;容器对象\n   3. 注册字符集过滤器，解决&#96;POST&#96;请求乱码问题\n5. 写spring , spring , mybatis 配置文件\n   1. springmvc.xml\n   2. spring.xml\n   3. mybatis.xml\n   4. mapper.xml\n   5. properties\n6. 写到吗，dao接口和mapper文件，service和实现类，controller，实体类\n7. 写jsp页面\n\n\n\n### 搭建开发环境\n\n#### applicationContext.xml\n\n&#96;&#96;&#96;xml\n&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;\n&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot;\n       xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;\n       xmlns:context&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&quot;\n       xmlns:tx&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot;\n       xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd\n                        http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;context&#x2F;spring-context.xsd\n                        http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;tx&#x2F;spring-tx.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop https:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt;\n\n    &lt;!--配置连接数据源--&gt;\n    &lt;context:property-placeholder location&#x3D;&quot;classpath:jdbc.properties&quot;&#x2F;&gt;\n    &lt;bean id&#x3D;&quot;dataSource&quot; class&#x3D;&quot;com.alibaba.druid.pool.DruidDataSource&quot;\n          init-method&#x3D;&quot;init&quot; destroy-method&#x3D;&quot;close&quot;&gt;\n        &lt;property name&#x3D;&quot;url&quot; value&#x3D;&quot;$&#123;jdbc.url&#125;&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;username&quot; value&#x3D;&quot;$&#123;jdbc.username&#125;&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;password&quot; value&#x3D;&quot;$&#123;jdbc.password&#125;&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;maxActive&quot; value&#x3D;&quot;$&#123;jdbc.maxActive&#125;&quot;&#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n\n\n    &lt;!--SqlSessionFactoryBean创建SqlSessionFactory--&gt;\n    &lt;bean id&#x3D;&quot;sqlSessionFactory&quot; class&#x3D;&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;\n        &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot; &#x2F;&gt;\n        &lt;property name&#x3D;&quot;configLocation&quot; value&#x3D;&quot;classpath:conf&#x2F;mybatis.xml&quot;&#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n\n    &lt;!--mybatis扫描器，创建dao对象--&gt;\n    &lt;bean class&#x3D;&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;\n        &lt;property name&#x3D;&quot;sqlSessionFactoryBeanName&quot; value&#x3D;&quot;sqlSessionFactory&quot;&#x2F;&gt;\n        &lt;property name&#x3D;&quot;basePackage&quot; value&#x3D;&quot;com.example.dao&quot;&#x2F;&gt;\n    &lt;&#x2F;bean&gt;\n\n    &lt;!--声明service的注解@Service所在的包名位置--&gt;\n    &lt;context:component-scan base-package&#x3D;&quot;com.example.service&quot;&#x2F;&gt;\n\n    &lt;!--事务配置--&gt;\n&lt;!--    &lt;bean id&#x3D;&quot;studentService&quot; class&#x3D;&quot;com.example.service.StudentServiceImpl&quot;&gt;--&gt;\n&lt;!--        &lt;property name&#x3D;&quot;studentDao&quot; ref&#x3D;&quot;studentDao&quot; &#x2F;&gt;--&gt;\n&lt;!--    &lt;&#x2F;bean&gt;--&gt;\n\n&lt;!--    &lt;bean id&#x3D;&quot;transactionManager&quot; class&#x3D;&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;--&gt;\n&lt;!--        &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;dataSource&quot; &#x2F;&gt;--&gt;\n&lt;!--    &lt;&#x2F;bean&gt;--&gt;\n&lt;!--    &lt;tx:advice id&#x3D;&quot;txadvice&quot;&gt;--&gt;\n&lt;!--        &lt;tx:attributes&gt;--&gt;\n&lt;!--            &lt;tx:method name&#x3D;&quot;sale&quot; propagation&#x3D;&quot;REQUIRED&quot; &#x2F;&gt;--&gt;\n&lt;!--        &lt;&#x2F;tx:attributes&gt;--&gt;\n&lt;!--    &lt;&#x2F;tx:advice&gt;--&gt;\n&lt;!--    &lt;aop:config&gt;--&gt;\n&lt;!--        &lt;aop:pointcut id&#x3D;&quot;pt&quot; expression&#x3D;&quot;execution(* com.example.service.xxx.sale(..))&quot;&#x2F;&gt;--&gt;\n&lt;!--        &lt;aop:advisor advice-ref&#x3D;&quot;txadvice&quot; pointcut-ref&#x3D;&quot;pt&quot;&#x2F;&gt;--&gt;\n&lt;!--    &lt;&#x2F;aop:config&gt;--&gt;\n&lt;&#x2F;beans&gt;\n\n\n\ndispatcherServlet.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        https://www.springframework.org/schema/context/spring-context.xsd\n         http://www.springframework.org/schema/mvc\n         https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n\n    &lt;context:component-scan base-package=\"com.example.controller\"/>\n\n    &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n\n        &lt;property name=\"prefix\" value=\"/\"/>\n\n        &lt;property name=\"suffix\" value=\".jsp\"/>\n    &lt;/bean>\n\n    &lt;!--ajax,静态资源-->\n    &lt;mvc:annotation-driven/>\n\n    &lt;mvc:resources mapping=\"/static/**\" location=\"/static/\"/>\n&lt;/beans>\n\nmybatis.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n&lt;!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n&lt;configuration>\n&lt;!--    &lt;settings>-->\n&lt;!--        &lt;setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/>-->\n&lt;!--    &lt;/settings>-->\n\n    &lt;typeAliases>\n        &lt;package name=\"com.example.domain\"/>\n    &lt;/typeAliases>\n\n    &lt;mappers>\n        &lt;package name=\"com.example.dao\"/>\n    &lt;/mappers>\n&lt;/configuration>\n\njdbc.propertiesjdbc.url=jdbc:mysql:///test\njdbc.username=root\njdbc.password=666666\njdbc.maxActive=20\n\nmapper.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n&lt;!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n&lt;mapper namespace=\"com.example.dao.StudentDao\">\n\n    &lt;select id=\"selectAll\" resultType=\"com.example.domain.Student\">\n        select id,name,age from student order by id desc\n    &lt;/select>\n\n    &lt;insert id=\"insertStudent\">\n        insert into student(name,age) values(#&#123;name&#125;,#&#123;age&#125;)\n    &lt;/insert>\n&lt;/mapper>\n\n\n\nSpringMVC核心技术请求转发和重定向转发//以下方式是配合视图解析器\nmv.setViewName(\"result\");\n\n//此方式不受视图解析器限制，主要用于访问视图解析器以外的资源\nmv.setViewName(\"forward:/result.jsp\");\n\n重定向//之前设置的参数会以url栏参数写到转发路径中\n//该方法无法访问/WEB-INF目录下资源\nmv.setViewName(\"redirect:/result.jsp\");\n\n\n\n异常处理\n新建一个自定义异常类MyUserException，再定义它的子类NameException，AgeException\n\n在controller抛出NameException，AgeException\n\n创建一个普通类，作用全局异常处理类\n\n在类上面加入@ControllerAdvice\n在类中定义方法，方法的上面加入@ExceptionHandler\n\n\n创建处理异常的视图页面\n\n创建springmvc配置文件\n\n组件扫描器，扫描@Controller注解和@ControllerAdvice所在的包名\n\n&#96;&#96;&#96;xml&lt;context:component-scan base-package&#x3D;”com.example.handler”&#x2F;&gt;mvc:annotation-driven/   \n   2. 声明注解驱动\n\n![image-20210218124329184](C:\\Users\\June\\AppData\\Roaming\\Typora\\typora-user-images\\image-20210218124329184.png)\n\n\n\n### 拦截器\n\n1. 拦截器是springmvc的一种，需要实现&#96;HandlerInterceptor&#96;接口\n2. 拦截器和过滤器类似，功能方向侧重点不同。过滤器是用来过滤请求参数的，设置编码字符集工作；拦截器是拦截用户请求，做请求判断处理的\n3. 拦截器是全局的，可以对多个&#96;Controller&#96;做拦截；\n4. 拦截器常用在：用户登录处理，权限检查，记录日志\n\n#### 使用步骤\n\n1. 实现&#96;HandlerInterceptor&#96;接口\n\n2. 在springmvc配置文件中，声明拦截器\n\n   - &#96;&#96;&#96;xml\n     &lt;mvc:interceptors&gt;\n         &lt;mvc:interceptor&gt;\n             &lt;mvc:mapping path&#x3D;&quot;&#x2F;*.do&quot;&#x2F;&gt;\n             &lt;bean class&#x3D;&quot;com.example.handler.MyInterceptor&quot;&#x2F;&gt;\n         &lt;&#x2F;mvc:interceptor&gt;\n     &lt;&#x2F;mvc:interceptors&gt;\n\n\n\n\n\n执行时间\n在请求处理之前，也就是controller类中的方法执行之前先被拦截；\n在控制器方法执行之后也会执行拦截器；\n在请求处理完成后也会执行拦截器。\n\n拦截器与过滤器的区别\n过滤器是servlet中的对象，拦截器是框架中的对象\n过滤器实现Filter接口的对象，拦截器是实现HandlerInterceptor\n过滤器是用来设置request，response的参数，属性的的，侧重对数据过滤的，拦截器是用来验证请求的，能截断请求。\n过滤器是在拦截器之前先执行的\n过滤器是tomcat服务器创建的对象，拦截器是springmvc容器中创建的对象\n过滤器是一个执行时间点，拦截器有三个执行时间点\n过滤器可以处理jsp，js，html等等，拦截器侧重于对controller的对象，如果请求不能被DispatcherServlet所接收，则不能被拦截器所处理\n拦截器拦截普通类方法执行，过滤器过滤servlet请求响应\n\nSpringMVC执行流程\n","slug":"SpringMVC","date":"2022-09-30T09:31:34.000Z","categories_index":"","tags_index":"Java框架","author_index":"JuneQQQ"},{"id":"b4181dd5d95268a72dc772ce74f718cd","title":"SpringBoot2","content":"入门案例几个注解@Cofiguration@Configuration(proxyBeanMethods=false)  // Lite模式 \n@Configuration(proxyBeanMethods=true)  // Full模式 严格保证Bean单实例，每次属性注入都要检查容器中是否有\n\n@Bean、@Component、@Controller、@Service、@Repository@ComponentScan、@Import/* @Import(&#123;User.class, DBHelper.class&#125;)\n *      给容器中自动创建出这两个类型的组件；\n *\t    默认组件的名字就是全类名；\n *      会破坏单例\n */\n@Import(&#123;User.class, DBHelper.class&#125;)\n@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件\npublic class MyConfig &#123;\n&#125;\n\n@Conditional条件注入：满足Conditional指定的条件，则进行组件注入\n\n@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件\n//@ConditionalOnBean(name = \"tom\")  //存在此bean时注入xx（条件装配）\n@ConditionalOnMissingBean(name = \"tom\")  //不存在此bean时注入xx\npublic class MyConfig &#123;\n    /**\n     * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象\n     * @return\n     */\n    @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例\n    public User user01()&#123;\n        User zhangsan = new User(\"zhangsan\", 18);\n        //user组件依赖了Pet组件\n        zhangsan.setPet(tomcatPet());\n        return zhangsan;\n    &#125;\n\n    @Bean(\"tom22\")\n    public Pet tomcatPet()&#123;\n        return new Pet(\"tomcat\");\n    &#125;\n&#125;\n\npublic static void main(String[] args) &#123;\n        //1、返回我们IOC容器\n        ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n        //2、查看容器里面的组件\n        String[] names = run.getBeanDefinitionNames();\n        for (String name : names) &#123;\n            System.out.println(name);\n        &#125;\n        boolean tom = run.containsBean(\"tom\");\n        System.out.println(\"容器中Tom组件：\"+tom);\n\n        boolean user01 = run.containsBean(\"user01\");\n        System.out.println(\"容器中user01组件：\"+user01);\n\n        boolean tom22 = run.containsBean(\"tom22\");\n        System.out.println(\"容器中tom22组件：\"+tom22);\n\n    &#125;\n\n\n\n配置绑定如何使用Java读取到properties文件中的内容，并且把它封装到JavaBean中，以供随时使用；\npublic class getProperties &#123;\n     public static void main(String[] args) throws FileNotFoundException, IOException &#123;\n         Properties pps = new Properties();\n         pps.load(new FileInputStream(\"a.properties\"));\n         Enumeration enum1 = pps.propertyNames();//得到配置文件的名字\n         while(enum1.hasMoreElements()) &#123;\n             String strKey = (String) enum1.nextElement();\n             String strValue = pps.getProperty(strKey);\n             System.out.println(strKey + \"=\" + strValue);\n             //封装到JavaBean。\n         &#125;\n     &#125;\n &#125;\n\n\n\n@ConfigurationProperties + @Component/**\n * 只有在容器中的组件，才会拥有SpringBoot提供的强大功能\n */\n@Component\n@ConfigurationProperties(prefix = \"mycar\")\npublic class Car &#123;\n\n    private String brand;\n    private Integer price;\n\n    public String getBrand() &#123;\n        return brand;\n    &#125;\n\n    public void setBrand(String brand) &#123;\n        this.brand = brand;\n    &#125;\n\n    public Integer getPrice() &#123;\n        return price;\n    &#125;\n\n    public void setPrice(Integer price) &#123;\n        this.price = price;\n    &#125;\n\n    @Override\n    public String toString() &#123;\n        return \"Car&#123;\" +\n                \"brand='\" + brand + '\\'' +\n                \", price=\" + price +\n                '&#125;';\n    &#125;\n&#125;\n\n@EnableConfigurationProperties + @ConfigurationProperties@EnableConfigurationProperties(Car.class)\n//1、开启Car配置绑定功能\n//2、把这个Car这个组件自动注册到容器中\npublic class MyConfig &#123;\n&#125;\n\n\n\n自动配置原理引导加载自动配置类@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\n        @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)\npublic @interface SpringBootApplication&#123;&#125;\n\n@SpringBootConfiguration@Configuration。代表当前是一个配置类\n@ComponentScan指定扫描哪些，Spring注解；\n@EnableAutoConfiguration@AutoConfigurationPackage\n@Import(AutoConfigurationImportSelector.class)\npublic @interface EnableAutoConfiguration &#123;&#125;\n\n– @AutoConfigurationPackage自动配置包？指定了默认的包规则\n@Import(AutoConfigurationPackages.Registrar.class)  //给容器中导入一个组件\npublic @interface AutoConfigurationPackage &#123;&#125;\n\n//利用Registrar给容器中导入一系列组件\n//将指定的一个包下的所有组件导入进来:MainApplication 所在包下。\n\n– @Import(AutoConfigurationImportSelector.class)1、利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件\n2、调用List&lt;String> configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类\n3、利用工厂加载 Map&lt;String, List&lt;String>> loadSpringFactories(@Nullable ClassLoader classLoader)；得到所有的组件\n4、从META-INF/spring.factories位置来加载一个文件。\n    默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件\n    spring-boot-autoconfigure-2.4.3.RELEASE.jar包里面也有META-INF/spring.factories\n\n\n文件里面写死了spring-boot一启动就要给容器中加载的所有配置类\nspring-boot-autoconfigure-2.3.4.RELEASE.jar/META-INF/spring.factories\n    \n# Initializers\norg.springframework.context.ApplicationContextInitializer=\\\norg.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\\norg.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener\n\n# Application Listeners\norg.springframework.context.ApplicationListener=\\\norg.springframework.boot.autoconfigure.BackgroundPreinitializer\n\n# Auto Configuration Import Listeners\norg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\\norg.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener\n\n# Auto Configuration Import Filters\norg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\\norg.springframework.boot.autoconfigure.condition.OnBeanCondition,\\\norg.springframework.boot.autoconfigure.condition.OnClassCondition,\\\norg.springframework.boot.autoconfigure.condition.OnWebApplicationCondition\n\n# Auto Configure\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\norg.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\\norg.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\\norg.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\\norg.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\\norg.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\\norg.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\\norg.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRestClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.r2dbc.R2dbcDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.r2dbc.R2dbcRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\\norg.springframework.boot.autoconfigure.elasticsearch.ElasticsearchRestClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\\norg.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\\norg.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\\norg.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\\norg.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\\norg.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\\norg.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\\norg.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\\norg.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\\norg.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\\norg.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\\norg.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\\norg.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\\norg.springframework.boot.autoconfigure.neo4j.Neo4jAutoConfiguration,\\\norg.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\\norg.springframework.boot.autoconfigure.r2dbc.R2dbcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.r2dbc.R2dbcTransactionManagerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketMessagingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketRequesterAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketServerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketStrategiesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.rsocket.RSocketSecurityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\\norg.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.client.reactive.ReactiveOAuth2ClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.resource.reactive.ReactiveOAuth2ResourceServerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\\norg.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration,\\\norg.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\\norg.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\\norg.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\\norg.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\\norg.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.webservices.client.WebServiceTemplateAutoConfiguration\n\n# Failure analyzers\norg.springframework.boot.diagnostics.FailureAnalyzer=\\\norg.springframework.boot.autoconfigure.data.redis.RedisUrlSyntaxFailureAnalyzer,\\\norg.springframework.boot.autoconfigure.diagnostics.analyzer.NoSuchBeanDefinitionFailureAnalyzer,\\\norg.springframework.boot.autoconfigure.flyway.FlywayMigrationScriptMissingFailureAnalyzer,\\\norg.springframework.boot.autoconfigure.jdbc.DataSourceBeanCreationFailureAnalyzer,\\\norg.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer,\\\norg.springframework.boot.autoconfigure.r2dbc.ConnectionFactoryBeanCreationFailureAnalyzer,\\\norg.springframework.boot.autoconfigure.session.NonUniqueSessionRepositoryFailureAnalyzer\n\n# Template availability providers\norg.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\\\norg.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\\\norg.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\\\norg.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\\\norg.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\\\norg.springframework.boot.autoconfigure.web.servlet.JspTemplateAvailabilityProvider\n\n\n\n按需开启自动配置项虽然我们130个场景的所有自动配置启动的时候默认全部加载。xxxxAutoConfiguration\n按照条件装配规则（@Conditional），最终会按需配置。\n\n\n\n修改默认配置@Bean\n@ConditionalOnBean(MultipartResolver.class)  //容器中有这个类型组件\n@ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) //容器中没有这个名字 multipartResolver 的组件\npublic MultipartResolver multipartResolver(MultipartResolver resolver) &#123;\n    //给@Bean标注的方法传入了对象参数，这个参数的值就会从容器中找。\n    //SpringMVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范\n    // Detect if the user has created a MultipartResolver but named it incorrectly\n    return resolver;\n&#125;\n给容器中加入了文件上传解析器；\n\nSpringBoot默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先\n@Bean\n@ConditionalOnMissingBean\npublic CharacterEncodingFilter characterEncodingFilter() &#123;\n&#125;\n\n\n\n总结\n\nSpringBoot先加载所有的自动配置类  xxxxxAutoConfiguration\n\n每个自动配置类按照条件进行生效，默认都会绑定配置文件指定的值。xxxxProperties里面拿。xxxProperties和配置文件进行了绑定\n\n生效的配置类就会给容器中装配很多组件\n\n只要容器中有这些组件，相当于这些功能就有了\n\n定制化配置\n\n\n用户直接自己@Bean替换底层的组件\n用户去看这个组件是获取的配置文件什么值就去修改。\n\n\n\nxxxxxAutoConfiguration —&gt; 组件  —&gt; xxxxProperties里面拿值  —-&gt; application.properties\n最佳实践\n引入场景依赖\n\n\nhttps://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html#using-boot-starter\n\n\n查看自动配置了哪些（选做）\n\n\n自己分析，引入场景对应的自动配置一般都生效了\n配置文件中debug=true开启自动配置报告。Negative（不生效）\\ Positive（生效）\n\n\n是否需要修改\n\n\n参照文档修改配置项\n\n\n\n\nhttps://docs.spring.io/spring-boot/docs/current/reference/html/appendix-application-properties.html#common-application-properties\n自己分析。xxxxProperties绑定了配置文件的哪些。\n\n\n\n\n\n自定义加入或者替换组件\n\n\n\n\n@Bean、@Component。。。\n\n\n\n\n\n自定义器  XXXXXCustomizer；\n\n\n\n开发小技巧Lombok简化JavaBean开发\n&lt;dependency>\n    &lt;groupId>org.projectlombok&lt;/groupId>\n    &lt;artifactId>lombok&lt;/artifactId>\n&lt;/dependency>\n\nidea中搜索安装lombok插件\n\n===============================简化JavaBean开发===================================\n@NoArgsConstructor  //无参构造\n@AllArgsConstructor  //有参构造\n@Data              //getter setter\n@ToString          //toString\n@EqualsAndHashCode  //equals hasCode\npublic class User &#123;\n\n    private String name;\n    private Integer age;\n\n    private Pet pet;\n\n    public User(String name,Integer age)&#123;\n        this.name = name;\n        this.age = age;\n    &#125;\n&#125;\n\n================================简化日志开发===================================\n@Slf4j           //日志\n@RestController  //ResponseBody  Controller\npublic class HelloController &#123;\n    @RequestMapping(\"/hello\")\n    public String handle01(@RequestParam(\"name\") String name)&#123;\n        \n        log.info(\"请求进来了....\");\n        \n        return \"Hello, Spring Boot 2!\"+\"你好：\"+name;\n    &#125;\n&#125;\n\n\n\ndev-tools (热更新)&lt;dependency>\n    &lt;groupId>org.springframework.boot&lt;/groupId>\n    &lt;artifactId>spring-boot-devtools&lt;/artifactId>\n    &lt;optional>true&lt;/optional>\n&lt;/dependency>\n\n项目或者页面修改以后：Ctrl+F9；\nSpring Initailizr（项目初始化向导）\n选择我们需要的开发场景\n自动创建项目结构\n自动编写好主配置类\n\n配置文件文件类型properties同以前properties的用法\nyaml简介YAML 是 “YAML Ain’t Markup Language”（YAML 不是一种标记语言）的递归缩写。在开发的这种语言时，YAML 的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）。 \n非常适合用来做以数据为中心的配置文件\n基本语法\nkey: value；kv之间有空格\n大小写敏感\n使用缩进表示层级关系\n缩进不允许使用tab，只允许空格\n缩进的空格数不重要，只要相同层级的元素左对齐即可\n‘#’表示注释\n字符串无需加引号，如果要加，’’与””表示字符串内容 会被 转义&#x2F;不转义\n\n数据类型\n字面量：单个的、不可再分的值。date、boolean、string、number、null\n\nk: v\n\n\n对象：键值对的集合。map、hash、set、object\n\n行内写法：  k: &#123;k1:v1,k2:v2,k3:v3&#125;\n#或\nk: \n  k1: v1\n  k2: v2\n  k3: v3\n\n\n数组：一组按次序排列的值。array、list、queue\n\n行内写法：  k: [v1,v2,v3]\n#或者\nk:\n - v1\n - v2\n - v3\n\n示例@Data\npublic class Person &#123;\n    \n    private String userName;\n    private Boolean boss;\n    private Date birth;\n    private Integer age;\n    private Pet pet;\n    private String[] interests;\n    private List&lt;String> animal;\n    private Map&lt;String, Object> score;\n    private Set&lt;Double> salarys;\n    private Map&lt;String, List&lt;Pet>> allPets;\n&#125;\n=====================================\n@Data\npublic class Pet &#123;\n    private String name;\n    private Double weight;\n&#125;\n\n# yaml表示以上对象\nperson:\n  userName: zhangsan\n  boss: false\n  birth: 2019/12/12 20:12:33\n  age: 18\n  pet: \n    name: tomcat\n    weight: 23.4\n  interests: [篮球,游泳]\n  animal: \n    - jerry\n    - mario\n  score:\n    english: \n      first: 30\n      second: 40\n      third: 50\n    math: [131,140,148]\n    chinese: &#123;first: 128,second: 136&#125;\n  salarys: [3999,4999.98,5999.99]\n  allPets:\n    sick:\n      - &#123;name: tom&#125;\n      - &#123;name: jerry,weight: 47&#125;\n    health: [&#123;name: mario,weight: 47&#125;]\n\n\n\n配置提示自定义的类和配置文件绑定一般没有提示。\n       &lt;dependency>\n           &lt;groupId>org.springframework.boot&lt;/groupId>\n           &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId>\n           &lt;optional>true&lt;/optional>\n       &lt;/dependency>\n\n\n&lt;build>\n       &lt;plugins>\n           &lt;plugin>\n               &lt;groupId>org.springframework.boot&lt;/groupId>\n               &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId>\n               &lt;configuration>\n                   &lt;excludes>\n                       &lt;exclude>\n                           &lt;groupId>org.springframework.boot&lt;/groupId>\n                           &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId>\n                       &lt;/exclude>\n                   &lt;/excludes>\n               &lt;/configuration>\n           &lt;/plugin>\n       &lt;/plugins>\n   &lt;/build>\n\n\n\n\n\nWeb开发SpringMVC自动配置概览简单功能分析静态资源访问静态资源目录只要静态资源放在类路径下： /static  or /public  or /resources or /META-INF/resources\n访问 ： 当前项目根路径&#x2F; + 静态资源名 \n原理： 静态映射&#x2F;**。\n请求进来，先去找Controller看能不能处理。不能处理的所有请求又都交给静态资源处理器。静态资源也找不到则响应404页面\n改变默认的静态资源路径\nspring:\n  mvc:\n    static-path-pattern: /res/**\n\n  resources:\n    static-locations: [classpath:/haha/]\n\n\n\n静态资源访问前缀默认无前缀\nspring:\n  mvc:\n    static-path-pattern: /res/**\n\n当前项目 + static-path-pattern + 静态资源名 &#x3D; 静态资源文件夹下找\nwebjar自动映射 &#x2F;webjars&#x2F;**\nhttps://www.webjars.org/\n&lt;dependency>\n    &lt;groupId>org.webjars&lt;/groupId>\n    &lt;artifactId>jquery&lt;/artifactId>\n    &lt;version>3.5.1&lt;/version>\n&lt;/dependency>\n\n访问地址：http://localhost:8080/webjars/jquery&#x2F;3.5.1&#x2F;jquery.js  后面地址要按照依赖里面的包路径\n欢迎页支持\n静态资源路径下  index.html\n\n\n可以配置静态资源路径\n但是不可以配置静态资源的访问前缀。否则导致 index.html不能被默认访问\n\n\n\nspring:\n#  mvc:\n#    static-path-pattern: /res/**   这个会导致welcome page功能失效\n\n  resources:\n    static-locations: [classpath:/haha/]\n\n\ncontroller能处理&#x2F;index\n\n自定义  Faviconfavicon.ico 放在静态资源目录下即可。\nspring:\n#  mvc:\n#    static-path-pattern: /res/**   这个会导致 Favicon 功能失效\n\n\n\n\n\n\n\n静态资源配置原理\nSpringBoot启动默认加载  xxxAutoConfiguration 类（自动配置类）\nSpringMVC功能的自动配置类 WebMvcAutoConfiguration，生效\n\n@Configuration(proxyBeanMethods = false)\n@ConditionalOnWebApplication(type = Type.SERVLET)\n@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class &#125;)\n@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)\n@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)\n@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class,\n        ValidationAutoConfiguration.class &#125;)\npublic class WebMvcAutoConfiguration &#123;&#125;\n\n\n给容器中配了什么。\n\n@Configuration(proxyBeanMethods = false)\n@Import(EnableWebMvcConfiguration.class)\n@EnableConfigurationProperties(&#123; WebMvcProperties.class, ResourceProperties.class &#125;)  //2.3.4\n@Order(0)\npublic static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer &#123;&#125;\n\n\n配置文件的相关属性和xxx进行了绑定。WebMvcProperties&#x3D;&#x3D;spring.mvc、ResourceProperties&#x3D;&#x3D;spring.resources\n\n配置类只有一个有参构造器//2.3.4\n//有参构造器所有参数的值都会从容器中确定\n//ResourceProperties resourceProperties；获取和spring.resources绑定的所有的值的对象\n//WebMvcProperties mvcProperties 获取和spring.mvc绑定的所有的值的对象\n//ListableBeanFactory beanFactory Spring的beanFactory\n//HttpMessageConverters 找到所有的HttpMessageConverters\n//ResourceHandlerRegistrationCustomizer 找到 资源处理器的自定义器。=========\n//DispatcherServletPath  \n//ServletRegistrationBean   给应用注册Servlet、Filter....\n    public WebMvcAutoConfigurationAdapter(ResourceProperties resourceProperties, WebMvcProperties mvcProperties,\n                ListableBeanFactory beanFactory, ObjectProvider&lt;HttpMessageConverters> messageConvertersProvider,\n                ObjectProvider&lt;ResourceHandlerRegistrationCustomizer> resourceHandlerRegistrationCustomizerProvider,\n                ObjectProvider&lt;DispatcherServletPath> dispatcherServletPath,\n                ObjectProvider&lt;ServletRegistrationBean&lt;?>> servletRegistrations) &#123;\n            this.resourceProperties = resourceProperties;\n            this.mvcProperties = mvcProperties;\n            this.beanFactory = beanFactory;\n            this.messageConvertersProvider = messageConvertersProvider;\n            this.resourceHandlerRegistrationCustomizer = resourceHandlerRegistrationCustomizerProvider.getIfAvailable();\n            this.dispatcherServletPath = dispatcherServletPath;\n            this.servletRegistrations = servletRegistrations;\n        &#125;\n\n资源处理的默认规则@Override\n   public void addResourceHandlers(ResourceHandlerRegistry registry) &#123;\n       if (!this.resourceProperties.isAddMappings()) &#123;\n           logger.debug(\"Default resource handling disabled\");\n           return;\n       &#125;\n       Duration cachePeriod = this.resourceProperties.getCache().getPeriod();\n       CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl();\n       //webjars的规则\n       if (!registry.hasMappingForPattern(\"/webjars/**\")) &#123;\n           customizeResourceHandlerRegistration(registry.addResourceHandler(\"/webjars/**\")\n                   .addResourceLocations(\"classpath:/META-INF/resources/webjars/\")\n                   .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl));\n       &#125;\n       \n       //\n       String staticPathPattern = this.mvcProperties.getStaticPathPattern();\n       if (!registry.hasMappingForPattern(staticPathPattern)) &#123;\n           customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern)\n                   .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations()))\n                   .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl));\n       &#125;\n   &#125;\n\nspring:\n#  mvc:\n#    static-path-pattern: /res/**\n\n  resources:\n    add-mappings: false   禁用所有静态资源规则\n\n@ConfigurationProperties(prefix = \"spring.resources\", ignoreUnknownFields = false)\npublic class ResourceProperties &#123;\n\n    private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; \"classpath:/META-INF/resources/\",\n            \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" &#125;;\n\n    /**\n     * Locations of static resources. Defaults to classpath:[/META-INF/resources/,\n     * /resources/, /static/, /public/].\n     */\n    private String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\n\n欢迎页的处理规则HandlerMapping：处理器映射。保存了每一个Handler能处理哪些请求。  \n\n       @Bean\n       public WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext,\n               FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) &#123;\n           WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping(\n                   new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(),\n                   this.mvcProperties.getStaticPathPattern());\n           welcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider));\n           welcomePageHandlerMapping.setCorsConfigurations(getCorsConfigurations());\n           return welcomePageHandlerMapping;\n       &#125;\n\n   WelcomePageHandlerMapping(TemplateAvailabilityProviders templateAvailabilityProviders,\n           ApplicationContext applicationContext, Optional&lt;Resource> welcomePage, String staticPathPattern) &#123;\n       if (welcomePage.isPresent() &amp;&amp; \"/**\".equals(staticPathPattern)) &#123;\n           //要用欢迎页功能，必须是/**\n           logger.info(\"Adding welcome page: \" + welcomePage.get());\n           setRootViewName(\"forward:index.html\");\n       &#125;\n       else if (welcomeTemplateExists(templateAvailabilityProviders, applicationContext)) &#123;\n           // 调用Controller  /index\n           logger.info(\"Adding welcome page template: index\");\n           setRootViewName(\"index\");\n       &#125;\n   &#125;\n\nfavicon请求参数处理请求映射rest使用\n@xxxMapping；\n\nRest风格支持（使用HTTP请求方式动词来表示对资源的操作）\n\n\n以前：&#x2F;getUser  获取用户   &#x2F;deleteUser 删除用户   &#x2F;editUser  修改用户    &#x2F;saveUser 保存用户\n现在： &#x2F;user   *GET-*获取用户   *DELETE-*删除用户   *PUT-*修改用户    *POST-*保存用户\n核心Filter；HiddenHttpMethodFilter\n\n\n\n\n用法： 表单method&#x3D;post，隐藏域 _method&#x3D;put\nSpringBoot中手动开启\n\n\n\n\n\n扩展：如何把_method 这个名字换成我们自己喜欢的。\n\n\n\n@GetMapping(\"/user\")\n   //@RequestMapping(value = \"/user\",method = RequestMethod.GET)\n   public String getUser()&#123;\n       return \"GET-张三\";\n   &#125;\n\n   @RequestMapping(value = \"/user\",method = RequestMethod.POST)\n   public String saveUser()&#123;\n       return \"POST-张三\";\n   &#125;\n\n\n   @RequestMapping(value = \"/user\",method = RequestMethod.PUT)\n   public String putUser()&#123;\n       return \"PUT-张三\";\n   &#125;\n\n   @RequestMapping(value = \"/user\",method = RequestMethod.DELETE)\n   public String deleteUser()&#123;\n       return \"DELETE-张三\";\n   &#125;\n\n   @Bean\n   @ConditionalOnMissingBean(HiddenHttpMethodFilter.class)\n   @ConditionalOnProperty(prefix = \"spring.mvc.hiddenmethod.filter\", name = \"enabled\", matchIfMissing = false)\n   public OrderedHiddenHttpMethodFilter hiddenHttpMethodFilter() &#123;\n       return new OrderedHiddenHttpMethodFilter();\n   &#125;\n\n\n//自定义filter\n   @Bean\n   public HiddenHttpMethodFilter hiddenHttpMethodFilter()&#123;\n       HiddenHttpMethodFilter methodFilter = new HiddenHttpMethodFilter();\n       methodFilter.setMethodParam(\"_m\");\n       return methodFilter;\n   &#125;\n\nRest原理（表单提交要使用REST的时候）\n\n表单提交会带上**_method&#x3D;PUT**\n请求过来被HiddenHttpMethodFilter拦截\n请求是否正常，并且是POST\n获取到**_method**的值。\n兼容以下请求；PUT  DELETE  PATCH\n原生request（post），包装模式requesWrapper重写了getMethod方法，返回的是传入的值。\n过滤器链放行的时候用wrapper。以后的方法调用getMethod是调用requesWrapper的\n\n\n\n\n\nRest使用客户端工具\n\n如PostMan直接发送Put、delete等方式请求，无需Filter。\n\n请求映射原理\nSpringMVC功能分析都从 org.springframework.web.servlet.DispatcherServlet-》doDispatch（)\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;\n        HttpServletRequest processedRequest = request;\n        HandlerExecutionChain mappedHandler = null;\n        boolean multipartRequestParsed = false;\n\n        WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n\n        try &#123;\n            ModelAndView mv = null;\n            Exception dispatchException = null;\n\n            try &#123;\n                processedRequest = checkMultipart(request);\n                multipartRequestParsed = (processedRequest != request);\n\n                // 找到当前请求使用哪个Handler（Controller的方法）处理\n                mappedHandler = getHandler(processedRequest);\n                \n                //HandlerMapping：处理器映射。/xxx->>xxxx\n\nRequestMappingHandlerMapping：保存了所有@RequestMapping 和handler的映射规则。\n\n所有的请求映射都在HandlerMapping中。\n\nSpringBoot自动配置欢迎页的 WelcomePageHandlerMapping 。访问 &#x2F;能访问到index.html；\n\nSpringBoot自动配置了默认 的 RequestMappingHandlerMapping\n\n请求进来，挨个尝试所有的HandlerMapping看是否有请求信息。\n\n\n如果有就找到这个请求对应的handler\n如果没有就是下一个 HandlerMapping\n\n\n我们需要一些自定义的映射处理，我们也可以自己给容器中放HandlerMapping。自定义 HandlerMapping\n\n\n普通参数与基本注解注解：带参获取单个，不带参获取全部（Map或List）\n@PathVariable：路径变量\n@RequestHeader：获取请求头\n@RequestParam：获取请求参数\n@CookieValue：获取Cookie值\n@RequestBody：表单请求体\n@RequestAttribute：获取request域属性\n@MatrixVariable：矩阵变量\n@ModelAttribute：获取请求参数\n@RestController\npublic class ParameterTestController &#123;\n\n\t// 动态匹配路径，获取信息\n    //  car/2/owner/zhangsan\n    @GetMapping(\"/car/&#123;id&#125;/owner/&#123;username&#125;\")\n    public Map&lt;String,Object> getCar(@PathVariable(\"id\") Integer id,\n                                     @PathVariable(\"username\") String name,\n                                     @PathVariable Map&lt;String,String> pv,\n                                     @RequestHeader(\"User-Agent\") String userAgent,\n                                     @RequestHeader Map&lt;String,String> header,\n                                     @RequestParam(\"age\") Integer age,\n                                     @RequestParam(\"inters\") List&lt;String> inters,\n                                     @RequestParam Map&lt;String,String> params,\n                                     @CookieValue(\"_ga\") String _ga,\n                                     @CookieValue(\"_ga\") Cookie cookie)&#123;\n\n\n        Map&lt;String,Object> map = new HashMap&lt;>();\n\n//        map.put(\"id\",id);\n//        map.put(\"name\",name);\n//        map.put(\"pv\",pv);\n//        map.put(\"userAgent\",userAgent);\n//        map.put(\"headers\",header);\n        map.put(\"age\",age);\n        map.put(\"inters\",inters);\n        map.put(\"params\",params);\n        map.put(\"_ga\",_ga);\n        System.out.println(cookie.getName()+\"===>\"+cookie.getValue());\n        return map;\n    &#125;\n\n\n    @PostMapping(\"/save\")\n    public Map postMethod(@RequestBody String content)&#123;\n        Map&lt;String,Object> map = new HashMap&lt;>();\n        map.put(\"content\",content);\n        return map;\n    &#125;\n\n\n    //1、语法： 请求路径：/cars/sell;low=34;brand=byd,audi,yd\n    //2、SpringBoot默认是禁用了矩阵变量的功能\n    //      手动开启：原理。对于路径的处理。UrlPathHelper进行解析。\n    //              removeSemicolonContent（移除分号内容）支持矩阵变量的\n    //3、矩阵变量必须有url路径变量才能被解析\n    @GetMapping(\"/cars/&#123;path&#125;\")\n    public Map carsSell(@MatrixVariable(\"low\") Integer low,\n                        @MatrixVariable(\"brand\") List&lt;String> brand,\n                        @PathVariable(\"path\") String path)&#123;\n        Map&lt;String,Object> map = new HashMap&lt;>();\n\n        map.put(\"low\",low);\n        map.put(\"brand\",brand);\n        map.put(\"path\",path);\n        return map;\n    &#125;\n\n    // /boss/1;age=20/2;age=10\n\n    @GetMapping(\"/boss/&#123;bossId&#125;/&#123;empId&#125;\")\n    public Map boss(@MatrixVariable(value = \"age\",pathVar = \"bossId\") Integer bossAge,\n                    @MatrixVariable(value = \"age\",pathVar = \"empId\") Integer empAge)&#123;\n        Map&lt;String,Object> map = new HashMap&lt;>();\n\n        map.put(\"bossAge\",bossAge);\n        map.put(\"empAge\",empAge);\n        return map;\n\n    &#125;\n\n&#125;\n\n\n\nServlet API：WebRequest、ServletRequest、MultipartRequest、 HttpSession、javax.servlet.http.PushBuilder、Principal、InputStream、Reader、HttpMethod、Locale、TimeZone、ZoneId\nServletRequestMethodArgumentResolver  以上的部分参数\n@Override\n    public boolean supportsParameter(MethodParameter parameter) &#123;\n        Class&lt;?> paramType = parameter.getParameterType();\n        return (WebRequest.class.isAssignableFrom(paramType) ||\n                ServletRequest.class.isAssignableFrom(paramType) ||\n                MultipartRequest.class.isAssignableFrom(paramType) ||\n                HttpSession.class.isAssignableFrom(paramType) ||\n                (pushBuilder != null &amp;&amp; pushBuilder.isAssignableFrom(paramType)) ||\n                Principal.class.isAssignableFrom(paramType) ||\n                InputStream.class.isAssignableFrom(paramType) ||\n                Reader.class.isAssignableFrom(paramType) ||\n                HttpMethod.class == paramType ||\n                Locale.class == paramType ||\n                TimeZone.class == paramType ||\n                ZoneId.class == paramType);\n    &#125;\n\n\n\n复杂参数：Map、Model（map、model里面的数据会被放在request的请求域  request.setAttribute）、**Errors/BindingResult、RedirectAttributes（ 重定向携带数据）**、ServletResponse（response）、SessionStatus、UriComponentsBuilder、ServletUriComponentsBuilder\nMap&lt;String,Object> map,  Model model, HttpServletRequest request 都是可以给request域中放数据，\nrequest.getAttribute();\n\nMap、Model类型的参数，会返回 mavContainer.getModel（）；—&gt; BindingAwareModelMap 是Model 也是Map\nmavContainer.getModel(); 获取到值的\n\n\n\n\n\n\n\n自定义对象参数：/**\n *     姓名： &lt;input name=\"userName\"/> &lt;br/>\n *     年龄： &lt;input name=\"age\"/> &lt;br/>\n *     生日： &lt;input name=\"birth\"/> &lt;br/>\n *     宠物姓名：&lt;input name=\"pet.name\"/>&lt;br/>\n *     宠物年龄：&lt;input name=\"pet.age\"/>\n */\n@Data\npublic class Person &#123;\n    \n    private String userName;\n    private Integer age;\n    private Date birth;\n    private Pet pet;\n    \n&#125;\n\n@Data\npublic class Pet &#123;\n\n    private String name;\n    private String age;\n\n&#125;\n\nresult\n\n\n\nPOJO封装过程\nServletModelAttributeMethodProcessor\n\n参数处理原理\nHandlerMapping中找到能处理请求的Handler（Controller.method()）\n为当前Handler 找一个适配器 HandlerAdapter； RequestMappingHandlerAdapter\n适配器执行目标方法并确定方法参数的每一个值\n\nHandlerAdapter\n\n支持方法上标注@RequestMapping \n支持函数式编程的\n\n执行目标方法// Actually invoke the handler.\n//DispatcherServlet -- doDispatch\nmv = ha.handle(processedRequest, response, mappedHandler.getHandler());\n\nmav = invokeHandlerMethod(request, response, handlerMethod); //执行目标方法\n\n\n//ServletInvocableHandlerMethod\nObject returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\n//获取方法的参数值\nObject[] args = getMethodArgumentValues(request, mavContainer, providedArgs);\n\n\n\n参数解析器-HandlerMethodArgumentResolver确定将要执行的目标方法的每一个参数的值是什么;\nSpringMVC目标方法能写多少种参数类型。取决于参数解析器。\n\n\n\n\n\n当前解析器是否支持解析这种参数\n支持就调用 resolveArgument\n\n返回值处理器\n\n\n\n如何确定目标方法每一个参数的值============InvocableHandlerMethod==========================\nprotected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\n            Object... providedArgs) throws Exception &#123;\n\n        MethodParameter[] parameters = getMethodParameters();\n        if (ObjectUtils.isEmpty(parameters)) &#123;\n            return EMPTY_ARGS;\n        &#125;\n\n        Object[] args = new Object[parameters.length];\n        for (int i = 0; i &lt; parameters.length; i++) &#123;\n            MethodParameter parameter = parameters[i];\n            parameter.initParameterNameDiscovery(this.parameterNameDiscoverer);\n            args[i] = findProvidedArgument(parameter, providedArgs);\n            if (args[i] != null) &#123;\n                continue;\n            &#125;\n            if (!this.resolvers.supportsParameter(parameter)) &#123;\n                throw new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\"));\n            &#125;\n            try &#123;\n                args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);\n            &#125;\n            catch (Exception ex) &#123;\n                // Leave stack trace for later, exception may actually be resolved and handled...\n                if (logger.isDebugEnabled()) &#123;\n                    String exMsg = ex.getMessage();\n                    if (exMsg != null &amp;&amp; !exMsg.contains(parameter.getExecutable().toGenericString())) &#123;\n                        logger.debug(formatArgumentError(parameter, exMsg));\n                    &#125;\n                &#125;\n                throw ex;\n            &#125;\n        &#125;\n        return args;\n    &#125;\n\n挨个判断所有参数解析器那个支持解析这个参数@Nullable\n   private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) &#123;\n       HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter);\n       if (result == null) &#123;\n           for (HandlerMethodArgumentResolver resolver : this.argumentResolvers) &#123;\n               if (resolver.supportsParameter(parameter)) &#123;\n                   result = resolver;\n                   this.argumentResolverCache.put(parameter, result);\n                   break;\n               &#125;\n           &#125;\n       &#125;\n       return result;\n   &#125;\n\n解析这个参数的值调用各自 HandlerMethodArgumentResolver 的 resolveArgument 方法即可\n自定义类型参数 封装POJOServletModelAttributeMethodProcessor  这个参数处理器支持，是否为简单类型。\npublic static boolean isSimpleValueType(Class&lt;?> type) &#123;\n        return (Void.class != type &amp;&amp; void.class != type &amp;&amp;\n                (ClassUtils.isPrimitiveOrWrapper(type) ||\n                Enum.class.isAssignableFrom(type) ||\n                CharSequence.class.isAssignableFrom(type) ||\n                Number.class.isAssignableFrom(type) ||\n                Date.class.isAssignableFrom(type) ||\n                Temporal.class.isAssignableFrom(type) ||\n                URI.class == type ||\n                URL.class == type ||\n                Locale.class == type ||\n                Class.class == type));\n    &#125;\n\n@Override\n    @Nullable\n    public final Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n            NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123;\n\n        Assert.state(mavContainer != null, \"ModelAttributeMethodProcessor requires ModelAndViewContainer\");\n        Assert.state(binderFactory != null, \"ModelAttributeMethodProcessor requires WebDataBinderFactory\");\n\n        String name = ModelFactory.getNameForParameter(parameter);\n        ModelAttribute ann = parameter.getParameterAnnotation(ModelAttribute.class);\n        if (ann != null) &#123;\n            mavContainer.setBinding(name, ann.binding());\n        &#125;\n\n        Object attribute = null;\n        BindingResult bindingResult = null;\n\n        if (mavContainer.containsAttribute(name)) &#123;\n            attribute = mavContainer.getModel().get(name);\n        &#125;\n        else &#123;\n            // Create attribute instance\n            try &#123;\n                attribute = createAttribute(name, parameter, binderFactory, webRequest);\n            &#125;\n            catch (BindException ex) &#123;\n                if (isBindExceptionRequired(parameter)) &#123;\n                    // No BindingResult parameter -> fail with BindException\n                    throw ex;\n                &#125;\n                // Otherwise, expose null/empty value and associated BindingResult\n                if (parameter.getParameterType() == Optional.class) &#123;\n                    attribute = Optional.empty();\n                &#125;\n                bindingResult = ex.getBindingResult();\n            &#125;\n        &#125;\n\n        if (bindingResult == null) &#123;\n            // Bean property binding and validation;\n            // skipped in case of binding failure on construction.\n            WebDataBinder binder = binderFactory.createBinder(webRequest, attribute, name);\n            if (binder.getTarget() != null) &#123;\n                if (!mavContainer.isBindingDisabled(name)) &#123;\n                    bindRequestParameters(binder, webRequest);\n                &#125;\n                validateIfApplicable(binder, parameter);\n                if (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) &#123;\n                    throw new BindException(binder.getBindingResult());\n                &#125;\n            &#125;\n            // Value type adaptation, also covering java.util.Optional\n            if (!parameter.getParameterType().isInstance(attribute)) &#123;\n                attribute = binder.convertIfNecessary(binder.getTarget(), parameter.getParameterType(), parameter);\n            &#125;\n            bindingResult = binder.getBindingResult();\n        &#125;\n\n        // Add resolved attribute and BindingResult at the end of the model\n        Map&lt;String, Object> bindingResultModel = bindingResult.getModel();\n        mavContainer.removeAttributes(bindingResultModel);\n        mavContainer.addAllAttributes(bindingResultModel);\n\n        return attribute;\n    &#125;\n\nWebDataBinder binder &#x3D; binderFactory.createBinder(webRequest, attribute, name);\nWebDataBinder :web数据绑定器，将请求参数的值绑定到指定的JavaBean里面\nWebDataBinder 利用它里面的 Converters 将请求数据转成指定的数据类型。再次封装到JavaBean中**\nGenericConversionService：在设置每一个值的时候，找它里面的所有converter那个可以将这个数据类型（request带来参数的字符串）转换到指定的类型（JavaBean – Integer）\nbyte – &gt; file\n@FunctionalInterfacepublic interface Converter&lt;S, T&gt;\n\n\n未来我们可以给WebDataBinder里面放自己的Converter；\nprivate static final class StringToNumber&lt;T **extends** Number&gt; implements Converter&lt;String, T&gt;\n自定义 Converter\n//1、WebMvcConfigurer定制化SpringMVC的功能\n    @Bean\n    public WebMvcConfigurer webMvcConfigurer()&#123;\n        return new WebMvcConfigurer() &#123;\n            @Override\n            public void configurePathMatch(PathMatchConfigurer configurer) &#123;\n                UrlPathHelper urlPathHelper = new UrlPathHelper();\n                // 不移除；后面的内容。矩阵变量功能就可以生效\n                urlPathHelper.setRemoveSemicolonContent(false);\n                configurer.setUrlPathHelper(urlPathHelper);\n            &#125;\n\n            @Override\n            public void addFormatters(FormatterRegistry registry) &#123;\n                registry.addConverter(new Converter&lt;String, Pet>() &#123;\n\n                    @Override\n                    public Pet convert(String source) &#123;\n                        // 啊猫,3\n                        if(!StringUtils.isEmpty(source))&#123;\n                            Pet pet = new Pet();\n                            String[] split = source.split(\",\");\n                            pet.setName(split[0]);\n                            pet.setAge(Integer.parseInt(split[1]));\n                            return pet;\n                        &#125;\n                        return null;\n                    &#125;\n                &#125;);\n            &#125;\n        &#125;;\n    &#125;\n\n\n\n目标方法执行完成将所有的数据都放在 ModelAndViewContainer；包含要去的页面地址View。还包含Model数据。\n\n处理派发结果processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);\nrenderMergedOutputModel(mergedModel, getRequestToExpose(request), response);\nInternalResourceView：\n@Override\n    protected void renderMergedOutputModel(\n            Map&lt;String, Object> model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123;\n\n        // Expose the model object as request attributes.\n        exposeModelAsRequestAttributes(model, request);\n\n        // Expose helpers as request attributes, if any.\n        exposeHelpers(request);\n\n        // Determine the path for the request dispatcher.\n        String dispatcherPath = prepareForRendering(request, response);\n\n        // Obtain a RequestDispatcher for the target resource (typically a JSP).\n        RequestDispatcher rd = getRequestDispatcher(request, dispatcherPath);\n        if (rd == null) &#123;\n            throw new ServletException(\"Could not get RequestDispatcher for [\" + getUrl() +\n                    \"]: Check that the corresponding file exists within your web application archive!\");\n        &#125;\n\n        // If already included or response already committed, perform include, else forward.\n        if (useInclude(request, response)) &#123;\n            response.setContentType(getContentType());\n            if (logger.isDebugEnabled()) &#123;\n                logger.debug(\"Including [\" + getUrl() + \"]\");\n            &#125;\n            rd.include(request, response);\n        &#125;\n\n        else &#123;\n            // Note: The forwarded resource is supposed to determine the content type itself.\n            if (logger.isDebugEnabled()) &#123;\n                logger.debug(\"Forwarding to [\" + getUrl() + \"]\");\n            &#125;\n            rd.forward(request, response);\n        &#125;\n    &#125;\n\n暴露模型作为请求域属性\n// Expose the model object as request attributes.\n        exposeModelAsRequestAttributes(model, request);\n\nprotected void exposeModelAsRequestAttributes(Map&lt;String, Object> model,\n            HttpServletRequest request) throws Exception &#123;\n\n    //model中的所有数据遍历挨个放在请求域中\n        model.forEach((name, value) -> &#123;\n            if (value != null) &#123;\n                request.setAttribute(name, value);\n            &#125;\n            else &#123;\n                request.removeAttribute(name);\n            &#125;\n        &#125;);\n    &#125;\n\n\n\n\n\n数据响应与内容协商\n响应JSONjackson.jar+@ResponseBody&lt;dependency>\n           &lt;groupId>org.springframework.boot&lt;/groupId>\n           &lt;artifactId>spring-boot-starter-web&lt;/artifactId>\n       &lt;/dependency>\nweb场景自动引入了json场景\n   &lt;dependency>\n     &lt;groupId>org.springframework.boot&lt;/groupId>\n     &lt;artifactId>spring-boot-starter-json&lt;/artifactId>\n     &lt;version>2.3.4.RELEASE&lt;/version>\n     &lt;scope>compile&lt;/scope>\n   &lt;/dependency>\n\n\n\n给前端自动返回json数据；\n\n返回值解析器\n\n\n\ntry &#123;\n            this.returnValueHandlers.handleReturnValue(\n                    returnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n        &#125;\n\n@Override\n    public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,\n            ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123;\n\n        HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType);\n        if (handler == null) &#123;\n            throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName());\n        &#125;\n        handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);\n    &#125;\n\nRequestResponseBodyMethodProcessor      \n@Override\n    public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,\n            ModelAndViewContainer mavContainer, NativeWebRequest webRequest)\n            throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123;\n\n        mavContainer.setRequestHandled(true);\n        ServletServerHttpRequest inputMessage = createInputMessage(webRequest);\n        ServletServerHttpResponse outputMessage = createOutputMessage(webRequest);\n\n        // Try even with null return value. ResponseBodyAdvice could get involved.\n        // 使用消息转换器进行写出操作\n        writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage);\n    &#125;\n\n\n返回值解析器原理\n\n\n\n1、返回值处理器判断是否支持这种类型返回值 supportsReturnType\n2、返回值处理器调用 handleReturnValue 进行处理\n3、RequestResponseBodyMethodProcessor 可以处理返回值标了@ResponseBody 注解的。\n\\1.  利用 MessageConverters 进行处理 将数据写为json\n1、内容协商（浏览器默认会以请求头的方式告诉服务器他能接受什么样的内容类型）\n2、服务器最终根据自己自身的能力，决定服务器能生产出什么样内容类型的数据，\n3、SpringMVC会挨个遍历所有容器底层的 HttpMessageConverter ，看谁能处理？\n1、得到MappingJackson2HttpMessageConverter可以将对象写为json\n2、利用MappingJackson2HttpMessageConverter将对象转为json再写出去。\n\n\n\n\n\n\n\n\nSpringMVC到底支持哪些返回值ModelAndView\nModel\nView\nResponseEntity \nResponseBodyEmitter\nStreamingResponseBody\nHttpEntity\nHttpHeaders\nCallable\nDeferredResult\nListenableFuture\nCompletionStage\nWebAsyncTask\n有 @ModelAttribute 且为对象类型的\n@ResponseBody 注解 ---> RequestResponseBodyMethodProcessor；\n\n\n\nHTTPMessageConverter原理\nMessageConverter规范\n\n\nHttpMessageConverter: 看是否支持将 此 Class类型的对象，转为MediaType类型的数据。\n例子：Person对象转为JSON。或者 JSON转为Person\n\n默认的MessageConverter\n\n\n0 - 只支持Byte类型的\n1 - String\n2 - String\n3 - Resource\n4 - ResourceRegion\n5 - DOMSource.*class * SAXSource.class) \\ StAXSource.**class **StreamSource.**class **Source.class\n6 - MultiValueMap\n7 - true \n8 - true\n9 - 支持注解方式xml处理的。\n最终 MappingJackson2HttpMessageConverter  把对象转为JSON（利用底层的jackson的objectMapper转换的）\n\n内容协商根据客户端接收能力不同，返回不同媒体类型的数据。\n引入xml依赖&lt;dependency>\n            &lt;groupId>com.fasterxml.jackson.dataformat&lt;/groupId>\n            &lt;artifactId>jackson-dataformat-xml&lt;/artifactId>\n&lt;/dependency>\n\npostman分别测试返回json和xml只需要改变请求头中Accept字段。Http协议中规定的，告诉服务器本客户端可以接收的数据类型。\n\n开启浏览器参数方式内容协商功能为了方便内容协商，开启基于请求参数的内容协商功能。\nspring:\n    contentnegotiation:\n      favor-parameter: true  #开启请求参数内容协商模式\n\n发请求： http://localhost:8080/test/person?format=json\nhttp://localhost:8080/test/person?format=xml\n\n确定客户端接收什么样的内容类型；\n1、Parameter策略优先确定是要返回json数据（获取请求头中的format的值）\n\n2、最终进行内容协商返回给客户端json即可。\n内容协商原理\n1、判断当前响应头中是否已经有确定的媒体类型。MediaType\n\n2、获取客户端（PostMan、浏览器）支持接收的内容类型。（获取客户端Accept请求头字段）【application&#x2F;xml】\n\ncontentNegotiationManager 内容协商管理器 默认使用基于请求头的策略\n\nHeaderContentNegotiationStrategy  确定客户端可以接收的内容类型 \n\n\n\n3、遍历循环所有当前系统的 MessageConverter，看谁支持操作这个对象（Person）\n\n4、找到支持操作Person的converter，把converter支持的媒体类型统计出来。\n\n5、客户端需要【application&#x2F;xml】。服务端能力【10种、json、xml\n\n\n\n6、进行内容协商的最佳匹配媒体类型\n\n7、用 支持 将对象转为 最佳匹配媒体类型 的converter。调用它进行转化 。\n\n\n\n导入了jackson处理xml的包，xml的converter就会自动进来\nWebMvcConfigurationSupport\njackson2XmlPresent = ClassUtils.isPresent(\"com.fasterxml.jackson.dataformat.xml.XmlMapper\", classLoader);\n\nif (jackson2XmlPresent) &#123;\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.xml();\n            if (this.applicationContext != null) &#123;\n                builder.applicationContext(this.applicationContext);\n            &#125;\n            messageConverters.add(new MappingJackson2XmlHttpMessageConverter(builder.build()));\n        &#125;\n\n自定义 MessageConverter实现多协议数据兼容。json、xml、x-guigu\n0、@ResponseBody 响应数据出去 调用 RequestResponseBodyMethodProcessor 处理\n1、Processor 处理方法返回值。通过 MessageConverter 处理\n2、所有 MessageConverter 合起来可以支持各种媒体类型数据的操作（读、写）\n3、内容协商找到最终的 messageConverter；\nSpringMVC的什么功能。一个入口给容器中添加一个  WebMvcConfigurer\n\n","slug":"SpringBoot2","date":"2022-09-30T09:31:29.000Z","categories_index":"","tags_index":"Java框架","author_index":"JuneQQQ"},{"id":"4a207b7e885fdbcca8129599135e5f2e","title":"MySQL基础","content":"MySQL 索引结构 - rickiyang - 博客园 (cnblogs.com)\nMySQL基础1.基础语法\nNull 相关\n\n使用 is null，例如查询哪些员工津贴为null：\nselect empno,ename,sal from emp where comm is null\n\nIS NULL &amp; &lt;&#x3D;&gt;\n\n前者仅可以判断NULL值，后者既可以判断NULL，又可以判断普通的数值\n2.条件语句and 和 orand 优先级比 or 高\nin\n语法：\nselect xxx from xxx where n in(&#39;a&#39;,&#39;b&#39;)\n\n\n\nlike（模糊查询）\n%：匹配任意个字符\n_：匹配一个字符\n[  ] ：表示括号内所列字符中的一个（类似正则表达式）。指定一个字符、字符串或范围，要求所匹配对象为它们中的任一个。\n如 [  ] 内有一系列字符（01234、abcde之类的）则可略写为“0-4”、“a-e”\n\n\n[^ ] ：表示不在括号所列之内的单个字符。其取值和 [ ] 相同，但它要求所匹配对象为指定字符以外的任一个字符。\n\n注意：\n\n涉及到% _ 可以用 \\ 转义\nlike 不匹配 null\n\n3.排序\n默认升序 ASC  可以指定降序 DESC\n根据两个或多个字段排序\n有先后之分，先写的优先排，只有其值相同，才会用到后面的排序\n\n\norder by 后面可以跟数字，表示根据第几列排序\n以上语句的执行顺序\nfrom -&gt; where -&gt; select -&gt; order by（排序总是在最后）\n\n\n\n4.单行处理函数字符串处理函数\nLower&#x2F;Upper：大小写\n\nconcat：拼接字符串\n\n\nselect concat(last_name,'_',first_name) from employees;\n\n\nsubstr：取子串（substr(被截取的字符串, 起始下标, 截取的长度)）\n\n起始下标从 1开始 ( field, [from, to] ) 包括两端取值\n\n\ninstr：字符串出现位置 ( [ source_str, example_str ] )，从1开始计算\n\nlength( )：长度\n\ntrim：去前后空格\n\ntrim( ‘a’ from ‘aaadsdsaaaa’ ) 去除前后的 ‘a’\n\n\nlpad( source_str, length, char )：用指定字符左填充指定长度\n\nrpad( source_str, length, char )：用指定字符右填充指定长度\n\nreplace( source, old, new )：字符串替换\n\ninstr(source, target)：查找targer字符串第一次在source出现的位置（从1开始，不存在返回0）\n\nlocate(target, source)：查找targer字符串在source出现的位置（从1开始，不存在返回0）\n\nposition( targer IN source )：查找targer字符串第一次在source出现的位置（从1开始，不存在返回0）\n\nsubstring_index(source, char ,n)：source 字符串截取函数，注意index不能为0，正数代表截取第n个出现的char之前的所有字符串，负数代表截取倒数第|n|个出现的char之后的所有字符串\n\nselect device_id,substring_index(blog_url,&#39;/&#39;,-1) user_name from user_submit\n\n\n\n数学函数\ncell(  )：向上取整，返回&gt;&#x3D;该参数的最小整数\n\nfloor(  )：向下取整，返回&lt;&#x3D;该参数的最小整数\n\ntrancate( num [,n ] )：数字截断，可以指定小数点后位数n\n\nmod( )：取余 &#x3D; a-a&#x2F;b*b\n\nround( )：四舍五入 ( field [,保留小数位数] )  \n\n负数代表向整数位舍入\n\n\nformat：设置千分位\n\nrand：生成随机数\n\n一百以内随机整数：round(rand()*100, 0)\n\n\n\n日期函数\nnow( )：获取当前时间\ncurdate( )：返回当前年月日\ncurtime( )：返回当前时分秒\nyear( time )：截断取年\nmonth( time )：截断取月\nstr_to_date：字符串转日期，–&gt; 数据库识别\nselect * from emp where hiredate = STR_TO_DATE(&#39;4-3 1992&#39;,&#39;%c-%d %Y&#39;);\n\n\n\n\n\n\n格式符\n含义\n\n\n\n%Y\n四位年份\n\n\n%y\n2位的年份\n\n\n%m\n月份(01,02…11,12)\n\n\n%c\n月份(1,2,…11,12)\n\n\n%d\n日(01,02,…)\n\n\n%H\n小时（24小时）\n\n\n%h\n小时（12小时）\n\n\n%i\n分钟（00，01…59）\n\n\n%s\n秒（00，01…59）\n\n\n\ndate_format：数据库日期， –&gt; 期望格式\nselect DATE_FORMAT(now(),&#39;%y-%m-%d&#39;);\n\n\ntimestampdiff( unit, start_time, end_time )：计算时间间隔函数\n\n其它函数\nifnull( field, replace )：将 null 转换\nversion( )\ndatabase( )\nuser( )\n\n5.多行处理函数若不配合分组字段使用，则默认将整张表当做一组；\n分组函数自动忽略 null\n\ncount：计数\n\nsum：求和\n\navg：平均值\n\nmax&#x2F;min：最值\n\ncount ( 具体字段 )：表示统计该字段下所有不为NULL的元素总数\n\ncount ( * )：统计表当中的总行数（只要有一行数据则count++）\n\ncount( n )：将所有行置1，统计行数\n\n有主键 count( 主键字段 )最快\n\n没主键 count( 1 )最快\n\n对于以上两种情况，这种情况更优先：\n\n表中只有一个字段，count( * )最快\n\n\nMyISAM存储引擎下，COUNT(*)效率最高\n\n\n详细对比：https://www.cnblogs.com/nov5026/p/12966889.html\n6.常用SQL技巧SQL执行顺序编写顺序\nselect distinct\n\t\t查询字段\nfrom\n \t\t表名\njoin\n\t\t表名 on 条件\nwhere\n\t\t条件\ngroup by\n\t\t字段\nhaving\n\t\t条件\norder by\n\t\t字段\nlimit\n\t\t参数\n\n执行顺序\nfrom -> on -> join -> where -> group by -> having -> select distinct -> order by -> limit\n\n\n\n模糊查询 - 正则表达式select * from tableName where name regexp 表达式\n\n\n\n\n\n\n\n7.分组查询找出每个部门，不同工作岗位的最高薪资\nSELECT\n\tdeptno,\n\tjob,\n\tmax( sal ) \nFROM\n\temp \nGROUP BY\n\tdeptno,\n\tjob\n\n找出每个部门最高薪资，要求显示最高薪资大于3000的\nSELECT\n\tdeptno,\n\tmax( sal ) maxsal \nFROM\n\temp \nGROUP BY\n\tdeptno \nHAVING\n\tmaxsal > 3000\n\t\n######↓改进↓######\n\nSELECT\n\tdeptno,\n\tmax( sal ) \nFROM\n\temp \nWHERE\n\tsal > 3000 \nGROUP BY\n\tdeptno\n\n找出每个部门平均薪资，要求显示平均薪资高于2500的\nSELECT\n\tdeptno,\n\tavg( sal ) \nFROM\n\temp \nGROUP BY\n\tdeptno \nHAVING\n\tavg( sal )> 2500\n\n\n\n8.distinct 关键字只能用在所有字段最前方\n统计所有工作岗位的数量\nselect count(distinct job) from emp\n\n\n\n9.连接查询内连接等值连接SELECT\n\te.ename,\n\td.dname \nFROM\n\temp e  # inner 省略\n\tJOIN dept d ON e.deptno = d.deptno\n\n非等值连接SELECT\n\te.ename,\n\te.sal,\n\ts.grade \nFROM\n\temp e\n\tJOIN SALGRADE s ON e.sal BETWEEN s.LOSAL \n\tAND s.HISAL\n\n自连接SELECT\n\te.ename emp,\n\td.ename mgr \nFROM\n\temp e\n\tJOIN emp d ON e.mgr = d.empno\n\n\n\n外连接左外连接&#x2F;右外连接SELECT\n\te.ename emp,\n\td.ename mgr \nFROM\n\temp e   # 省略 outer -> left outer join\n\tLEFT JOIN emp d ON e.mgr = d.empno\n\n全外连接MySQL不支持，全外连接 &#x3D; 内连接的结果 + 表1中有但表2中没有的 + 表2中有但表1中没有的\n交叉连接# 笛卡尔积的体现\nselect a.*,b.* from beauty b cross join boys a ;\n\n\n\n10.子查询# 放在 where 或者 having 后面 或 from后面 或 select 后面（单行单列）\nselect\n\t...(select)\nfrom \n\t...(select)\nwhere\n\t...(select)\n\n例：找出每个工作岗位的平均工资的薪资等级\nSELECT\n\t* \nFROM\n\tSALGRADE s\n\tJOIN ( SELECT avg( sal ) avgsal, job FROM emp GROUP BY job ) t ON t.avgsal BETWEEN s.LOSAL \n\tAND s.HISAL\n\n例：找出每个员工的部门名称，要求显示员工名、部门名\nSELECT e.ename,( SELECT d.dname FROM dept d WHERE e.DEPTNO = d.deptno ) dname \nFROM\n\temp e;\n\n例：查询每个部门的员工个数\n# 子查询使用在 select 之后\nSELECT d.*,(\n  SELECT COUNT(*)\n  FROM employees e\n  WHERE e.department_id = d.department_id\n) 个数\nFROM departments d;\n\n例：查询所有员工的部门名\n# 子查询使用在 EXISTS 之后\nSELECT department_name\nFROM departments d\nWHERE EXISTS(\n  SELECT * \n  FROM employees e \n  WHERE d.department_id = e.department_id\n)\n\n\n\n\n\n多行子查询\n\n\n操作符\n含义\n\n\n\nIN&#x2F;NOT IN\n等于列表中任意一个\n\n\nANY | SOME\n和子查询返回的某一个值比较 min\n\n\nALL\n和子查询返回的所有值比较 max\n\n\nNOT IN &#x3D;&gt; &lt;&gt;ALL\nIN &#x3D;&gt; &#x3D;ANY\nUNION例：查询工作岗位是MANAGER和SALESMAN的员工\nselect * from employees where email 条件1\nunion\nselect * from employees where email 条件2\n###### UNION效率更高 ######\n\n\n联合查询的多条查询语句列数必须一致\n列对应关系与select后的字段顺序有关\nunion 默认去重，union all 取消去重\n\nEXISTSexists ( 子查询 ) 返回的是一个boolean值，有或没有\n11.Limit 使用SELECT * FROM 表名 limit 6,5;\n结果：检索记录第7行至11行记录，共取出5条记录。\n\nSELECT * FROM 表名 limit 6,-1;\n结果：检索取出第7行至以后的所有数据。\n\nSELECT * FROM 表名 limit 6;\n结果：检索取出前6条记录行。\n\n\n偏移量offset较小的时候，直接使用limit较优\n\n偏移量offset越大，直接使用子查询越优。\n\n\n12.表相关操作创建表（DDL）CREATE TABLE 表名称\n(\n    列名称1 数据类型,\n    列名称2 数据类型,\n    列名称3 数据类型,\n    ....\n)default character set = 'utf8';\n\n复制建表# 复制表结构 + 数据\ncreate table tableName1  as select * from tableName2\n\n# 仅复制表结构\ncreate table newTable like oldTable\n\n# 选择字段复制结构\ncreate table tableName select filed1,filed2 from tableName1 where o;\n\n#SQL Server\nselect * into newTable from oldTable\n\n\n\n数据类型主要包括以下五大类：\n整数类型：BIT、BOOL、TINY INT、SMALL INT、MEDIUM INT、 INT、 BIG INT\n浮点数类型：FLOAT、DOUBLE、DECIMAL\n字符串类型：**CHAR(0255,fixed)、VARCHAR(065535,variable)**、TINY TEXT、TEXT、MEDIUM TEXT、LONGTEXT、TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB\n日期类型：Date、DateTime、TimeStamp、Time、Year\n其他数据类型：BINARY、VARBINARY、ENUM、SET、Geometry、Point、MultiPoint、LineString、MultiLineString、Polygon、GeometryCollection等\n约束（*********）\n非空约束：not null（只能加在列上）\n唯一性约束：unique\n修饰的字段不能重复，但可以重复为NULL\n表级约束：[constraint key_name]unique(field_1,field_2...) \n\n\n主键约束：primary key（简称PK）\nauto_increment 主键自增\n选取主键的一个基本原则是：不使用任何业务相关的字段作为主键。\n表级约束：[constraint key_name]primary key(field_name) \n\n\n外键约束：foreign key（简称FK）\n表级约束：[constraint key_name] foreign key(field_1) references tableName(field_2)\n\n\n检查约束：check（mysql5.6不支持但不会报错，8.0支持；oracle支持）\n列级约束：字段名 类型 check(条件)\n默认约束：default\n列级约束：字段名 类型 default 值\n\n\nunique &amp;&amp; not null &#x3D; primary key  （MySQL）\n\n\n\n\n\n\n\n\n\n\n修改表的约束\n# 除外键\nalter table tableName modify [column] columnName typeName constraintName\n\n# 外键\nalter table tableName add constraint keyName foreign key(columnName) references tableName(columnName)\n\n\n\n\n\n\n\n\n\n\n删除表的约束\n# 删除非空约束\nalter table tableName modify [column] columnName typeName NULL;\n# 删除默认约束\nalter table tableName modify [column] columnName typeName;\n# 删除唯一约束\nalter table tableName drop index;\n# 删除外键约束，keyName默认为列名\ndrop table tableName drop foreign key keyName;\n\n修改表（DDL）# 修改列名/类型\nalter table tableName change [column] oldName newName type\n# 修改类型\nalter table tableName modify [column] columnName type;\n# 添加新列\nalter table tableName add [column] columnName type;\n# 删除列\nalter table tableName drop [column] columnName;\n# 修改表名\nalter table oldName rename to newName\n\n删除表（DDL）# 删除支持回滚，但效率低\ndrop table if exists tableName\n# 删除不支持回滚，但效率高\ntruncate table tableName\n\n插入（DML）insert into tableName(field_1,field_2,...) values(v1,v2,...)\n# 一一对应，可以不全写 field\n# 另外一种简写方法，需要全写字段,可以同时插入多条\ninsert into tableName values(AllFieldValue)\n# 另外一种写法\ninsert into tableName set field1 = v1,field2 = v2 ...;\n\n插入日期：\n# varchar -> date\n# %Y 年\n# %m 月\n# %d 日\n# %h 时\n# %i 分\n# %s 秒\nstr_to_date('01-10-1990','%d-%m-%Y')\n# 如果字符串正好是 1990-10-01 这种格式，可以省略这个函数\n\n获取日期：\ndate_fromat(dateField, 'fromat')\n# 例子 ↓\nselect id,name,date_format(birth,'%m/%d/%Y') as birth from t_user;\n\nMySQL中如何获取当前时间？\n可以通过 now() 函数，获取类型是 datetime 类型的\n修改（DML）update tableName set field1 = value 1, field 2 = value 2 ...  where 条件\n\n\n\n删除（DML）delete from tableName where 条件\n# 没有条件，会删除表内全部数据\n\n\n\n13.事务只有DML（增删改）操作才会跟事务有关；\n注意：MySQL事务默认值自动提交\n事务四个特性\n原子性（Atomicity）\n原子性是指事务都是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。\n能够在错误时中止事务，丢弃该事务进行的所有写入变更的能力。\n\n\n一致性（Consistency）\n一致性是指在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。\n\n\n隔离性（Isolation）\n隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能相互干扰。\n\n\n持久性（Durability）\n持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。\n\n\n\n数据库隔离级别&amp;问题问题\n\n脏读：对于两个事务T1，T2，T1读取了已经被T2更新但还没有被提交的字段，之后，若T2回滚，T1读取的内容就是临时且无效的\n不可重复读：对于两个事务T1，T2，T1读取了一个字段，然后T2更新并提交了该字段，之后，T1再次读取同一个字段，值就不同了\n幻读（虚读）：对于两个事务T1，T2，T1从一个表中读取了一个字段，然后T2在该表中插入了一些新的行，之后，如果T1再次读取同一个表，就会多出几行（这个只会在增删改时会体现出来！）\n\n隔离级别\n\n读未提交（read uncommitted）\n没有提交就可以读到\n\n\n读已提交（read committed）\n存在不可重复读、幻读，解决脏读\n提交后才可以读到\n\n\n可重复读（repeatable read）\n解决了不可重复读、脏读，存在幻读\n提交后也读不到\nMySQL默认隔离级别\n\n\n序列化（serializable）\n事务排队，不能并发，效率低，解决了所有问题\n\n\n\n相关命令\nselect @@transaction_isolation; # 查看隔离级别,MySQL80\nselect @@tx_isolation; # 查看隔离级别,MySQL56\n\nset global transaction isolation level read uncommitted; # 设置事务隔离级别\n\nselect  @@global.autocommit;\nset  @@global.autocommit  = 0; # 关闭自动提交\n\n\n\n14.视图\n重用SQL语句\n简化复杂SQL操作，封装细节\n保护数据，提高安全性\n\n视图能不能更新、删除、添加？\n如果视图的每一行是与物理表一一对应的，则可以，否则不可以。\n视图的更新性和视图中查询的定义有关，以下类型的视图是不能更新的：\n\n包含以下关键字的SQL语句：分组函数、distinct、group by、having、union或者union all\n常量视图\nselect 中包含子查询\njoin\nfrom 一个不能更新的视图\nwhere 子句的子查询引用了 from 子句中的表\n\n创建create [or replace] [algorithm = &#123;UNDEFINED|MEGRE|TEMPTABLE&#125;] view 视图名 as 查询语句 [WITH [CASCADED|LOCAL] CHECK OPTION1];\n# LOCAL:只要满足本视图的条件就可以更新\n# CASCADED:必须满足所有针对该视图的所有视图的条件才可以更新，默认\n\n修改alter view 视图名 as 查询语句/视图;\n\n删除drop view [if exists] 视图名[,视图名...];\n\n查看# 查看指定数据库下所有视图\nSHOW FULL TABLES IN databaseName WHERE TABLE_TYPE LIKE 'VIEW'; \nSHOW TABLE STATUS;\n\n\n\n15. 34道作业题\n取得每个部门最高最高薪水的人员名称\n\n#1\nSELECT\n\te.ename,\n\tt.* \nFROM\n\temp e\n\tJOIN ( SELECT deptno, max( sal ) maxsal FROM emp GROUP BY deptno ) t ON e.sal = t.maxsal \n\tAND t.deptno = e.deptno\n\n\n#2\nSELECT\n\te.ename,\n\te.sal,\n\te.deptno \nFROM\n\temp e \nWHERE\n\t( e.deptno, e.sal ) IN ( SELECT deptno, max( sal ) sal  FROM emp  GROUP BY deptno)\n\n\n哪些人的薪水在部门的平均薪水之上\n\nSELECT\n\te.ename,\n\te.sal,\n\tt.avgsal\nFROM\n\temp e\n\tJOIN ( SELECT deptno, avg( sal ) avgsal FROM emp GROUP BY deptno ) t ON t.deptno = e.deptno \n\tAND e.sal > t.avgsal;\n\n\n取得部门中所有人的平均薪水等级\n\nSELECT\n\te.deptno,\n\tavg(s.grade)\nFROM\n\temp e\n\tJOIN salgrade s ON e.sal BETWEEN s.losal AND s.hisal\nGROUP BY\n\te.deptno\n\t\n\n# 所有部门平均薪资的薪水等级\nSELECT\n\te.deptno,s.grade\nFROM\n\tsalgrade s\n\tJOIN ( SELECT deptno, avg( sal ) avgsal FROM emp GROUP BY deptno ) e ON e.avgsal BETWEEN s.losal \n\tAND s.hisal\n\n\n不准用（max），取得最高薪水\n\nselect ename,sal from emp order by sal desc limit 1;\n# or\nSELECT\n\tsal \nFROM\n\temp \nWHERE\n\tsal NOT IN ( SELECT DISTINCT a.sal FROM emp a JOIN emp b ON a.sal &lt; b.sal );\n\n\n取得平均薪水最高的部门的部门编号\n\nSELECT\n\tdeptno,\n\tavg( sal ) avgsal \nFROM\n\temp \nGROUP BY\n\tdeptno \nORDER BY\n\tavgsal DESC \n\tLIMIT 1;\t\n\n\n取得平均薪水最高的部门名称\n\nSELECT\n\td.dname,\n\tavg( e.sal ) avgsal \nFROM\n\tdept d\n\tJOIN emp e ON d.deptno = e.deptno \nGROUP BY\n\td.dname\nORDER BY\n\tavgsal DESC \n\tLIMIT 1;\n\n\n求平均薪水的等级最低的部门的部门名称\n\nSELECT\n\td.dname\nFROM\n\tdept d\n\tJOIN ( SELECT deptno, sum( sal ) sumsal FROM emp GROUP BY deptno ORDER BY sumsal ASC LIMIT 1 ) t ON d.deptno = t.deptno;\n\n\n取得比普通员工（员工代码没有在 mgr 字段上出现的）的最高薪水还要高的领导人姓名\n\nSELECT\n\tename,\n\tsal \nFROM\n\temp \nWHERE\n\tsal > (\n\tSELECT\n\t\tmax( sal ) \n\tFROM\n\t\temp \nWHERE\n\tempno NOT IN ( SELECT DISTINCT mgr FROM emp WHERE mgr IS NOT NULL ));\n\n\n取得薪水最高的前五名员工\n\nselect ename,sal from emp order by sal desc limit 5;\n\n\n取得薪水最高的第六到第十名员工\n\nselect ename,sal from emp order by sal desc limit 5,5;\n\n\n取得最后入职的5名员工\n\nselect ename,hiredate from emp order by hiredate desc limit 5;\n\n\n取得每个薪水等级有多少员工\n\nSELECT\n\ts.grade,\n\tcount(*) \nFROM\n\temp e\n\tJOIN salgrade s ON e.sal BETWEEN s.LOSAL AND s.HISAL \nGROUP BY\n\ts.grade;\n\n\n有三个表S（学生表）、C（课程表）、SC（学生选课表）S（SNO，SNAME）– 代表（学号，姓名）C（CNO，CNAME，CTEACHER）– 代表（课程号，课程名，教师名）SC（SNO，CNO，SCGRADE）– 代表（学号，课程号，成绩）\n\n问题：\n\n找出没选过”黎明“老师的所有学生姓名；\n\nSELECT\n\tsname s \nWHERE\n\tsno NOT IN (SELECT sno FROM  sc WHERE cno IN \n              ( SELECT cno FROM c WHERE cteacher = '黎明' ));\n\n\n找出两门及以上不及格学生姓名及平均成绩；\n\nselect\n  t1.sno,t1.sname,t2.avggrade\nfrom\n  (select\n    sc.sno,s.sname\n  from\n    SC sc\n  join\n    S s\n  on\n    sc.sno=s.sno\n  where\n    sc.scgrade &lt; 60\n  group by\n      sc.sno,s.sname\n  having\n    count(*) >=2) t1\njoin\n  (select sno,avg(scgrade) as avggrade from SC group by sno) t2\non\n  t1.sno=t2.sno;\n\n\n既学过1号课程又学过2号课程的所有学生的姓名。\n\nSELECT\n\ts.sno,\n\ts.sname \nFROM\n\tsc\n\tJOIN s ON sc.sno = s.sno \nWHERE\n\tcno = 1 \n\tAND sno IN (\n    SELECT\n      sno \n    FROM\n      sc \n  \tWHERE\n   \t \tcno = 2)\n\n\n\n\n列出所有员工及领导的姓名\n\nSELECT\n\ta.ename '员工',\n\tb.ename \"领导\" \nFROM\n\temp a\n\tLEFT JOIN emp b ON a.mgr = b.empno;\n\n\n列出雇佣日期早于其直接上级的所有员工的编号、姓名、部门名称\n\nSELECT\n\ta.deptno,\n\ta.ename,\n\td.dname \nFROM\n\temp a\n\tLEFT JOIN emp b ON a.mgr = b.empno\n\tLEFT JOIN dept d ON a.deptno = d.deptno \nWHERE\n\ta.hiredate &lt; b.hiredate\n\n\n列出部门名称和这些部门的员工信息，同时列出那些没有员工的部门\n\nSELECT\n\td.dname,\n\te.* \nFROM\n\tdept d\n\tLEFT JOIN emp e ON d.deptno = e.deptno\n\n\n列出至少有5个员工的所有部门\n\nselect deptno from emp group by deptno having count(*) >=5;\n\n\n列出比”SMIT”工资高的员工信息\n\nSELECT\n\t* \nFROM\n\temp \nWHERE\n\tsal > ( SELECT sal FROM emp WHERE ename = \"SMITH\" );\n\n\n列出所有JOB为“CLERK”的员工姓名及其部门名称，部门人数\n\nSELECT\n\ta.ename,\n\ta.dname,\n\tb.deptcount \nFROM\n\t( SELECT e.ename, d.dname, d.deptno FROM emp e JOIN dept d ON e.deptno = d.deptno WHERE job = \"CLERK\" ) a\n\tJOIN ( SELECT deptno, count(*) deptcount FROM emp GROUP BY deptno ) b ON a.deptno = b.deptno;\n\n\n列出最低薪金大于1500的各种工作及从事此工作的全部雇员人数，按照工作岗位分组求最小值\n\nselect job,count(*) from emp group by job having min(sal)>1500;\n\n\n列出部门“SALES”工作的员工姓名，假定不知道销售部的部门编号\n\nSELECT\n\tename\nFROM\n\temp \nWHERE\n\tdeptno = ( SELECT deptno FROM dept WHERE dname = \"SALES\" );\n\n\n列出薪金高于公司平均薪金的所有员工、所在部门、上级领导、雇员的工资等级\n\nSELECT\n\te.ename,\n\td.dname,\n\tee.ename manager,\n\ts.grade \nFROM\n\temp e\n\tLEFT JOIN emp ee ON e.mgr = ee.empno\n\tJOIN dept d ON e.deptno = d.deptno\n\tJOIN salgrade s ON e.sal BETWEEN s.LOSAL \n\tAND s.HISAL \nWHERE\n\te.sal >(SELECT avg( sal )  FROM emp);\n\n\n列出与“SCOTT”从事相同工作的所有员工及部门名称\n\nSELECT\n\tename,\n\tdname \nFROM\n\temp e\n\tJOIN dept d ON e.deptno = d.deptno \nWHERE\n\tjob = ( SELECT job FROM emp WHERE ename = \"SCOTT\" ) \n\tAND ename != \"SCOTT\";\n\n\n列出薪金等于部门30中员工的薪金的其他员工的姓名和薪金\n\nSELECT\n\tename,\n\tsal \nFROM\n\temp \nWHERE\n\tsal IN ( SELECT DISTINCT sal FROM emp WHERE deptno = 30 ) \n\tAND deptno != 30;\n\n25.列出薪金高于在部门30工作的所有员工的薪金的员工姓名和薪金、部门名称\nSELECT\n\te.ename,\n\te.sal,\n\td.dname \nFROM\n\temp e\n\tJOIN dept d ON e.deptno = d.deptno \nWHERE\n\te.sal >(SELECT max( sal ) FROM emp WHERE deptno = 30);\n\n\n列出每个部门工作的员工数量，平均工资和平均服务期限\n\nSELECT\n\td.*,\n\tcount( e.ename ),\n\tifnull( avg( e.sal ), 0 ),\n\tavg(\n\t\ttimestampdiff(\n\t\t\tYEAR,\n\t\t\thiredate,\n\t\tnow())) \nFROM\n\tdept d\n\tLEFT JOIN emp e ON e.DEPTNO = d.DEPTNO \nGROUP BY\n\td.deptno,\n\td.dname,\n\td.loc;\n\n\n列出员工的姓名、部门名称和工资\n\nSELECT\n\te.ename,\n\td.dname,\n\te.sal \nFROM\n\temp e\n\tJOIN dept d ON e.DEPTNO = d.DEPTNO\n\n\n列出所有部门的详细信息和人数\n\nSELECT\n\td.*,\n\tcount( e.ename ) \nFROM\n\tdept d\n\tJOIN emp e ON d.DEPTNO = e.DEPTNO \nGROUP BY\n\td.DEPTNO,\n\td.DNAME,\n\td.LOC;\n\n\n列出各种工作的最低工资及从事此工作的雇员姓名\n\nSELECT\n\te.ename,\n\tt.* \nFROM\n\temp e\n\tJOIN ( SELECT job, min( sal ) minsal FROM emp GROUP BY job ) t ON e.sal = t.minsal \n\tAND e.job = t.job;\n\n\n列出各个部门的MANGER（领导）的最低薪金\n\nSELECT\n\tdeptno,\n\tmin( sal ) \nFROM\n\temp \nWHERE\n\tjob = \"MANAGER\" \nGROUP BY\n\tdeptno;\n\n\n列出所有员工的年工资，按年薪从低到高排序\n\nSELECT\n\tifnull( sal, 0 )* 12 \nFROM\n\temp \nORDER BY\n\tsal ASC;\n\n\n求出员工领导的薪水超过3000的员工名字与领导名字\n\nSELECT\n\ta.ename,\n\tb.ename manager,\n\tb.sal \nFROM\n\temp a\n\tJOIN emp b ON a.mgr = b.empno \nWHERE\n\tb.sal > 3000;\n\n\n求出部门名称中，带’S’字符的部门员工的工资合计、部门人数\n\nSELECT\n\td.dname,\n\tcount( e.ename ) \nFROM\n\tdept d\n\tLEFT JOIN emp e ON e.DEPTNO = d.DEPTNO \nWHERE\n\td.dname LIKE '%S%' \nGROUP BY\n\td.dname;\n\n\n给任职日期超过30年的员工加薪10%\n\nUPDATE emp \nSET sal = sal * 1.1 \nWHERE\n\tTIMESTAMPDIFF(\n\t\tYEAR,\n\tHIREDATE,\n\tnow())> 30\n\n\n\n16.变量系统变量由系统提供，服务器层面，只要服务器不重启，就会一直有效。有以下两种\n\n全局变量\n会话变量（将下面的 ‘global’ 换成 ‘session’ 即为会话变量操作）\n\n\n查看所有的系统变量：show global variables\n查看满足条件的部分系统变量：show global variables like &#39;%xx%&#39;\n查看指定的某个系统变量的值：select @@global.系统变量名\nselect @@global.autocommit   \nselect @@[session.]transaction_isolation （不写默认显示局部变量）\n\n\n为某个具体的系统变量赋值\nset global 系统变量名 = 值 or  set @@gloabl.系统变量名 = 值\nset global autocommit = 0\n\n\n\n\n\n自定义变量用户自定义，作用域为当前会话（连接）有效，同于会话变量的作用域\n自定义变量 - 用户变量用户变量 - 定义\n# 三种方式\nset @用户变量名 = 值\nset @用户变量名 := 值\nselect @用户变量名 := 值\n\n用户变量 - 赋值\n# 四种方式\nset @用户变量名 = 值\nset @用户变量名 := 值\nselect @用户变量名 := 值\nselect 端字段 into @用户变量名 from 表\n\n自定义变量 - 局部变量作用域：仅仅在定义它的 begin end 中有效，并且必须放在行首\n局部变量 - 定义\ndeclare 变量名 类型 [default 值];\n\n局部变量 - 赋值\nset 局部变量名 = 值;\nset 局部变量名 := 值\nselect @局部变量名 := 值\nselect 字段 into 局部变量名 from 表\n\n\n\n17.存储过程和函数存储过程 procedure创建delimiter 变量1\ncreate procedure 存储过程名(参数列表)\nbegin\n\t\t存储过程体（一组合法SQL语句） \nend 变量1\n\n# 参数列表包括三部分：参数模式(in/out/inout) 参数名 参数类型\n# in：该参数可以作为输入，也就是该参数需要调用方法传入值\n# out：该参数可以作为输出，也就是该参数可以作为返回值\n# inout：该参数是以上两种的合体\n\n调用call 存储过程名(参数列表);\n\n\n删除drop procedure [if exists] 存储过程名\n查看show create procedure 存储过程名\nshow procedure status\n\n\n\n\n\n函数 function创建语法CREATE FUNCTION 函数名(参数列表) RETURNS 返回类型\nBEGIN\n\t函数体\nEND\n# 参数列表包含两部分：参数名 参数类型\n# 函数一定有返回语句 RETURN V\n# 注意：函数不允许产生查询结果！\n\n查看show create function 函数名（不带括号）;\n\n\n\n删除drop  function 函数名（不带括号）;\n\n\n\n\n\n函数 vs 存储过程存储过程是procedure用户定义的一系列sql语句的集合，涉及特定表或其它对象的任务，用户可以调用存储过程，而函数通常是数据库已定义的方法，它接收参数并返回某种类型的值并且不涉及特定用户表。\n18.流程控制结构分支结构\nif 函数 &amp; 结构\n\n# 函数 if\nif(表达式a,结果b,结果c)\n# 结构 if\nif 条件1 then 语句1;\nelse if 条件2 then 语句2;\n...\n[else 语句n;]\nend if;\n\n\ncase 结构\n\nCASE [变量/表达式/字段] \t# 类似Java switch/if-else\nWHEN 要判断的值 THEN 返回的值1;\nWHEN 要判断的值 THEN 返回的值2;\nWHEN 要判断的值 THEN 返回的值3;\n...\nELSE 要返回的值 n;\nEND ;\n\n例子：\n# 1.统计每个班的男生和女生各是多少，统计结果的表头为：班号、男生数量、女生数量\nSELECT 班号,\nCOUNT(CASE WHEN 性别='男' THEN '男' END) 男生数,\nCOUNT(CASE WHEN 性别='女' THEN '女' END) 女生数\nFROM 学生表 GROUP BY 班号\n\n# 2.判断成绩的等级，85-100为“优”，70-84为“良”，60-69为“及格”，60以下为“不及格”，并统计每一等级的人数。\nSELECT\nCASE\nWHEN GRADE BETWEEN 85 AND 100 THEN '优'\nWHEN GRADE BETWEEN 70 AND 84 THEN '良'\nWHEN GRADE BETWEEN 60 AND 69 THEN '及格'\nELSE '不及格'\nEND 等级,     COUNT(*) 人数\nFROM SC\nGROUP BY\nCASE\nWHEN GRADE BETWEEN 85 AND 100 THEN '优'\nWHEN GRADE BETWEEN 70 AND 84 THEN '良'\nWHEN GRADE BETWEEN 60 AND 69 THEN '及格'\nELSE '不及格'\nEND\n\n# 3.现在运营想要将用户划分为25岁以下和25岁及以上两个年龄段，分别查看这两个年龄段用户数量\nSELECT\nCASE \nWHEN age &lt; 25 OR age IS NULL THEN '25岁以下' \nWHEN age >= 25 THEN '25岁及以上'\nEND age_cut,COUNT(*) number\nFROM user_profile\nGROUP BY age_cut\n\n\n\n循环结构# 1.while\n[标签:]while 循环条件 do\n\t循环体;\nend while [标签];\n# 标签可以搭配循环控制使用：iterate(continue)/leave(break)\n\n# 2.loop  死循环\n[标签:]loop\n\t循环体;\nend loop [标签];\n\n# 3.repeat(do-while)\n[标签:] repeat\n\t循环体;\nuntil 结束循环的条件\nend repeat [标签];\n\n\n\n游标（光标）1.声明declare 游标名 cursor for 查询语句 # MySQL SQL Server DB2\ndeclare 有标明 cursor is 查询语句  # Oracle PostgreSQL\n\n2.OPENopen 游标名\n\n3.FETCHfetch 游标名 into 变量1,...\n\n4.CLOSEclose 游标名\n\n\n\n\n\n19.窗口函数基本语法如下：\n&lt;窗口函数> over (partition by &lt;用于分组的列名>\n                order by &lt;用于排序的列名>)\n# partition子句可是省略，省略就是不指定分组\n# 这就失去了窗口函数的功能，所以一般不要这么使用\n\n专用窗口函数 rank\n\n\n\nselect *,\n   rank() over (partition by 班级 order by 成绩 desc) as ranking\nfrom 班级表\n\nrank &amp; dense_rank &amp; row_number 有什么区别？\nselect *,\n   rank() over (order by 成绩 desc) as ranking,\n   dense_rank() over (order by 成绩 desc) as dese_rank,\n   row_number() over (order by 成绩 desc) as row_num\nfrom 班级表\n\n\n\n\n\n聚合函数作为窗口函数select *,\n   sum(成绩) over (order by 学号) as current_sum,\n   avg(成绩) over (order by 学号) as current_avg,\n   count(成绩) over (order by 学号) as current_count,\n   max(成绩) over (order by 学号) as current_max,\n   min(成绩) over (order by 学号) as current_min\nfrom 班级表\n\n\n\n如上图，聚合函数sum在窗口函数中，是对自身记录、及位于自身记录以上的数据进行求和的结果。比如0004号，在使用sum窗口函数后的结果，是对0001，0002，0003，0004号的成绩求和，若是0005号，则结果是0001号~0005号成绩的求和，以此类推。\n不仅是sum求和，平均、计数、最大最小值，也是同理，都是针对自身记录、以及自身记录之上的所有数据进行计算\n20.关于自增\n自增列必须是键，但不一定非是主键。\n一张表只能有一个自增列\n\n自增主键利弊优点\n\n自增主键执行insert效率高，数据按顺序存储\n占空间小，所有二级索引都含有主键并使用主键进行记录查找\n物理存储要求表必须有主键，自增int主键开销小，使用便捷\n\n缺点\n\n高并发场景自增Id的生成影响系统性能\n该值与业务无关，除了唯一标识一条记录并无太多意义（未必是缺点，正因为没有确定意义，业务变化时不会影响自增主键，从而不影响底层存储顺序）\n\nMySQL :: MySQL 5.7 Reference Manual :: MySQL Glossary\n使用UUID为主键？优点\n\nUUID便于分布式数据库并发插入\n业务逻辑不依赖于Id生成，如业务需要通过Id关联多条记录，在自增Id条件下记录必须先行插入之后才能获取Id再行关联。UUID可以线下生成Id并直接关联，不依赖于数据库\n\n缺点\n\n相对自增主键，使得所有二级索引占据更多空间\n数据插入效率较低，新插数据可能在索引的中间位置，为将数据插入合适的位置可能需要额外的IO操作，同时造成索引不连续，影响查询效率\n\n总结业务逻辑中含有自然唯一键值时（如accountId），可以考虑下accountId本身的属性，如果它本身就是个int型，那么就可以直接用来作为主键，如果它本身比较长（比如身份证号），那用来做主键可能会带来一些负面影响。此外，还要考虑使用自增主键可能会影响系统的并发度\n建议在建表时默认加上一列自增int主键，至于按自然键值查找的需求，增加对应的二级索引即可。\n21. 触发器（能不用就不用）创建create trigger 触发器名称\n&#123;before|after&#125; &#123;insert|update|delete&#125; on 表名\nfor each row\n触发器执行语句块;\n\n删除drop trigger [if exists] 触发器名;\n\n\n\n22. 数据库三范式\n第一范式：确保每列保持原子性\n第二范式：确保表中每列都与主键相关\n第三范式：确保每列都和主键直接相关，而不是间接相关\n\n","slug":"MySQL基础","date":"2022-09-30T09:27:41.000Z","categories_index":"","tags_index":"学习笔记,MySQL基础","author_index":"JuneQQQ"},{"id":"b6845422ba4775a7cab0c414606e3ecd","title":"Redis基础","content":"\nLinux 基础环境配置\n配置gcc\n\n# 检查是否安装\ngcc --version\n# 未安装的话\nyum install centos-release-scl scl-utils-build\nyum install -y devtoolset-8-toolchain\nscl enable devtoolset-8 bash\n# 再次测试\ngcc --version\n\n\n压缩编译redis\n\n# 解压缩\ntar -zxvf redis-6.2.6.tar.gz\n# 编译\ncd redis-6.2.6\nmake \nmake install\n\n\n后台启动\n\n# 查看是否成功安装\ncd /usr/local/bin\n# 后台启动\nredis-server /opt/redis-6.2.6/redis.conf\n# 检验端口\nps -ef | grep redis\n\n\n关闭\n\nredis-cli shutdown\n# 或\nkill -9 pid\n# 多实例关闭\nredis-cli -p 6379 shutdown\n\n\n\nRedis 基础知识\n默认16个数据库，类似数组下标从0开始，初始默认使用0号\n使用命令 select &lt;dbid&gt; 来切换数据库，如 select 8\n统一密码管理，所有库使用同样的密码\ndbsize 查看当前数据库的 key 数量\nflushdb  清空当前库\nflushall  通杀全部库\n\n五大数据类型Redis基本数据结构及底层实现原理 - 知乎 (zhihu.com)\n最详细的Redis五种数据结构详解（理论+实战），建议收藏。 - 知乎 (zhihu.com)\nString\nRedis最基本的类型，一个key对应一个value；\nString 类型是二进制安全的，意味着Redis的 string 可以包含任何数据，比如 jpg 图片或者序列化对象；\nvalue 最大值为 512M\n\n常用命令set key value   \t# 设置键值，也可用与更改\nget key\t\t\t\t\t\t# 获取值\nappend key value  # 为 key 追加值\nstrlen key\t\t\t\t# 获取 key 长度\nsetnx key value   # 只有 key 不存在时，才设置 key 值\n\nincr key \t\t\t\t\t# 将 key 中存储的【数字字符串】+1，如果为空，则新值为1\ndecr key \t\t\t\t\t# 同上，值减一\n\nmset key1 value1 key2 value2 ... # 同时设置一个或多个 key-value 对\nmget key1 key2 ... # 同时获取多个 key-value对\nmsetnx key1 value1 key2 value2  # 设置多个值【有一个失败则都失败】\n\ngetrange key fromIndex toIndex  # 切割 value -> []\nsetrange key fromIndex  value   # 设置 key\nsetex key expireTime value  \t\t# 设置 key-value 和过期时间\ngetset key value\t\t\t\t\t\t\t\t# 设置了新值同时获得旧值\n\n\n\n数据结构String 的数据结构为简单动态字符串（Simple Dynamic String，缩写SDS）。是可以修改的字符串，内部结构实现上类似Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。\n\n\n\n\nList\n单值多键；\nRedis 列表是简单的字符串列表，按照插入顺序排序。可以头插或者尾插；\n它的底层实际上是个双向链表，对两端操作性能很高，通过索引下标操作性能会比较差\n\n\n\n常用命令lpush/rpush  key value1 value2 ...  # 头插/尾插\nlrange  key fromInded toIndex  # 范围 get，包括首位 [0,-1]查所有 可以使用负数，表示倒数\nlpop/rpop  key \t\t   # 删除且获取值\nbrpop k v # 阻塞式获取值\nrpoplpush list_from list_to # 移除列表的最后一个元素，并将该元素添加到另一个列表并返回。\n\nlindex key index \t\t # 按照索引下标获取元素\nllen key \t\t\t\t\t\t # 获得列表长度\nlinsert key before value newvalue  # 在 value 后面都插入 newvalue 插入值\nlrem key count value\t\t # 从左到右删除 count 个指定 value  count=0移除所有  count&lt;0取绝对值\nlset key index value # 将列表 key 下标为 index 的值替换成 value\n\n数据结构\nRedis中的列表在3.2之前的版本是使用ziplist和linkedlist进行实现的。在3.2之后的版本就是引入了quicklist。\nquicklist就是把一个个的ziplist串成双向链表的形式\n\nSet\nSet对外提供功能与list类似，特殊之处在于set是可以自动排重的。\nSet是string类型的无序集合。他底层其实是一个 value 为 null 和 hash表，所以添加、删除、查找的复杂度都是O(1)\n一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变\n\n常用命令sadd key value1 value2  # 将一个或多个元素加入到 key 中，忽略已存在的\nsmembers key \t\t\t\t\t\t# 取出该集合的所有值\nsismember key value  \t\t# 判断集合 key 是否含有 value，返回0 - 1\nscard key\t\t\t\t\t\t\t\t# 返回该集合的元素个数\nsrem key value1 value2\t# 删除集合中的某个元素\nspop key\t\t\t\t\t\t\t\t# 随机 pop 一个值\nsrandmember key n       # 随即从该集合中取出 n 个值，不会删除元素\nsmove src dst value \t\t# 把集合中一个值从一个集合移动到另外一个集合\nsinter key1 key2        # 返回两个集合【交集】\nsunion key1 key2        # 返回两个集合【并集】\nsdiff  key1 key2        # 返回两个集合【差集】（key1-key2)\n\n数据结构\nintset || hashtable\n当集合对象保存的元素都是整数，并且个数不超过512个时，使用intset编码，否则使用hashtable编码。\n\nHash\n\n常用命令hset  key   field value \t\t# 简单添加\nhget  key   field  \t\t\t\t\t# 简单获取\nhmset key  f1 v1 f2 v2 ...  # 批量添加\nhexists key1  field \t\t\t\t# 检查 field 是否存在\nhkeys  key                  # 列出该 hash 集合的所有 field\nhvals  key\t\t\t\t\t\t\t\t\t# 列出该 hash 集合的所有 value\nhincrby key field n \t\t\t\t# 为哈希表 key 中的域 field 值+n\nhsetnx key field value      # 不存在 field - value时，添加值\n\n数据结构\nziplist || hashtable\n哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节并且保存的键值对数量小于 512 个，使用ziplist 编码；否则使用hashtable；\n\nZset\nRedis有序集合zset与普通集合set非常相似，都没有重复元素\nZset 每个成员都关联了一个评分（score），这个评分（score）被用来按照从低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但评分可以重复。\n可以根据评分（score）或次序（position）来获取一个范围的元素\n访问有序集合的中间元素也是非常快的，因此能够使用有序集合作为一个没有重复成员的只能列表\n\n常用命令zadd key score1 value1 score2 value2 ...  # 将一个或多个元素添加到 key 中\nzrange key fromIndex toIndex [withscores] # 返回下标在之间的元素，带WITHSCORES，可以让分数和值一起返回\nzrangebyscore key min max [withscores] [limit offset count] # 返回有序集合 key 中，所有 min &lt;= score &lt;= max 的成员，返回结果按score从小到大排序\nzscore set value # 获取set中value的分值\nzrevrangebyscore key max min [withscores] [limit offset count] # 同上，改为从大到小排列\nzincrby key n value   # key 中的 value 加上增量 n\nzrem key value \t\t\t\t# 删除指定元素\nzcount key min max    # 统计该集合，分数区间内的元素个数\nzrank key value\t\t\t\t# 返回该集合在集合中的排名，从0开始\n\n数据结构\n有序集合的编码可以是ziplist或者skiplist。\n\n当有序集合保存的元素个数小于128个，且所有元素成员长度都小于64字节时，使用ziplist编码，否则，使用skiplist编码。\n\n\n\n\n数据结构汇总\n\nString\nint：只有整数时\n（SDS之一）raw：字符串长度大于32个字节\n（SDS之二）embstr：字符串长度小于等于32个字节\n\n\nList\n（3.2之前）ziplist\n（3.2之前）linkedlist：双向链表\n（3.2之后）quicklist：取代上面两者，quicklist就是把一个个的ziplist串成双向链表的形式\n\n\nHash\nziplist：key和value字符串长度都小于 64 字节并且保存的键值对数量小于 512 \nhashtable：上面的反例\n\n\nSet\nintset：元素都是整数，并且个数不超过512个\nhashtable：上面的反例\n\n\nZSet\nziplist：元素个数小于128个，且所有元素成员长度都小于64字节\nskiplist+ht：上面的反例\n\n\n\n注：（7.0之后）redis7把ziplist替换为了listpack\n\nredis7把ziplist替换为了listpack\n\n\n原始ziplist结构图：\n\nquicklist结构图：\n\n单独看这个图会感觉比较眼熟，这里再放下ziplist的结构图示：\n\n会发现整体上看，listpack少了一些。其实相比较ziplist，listpack中的优化在于entry中。\n不同于ziplist，listpackEntry中的len记录的是当前entry的长度，而非上一个entry的长度。listpackEntry中可存储的为字符串或整型。\n\n当存储的为字符串，那么lsentry的sval不为空，slen记录大小。\n当存储的为整形，那么lval记录整型，sval字段为空\n\nBitmaps合理使用操作位能有效地提高内存使用率和开发效率\n\nBitmaps 本身不是一种数据类型，实际上它就是字符串（key-value），但是它可以对字符串的位进行操作。\nBitmaps 单独提供了一套命令，所以在Redis中使用 Bitmaps 和使用字符串的方法不太相同。可以把 Bitmaps 想象成一个以位为单温的数组，数组的每个单元只能存储0和1，数组的下标在Bitmaps中叫做偏移量。\n\n\n\n常用命令setbit key offset value \t\t# 设置/清除Bitmaps中某个偏移量的值 0/1 from index 0\ngetbit key offset \t\t\t\t\t# 获取 Bitmaps 中某个偏移量的值\nbitcount key [start end]\t\t# 返回1的个数，区间单位是【字节】-> []，可以使用负数\nbitop and/or/not/xor destkey [key...]   # 交、并、非、异或运算，结果->destkey\nbitpos key bit [start [end [BYTE | BIT]]] # 查找指定范围内第一个0或1出现的位置\nbitfield key \n  &lt;GET encoding offset | [OVERFLOW &lt;WRAP | SAT | FAIL>]\n  &lt;SET encoding offset value | INCRBY encoding offset increment>\n  [GET encoding offset | [OVERFLOW &lt;WRAP | SAT | FAIL>]\n  &lt;SET encoding offset value | INCRBY encoding offset increment>\n  ...]>                               # 操作（查、改、自增）bitmap数组中的指定位置的值\n\n\n\n\n\n\n\n\n\n\n\n统计连续签到天数\n\n直接遍历每一位\n\n得到本月到今天为止的所有签到数据\n\nbitfield key GET u[dayOfMonth] 0\n\n从后向前遍历得到每一个bit位\n\n&amp;1 &gt;&gt;1 &amp;1 &gt;&gt;1 …\nBitmaps与set对比\n\n\n\nHyperLogLogHyperloglog（HLL）是从Loglog算法派生的概率算法，用于确定非常大的集合的基数，而不需要存储其所有值。Redis中的HLL是基于string结构实现的，单个HLL的内存永远小于16kb，但有&lt;&#x3D;0.81%的误差\n常用命令pfadd key element1 element2 ...\t\t# 添加指定元素到 HyperLogLog 中；基数变化返回1\npfcount key1 key2 ...\t\t\t\t\t\t\t# 计算HLL的近似基数，多个key->HLL和\npfmerge\tdst src1 src2 ...\t\t\t\t\t# 将一个或多个HLL合并存储在另一个HLL中\n\n\n\n\n\nGeospatialRedis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。\n# 添加地理位置（经度，纬度，名称）\ngeoadd key longitude latitude member [longtitude latitude member ...]\n# 获取指定地区的坐标值\ngeopos key member [member ...]\n# 获取两个位置之间的直线距离，单位可选 m米（默认） km千米，mi英里，ft英尺\ngeodist key member1 member2 [m|km|ft|mi] \n# 以给定的经纬度为中心，找出某一半径内的元素\ngeoradius key longitude latitude radius m|km|ft|mi \n# 将指定member的坐标转为hash字符串形式并返回\ngeohash\n# 在指定范围内搜索member，并按照与指定点之间的距离排序后返回。范围可以使圆形或矩形 since6.2\nGEOSEARCH key &lt;FROMMEMBER member | FROMLONLAT longitude latitude> &lt;BYRADIUS radius &lt;M | KM | FT | MI> | BYBOX width height &lt;M | KM | FT | MI>> [ASC | DESC] [COUNT count [ANY]] [WITHCOORD] [WITHDIST] [WITHHASH]\n# 与上述基本一致，不过可以吧结果存储到一个指定的key since6.2\nGEOSEARCHSTORE destination source &lt;FROMMEMBER member | FROMLONLAT longitude latitude> &lt;BYRADIUS radius &lt;M | KM | FT | MI> | BYBOX width height &lt;M | KM | FT | MI>> [ASC | DESC] [COUNT count [ANY]] [STOREDIST]\n\n\nStreamXADD key [NOMKSTREAM] [&lt;MAXLEN | MINID> [= | ~] threshold [LIMIT count]] &lt;* | id> field value [field value ...]\nXREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...]\nXGROUP CREATE key groupName ID [MKSTREAM]\nXRANGE key start end [COUNT count]\nXACK key group ID [ID...]\n\nxadd q1 * name jack age 21\nxread count 100 block 0 streams q1 0\nxlen q1\nxrange  q1 - +  # 特殊符号，第一个-，最后一个+\nXRANGE somestream 1526985054069-0 + COUNT 1 # 获取>=某个指定id的第一个\nXRANGE q1 (1526985685298-0 + COUNT 2\nxreadgroup group g1 c1 streams q1 >  # 获取未ack\nxack q1 g1 0\nxpending q1 g1 - + 10  # 获取10条g1组中q1stream的未确认消息\n\n\n\n\n\n\n\n\n\n\n\n\n注：\n\n阻塞时间设置0表示无限等待\n使用$符号作为起始id表示读取命令执行时间点之后加入流的数据\n\n\n\nRedis 基础操作Redis 键（Key）keys *    \t# 查看当前库所有key  keys *num 顺序选取\nset key value   # 设置键值\nexists key  # 判断某个 key 是否存在\ntype key  \t#\t判断某个 key 的类型\ndel key \t\t# 【直接删除】\nunlink key \t# 【异步删除】只是先删除链接，之后再异步删除\nexpire key 10 # 设置 key 的过期时间，单位s\nttl key  \t\t# 查看过期时间\nselect \t\t\t# 切换数据库\ndbsize\t\t\t# 查看当前数据库的 key 数量\nflushdb \t\t# 清空当前库\nflushall\t\t# 通杀全部库\n\n发布和订阅\n\n\n\nsubscribe channel1 channel2 ...  #订阅一个或多个通道\npublish channel1 message # 向通道发布消息\npsubscribe pattern # 订阅匹配的所有通道\n\n\n\n\n\n\n\n\n\n\n注意：\n\n不支持数据持久化\n复发避免消息丢失\n消息堆积有上限，超出数据丢失\n\n两种Java整合操作Jedisimport org.junit.Test;\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.resps.Tuple;\n\nimport java.util.List;\nimport java.util.Set;\n\npublic class Test1 &#123;\n    Jedis jedis = new Jedis(\"123.60.108.20\", 6379);\n\n    &#123;\n        jedis.auth(\"1243\");\n        jedis.flushAll();\n    &#125;\n\n    @Test\n    public void test0() &#123;\n        // 连接测试\n        String ping = jedis.ping();\n        System.out.println(ping);\n    &#125;\n\n    @Test\n    public void test1() &#123;\n        Set&lt;String> keys = jedis.keys(\"*\");\n        for (String key : keys) &#123;\n            System.out.println(key);\n            System.out.println(jedis.type(key));\n        &#125;\n    &#125;\n\n    @Test\n    public void test2() &#123;\n        // List\n        jedis.lpush(\"key1\", \"1\", \"2\", \"3\", \"5\", \"6\");\n        List&lt;String> key1 = jedis.lrange(\"key1\", 0, -1);\n        for (String s : key1) &#123;\n            System.out.println(s);\n        &#125;\n    &#125;\n\n\n    @Test\n    public void test3() &#123;\n        // Set\n        jedis.sadd(\"set1\", \"1,2\", \"3\", \"4\");\n        System.out.println(jedis.smembers(\"set1\"));\n    &#125;\n\n    @Test\n    public void test4() &#123;\n        // Hash\n        jedis.hset(\"h1\", \"name\", \"June\");\n        jedis.hset(\"h1\", \"age\", \"15\");\n\n        Set&lt;String> h1 = jedis.hkeys(\"h1\");\n        for (String s : h1) &#123;\n            System.out.println(jedis.hget(\"h1\", s));\n        &#125;\n    &#125;\n\n\n    @Test\n    public void test5() &#123;\n        // zset\n        jedis.zadd(\"countries\", 100d, \"china\");\n        jedis.zadd(\"countries\", 1000d, \"us\");\n        jedis.zadd(\"countries\", 666d, \"uk\");\n\n        List&lt;Tuple> countries = jedis.zrangeByScoreWithScores(\"countries\", 0, 9999);\n        for (Tuple country : countries) &#123;\n            System.out.println(country);\n        &#125;\n    &#125;\n&#125;\n\n简单案例：验证码\n输入手机号，点击发送后随机生成6位数字码，2分钟有效。\n输入验证码，点击验证，返回或失败。\n每个手机号每天只能输入3次。\n\nimport redis.clients.jedis.Jedis;\n\nimport java.util.Random;\n\npublic class VerificationCode &#123;\n    public static void main(String[] args) &#123;\n        new VerificationCode().verifyCode(\"45678\", getNewCode());\n    &#125;\n\n    public void verifyCode(String phone, String code) &#123;\n        Jedis jedis = new Jedis(\"123.60.108.20\", 6379);\n        jedis.auth(\"1243\");\n\n        String countKey = \"VerificationCode\" + phone + \":count\";\n        String codeKey = \"VerificationCode\" + phone + \":code\";\n\n        String count = jedis.get(countKey);\n        if (count != null &amp;&amp; Integer.parseInt(count) >= 3) &#123;\n            System.out.println(\"超过3次\");\n        &#125; else &#123;\n            jedis.incr(countKey);\n            jedis.expire(countKey, 24 * 60 * 60); // 一天只能发三次\n            jedis.setex(codeKey, 2 * 60, code); // 验证码过期时间2min\n        &#125;\n\n        jedis.close();\n    &#125;\n\n    public static String getNewCode() &#123;\n        Random random = new Random();\n        StringBuilder s = new StringBuilder();\n        for (int i = 0; i &lt; 6; i++) &#123;\n            int i1 = random.nextInt(10);\n            s.append(i1);\n        &#125;\n        return s.toString();\n    &#125;\n&#125;\n\n\n\nletuuce（SpringDataRedis默认）\npom.xml 依赖\n\n&lt;!-- redis -->\n&lt;dependency>\n  &lt;groupId>org.springframework.boot&lt;/groupId>\n  &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId>\n&lt;/dependency>\n&lt;!-- spring2.X集成redis所需common-pool2-->\n&lt;dependency>\n  &lt;groupId>org.apache.commons&lt;/groupId>\n  &lt;artifactId>commons-pool2&lt;/artifactId>\n  &lt;version>2.6.0&lt;/version>\n&lt;/dependency>\n&lt;dependency>\n  &lt;groupId>com.fasterxml.jackson.core&lt;/groupId>\n  &lt;artifactId>jackson-core&lt;/artifactId>\n  &lt;version>2.12.1&lt;/version>\n&lt;/dependency>\n&lt;dependency>\n  &lt;groupId>com.fasterxml.jackson.core&lt;/groupId>\n  &lt;artifactId>jackson-annotations&lt;/artifactId>\n  &lt;version>2.11.4&lt;/version>\n&lt;/dependency>\n&lt;dependency>\n  &lt;groupId>com.fasterxml.jackson.core&lt;/groupId>\n  &lt;artifactId>jackson-databind&lt;/artifactId>\n  &lt;version>2.11.4&lt;/version>\n&lt;/dependency>\n\n\napplication.properties 配置\n\n#Redis服务器地址\nspring.redis.host=123.60.108.20\n#Redis服务器连接端口\nspring.redis.port=6379\n#Redis数据库索引（默认为0）\nspring.redis.database= 0\n#连接超时时间（毫秒）\nspring.redis.timeout=1800000\n#连接池最大连接数（使用负值表示没有限制）\nspring.redis.lettuce.pool.max-active=20\n#最大阻塞等待时间(负数表示没限制)\nspring.redis.lettuce.pool.max-wait=-1\n#连接池中的最大空闲连接\nspring.redis.lettuce.pool.max-idle=5\n#连接池中的最小空闲连接\nspring.redis.lettuce.pool.min-idle=0\n\n\nRedis 配置类\n\n@EnableCaching\n@Configuration\npublic class RedisConfig extends CachingConfigurerSupport &#123;\n\n    @Bean\n    public RedisTemplate&lt;String, Object> redisTemplate(RedisConnectionFactory factory) &#123;\n        RedisTemplate&lt;String, Object> template = new RedisTemplate&lt;>();\n        RedisSerializer&lt;String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        template.setConnectionFactory(factory);\n//key序列化方式\n        template.setKeySerializer(redisSerializer);\n//value序列化\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n//value hashmap序列化\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        return template;\n    &#125;\n\n    @Bean\n    public CacheManager cacheManager(RedisConnectionFactory factory) &#123;\n        RedisSerializer&lt;String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n//解决查询缓存转换异常的问题\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n// 配置序列化（解决乱码的问题）,过期时间600秒\n        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()\n                .entryTtl(Duration.ofSeconds(600))\n                .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))\n                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))\n                .disableCachingNullValues();\n        RedisCacheManager cacheManager = RedisCacheManager.builder(factory)\n                .cacheDefaults(config)\n                .build();\n        return cacheManager;\n    &#125;\n&#125;\n\n\n测试\n\n@RestController\n@RequestMapping(\"/redisTest\")\npublic class RedisTestController &#123;\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    @GetMapping\n    public String testRedis() &#123;\n        //设置值到redis\n        redisTemplate.opsForValue().set(\"name\",\"lucy\");\n        //从redis获取值\n        String name = (String)redisTemplate.opsForValue().get(\"name\");\n        return name;\n    &#125;\n&#125;\n\n\n\n\n\n\n\nRedis 事务Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\nRedis 事务的主要作用就是串联多个命令防止别的命令插队。\nMulti、Exec、discard从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。组队的过程中可以通过discard来放弃组队。  \n\n\n\n\n\n\n事务错误处理\n\n事务冲突\n\n悲观锁悲观锁（Pessimistic Lock）, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。\n乐观锁乐观锁（Optimistic Lock），顾名思义，乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多度的应用类型，这样可以提高吞吐量。Redis就是利用这种 check-and-set 机制实现事务的。\nRedis 加锁机制WATCH key [ key ... ]\n在执行 multi 之前，先执行 watch key1 key2 … ，可以监视一个或多个 key，如果在事务执行之前这些 key 被其它命令所改动，那么事务将会被打断。\nunwatch\n取消监视。如果在执行了WATCH 命令之后，EXEC命令DISCARD命令先被执行了，那么就不需要UNWATCH了。\nRedis 事务三特性\n单独的隔离操作\n事务中的所有命令都会被序列化、按顺序执行。事务在执行过程中，不会被其他客户端发来的命令打断。\n\n\n没有隔离级别的概念\n队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行\n\n\n不保证原子性\n事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚\n\n\n\nRedis 秒杀实现并发测试工具yum install httpd-tools\n\n测试模板ab -n 2000 -c 200 -k -p ~/postfile -T application/x-www-form-urlencoded http://124.223.14.18:8080/Seckill/doseckill\n\nJava 代码public static boolean doSecKill(String uid, String prodid) throws IOException &#123;\n        // 判断非空\n        if (uid == null || prodid == null) &#123;\n            return false;\n        &#125;\n        // 连接 redis\n//        Jedis jedis = new Jedis(\"123.60.108.20\", 6379);\n        JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance();\n        Jedis jedis = jedisPool.getResource();\n\n        // 拼接 key\n        String kcKey = \"sk:\" + prodid + \":qt\";\n        String userKey = \"sk:\" + prodid + \":user\";\n        // 监视库存\n        jedis.watch(kcKey);\n\n        String kc = jedis.get(kcKey);\n        if(kc == null)&#123;\n            System.out.println(\"秒杀未开始\");\n            jedis.close();\n            return false;\n        &#125;\n        if(jedis.sismember(userKey,uid))&#123;\n            System.out.println(\"已经秒杀成功，不能重复秒杀\");\n            jedis.close();\n            return false;\n        &#125;\n        if (Integer.parseInt(kc)&lt;=0)&#123;\n            System.out.println(\"秒杀已经结束\");\n            jedis.close();\n            return false;\n        &#125;;\n        Transaction multi = jedis.multi();\n        // 组队：搭配watch\n        multi.decr(kcKey);        // 库存--\n        multi.sadd(userKey,uid);  // 成功用户添加至set\n        List&lt;Object> result = multi.exec();\n        // 获取执行结果\n        if (result == null|| result.size()==0)&#123;\n            System.out.println(\"秒杀失败..\");\n            jedis.close();\n            return false;\n        &#125;\n\n        jedis.close();\n        return true;\n    &#125;\n\npublic class JedisPoolUtil &#123;\n   private static volatile JedisPool jedisPool = null;\n\n   private JedisPoolUtil() &#123;\n   &#125;\n\n   public static JedisPool getJedisPoolInstance() &#123;\n      if (null == jedisPool) &#123;\n         synchronized (JedisPoolUtil.class) &#123;\n            if (null == jedisPool) &#123;\n               JedisPoolConfig poolConfig = new JedisPoolConfig();\n               poolConfig.setMaxTotal(200);\n               poolConfig.setMaxIdle(32);\n               poolConfig.setMaxWaitMillis(100*1000);\n               poolConfig.setBlockWhenExhausted(true);\n               poolConfig.setTestOnBorrow(true);  // ping  PONG\n             \n               jedisPool = new JedisPool(poolConfig, \"123.60.108.20\", 6379, 60000 );\n            &#125;\n         &#125;\n      &#125;\n      return jedisPool;\n   &#125;\n\n   public static void release(JedisPool jedisPool, Jedis jedis) &#123;\n      if (null != jedis) &#123;\n         jedisPool.returnResource(jedis);\n      &#125;\n   &#125;\n\n&#125;\n\n最终实现public class SecKill_redisByScript &#123;\n\n    private static final org.slf4j.Logger logger = LoggerFactory.getLogger(SecKill_redisByScript.class);\n\n    static String secKillScript = \"local userid=KEYS[1];\\r\\n\" +\n            \"local prodid=KEYS[2];\\r\\n\" +\n            \"local qtkey='sk:'..prodid..\\\":qt\\\";\\r\\n\" +\n            \"local usersKey='sk:'..prodid..\\\":usr\\\";\\r\\n\" +\n            \"local userExists=redis.call(\\\"sismember\\\",usersKey,userid);\\r\\n\" +\n            \"if tonumber(userExists)==1 then \\r\\n\" +\n            \"   return 2;\\r\\n\" +\n            \"end\\r\\n\" +\n            \"local num= redis.call(\\\"get\\\" ,qtkey);\\r\\n\" +\n            \"if tonumber(num)&lt;=0 then \\r\\n\" +\n            \"   return 0;\\r\\n\" +\n            \"else \\r\\n\" +\n            \"   redis.call(\\\"decr\\\",qtkey);\\r\\n\" +\n            \"   redis.call(\\\"sadd\\\",usersKey,userid);\\r\\n\" +\n            \"end\\r\\n\" +\n            \"return 1\";\n\n    static String secKillScript2 =\n            \"local userExists=redis.call(\\\"sismember\\\",\\\"&#123;sk&#125;:0101:usr\\\",userid);\\r\\n\" +\n                    \" return 1\";\n\n    public static boolean doSecKill(String uid, String prodid) throws IOException &#123;\n        JedisPool jedispool = JedisPoolUtil.getJedisPoolInstance();\n        Jedis jedis = jedispool.getResource();\n\n        String sha1 = jedis.scriptLoad(secKillScript);\n\n        Object result = jedis.evalsha(sha1, 2, uid, prodid);\n\n        String reString = String.valueOf(result);\n        if (\"0\".equals(reString)) &#123;\n            System.err.println(\"已抢空！！\");\n        &#125; else if (\"1\".equals(reString)) &#123;\n            System.out.println(\"抢购成功！！！！\");\n        &#125; else if (\"2\".equals(reString)) &#123;\n            System.err.println(\"该用户已抢过！！\");\n        &#125; else &#123;\n            System.err.println(\"抢购异常！！\");\n        &#125;\n        jedis.close();\n        return true;\n    &#125;\n&#125;\n\n\n\nRedis 持久化Redis 提供了2个不同形式的持久化方式。\n\nRDB（Redis DataBase）\nAOF（Append Of File）\n\nRDB（Redis Database Backup file）[Redis主从复制原理总结 - 老虎死了还有狼 - 博客园 (cnblogs.com)](https://www.cnblogs.com/daofaziran/p/10978628.html#:~:text=Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。,增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。)\n\nRedis使用fork函数复制一份当前进程（父进程）的副本（子进程）；\n\n父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；\n\n当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。\n\n在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令 ），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。\n  Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实 现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。\n  除了自动快照，还可以手动发送SAVE或BGSAVE命令让Redis执行快照，两个命令的区别在于，前者是由主进程进行快照操作，会阻塞住其他请求，后者会通过fork子进程进行快照操作。 Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录一千万个字符串类型键、大小为1GB的快照文件载入到内 存中需要花费20～30秒钟。 通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。\n\n\n配置以下三项即可开启 RDB\n\n\n\n\n\nsave ：默认如下配置\n\nsave 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存\nsave 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存\nsave 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存\n\n可以通过lastsave命令获取最后一次成功执行快照的时间\n执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义\n\nstop-writes-on-bgsave-error：默认yes，当启用了 RDB 且最后一次后台保存数据失败，Redis 是否停止接收数据。\nrdbcompression：默认yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果yes，redis 会采用LZF算法进行压缩。会产生10%的性能损耗。\n\n触发方式\nsave&#x2F;bgsave 命令主动触发\n配置 save 由redis自动触发\n其他触发方式\n主从复制时，自动生成 RDB 文件\nRedis中的 debug reload 提供debug级别的重启（不清空内存），此时自动生成 RDB 文件\nshutdown 自动生成 RDB文件\n\n\n\n\n\n动态停止 RDB：config set save &quot; &quot;\n\n优势&amp;劣势\n适合大规模数据恢复\n对数据完整性和一致性要求不高更适合使用\n节省磁盘空间\n恢复速度块\n\n\n\nFork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑\n虽然Redis在fork时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能。\n在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。\n\n\n\n\n\nAOF以日志的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来（读操作不记录）， 只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作\n持久化流程\n客户端请求写命令会被append到AOF缓冲区中；\nAOF缓冲区根据AOF持久化策略[ always, everysec, no ]将 sync 同步到磁盘的AOF文件中；\nAOF文件大小超过重写策略或手动重写时，会对AOF文件 rewrite 重写，压缩 AOF文件容量；\nRedis 服务重启时，会重新 load 加载 AOF 文件中的写操作来恢复数据\n\n\n\nAOF 默认关闭，可以在redis.conf中配置文件名称，默认为 appendonly.aof。AOF文件的保存路径，同RDB的路径一致。\nAOF 启动&#x2F;修复&#x2F;恢复\nAOF的备份机制和性能虽然和RDB不同，但是备份和恢复的操作同RDB一样，都是拷贝文件，需要恢复时再拷贝到 Redis 工作目录下，启动系统即加载。\n正常启动&#x2F;恢复\n修改默认的  appendonly no 改为 yes\n将有数据的 aof 文件复制一份保存到对应目录（ config get dir）\n恢复：重启 redis 然后重新加载\n\n\n异常恢复\n修改默认的 appendonly no -&gt; yes\n如遇到 AOF 文件损坏，通过 /usr/local/bin/redis-check-aof --fix appendonly.aof 进行恢复\n备份被写坏的 AOF 文件\n恢复：重启 redis，然后重新加载\n\n\n\nAOF 同步频率appendfsync always：始终同步，每次 Redis 的写入都会立刻计入日志；性能较差但数据完整性较好\nappendfsync everysec：每秒同步，存在数据丢失风险\nappendfsync no：redis 不主动进行同步，把同步时机交给操作系统\nRewrite 重写AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制, 当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集。可以使用命令bgrewriteaof主动重写\nAOF文件持续增长而过大时，会 fork 出一条新进程来将文件重写(也是先写临时文件最后再rename)，redis4.0版本后的重写，就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。\nno-appendfsync-on-rewrite：如果 yes，那么 aof 文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）；如果 no，还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低）\nredis中AOF的no-appendfsync-on-rewrite参数详解 - Arbitrary233 - 博客园 (cnblogs.com)\n\n\n\n\n\n\n\n\n\n何时重写？\nRedis 会记录上次重写时的 AOF 大小，默认大小是上次 rewrite 后大小的一倍且文件大于 64M 时触发\n重写虽然可以节省大量磁盘空间，减少恢复时间。但是每次重写还是有一定负担的，因此可以设定 Redis 要满足一定条件才会进行重写。\nauto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）\nauto-aof-rewrite-min-size：设置重写的基准值，最小64M，达到这个值开始重写。\n例如：文件达到70M开始重写，下降到50M，下次则会在100MB时进行重写。\n系统载入时或者上次重写完毕时，Redis会记录此时AOF大小，设为 base_size，如果Redis的AOF当前大小 &gt;&#x3D; base_size + base_size * 100%（默认）且当前大小 &gt;&#x3D; 64MB（默认）情况下，Redis会对 AOF 进行重写\n\n\n\n\n\n\n\n\n\n重写流程\n\nbgrewriteaof触发重写，判断当前是否有 bgsave 或 bgrewriteaof  在运行，如果有，则等待该命令结束后再继续执行。\n主进程 fork 出子进程执行重写操作，保证主进程不会阻塞。\n子进程遍历 redis 内存中数据到临时文件，客户端的写请求同时写入 aof_buf 缓冲区和 aof_rewrite_buf 重写缓冲区保证原 AOF 文件完整以及新 AOF 文件生成期间的新的数据修改动作不会丢失。\n子进程写完新的 AOF 文件后，向主进程发信号，父进程更新统计信息。主进程把 aof_rewrite_buf 中的数据写入到新的 AOF 文件。\n使用新的 AOF 文件覆盖旧的 AOF 文件，完成AOF重写。\n\n\n\n优势\n备份机制更稳健，丢失数据概率低。\n可读的日志文本，通过操作 AOF 文件，可以处理误操作。\n\n劣势\n比起 RDB 占用更多的磁盘空间\n恢复备份速度慢\n每次读写都同步的话，有一定的性能压力\n存在个别 Bug，造成不能恢复问题\n\n\n\n使用建议\n官方推荐两个都启用；\n如果对数据不敏感，可以选单独用RDB；\n不建议单独用 AOF，因为可能会出现Bug；\n如果只是做纯内存缓存，可以都不用\n\n性能建议因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果使用AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价，一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。\nRedis 主从复制读（Slave）写（Master）分离、性能扩展、容灾恢复\n复制原理[Redis主从复制原理总结 - 老虎死了还有狼 - 博客园 (cnblogs.com)](https://www.cnblogs.com/daofaziran/p/10978628.html#:~:text=Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。,增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。)\n常用三招一主二仆############## 一主二从 #################\n# 1. 配置统一 redis.conf\ndaemonize yes\nappendonly no\n# 2. 配置单个redis 配置文件\nmkdir /redisconfs\ncp /opt/redis-6.2.6/redis.conf /redisconfs/\n\nvim /redisconfs/redis6379.conf\ni\ninclude /redisconfs/redis.conf\npidfile /var/run/redis_6379.pid\nport 6379\ndbfilename dump6379.rdb\n\nvim /redisconfs/redis6380.conf\ni\ninclude /redisconfs/redis.conf\npidfile /var/run/redis_6380.pid\nport 6380\ndbfilename dump6380.rdb\n\nvim /redisconfs/redis6381.conf\ni\ninclude /redisconfs/redis.conf\npidfile /var/run/redis_6381.pid\nport 6381\ndbfilename dump6381.rdb\n\n# 3. 启动三台服务器\nredis-server /redisconfs/redis6379.conf\nredis-server /redisconfs/redis6380.conf\nredis-server /redisconfs/redis6381.conf\n\n# 4. 查看启动情况\nps -ef | grep redis\n\n# 5. 进入redis查看主从\nredis-cli -p 6379\ninfo replication\n\n# 6. 设置从机\nredis-cli -p 6380\nslaveof 127.0.0.1 6379\n\nredis-cli -p 6381\nslaveof 127.0.0.1 6379\n\n注意：\n\n主服务器挂掉后，从机不会上位，等待主机的重连\n从机挂掉后，再次重连需要重新指定 master\n\n薪火相传上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力,去中心化降低风险。\n反客为主当一个 master 宕机后，后面的 slave 可以立刻提升为 master，其后面的 slave 不用做任何修改 \nslaveof no one 从 -&gt; 主\n哨兵模式Redis Sentinel是一个分布式系统，Sentinel运行在有许多Sentinel进程互相合作的环境下，它本身就是这样被设计的。有许多Sentinel进程互相合作的优点如下：\n\n当多个Sentinel同意一个master不再可用的时候，就执行故障检测。这明显降低了错误概率。\n即使并非全部的Sentinel都在工作，Sentinel也可以正常工作，这种特性，让系统非常的健康\n\nvi /redisconfs/sentinel.conf\nsentinel monitor mymaster 127.0.0.1 6379 1\nredis-sentinel /redisconfs/sentinel.conf\n\n复制延迟由于所有的写操作都是现在 Master 上操作，所以从 Master 同步到 Slave 及其有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave 机器数量的增加也会使这个问题更加严重。\n故障恢复\n\n优先级在redis.conf中默认：slave-priority 100（新版本中叫 replica-priority），值越小优先级越高\n偏移量是指获得原主机数据最全的\n每个redis实例启动后都会随机生成一个40位的runid\nJava 实现private static JedisSentinelPool jedisSentinelPool=null;\n\npublic static  Jedis getJedisFromSentinel()&#123;\nif(jedisSentinelPool==null)&#123;\n            Set&lt;String> sentinelSet=new HashSet&lt;>();\n            sentinelSet.add(\"192.168.11.103:26379\");\n\n            JedisPoolConfig jedisPoolConfig =new JedisPoolConfig();\n            jedisPoolConfig.setMaxTotal(10); //最大可用连接数\njedisPoolConfig.setMaxIdle(5); //最大闲置连接数\njedisPoolConfig.setMinIdle(5); //最小闲置连接数\njedisPoolConfig.setBlockWhenExhausted(true); //连接耗尽是否等待\njedisPoolConfig.setMaxWaitMillis(2000); //等待时间\njedisPoolConfig.setTestOnBorrow(true); //取连接的时候进行一下测试 ping pong\n\njedisSentinelPool=new JedisSentinelPool(\"mymaster\",sentinelSet,jedisPoolConfig);\nreturn jedisSentinelPool.getResource();\n        &#125;else&#123;\nreturn jedisSentinelPool.getResource();\n        &#125;\n&#125;\n\n\n\n\n\nRedis 集群Redis 集群实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。\n\nRedis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。\n\n简单搭建Demo# 1. 删除之前的数据文件 rdb\nrm -rf  /redisconfs/ dump63*\n# 2.设置6个节点的配置文件，仅仅是端口号不同\n\ninclude /redisconfs/redis.conf\npidfile \"/var/run/redis_6379.pid\"\nport 6379\ndbfilename \"dump6379.rdb\"\ncluster-enabled yes\ncluster-config-file nodes-6379.conf\ncluster-node-timeout 15000\n# :%s/6379/63..  vim中可以替换\n\n# 3.依次启动6个服务器\nredis-server /redisconfs/redis6379.conf\nredis-server /redisconfs/redis6380.conf\nredis-server /redisconfs/redis6381.conf\nredis-server /redisconfs/redis6382.conf\nredis-server /redisconfs/redis6383.conf\nredis-server /redisconfs/redis6384.conf\n\n# 4.合成集群，注意ip和端口\nredis-cli --cluster create --cluster-replicas 1 124.223.14.18:6379 124.223.14.18:6380 124.223.14.18:6381 124.223.14.18:6382 124.223.14.18:6383 124.223.14.18:6384\n\n# 5.登录查看，任意一个都可以登录到集群\nredis-cli -c -p 6379\n\n\n\n集群命令# 多值set必须使用以下形式 &#123;&#125; 组\nmset k1&#123;user&#125; v1 k2&#123;user1&#125; v2\n# 返回 count 个slot槽中的值\ncluster getkeysinslot slot count\n\n\n\n注意事项\n尽量保证每个主数据库运行在不同的IP地址，每个从库和主库不在一个IP地址上\n主节点下线，从节点会替补上去，而主节点再次上线会变成从节点。\n集群的主从节点都挂掉，是否继续服务？ cluster-require-full-coverage yes-&gt;挂掉   no-&gt;继续服务\n\nJava集群Jedispublic class JedisClusterTest &#123;\n  public static void main(String[] args) &#123; \n     Set&lt;HostAndPort>set =new HashSet&lt;HostAndPort>();\n     set.add(new HostAndPort(\"192.168.31.211\",6379));\n     JedisCluster jedisCluster=new JedisCluster(set);\n     jedisCluster.set(\"k1\", \"v1\");\n     System.out.println(jedisCluster.get(\"k1\"));\n  &#125;\n&#125;\n\n\n\n集群利弊利\n\n实现扩容\n分摊压力\n无中心配置相对简单\n\n弊\n\n多键操作不支持\n多键的Redis事务是不被支持的。lua脚本不被支持\n由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。\n\nRedis 应用问题缓存穿透问题描述\n解决方案\n对空值缓存：如果一个查询返回的数据为空（不管数据是否存在），都对其进行缓存，设置空结果过期时间很短，最长不超过5分钟\n采用布隆过滤器：它是一个很长的二进制向量和一些列随机映射函数（哈希函数），可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远超过一般的算法，缺点是有一定的误识率和删除困难。将所有可能存在的数据哈希到一个足够大的 bitmaps 中，一个一定不存在的数据会被这个 bitmaps 拦截点，从而避免了对底层存储系统的查询压力。布隆过滤器有假阳性的问题。\n\n缓存雪崩问题描述\n解决方案\n\n逻辑过期\n\n使用锁\n\n\n\n缓存失效时（判断拿出来的值为空），不是立刻去 load db\n先使用缓存工具的某些带成功操作返回值的操作（比如 Redis 的 SETNX）去 set 一个 mutex key\n当操作返回成功时，再进行 load db操作，并回设缓存，最后删除 mutex key\n当操作返回失败，证明有线程在 load db，当前线程睡眠一段时间后再重试整个 get 缓存的方法\n\n\n缓存雪崩问题描述\n解决方案\n构建多级缓存架构：nginx 缓存 + redis 缓存 + 其他缓存（ehcache 等）\n使用锁或者队列：用加锁或队列的方式保证不会有大量得线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况\n设置过期标志更新缓存：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际 key 的缓存\n设置随机过期时间：比如我们可以在原有的失效时间基础上增加一个随机值，比如 1-5分钟随机，这样每一个缓存的过期时间重复概率就会变低，很难引发集体缓存失效事件。\n\n分布式锁问题描述随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！\n\n分布式锁的主流解决方案：\n\n基于数据库实现分布式锁；\n基于缓存（Redis等）；\n基于 Zookeeper\n\n每一种分布式锁解决方案都有各自的优缺点：\n\n性能：redis最高\n可靠性：zookeeper 最高\n\n解决方案：Redis 实现分布式锁\n\nset key value nx ex n\n\n\n\n@GetMapping(\"testLockLua\")\npublic void testLockLua() &#123;\n    //1 声明一个uuid ,将做为一个value 放入我们的key所对应的值中\n    String uuid = UUID.randomUUID().toString();\n    //2 定义一个锁：lua 脚本可以使用同一把锁，来实现删除！\n    String skuId = \"25\"; // 访问skuId 为25号的商品 100008348542\n    String locKey = \"lock:\" + skuId; // 锁住的是每个商品的数据\n\n    // 3 获取锁\n    Boolean lock = redisTemplate.opsForValue().setIfAbsent(locKey, uuid, 3, TimeUnit.SECONDS);\n\n    // 第一种： lock 与过期时间中间不写任何的代码。\n    // redisTemplate.expire(\"lock\",10, TimeUnit.SECONDS);//设置过期时间\n    // 如果true\n    if (lock) &#123;\n        // 执行的业务逻辑开始\n        // 获取缓存中的num 数据\n        Object value = redisTemplate.opsForValue().get(\"num\");\n        // 如果是空直接返回\n        if (StringUtils.isEmpty(value)) &#123;\n            return;\n        &#125;\n        // 不是空 如果说在这出现了异常！ 那么delete 就删除失败！ 也就是说锁永远存在！\n        int num = Integer.parseInt(value + \"\");\n        // 使num 每次+1 放入缓存\n        redisTemplate.opsForValue().set(\"num\", String.valueOf(++num));\n        /*使用lua脚本来锁*/\n        // 定义lua 脚本\n        String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";\n        // 使用redis执行lua执行\n        DefaultRedisScript&lt;Long> redisScript = new DefaultRedisScript&lt;>();\n        redisScript.setScriptText(script);\n        // 设置一下返回值类型 为Long\n        // 因为删除判断的时候，返回的0,给其封装为数据类型。如果不封装那么默认返回String 类型，\n        // 那么返回字符串与0 会有发生错误。\n        redisScript.setResultType(Long.class);\n        // 第一个要是script 脚本 ，第二个需要判断的key，第三个就是key所对应的值。\n        redisTemplate.execute(redisScript, Arrays.asList(locKey), uuid);\n    &#125; else &#123;\n        // 其他线程等待\n        try &#123;\n            // 睡眠\n            Thread.sleep(1000);\n            // 睡醒了之后，调用方法。\n            testLockLua();\n        &#125; catch (InterruptedException e) &#123;\n            e.printStackTrace();\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\nRedis6 新功能ACLRedis ACL是Access Control List（访问控制列表）的缩写，该功能允许根据可以执行的命令和可以访问的键来限制某些连接。\n在Redis 5版本之前，Redis 安全规则只有密码控制 还有通过rename 来调整高危命令比如 flushdb ， keys *， shutdown 等。Redis 6 则提供ACL的功能对用户进行更细粒度的权限控制 ：\n（1）接入权限:用户名和密码 \n（2）可以执行的命令 \n（3）可以操作的 KEY\n参考官网：https://redis.io/topics/acl\n命令acl list\t\t\t\t# 显示用户权限列表\n\n\n\nacl cat \t\t\t\t# 查看添加权限指令类别，加参数类型名可以查看具体命令\nacl whoami\t\t\t# 查看当前用户\naclsetuser\t\t\t# 创建和编辑用户ACL\n\n\n\nacl setuser username\t\t# 创建新用户\n\n\n\nauth username password # 切换用户\n\n\n\nIO 多线程IO多线程其实指客户端交互部分的网络IO交互处理模块多线程，而非执行命令多线程。Redis6执行命令依然是单线程。\n\n\n# 多线程IO默认关闭，开启：\nio-threads-do-reads yes\nio-threads 4\n\n\n\n\n\nRedis Lua\n查询比较删除\nJavaAPItemplate.execute(\"script\",keyList,argsList)\n","slug":"Redis基础","date":"2022-09-30T09:26:18.000Z","categories_index":"","tags_index":"学习笔记,Redis","author_index":"JuneQQQ"},{"id":"0078db1e0e91966be57f6a3288ece9dc","title":"浅析HTTP发展历程","content":"浅析HTTP发展历程HTTP0.9 - 诞生最初版本的 HTTP 协议并没有版本号，后来它的版本号被定位在 0.9 以区分后来的版本。 HTTP&#x2F;0.9 极其简单：请求由单行指令构成，以唯一可用方法GET开头，其后跟目标资源的路径（一旦连接到服务器，协议、服务器、端口号这些都不是必须的）。\nGET /mypage.html\n\n响应也极其简单的：只包含响应文档本身。\n&lt;HTML&gt;\n这是一个非常简单的 HTML 页面\n&lt;&#x2F;HTML&gt;\n\n跟后来的版本不同，HTTP&#x2F;0.9 的响应内容并不包含 HTTP 头，这意味着只有 HTML 文件可以传送，无法传输其他类型的文件；也没有状态码或错误代码：一旦出现问题，一个特殊的包含问题描述信息的 HTML 文件将被发回，供人们查看。\nHTTP1.0 - 构建可扩展性一个典型的请求看起来就像这样：\nGET /mypage.html HTTP/1.0\nUser-Agent: NCSA_Mosaic/2.0 (Windows 3.1)\n\n200 OK\nDate: Tue, 15 Nov 1994 08:12:31 GMT\nServer: CERN/3.0 libwww/2.17\nContent-Type: text/html\n&lt;HTML>\n一个包含图片的页面\n  &lt;IMG SRC=\"/myimage.gif\">\n&lt;/HTML>\n\n接下来是第二个连接，请求获取图片：\nGET /myimage.gif HTTP/1.0\nUser-Agent: NCSA_Mosaic/2.0 (Windows 3.1)\n\n200 OK\nDate: Tue, 15 Nov 1994 08:12:32 GMT\nServer: CERN/3.0 libwww/2.17\nContent-Type: text/gif\n(这里是图片内容)\n\nHTTP1.1 - 标准化的协议\n持久连接：HTTP&#x2F;1.1 最大的变化就是引入了持久连接（persistent connection），在HTTP&#x2F;1.1中默认开启 Connection: keep-alive，即TCP连接默认不关闭，可以被多个请求复用，但是这里存在队头阻塞问题\n缓存处理：HTTP&#x2F;1.0 使用 Pragma:no-cache + Last-Modified&#x2F;If-Modified-Since来作为缓存判断的标准；HTTP&#x2F;1.1 引入了更多的缓存控制策略：Cache-Control、Etag&#x2F;If-None-Match等\n范围请求：HTTP&#x2F;1.1在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接，支持断点续传\n错误状态管理：HTTP&#x2F;1.1新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。\n\n\n\n\n\n\n\n\n\n\nHTTP&#x2F;1.1 的持久连接和管道机制允许复用TCP连接，在一个TCP连接中，也可以同时发送多个请求，但是所有的数据通信都是按次序完成的，服务器只有处理完一个回应，才会处理下一个回应。比如客户端需要A、B两个资源，管道机制允许浏览器同时发出A请求和B请求，但服务器还是按照顺序，先回应A请求，完成后再回应B请求，这样如果前面的回应特别慢，后面就会有很多请求排队等着，这称为”队头阻塞(Head-of-line blocking)”。这个问题到HTTP3才被完全解决。\nHTTP2.0 - 为了更优异的表现这些年来，网页愈渐变得的复杂，甚至演变成了独有的应用，可见媒体的播放量，增进交互的脚本大小也增加了许多：更多的数据通过 HTTP 请求被传输。HTTP&#x2F;1.1 链接需要请求以正确的顺序发送，理论上可以用一些并行的链接（尤其是 5 到 8 个），带来的成本和复杂性堪忧。比如，HTTP 管线化（pipelining）就成为了 Web 开发的负担。\n在 2010 年到 2015 年，谷歌通过实践了一个实验性的 SPDY 协议，证明了一个在客户端和服务器端交换数据的另类方式。其收集了浏览器和服务器端的开发者的焦点问题。明确了响应数量的增加和解决复杂的数据传输，SPDY 成为了 HTTP&#x2F;2 协议的基础。HTTP2的主要特点如下：\n\n二进制分帧：HTTP&#x2F;1.1的头信息是文本（ASCII编码），数据体可以是文本，也可以是二进制；HTTP&#x2F;2 头信息和数据体都是二进制，统称为“帧”：头信息帧和数据帧；\n\n\n\n\n多路复用：在http1.1中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源 CDN 域名的原因之一。\n而http2.0中的多路复用优化了这一性能。多路复用允许同时通过单一的http&#x2F;2 连接发起多重的请求-响应消息。有了新的分帧机制后，http&#x2F;2 不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级，最后再在另一端把它们重新组合起来。\nhttp 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接（每个域名一个连接）即可。http2连接可以承载数十或数百个流的复用，多路复用意味着来自很多流的数据包能够混合在一起通过同样连接传输。当到达终点时，再根据不同帧首部的流标识符重新连接将不同的数据流进行组装。\n\n\n头部压缩：HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。HTTP&#x2F;2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息压缩后再发送（SPDY 使用的是通用的DEFLATE 算法，而 HTTP&#x2F;2 则使用了专门为首部压缩而设计的 HPACK 算法）。；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n  例如：下图中的两个请求， 请求一发送了所有的头部字段，第二个请求则只需要发送差异数据，这样可以减少冗余数据，降低开销。\n\n\n\n\n服务端推送：HTTP&#x2F;2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。\n\n穿插一下HTTPSHTTPS可以说是安全版的HTTP，HTTPS基于安全SSL&#x2F;TLS（安全套接层Secure Sockets Layer&#x2F;安全传输层Transport Layer Security）层，即在传统的HTTP和TCP之间加了一层用于加密解密的SSL&#x2F;TLS层。HTTP默认使用80端口，HTTPS默认使用443端口。\n\n不使用SSL&#x2F;TLS的HTTP通信，所有信息明文传播，会带来三大风险；\n\n窃听风险：第三方可以获取通信内容；篡改风险：第三方可以修改通信内容；冒充风险：第三方可以冒充他人进行通信。SSL&#x2F;TLS协议是为了解决这三大风险而设计的，以期达到；\n\n信息加密传输：第三方无法窃听；校验机制：一旦被篡改，通信双方会立刻发现；身份证书：防止身份被冒充。\n\n\nHTTPS通信过程\n\nTCP的3次握手\nTLS连接\nHTTP请求和响应\n\n共计3RTT，速度略慢，所以HTTP3将对此进行优化\n以下三幅图不同程度描述了HTTPS通信过程：\n\n\n这里是TLS1.2，请注意\n\n\n\n\n\n\nHTTP3.0 - 为什么更快的速度Quick是什么？\n\n\n\n\n\n\n\n\n    QUIC（Quick UDP Internet Connection）是谷歌制定的一种基于UDP的低时延的互联网传输层协议。我们知道，TCP/IP协议族是互联网的基础。其中传输层协议包括TCP和UDP协议。与[TCP协议](https://baike.baidu.com/item/TCP协议/8988699?fromModule=lemma_inlink)相比，UDP更为轻量，但是错误校验也要少得多。这意味着UDP往往效率更高（不经常跟服务器端通信查看数据包是否送达或者按序），但是可靠性比不上TCP。通常游戏、流媒体以及VoIP等应用均采用UDP，而网页、邮件、远程登录等大部分的应用均采用TCP。\n    \n                                                     \t\t\t\t\t\t\t————————摘自百度百科\n\n\n\n从协议栈可以看出：QUIC &#x3D; HTTP&#x2F;2 + TLS + UDP\n数据包格式\n\n\n\n由 header 和 data 两部分组成。\nheader 是明文的，包含 4 个字段：Flags、Connection ID、QUIC Version、Packet Number；\ndata 是加密的，可以包含 1 个或多个 frame，每个 frame 又分为 type 和 payload，其中 payload 就是应用数据；\n数据帧有很多类型：Stream、ACK、Padding、Window_Update、Blocked 等，这里重点介绍下用于传输应用数据的 Stream 帧。\n\nFrame Type： 帧类型，占用 1 个字节\n\n（1）Bit7：必须设置为 1，表示 Stream 帧\n（2）Bit6：如果设置为 1，表示发送端在这个 stream 上已经结束发送数据，流将处于半关闭状态\n（3）Bit5：如果设置为 1，表示 Stream 头中包含 Data length 字段\n（4）Bit432：表示 offset 的长度。000 表示 0 字节，001 表示 2 字节，010 表示 3 字节，以此类推\n（5）Bit10：表示 Stream ID 的长度。00 表示 1 字节，01 表示 2 字节，10 表示 3 字节，11 表示 4 字节\nStream ID： 流 ID，用于标识数据包所属的流。后面的流量控制和多路复用会涉及到\nOffset：偏移量，表示该数据包在整个数据中的偏移量，用于数据排序。\nData Length： 数据长度，占用 2 个字节，表示实际应用数据的长度\nData： 实际的应用数据\n建立连接先分析下 HTTPS 的握手过程，包含 TCP 握手和 TLS 握手，TCP 握手：\n\n\n从图中可以看出，TCP 握手需要 2 个 RTT。\nTLS 握手：密钥协商（1.3 版本）\n\n\n\n\n从图中可以看出，TLS 握手需要 1 个 RTT，也就是 1 次 RTT 就把通信密钥协商好了，这是怎么做到的？\n（1）客户端：生成随机数 a，选择公开的大数 G 和 P，计算 A&#x3D;a*G%P，将 A 和 G 发送给服务器，也就是 Client Hello 消息\n（2）服务器：生成随机数 b，计算 B&#x3D;b*G%P，将 B 发送给客户端，也就是 Server Hello 消息\n（3）客户端：使用 ECDH 算法生成通信密钥 KEY &#x3D; aB &#x3D; ab*G%P\n（4）服务器：使用 ECDH 算法生成通信密钥 KEY &#x3D; bA &#x3D; ba*G%P\n所以，这里的关键就是 ECDH 算法，a 和 b 是客户端和服务器的私钥，是不公开的，而其他参数是公开的。ECDH 算法有个非常重要的特征：即使知道 A、G、P，通过 A &#x3D; a*G%P 公式也是无法推到出 a 的，保证了私钥的安全性。\n综上所述，HTTPS 建立连接需要 3 个 RTT，由于 QUIC 的握手是基于 TLS1.3 实现的，所以首次建立连接时也是需要 1 次 RTT，那 QUIC 是如何做到 0-RTT 握手的呢？\n如何做到0RTT握手？其实原理很简单：客户端缓存了 ServerConfig（B&#x3D;b*G%P），下次建连直接使用缓存数据计算通信密钥：\n\n\n（1）客户端：生成随机数 c，选择公开的大数 G 和 P，计算 A&#x3D;c*G%P，将 A 和 G 发送给服务器，也就是 Client Hello 消息\n（2）客户端：客户端直接使用缓存的 ServerConfig 计算通信密钥 KEY &#x3D; cB &#x3D; cb*G%P，加密发送应用数据\n（3）服务器：根据 Client Hello 消息计算通信密钥 KEY &#x3D; bA &#x3D; bc*G%P\n也就是说，客户端不需要经过握手就可以发送应用数据，这就是 0-RTT 握手。再来思考一个问题：假设攻击者记录下所有的通信数据和公开参数（A1&#x3D;aG%P，A2&#x3D;cG%P，……），一旦服务器的随机数 b（私钥）泄漏了，那之前通信的所有数据就都可以破解了。\n为了解决这个问题，需要为每次会话都创建一个新的通信密钥，来保证前向安全性\n可靠传输QUIC 是基于 UDP 协议的，而 UDP 是不可靠传输协议，那 QUIC 是如何实现可靠传输的呢？\n可靠传输有 2 个重要特点：\n（1）完整性：发送端发出的数据包，接收端都能收到\n（2）有序性：接收端能按序组装数据包，解码得到有效的数据\n问题 1：发送端怎么知道发出的包是否被接收端收到了？\n解决方案：通过包号（PKN）和确认应答（SACK）\n\n\n（1）客户端：发送 3 个数据包给服务器（PKN &#x3D; 1，2，3）\n（2）服务器：通过 SACK 告知客户端已经收到了 1 和 3，没有收到 2\n（3）客户端：重传第 2 个数据包（PKN&#x3D;4）\n由此可以看出，QUIC 的数据包号是单调递增的。也就是说，之前发送的数据包（PKN&#x3D;2）和重传的数据包（PKN&#x3D;4），虽然数据一样，但包号不同。\n问题 2：既然包号是单调递增的，那接收端怎么保证数据的有序性呢？\n解决方案：通过数据偏移量 offset\n每个数据包都有一个 offset 字段，表示在整个数据中的偏移量。\n\n\n接收端根据 offset 字段就可以对异步到达的数据包进行排序了。为什么 QUIC 要将 PKN 设计为单调递增？解决 TCP 的重传歧义问题：\n由于原始包和重传包的序列号是一样的，客户端不知道服务器返回的 ACK 包到底是原始包的，还是重传包的。但 QUIC 的原始包和重传包的序列号是不同的，也就可以判断 ACK 包的归属。\n流量控制和 TCP 一样，QUIC 也是利用滑动窗口机制实现流量控制：\n\n\n发送端的窗口大小由接收端告知，包括发送窗口和可用窗口，如果发送端收到了接收端的 ACK 确认应答（比如 ACK 36），那整个窗口就会向右滑动，发送新的数据包。\n\n\n和 TCP 不同的是，QUIC 的滑动窗口分为 Connection 和 Stream 两种级别。Connection 流量控制：规定了所有数据流的总窗口大小；Stream 流量控制：规定了每个流的窗口大小。\n假设现在有 3 个 Stream，滑动窗口分别如下：\n\n\n则整个 Connection 的可用窗口大小为：20+30+10 &#x3D; 60\n拥塞控制拥塞控制是通过拥塞窗口限制发送方的数据量，避免整个网络发生拥塞。那拥塞窗口（cwnd）和滑动窗口（发送窗口：swnd，接收窗口：rwnd）有什么关系呢？\nswnd &#x3D; min（cwnd，rwnd）\n也就是说，发送窗口的大小是由接收窗口和拥塞窗口共同决定的。那拥塞窗口的大小是如何计算的？通过 4 个拥塞控制算法：慢启动、拥塞避免、拥塞发生、快速恢复\n1.慢启动初始拥塞窗口大小 cwnd&#x3D;1，也就是可以传输 1 个 MDS（Max Datagram Size）大小的数据包，一般网卡允许传输的最大数据单元 MTU 的大小是 1500 字节。对于 UDP 数据报而言：MDS &#x3D; 1500（MTU）- 20（IP 首部）- 8（UDP 首部） &#x3D; 1472 字节\n慢启动算法： 当发送方每收到一个 ACK，拥塞窗口就加 1（cwnd++）\n\n\n由此可以看出，慢启动阶段，拥塞窗口呈指数增长，那增长到多少是个头？\n有一个上限值：ssthresh（slow start threshold），从源码看，这个值是 2000 * MDS\nconst QuicPacketCount kDefaultMaxCongestionWindowPackets &#x3D; 2000;\n\n\n当 cwnd &lt; ssthresh 时，使用慢启动算法\n当 cwnd &gt;&#x3D; ssthresh 时，使用拥塞避免算法\n\n2.拥塞避免当拥塞窗口大小超过慢启动上限后，就会进入拥塞避免阶段。\n拥塞避免算法： 当发送方每收到一个 ACK，拥塞窗口就加 1&#x2F;cwnd\n\n\n假设现在的 cwnd&#x3D;8，可以发送 8 个数据包，当收到这 8 个包的 ACK 时，拥塞窗口才会加 1，由此可知，在拥塞避免阶段，拥塞窗口是线性增长的。\n那啥时候是个头呢？不管，让它继续增长，直到网络发生拥塞，出现丢包，这时就会触发重传机制，进入拥塞发生阶段\n3.拥塞发生重传有 2 种：超时重传和快速重传\n如果发生超时重传，使用的拥塞发生算法为：\n\nssthresh &#x3D; cwnd &#x2F; 2\ncwnd &#x3D; 1\n\n\n\n重新使用慢启动和拥塞避免算法增加拥塞窗口的大小。\n如果发生快速重传（发送方收到 3 个相同的 ACK），使用的拥塞发生算法为：\n\ncwnd &#x3D; cwnd &#x2F; 2\nssthresh &#x3D; cwnd\n\n接下来就会进入快速恢复阶段。\n4.快速恢复快速恢复算法：cwnd &#x3D; ssthresh + 3（因为收到 3 个 ACK），然后进入拥塞避免阶段。\n\n\n5.拥塞控制常见算法\nNew Reno：基于丢包检测\nCUBIC：基于丢包检测\nBBR：基于网络带宽\n\n和 TCP 不同的是，QUIC 是在用户空间实现的拥塞控制，可以非常灵活的设置，甚至可以为每一个请求都设置一种拥塞控制算法。\n解决队头阻塞多路复用是 HTTP&#x2F;2 的主要特性之一，但 HTTP&#x2F;3 的多路复用不完全和2相同。\n概念：单条 TCP 连接上可以同时发送多个 HTTP 请求，解决了 HTTP1.1 中单个连接 1 次只能发送 1 个请求的性能瓶颈。HTTP&#x2F;2 能实现多路复用的根本原因是采用了二进制帧格式的数据结构。\n\n\nLength：表示 Payload 的长度\nType：表示帧类型\nFlags：帧标识\nStream ID：数据帧所属的流\nPayload：应用数据，长度由 Length 字段指定\n\n一个请求就对应一条流，通过 Stream ID 就可以判断该数据帧属于哪个请求，假设有 A 和 B 两个请求，对应的 Stream ID 分别为 1 和 2，那这个 TCP 连接上传输的数据大概如下：\n\n虽然在 HTTP 应用层，可以同时发送多个请求，但是在 TCP 传输层，仍然只有 1 个滑动窗口来发送这些数据包，考虑下面的情形：\n\n\n客户端发送的 5 个数据包（56789）服务器都收到了，并且回应了 5 个 ACK，但是第 5 个数据包的 ACK 丢失了，导致客户端的发送窗口无法向前移动，也就无法发送新的数据，这就是 TCP 层的队头阻塞问题。\nHTTP&#x2F;2 虽然通过多路复用解决了 HTTP 层的队头阻塞，但仍然存在 TCP 层的队头阻塞。那 QUIC 是如何解决 TCP 层的队头阻塞问题的呢？其实很简单，HTTP&#x2F;2 之所以存在 TCP 层的队头阻塞，是因为所有请求流都共享一个滑动窗口，那如果给每个请求流都分配一个独立的滑动窗口，是不是就可以解决这个问题了？\nQUIC 就是这么做的：\n\nA 请求流上的丢包不会影响 B 请求流上的数据发送。但是，对于每个请求流而言，也是存在队头阻塞问题的，也就是说，虽然 QUIC 解决了 TCP 层的队头阻塞，但仍然存在单条流上的队头阻塞。这就是 QUIC 声明的无队头阻塞的多路复用。\n连接迁移连接迁移：当客户端切换网络时，和服务器的连接并不会断开，仍然可以正常通信，对于 TCP 协议而言，这是不可能做到的。因为 TCP 的连接基于 4 元组：源 IP、源端口、目的 IP、目的端口，只要其中 1 个发生变化，就需要重新建立连接。但 QUIC 的连接是基于 64 位的 Connection ID，网络切换并不会影响 Connection ID 的变化，连接在逻辑上仍然是通的。\n\n假设客户端先使用 IP1 发送了 1 和 2 数据包，之后切换网络，IP 变更为 IP2，发送了 3 和 4 数据包，服务器根据数据包头部的 Connection ID 字段可以判断这 4 个包是来自于同一个客户端。QUIC 能实现连接迁移的根本原因是底层使用 UDP 协议就是面向无连接的。\n\n\n\n\n\n\n\n\n\n参考链接\n为什么需要QUIC | HTTP&#x2F;3详解 (hungryturbo.com)\nQUIC 协议详解 - 知乎 (zhihu.com)\nhttp2是如何解决tcp的队首阻塞的？ - 知乎 (zhihu.com)\n一文读懂 HTTP&#x2F;2 特性 - 知乎 (zhihu.com)\n深入解读HTTP3的原理及应用 - 知乎 (zhihu.com)\n详解HTTP&#x2F;1.0、HTTP&#x2F;1.1、HTTP&#x2F;2、HTTPS - 腾讯云开发者社区-腾讯云 (tencent.com)\n深入理解http2.0协议，看这篇就够了！ - 知乎 (zhihu.com)\n\n","slug":"浅析HTTP发展历程","date":"2022-09-27T14:15:15.000Z","categories_index":"","tags_index":"","author_index":"JuneQQQ"},{"id":"34c2acd56bc16b503002a852a65f4137","title":"Java 集合","content":"Java 集合Collection 接口 （父接口）\n\n\n\nIterator 迭代器所有实现了Iteratable接口的类都可以通过iterator()方法获取迭代器\n注意：重新获取iterator即可重置迭代器；\n增强 for 循环\n可以对 数组 和 集合 使用；\n底层使用的仍然是 iterator；\n大写 I 可以快速生成代码（Idea）。\n\nList 接口  可重复-有顺序ArrayList\n线程不安全\n\nArrayList 维护了一个 Object 类型的数组 elementData – transient Object[] elementData &#x2F;&#x2F; transient 表示该属性不会被序列化\n\n两种构造方式（构造时数组已经初始化）：\n\n无参构造： ArrayList，则初始化 elementData 容量为0，第一次添加时，则扩容至默认容量10，如需再次扩容，则扩容为当前的1.5倍（1+1&#x2F;2）;Vector（无参情况下） 扩容倍数是2，线程安全是因为每个方法头上添加了 synchronized\n指定initialCapacity大小的构造器：初始 elementData 容量为指定大小，如需扩容，则直接扩容 elementData 为当前的1.5倍\n\n\n每次添加元素时，都会触发一次扩容检查，容量不满足 size+1 就扩容\n\n源码解读如下\n\n\n\n\nVector\n线程安全\n如果无参，默认10，满后，2倍扩容；如果指定大小，满后则每次直接2倍扩容（优先使用自定义增量capacityIncrement）\n有参构造可以指定扩容大小 Vector(int initialCapacity, int capacityIncrement)\n源码解读如下\n\n====================================================\npublic synchronized boolean add(E e) &#123;\n    modCount++;\n    ensureCapacityHelper(elementCount + 1);   // 扩容检查\n    elementData[elementCount++] = e;\n    return true;\n&#125;\n====================================================\nprivate void ensureCapacityHelper(int minCapacity) &#123;\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        grow(minCapacity);    // 真正扩容方法\n&#125;\n====================================================\nprivate void grow(int minCapacity) &#123;\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    //扩容的关键算法\n    int newCapacity = oldCapacity + ((capacityIncrement > 0) ?\n                                     capacityIncrement : oldCapacity);\n    if (newCapacity - minCapacity &lt; 0)    // 扩容后仍不满足最小capacity要求\n        newCapacity = minCapacity;\n    if (newCapacity - MAX_ARRAY_SIZE > 0)    // 超过最大容量\n        newCapacity = hugeCapacity(minCapacity);\n    elementData = Arrays.copyOf(elementData, newCapacity);\n&#125;\n====================================================\n\n\n\nLinkedList\n\n底层维护了一个双向链表\n可以添加任意元素\n其中有两个属性first和last分别指向首节点和尾结点\n每个节点（Node对象），里面又维护了prev，next，item三个属性，其中通过prev指向前一个，通过next指向后一个节点，最终实现双向链表\nLinkedList 增删快，查找慢\n源码解读如下（尾插头删）\n\n-----------------------------\npublic boolean add(E e) &#123;\n        linkLast(e);\n        return true;\n    &#125;\n-----------------------------\nvoid linkLast(E e) &#123;\n        final Node&lt;E> l = last;  // 旧尾结点\n        final Node&lt;E> newNode = new Node&lt;>(l, e, null);  // 创建新节点\n        last = newNode;     // 新节点上位尾结点\n        if (l == null)\n            first = newNode; // 第一个节点 first->a  last->a\n        else\n            l.next = newNode;  // 新节点是从尾部连接的！新节点赋值->旧尾结点.next \n        size++;\n        modCount++;\n    &#125;\n-----------------------------\npublic E remove() &#123;\n        return removeFirst();  //注意是第一个\n    &#125;\npublic E removeFirst() &#123;\n        final Node&lt;E> f = first;\n        if (f == null)\n            throw new NoSuchElementException();\n        return unlinkFirst(f);\n    &#125;\n-----------------------------\nprivate E unlinkFirst(Node&lt;E> f) &#123;\n        // assert f == first &amp;&amp; f != null;\n        final E element = f.item;\n        final Node&lt;E> next = f.next;\n        f.item = null;\n        f.next = null; // help GC\n        first = next;\n        if (next == null)\n            last = null;   // 只有一个节点\n        else\n            next.prev = null;  \n        size--;\n        modCount++;\n        return element;   // 返回删除的元素\n    &#125;\n-----------------------------\n\n\n\n集合选择\nArrayList 查询快，增删慢\nLinkedList查询慢，增删快\n一般来说，程序中 80~90的业务都是查询，因此大部分情况下选择ArrayList\n也可以根据业务需要灵活选择\n\nSet 接口\nTreeSet有序，HashSet无序\n不允许重复，最多包含一个null\n\nHashSet\n\n\n\n\n\n\n\n\n如何决定元素是相同的？\n\nhashCode() 决定节点添加到数组下标的位置；\n真正地逻辑是：**(table.length -1) &amp; hash(hashCode())**\n\n\n当 hashCode() 方法算出的元素落到了某个链表上，从头到尾依次比较，有相同元素，添加失败，无相同元素，添加到链表尾部；\n可以存放null，但只能有一个（null的哈希值为0）\n\n\n\n\n\n\n\n\n\n\n\n\n源码分析\n\n底层实际上是HashMap\n底层调用的是Hashmap的API，value是占位符PRESENT – new Object()\n元素顺序取决于hash函数的结果，是一个固定的顺序\n无参构造器：default-capacity(16)  loadFactor(0.75) \n单链表长度达到9个（在添加第9个元素后立刻检查，这是由于binCount是之前的容量！）时才进入 treeifbin()方法\ntab == null || (n = tab.length) &lt; 64\n64指的是HashSet中所有的元素（包括链表上的）\n\n\nresize 扩容发生在以下三个时机：\n初始化一个HashSet，第一次添加元素时，table为null，此时扩容为长度为16的数组(无参构造，有参则初始化为指定的大小向上取2^n值)\n当前HashMap.size&gt;threshold时，成功添加第(threshold+1)个元素时，触发扩容方法\n链表的节点数大于8，若table.length&lt;64，触发扩容方法；若table.length&gt;&#x3D;64，触发树化\n\n\n不错的帖子\n从泊松分布谈起HashMap为什么默认扩容因子是0.75 - 知乎 (zhihu.com)\n2022面试题：HashMap相关问题硬核梳理_小牛呼噜噜的博客-CSDN博客\n\n\n\n// 调用链 add->put->putVal(hash->hashCode)\n---------------------------------\npublic boolean add(E e) &#123;\n    \t//PRESENT相当于一个占位符，Object[]\n        return map.put(e, PRESENT)==null;\n    &#125;\n---------------------------------\npublic V put(K key, V value) &#123;\n        return putVal(hash(key), key, value, false, true);\n    &#125;\n---------------------------------\nstatic final int hash(Object key) &#123;\n        int h;\n    \t// 由此可见，真正的哈希值是hashCode方法进一步包装的值\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n    &#125;\n---------------------------------\n/**------------------------核心算法------------------------**/\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) &#123;\n        Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i;\n    \t  // 初始化 table 数组\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length;\n    \t  // tab[i]初始化\n        if ((p = tab[i = (n - 1) &amp; hash]) == null)\n            tab[i] = newNode(hash, key, value, null);\n        else &#123;\n          \t// tab[i]已经有节点了\n            Node&lt;K,V> e; K k;\n            // p 是 table[i] 的第一个元素（可能是Node或TreeNode，TreeNode是HashMap的静态内部类，已树化的节点）\n            // 以下代码判断是否是同一个对象\n            // CASE1:Node 第一个节点的hash、equals||地址 与加入节点相同\n            if (p.hash == hash &amp;&amp;\n                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))\n                e = p;\n            else if (p instanceof TreeNode)\n                // CASE2:p 是一颗红黑树\n                e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else &#123;\n                // CASE3:Node 有多个节点，第一个节点不能匹配，遍历链表\n                for (int binCount = 0; ; ++binCount) &#123;\n                    // 注意此处 p.next 赋给 e\n                    if ((e = p.next) == null) &#123;\n                        p.next = newNode(hash, key, value, null);\n                        // 本次添加过后链表元素达到了9个才进行扩容，因为binCount是之前的容量\n                        if (binCount >= TREEIFY_THRESHOLD - 1) \n                            //是否要进行红黑树化判断，以下是条件，不满足执行 resize() 方法\n                            // treeifyBin方法中还有判断：tab == null || (n = tab.length) &lt; 64  \n                            // 满足才能真正树化\n                            treeifyBin(tab, hash);\n                        break;\n                    &#125;\n                    // e = p.next\n                    if (e.hash == hash &amp;&amp;\n                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))\n                        break;\n                    // p 向下指一个节点\n                    p = e;\n                &#125;\n            &#125;\n            \n            // value 替换细节\n            if (e != null) &#123;\n                //此处把k-v的v替换，value是传参进来的v\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            &#125;\n        &#125;\n        ++modCount;\n        // 添加后检查，第十三个元素添加后进入if执行扩容\n        if (++size > threshold)\n            resize();\n    \t  // 为 HashMap 子类准备的方法（如LinkedList），在本类中为空实现\n        afterNodeInsertion(evict);\n        return null;\n    &#125;\n\n/**-------------------数组扩容---------------------**/\nfinal Node&lt;K,V>[] resize() &#123;\n    Node&lt;K,V>[] oldTab = table;\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) &#123;\n        // 超过最大值就不再扩充了，就只好随你碰撞去吧\n        if (oldCap >= MAXIMUM_CAPACITY) &#123;\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        &#125;\n        // 没超过最大值，就扩充为原来的2倍\n        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;\n                 oldCap >= DEFAULT_INITIAL_CAPACITY)\n            newThr = oldThr &lt;&lt; 1; // double threshold\n    &#125;\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        newCap = oldThr;\n    else &#123;               // zero initial threshold signifies using defaults\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    &#125;\n    // 计算新的resize上限\n    if (newThr == 0) &#123;\n\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?\n                  (int)ft : Integer.MAX_VALUE);\n    &#125;\n    threshold = newThr;\n    @SuppressWarnings(&#123;\"rawtypes\"，\"unchecked\"&#125;)\n        Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap];\n    table = newTab;\n    if (oldTab != null) &#123;\n        // 把每个bucket都移动到新的buckets中\n        for (int j = 0; j &lt; oldCap; ++j) &#123;\n            Node&lt;K,V> e;\n            if ((e = oldTab[j]) != null) &#123;\n                oldTab[j] = null;\n                if (e.next == null)\n                    newTab[e.hash &amp; (newCap - 1)] = e;\n                else if (e instanceof TreeNode)\n                    ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap);\n                else &#123; // 链表优化重hash的代码块\n                    Node&lt;K,V> loHead = null, loTail = null; // 原索引存放的引用\n                    Node&lt;K,V> hiHead = null, hiTail = null; // 原索引+oldCap存放的引用\n                    Node&lt;K,V> next;\n                    do &#123;\n                        next = e.next;\n                       /*\n                       \t取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&amp;)操作\n                     \t （也就是说 hash%length==hash&amp;(length-1)的前提是 length 是2的 n 次方；）。\n                      */\n                        // 原索引\n                        if ((e.hash &amp; oldCap) == 0) &#123;\n                            if (loTail == null)\n                                loHead = e;\n                            else\n                                loTail.next = e; // 尾插\n                            loTail = e; // 尾插\n                        &#125; else &#123; // 原索引+oldCap\n                            if (hiTail == null)\n                                hiHead = e;\n                            else\n                                hiTail.next = e;\n                            hiTail = e;\n                        &#125;\n                    &#125; while ((e = next) != null);\n                    // 原索引放到bucket里\n                    if (loTail != null) &#123;\n                        loTail.next = null;\n                        newTab[j] = loHead;\n                    &#125;\n                    // 原索引+oldCap放到bucket里\n                    if (hiTail != null) &#123;\n                        hiTail.next = null;\n                        newTab[j + oldCap] = hiHead;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n    return newTab;\n&#125;\n\n\n\n\n\nLinkedHashSet\n\n\n\n\n\n\n\n\n继承HashSet，实现Set\n\nHashMap维护对象是 Node ，LinkedHashSet维护对象是 Entry extends HashMap.Node\n底层维护了一个哈希表和双向链表\n每一个节点有pre和next属性，这样可以形成双向链表\n在添加一个元素时，先求hash值，再求索引，确定该元素在hashtable中的位置，然后将添加的元素加入到双向链表中（如果已经存在，则不添加，原则上通hashset一致）\n这样LinkedHashSet能确保插入顺序和遍历顺序一致\n源码解读\n\n/*LinkedHashSet内部类 Entry ，将来会取代Node成为LinkedHashSet的table的节点元素*/\nstatic class Entry&lt;K,V> extends HashMap.Node&lt;K,V> &#123;\n        Entry&lt;K,V> before, after;\n        Entry(int hash, K key, V value, Node&lt;K,V> next) &#123;\n            super(hash, key, value, next);\n        &#125;\n    &#125;\n\n\n\n\n\n\n\nTreeSet\n使用无参构造器时，元素仍是无序的\nTreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树\n源码解析如下\n\npublic V put(K key, V value) &#123;\n        Entry&lt;K,V> t = root;\n    \t// 第一次添加元素，注意节点对象是 Entry\n        if (t == null) &#123;\n            compare(key, key); // 此处的compare是为了检查 key 是否为空值\n            \n            root = new Entry&lt;>(key, value, null);\n            size = 1;\n            modCount++;\n            return null;\n        &#125;\n        int cmp;\n        Entry&lt;K,V> parent;\n        // split comparator and comparable paths\n        Comparator&lt;? super K> cpr = comparator;\n        if (cpr != null) &#123;\n            do &#123;\n                // 遍历所有的 key，给key找适当的位置\n                parent = t;\n                cmp = cpr.compare(key, t.key);  //绑定到定义的 compare 方法\n                if (cmp &lt; 0)\n                    t = t.left;\n                else if (cmp > 0)\n                    t = t.right;\n                else // 发现相等的 key ，用 value 的值覆盖这个 key 的 value，且方法退出\n                    return t.setValue(value);\n            &#125; while (t != null);\n        &#125;\n        else &#123;\n            if (key == null)\n                throw new NullPointerException();\n            @SuppressWarnings(\"unchecked\")\n                Comparable&lt;? super K> k = (Comparable&lt;? super K>) key;\n            do &#123;\n                parent = t;\n                cmp = k.compareTo(t.key);\n                if (cmp &lt; 0)\n                    t = t.left;\n                else if (cmp > 0)\n                    t = t.right;\n                else\n                    return t.setValue(value);\n            &#125; while (t != null);\n        &#125;\n        Entry&lt;K,V> e = new Entry&lt;>(key, value, parent);\n        if (cmp &lt; 0)\n            parent.left = e;\n        else\n            parent.right = e;\n        fixAfterInsertion(e);\n        size++;\n        modCount++;\n        return null;\n    &#125;\n\n\n\n\n\nMap 接口\nTreeMap有序，HashMap无序\nkey 不允许重复(null也不能重复），value可以重复\nk-v 最后是 HashMap$Node node &#x3D; newNode(hash , key , value , null)\nk-v 是为了方便程序员进行遍历设计的，会创建 EntrySet 集合，该集合存放的元素类型 Entry ，而一个 Entry 对象就有 k-v EntrySet&lt;Entry&lt;K,V&gt;&gt; 即： transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;\nentrySet 中，定义的类型是 Map.Entry , 但实际上存放的是 HashMap$Node , 这是因为 HashMap$Node implements Map.Entry static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;\n当把 HashMap$Node 对象存放到 entrySet 就方便我们的遍历，因为 Map.Entry 提供了重要方法 K getKey() – V getValue()\n\nMap 遍历\n增强 FOR\n迭代器 Iterator\nvalues() 方法 ，此方法返回集合 Collection ，可以使用以上两种遍历方式\nentrySet() 方法 ， 此方法返回 Set –&gt; EntrySet&lt;Map.Entry&lt;K,V&gt;&gt;  ， 可以使用 1 ，2 两种方式遍历\n\nHashMap\n\n\n\n\n当添加 key-val 时，通过 key 的哈希值得到在table的索引，然后判断该索引处是否有元素，如果没有元素则直接添加，如果有元素则继续判断该元素的 key 和准备加入的 key 是否相等，如果相等，则直接替换 val；如果不相等则需要判断是树结构还是链表结构，做出相应处理，如果添加时发现容量不够，则需要扩容。\n执行构造 new HashMap() ，初始化加载因子 loadfactor &#x3D; 0.75 &amp; hashMap$Node[] table &#x3D; null\n执行 put 调用 putVal() ，详细细节见 HashSet\n\n\n\n\n\nHashtable\n实现了 Map 集合，即存放 k-v 键值对，key不能重复\nHashtable 的键和值都不能为 null ，否则抛出 NullPointerException\nHashtable 使用方法基本上和 HashMap 一致\nHashtable 线程安全\n默认值 initialCapacity-11 loadFactor-0.75，扩容方式 2*old+1\n源码解析如下\n\n--------------------------------------------\n// 无参构造 默认大小是 11 ，loadFactor仍然是 0.75，所以threshold是 11*0.75=8\npublic Hashtable() &#123;\n        this(11, 0.75f);\n    &#125;\n--------------------------------------------\npublic synchronized V put(K key, V value) &#123;\n        // Make sure the value is not null\n        if (value == null) &#123;\n            throw new NullPointerException();\n        &#125;\n\n        // Makes sure the key is not already in the hashtable.\n        Entry&lt;?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V> entry = (Entry&lt;K,V>)tab[index];\n        for(; entry != null ; entry = entry.next) &#123;\n            if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123;\n                V old = entry.value;\n                entry.value = value;\n                return old;\n            &#125;\n        &#125;\n\n        addEntry(hash, key, value, index);\n        return null;\n    &#125;\n-------------------------------------------------------------\nprivate void addEntry(int hash, K key, V value, int index) &#123;\n        modCount++;\n\n        Entry&lt;?,?> tab[] = table;\n        if (count >= threshold) &#123;\n            // Rehash the table if the threshold is exceeded\n            rehash();\n\n            tab = table;\n            hash = key.hashCode();\n            index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        &#125;\n\n        // Creates the new entry.\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V> e = (Entry&lt;K,V>) tab[index];\n        tab[index] = new Entry&lt;>(hash, key, value, e);\n        count++;\n    &#125;\n-------------------------------------------------------------\nprotected void rehash() &#123;\n        int oldCapacity = table.length;\n        Entry&lt;?,?>[] oldMap = table;\n\n        //扩容机制如下 2*oldCapacity+1\n        int newCapacity = (oldCapacity &lt;&lt; 1) + 1;\n        if (newCapacity - MAX_ARRAY_SIZE > 0) &#123;\n            if (oldCapacity == MAX_ARRAY_SIZE)\n                // Keep running with MAX_ARRAY_SIZE buckets\n                return;\n            newCapacity = MAX_ARRAY_SIZE;\n        &#125;\n    \t//数组扩容\n        Entry&lt;?,?>[] newMap = new Entry&lt;?,?>[newCapacity];\n\n        modCount++;\n        threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1);\n        table = newMap;\n\n        for (int i = oldCapacity ; i-- > 0 ;) &#123;\n            for (Entry&lt;K,V> old = (Entry&lt;K,V>)oldMap[i] ; old != null ; ) &#123;\n                Entry&lt;K,V> e = old;\n                old = old.next;\n\n                int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity;\n                e.next = (Entry&lt;K,V>)newMap[index];\n                newMap[index] = e;\n            &#125;\n        &#125;\n    &#125;\n\n\n\nProperties\n继承自 Hashtable，仍然以 k-v 键值对保存数据\n使用方式与 Hashtable 类似\nProperties可以从 xxx.properties文件中，加载数据到其创建的对象中，并对其修改\n\nTreeMap这个类不依赖hashCode和equals\n\n使用比较器构造器\n\n&#96;&#96;&#96;javapublic TreeSet(Comparator&lt;? super E&gt; comparator) {    this(new TreeMap&lt;&gt;(comparator));}\n2. 第一次添加，把k-v封装到 Entry 对象，放入 root\n\n   - &#96;&#96;&#96;java\n     Entry&lt;K,V&gt; t &#x3D; root;\n     if (t &#x3D;&#x3D; null) &#123;\n         compare(key, key); &#x2F;&#x2F; type (and possibly null) check\n     \n         root &#x3D; new Entry&lt;&gt;(key, value, null);\n         size &#x3D; 1;\n         modCount++;\n         return null;\n     &#125;\n\n\n以后添加\n\n&#96;&#96;&#96;javaint cmp;Entry&lt;K,V&gt; parent;&#x2F;&#x2F; split comparator and comparable pathsComparator&lt;? super K&gt; cpr &#x3D; comparator;if (cpr !&#x3D; null) {do {  &#x2F;&#x2F; 遍历所有key，给key找适当的位置    parent &#x3D; t;    cmp &#x3D; cpr.compare(key, t.key); &#x2F;&#x2F;调用的是传入的比较器    if (cmp &lt; 0)        t &#x3D; t.left;    else if (cmp &gt; 0)        t &#x3D; t.right;    else          &#x2F;&#x2F; 发现已经有重复的key，覆盖value并返回        return t.setValue(value);} while (t !&#x3D; null);}\n\n\n## 集合选择\n\n1. 先判断存储的类型（一组对象或一组键值对）\n2. 一组对象：Collection接口实现类\n   1. 允许重复：List\n      - 增删多：LinkedList（底层维护了一个双向链表）\n      - 改查多：ArrayList（底层维护Object类型可变数组）\n   2. 不允许重复：Set\n      - 无序：HashSet（底层是HashMap，维护了一个哈希表，即数组+链表+红黑树）\n      - 排序：TreeSet\n      - 插入和取出顺序一致：LinkedHashSet（底层维护了数组+双向链表）\n3. 一组键值对：Map\n   - 键无序：HashMap（底层是哈希表）\n   - 键排序：TreeMap\n   - 键插入和取出顺序一致：LinkedHashMap\n   - 文件操作：Properties\n\n\n\n## Collections 工具类\n\n1. 排序相关\n   - reverse()   &#x2F;&#x2F; 反转\n   - shuffle()     &#x2F;&#x2F; 乱序\n   - sort()        &#x2F;&#x2F; 排序 ，可以定义比较器\n   - swap()     &#x2F;&#x2F; 交换\n2. 查找、替换\n   - max()   &#x2F;&#x2F; 可以定义比较器\n   - **frequency()**   &#x2F;&#x2F; 某元素出现频率\n   - copy()     &#x2F;&#x2F; 注意数组越界问题！\n   - replaceAll()  &#x2F;&#x2F; 集合中某元素替换\n\n\n\n&#96;&#96;&#96;java\n\n\n\n\n","slug":"Java集合详解","date":"2022-09-22T01:13:17.000Z","categories_index":"","tags_index":"Java,Python","author_index":"JuneQQQ"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new \"My New Post\"\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-09-20T06:36:56.163Z","categories_index":"","tags_index":"","author_index":"JuneQQQ"}]